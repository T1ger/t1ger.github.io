<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2017-08-21T09:41:07.810Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Go基础02基本数据类型</title>
    <link href="https://t1ger.github.io/2017/08/21/Go%E5%9F%BA%E7%A1%8002%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"/>
    <id>https://t1ger.github.io/2017/08/21/Go基础02基本数据类型/</id>
    <published>2017-08-21T08:58:39.000Z</published>
    <updated>2017-08-21T09:41:07.810Z</updated>
    
    <content type="html"><![CDATA[<p>简单的数据类型以及赋值</p>
<ul>
<li><p>声明变量<br>var a int<br>var a string<br>var a [10]int    //array<br>var a []int      //slice<br>var a struct {<br>  f int<br>}<br>var a *int    //pointer<br>var a map[string]int //map,key is string type<br>var a func(b int) int<br>var (<br>  a int<br>  b string<br>)</p>
</li>
<li><p>基本数据类型<br>先看内置类型<br>int/uint   //int8、 byte、 int16、 int、 uint、 uintptr<br>float      //float32 、 float64<br>string<br>bool<br>rune       //int32别名,表示unicode的字符<br>error<br>复合类型<br>slice, map, chan<br>interface<br>func<br>array<br>以上是最常用的数据类型。此外还有以下类型，有兴趣的可以学习一下<br>complex   //复数类型<br>byte      //uint8别名<br>uintptr   //指针用的类型<br>下面是基本数据类型的赋值<br>var a int =10<br>var a float =1.3<br>var a bool =True<br>var a string =”Hello”<br>一般情况下,值类型默认为0, bool默认为false, string为空串<br>如何判断自己的类型呢? 可以尝试下每个类型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">        &quot;fmt&quot;</div><div class="line">        &quot;reflect&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">        var a float32 = 1.3</div><div class="line">        fmt.Println(&quot;type:&quot;, reflect.TypeOf(a))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>总结<br>变量需要声明才能使用<br>内置类型和复合类型<br>整形, 浮点数, 布尔, 字符串</p>
</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简单的数据类型以及赋值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;声明变量&lt;br&gt;var a int&lt;br&gt;var a string&lt;br&gt;var a [10]int    //array&lt;br&gt;var a []int      //slice&lt;br&gt;var a struct {&lt;b
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Go基础01 Hello World</title>
    <link href="https://t1ger.github.io/2017/08/21/Go%E5%9F%BA%E7%A1%8001-Hello-World/"/>
    <id>https://t1ger.github.io/2017/08/21/Go基础01-Hello-World/</id>
    <published>2017-08-21T08:23:03.000Z</published>
    <updated>2017-08-21T07:59:37.674Z</updated>
    
    <content type="html"><![CDATA[<p>简单的‘Hello World!’</p>
<ul>
<li>go命令行<br>假设你已经安装好了go, 那么在Linux命令行输入:<br>[tiger@bogon go]$ go version<br>go version go1.8.3 linux/amd64</li>
</ul>
<ul>
<li><p>写一段小程序<br>用文本编辑器写一个.go结尾的文件，比如说hello.go<br>在hello.go中写入如下，并保存:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[tiger@bogon go]$ cat hello.go </div><div class="line">package main</div><div class="line"></div><div class="line">import &quot;fmt&quot;</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    fmt.Println(&quot;Hello, world. 你好, 世界! &quot;)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  退出文本编辑器，然后在命令行输入:<br>$go run hello.go<br>来运行hello.go。可以看到go随后输出<br>Hello, world. 你好, 世界!</p>
</li>
<li><p>编译后执行<br>我们还可以将hello.go编译后在运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[tiger@bogon go]# go build hello.go </div><div class="line">[tiger@bogon go]# ls</div><div class="line">hello  hello.go</div><div class="line">[tiger@bogon go]# ./hello </div><div class="line">Hello, world. 你好, 世界!</div></pre></td></tr></table></figure>
</li>
<li><p>总结<br>fmt.Println()<br>直接运行: go run hello.go<br>编译后运行: go build hello.go 之后在运行</p>
</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;简单的‘Hello World!’&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;go命令行&lt;br&gt;假设你已经安装好了go, 那么在Linux命令行输入:&lt;br&gt;[tiger@bogon go]$ go version&lt;br&gt;go version go1.8.3 linux/amd64&lt;/li
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Go快速教程(手册)</title>
    <link href="https://t1ger.github.io/2017/08/21/Go%E5%BF%AB%E9%80%9F%E6%95%99%E7%A8%8B-%E6%89%8B%E5%86%8C/"/>
    <id>https://t1ger.github.io/2017/08/21/Go快速教程-手册/</id>
    <published>2017-08-21T08:17:41.000Z</published>
    <updated>2017-08-21T07:59:15.074Z</updated>
    
    <content type="html"><![CDATA[<p>说明</p>
<ol>
<li>教程将专注于go基础，语法基于go1.8 , 测试环境为Linux</li>
<li>我将专注于go的主干，以便读者能以最快时间对go形成概念</li>
<li>Linux命令行将以 $ 开始，比如 $ls</li>
<li>单行注释会以 // 开始,多行均已以 /* 开头，并以 */ 结尾</li>
</ol>
<p>建议</p>
<ol>
<li>将教程中的命令敲到go中看看效果</li>
<li>你可以在了解之后立即去查看相关更完备的内容 (比如查阅官方文档)</li>
</ol>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;说明&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;教程将专注于go基础，语法基于go1.8 , 测试环境为Linux&lt;/li&gt;
&lt;li&gt;我将专注于go的主干，以便读者能以最快时间对go形成概念&lt;/li&gt;
&lt;li&gt;Linux命令行将以 $ 开始，比如 $ls&lt;/li&gt;
&lt;li&gt;单行注释会以 /
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to use docker in windows</title>
    <link href="https://t1ger.github.io/2017/08/16/how-to-use-docker-in-windows/"/>
    <id>https://t1ger.github.io/2017/08/16/how-to-use-docker-in-windows/</id>
    <published>2017-08-16T03:06:29.000Z</published>
    <updated>2017-08-16T05:20:04.127Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>本文运行环境针对Windows 10操作系统,主要解决的痛点是各种平台开发环境的不统一以及多版本共存的问题.主要讲解如何安装docker和使用内网registry</p>
<p>在windows环境下,如何安装docker呢? Docker Toolbox 是一个不错的选择,你可以在Mac或者Windows上像安装其它应用一样来安装它.<br>下载点击<a href="https://www.docker.com/products/docker-toolbox" target="_blank" rel="external">这里</a></p>
<h5 id="Docker-Toolbox-安装"><a href="#Docker-Toolbox-安装" class="headerlink" title="Docker Toolbox 安装"></a><b>Docker Toolbox 安装</b></h5><p>默认安装完成后,安装目录结构如下<br> boot2docker.iso<br> docker-compose.exe<br> docker-machine.exe<br> docker-quickstart-terminal.ico<br> docker.exe<br> installers<br> kitematic<br> start.sh<br> unins000.dat<br> unins000.exe</p>
<p>未避免因为墙无法下载问题,我们手动将boot2docker.iso文件拷贝到C:\Users\用户名.docker\machine\cache目录下</p>
<p>现在有两种启动方式,一个是图形启动,一个是命令行方式启动.<br>图形启动的就双击Kitematic<br>命令行启动就双击docker-quickstart-terminal</p>
<p>备注:非administrator用户,请右键-以管理员身份运行,运行如下</p>
<p>命令行启动如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">Running pre-create checks...</div><div class="line">Creating machine...</div><div class="line">(default) Copying C:\Users\abc\.docker\machine\cache\boot2docker.iso to C:\Users\abc\.docker\machine\machines\default\boot2docker.iso...</div><div class="line">(default) Creating VirtualBox VM...</div><div class="line">(default) Creating SSH key...</div><div class="line">(default) Starting the VM...</div><div class="line">(default) Check network to re-create if needed...</div><div class="line">(default) Windows might ask for the permission to create a network adapter. Sometimes, such confirmation window is minimized in the taskbar.</div><div class="line">(default) Found a new host-only adapter: &quot;VirtualBox Host-Only Ethernet Adapter #2&quot;</div><div class="line">(default) Windows might ask for the permission to configure a network adapter. Sometimes, such confirmation window is minimized in the taskbar.</div><div class="line">(default) Windows might ask for the permission to configure a dhcp server. Sometimes, such confirmation window is minimized in the taskbar.</div><div class="line">(default) Waiting for an IP...</div><div class="line">Waiting for machine to be running, this may take a few minutes...</div><div class="line">Detecting operating system of created instance...</div><div class="line">Waiting for SSH to be available...</div><div class="line">Detecting the provisioner...</div><div class="line">Provisioning with boot2docker...</div><div class="line">Copying certs to the local machine directory...</div><div class="line">Copying certs to the remote machine...</div><div class="line">Setting Docker configuration on the remote daemon...</div><div class="line">Checking connection to Docker...</div><div class="line">Docker is up and running!</div><div class="line">To see how to connect your Docker Client to the Docker Engine running on this virtual machine, run: C:\Program Files\Docker Toolbox\docker-machine.exe env default</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">                        ##         .</div><div class="line">                  ## ## ##        ==</div><div class="line">               ## ## ## ## ##    ===</div><div class="line">           /&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\___/ ===</div><div class="line">      ~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~</div><div class="line">           \______ o           __/</div><div class="line">             \    \         __/</div><div class="line">              \____\_______/</div><div class="line"></div><div class="line">docker is configured to use the default machine with IP 192.168.99.100</div><div class="line">For help getting started, check out the docs at https://docs.docker.com</div><div class="line"></div><div class="line">Start interactive shell</div></pre></td></tr></table></figure></p>
<p>到这里我们就安装完了,查看下docker版本信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line">$ docker info</div><div class="line">Containers: 1</div><div class="line"> Running: 1</div><div class="line"> Paused: 0</div><div class="line"> Stopped: 0</div><div class="line">Images: 1</div><div class="line">Server Version: 17.06.0-ce</div><div class="line">Storage Driver: aufs</div><div class="line"> Root Dir: /mnt/sda1/var/lib/docker/aufs</div><div class="line"> Backing Filesystem: extfs</div><div class="line"> Dirs: 16</div><div class="line"> Dirperm1 Supported: true</div><div class="line">Logging Driver: json-file</div><div class="line">Cgroup Driver: cgroupfs</div><div class="line">Plugins:</div><div class="line"> Volume: local</div><div class="line"> Network: bridge host macvlan null overlay</div><div class="line"> Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslog</div><div class="line">Swarm: inactive</div><div class="line">Runtimes: runc</div><div class="line">Default Runtime: runc</div><div class="line">Init Binary: docker-init</div><div class="line">containerd version: cfb82a876ecc11b5ca0977d1733adbe58599088a</div><div class="line">runc version: 2d41c047c83e09a6d61d464906feb2a2f3c52aa4</div><div class="line">init version: 949e6fa</div><div class="line">Security Options:</div><div class="line"> seccomp</div><div class="line">  Profile: default</div><div class="line">Kernel Version: 4.4.74-boot2docker</div><div class="line">Operating System: Boot2Docker 17.06.0-ce (TCL 7.2); HEAD : 0672754 - Thu Jun 29 00:06:31 UTC 2017</div><div class="line">OSType: linux</div><div class="line">Architecture: x86_64</div><div class="line">CPUs: 1</div><div class="line">Total Memory: 995.8MiB</div><div class="line">Name: default</div><div class="line">ID: G6PB:FV47:YOTF:CIHJ:GNUB:DTML:7GQ2:6GOO:5WIK:EB3J:J4WR:2DVZ</div><div class="line">Docker Root Dir: /mnt/sda1/var/lib/docker</div><div class="line">Debug Mode (client): false</div><div class="line">Debug Mode (server): true</div><div class="line"> File Descriptors: 41</div><div class="line"> Goroutines: 50</div><div class="line"> System Time: 2017-08-14T08:10:46.381858948Z</div><div class="line"> EventsListeners: 1</div><div class="line">Registry: https://index.docker.io/v1/</div><div class="line">Labels:</div><div class="line"> provider=virtualbox</div><div class="line">Experimental: false</div><div class="line">Insecure Registries:</div><div class="line"> 127.0.0.0/8</div><div class="line">Live Restore Enabled: false</div></pre></td></tr></table></figure></p>
<p>图形启动的话,会让我们登录到 Docker Hub。如果我们还没有账户或者还不想登录，可以点击 SKIP FOR NOW 继续后面的步骤.<br>完成之后，就会出现 Kitematic 应用程序的第一个界面.<br>在这里,我们会看到hello-world-nginx,如果找不到,可以在搜索区域搜索hello world nginx,我们点击 Create 来部署容器,在镜像下载完成之后,它会自动部署.我们可以在 Kitematic界面上预览web页面</p>
<h5 id="主机与docker主机共享文件夹"><a href="#主机与docker主机共享文件夹" class="headerlink" title="主机与docker主机共享文件夹"></a><b>主机与docker主机共享文件夹</b></h5><p>假设我们需要共享的work文件夹,我们需要打开Oracle VM VirtualBox，选中“正在运行”状态的 default 虚拟机，进入 设置-&gt; 共享文件夹，添加共享文件夹，选中work文件夹，勾选“自动挂载”、“固定分配”，确定.<br>重启完成后,通过终端连接docker主机,输入<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">$ docker-machine.exe ssh default</div><div class="line">                        ##         .</div><div class="line">                  ## ## ##        ==</div><div class="line">               ## ## ## ## ##    ===</div><div class="line">           /&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\___/ ===</div><div class="line">      ~~~ &#123;~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~</div><div class="line">           \______ o           __/</div><div class="line">             \    \         __/</div><div class="line">              \____\_______/</div><div class="line"> _                 _   ____     _            _</div><div class="line">| |__   ___   ___ | |_|___ \ __| | ___   ___| | _____ _ __</div><div class="line">| &apos;_ \ / _ \ / _ \| __| __) / _` |/ _ \ / __| |/ / _ \ &apos;__|</div><div class="line">| |_) | (_) | (_) | |_ / __/ (_| | (_) | (__|   &lt;  __/ |</div><div class="line">|_.__/ \___/ \___/ \__|_____\__,_|\___/ \___|_|\_\___|_|</div><div class="line">Boot2Docker version 17.06.0-ce, build HEAD : 0672754 - Thu Jun 29 00:06:31 UTC 2017</div><div class="line">Docker version 17.06.0-ce, build 02c1d87</div><div class="line">docker@default:~$ mount</div><div class="line">tmpfs on / type tmpfs (rw,relatime,size=917692k)</div><div class="line">proc on /proc type proc (rw,relatime)</div><div class="line">sysfs on /sys type sysfs (rw,relatime)</div><div class="line">devpts on /dev/pts type devpts (rw,relatime,mode=600,ptmxmode=000)</div><div class="line">tmpfs on /dev/shm type tmpfs (rw,relatime)</div><div class="line">fusectl on /sys/fs/fuse/connections type fusectl (rw,relatime)</div><div class="line">/dev/sda1 on /mnt/sda1 type ext4 (rw,relatime,data=ordered)</div><div class="line">cgroup on /sys/fs/cgroup type tmpfs (rw,relatime,mode=755)</div><div class="line">cgroup on /sys/fs/cgroup/cpuset type cgroup (rw,relatime,cpuset)</div><div class="line">cgroup on /sys/fs/cgroup/cpu type cgroup (rw,relatime,cpu)</div><div class="line">cgroup on /sys/fs/cgroup/cpuacct type cgroup (rw,relatime,cpuacct)</div><div class="line">cgroup on /sys/fs/cgroup/blkio type cgroup (rw,relatime,blkio)</div><div class="line">cgroup on /sys/fs/cgroup/memory type cgroup (rw,relatime,memory)</div><div class="line">cgroup on /sys/fs/cgroup/devices type cgroup (rw,relatime,devices)</div><div class="line">cgroup on /sys/fs/cgroup/freezer type cgroup (rw,relatime,freezer)</div><div class="line">cgroup on /sys/fs/cgroup/net_cls type cgroup (rw,relatime,net_cls)</div><div class="line">cgroup on /sys/fs/cgroup/perf_event type cgroup (rw,relatime,perf_event)</div><div class="line">cgroup on /sys/fs/cgroup/net_prio type cgroup (rw,relatime,net_prio)</div><div class="line">cgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,relatime,hugetlb)</div><div class="line">cgroup on /sys/fs/cgroup/pids type cgroup (rw,relatime,pids)</div><div class="line">c/Users on /c/Users type vboxsf (rw,nodev,relatime)</div><div class="line">work on /work type vboxsf (rw,nodev,relatime)</div><div class="line">/dev/sda1 on /mnt/sda1/var/lib/docker/aufs type ext4 (rw,relatime,data=ordered)</div></pre></td></tr></table></figure></p>
<p>可以看到配置共享文件夹work成功.</p>
<h5 id="创建容器"><a href="#创建容器" class="headerlink" title="创建容器"></a><b>创建容器<b></b></b></h5><p>在终端下输入以下命令,表示安装最新版本node的linux系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull node</div></pre></td></tr></table></figure></p>
<p>之后就可以通过使用该镜像生成容器了:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">#查看镜像</div><div class="line">docker images</div><div class="line">#生成容器</div><div class="line">docker run -d -p 3000:3000 node</div></pre></td></tr></table></figure></p>
<h5 id="定制开发环境"><a href="#定制开发环境" class="headerlink" title="定制开发环境"></a><b>定制开发环境</b></h5><p>这里有两种方法,一个是编写Dockerfile 发布到版本库,其他人从版本库下载本地编译;另一种是打包代码到镜像,上传到仓库,其他人从仓库下载运行.</p>
<p>假如我们的发布目录结构如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@localhost docker-node]# tree</div><div class="line">.</div><div class="line">├── Dockerfile</div><div class="line">├── index.js</div><div class="line">└── package.json</div></pre></td></tr></table></figure></p>
<p>第一种方法就不多说了,这里我们来看下第二种方法,比如要发布nodejs应用,首先是要编写Dockerfile<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">FROM centos:centos6</div><div class="line">MAINTAINER WeiShao Project &lt;tiger@whistle.com.cn&gt;</div><div class="line">ENV NODEJS_VERSION=v8.3.0</div><div class="line">ENV PATH=/usr/local/node/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/bin</div><div class="line"></div><div class="line">RUN yum -y update; yum clean all</div><div class="line">RUN yum -y install epel-release; yum clean all</div><div class="line">RUN yum -y install make gcc gcc-c++ &amp;&amp; yum -y clean all</div><div class="line">RUN yum -y install xz</div><div class="line"></div><div class="line">RUN mkdir -p /usr/local &amp;&amp; cd /usr/local &amp;&amp; curl -s -L -O http://cdn.npm.taobao.org/dist/node/$&#123;NODEJS_VERSION&#125;/node-$&#123;NODEJS_VERSION&#125;-linux-x64.tar.xz &amp;&amp; tar xf node-$&#123;NODEJS_VERSION&#125;-linux-x64.tar.xz &amp;&amp; mv node-$&#123;NODEJS_VERSION&#125;-linux-x64 node</div><div class="line"></div><div class="line">RUN npm install -g cnpm --registry=https://registry.npm.taobao.org</div><div class="line">RUN cnpm install -g pm2 --registry=https://registry.npm.taobao.org</div><div class="line"></div><div class="line">add . /usr/local/whistle/webapps/src</div><div class="line">RUN cd /usr/local/whistle/webapps/src; npm install</div><div class="line">EXPOSE 3000</div><div class="line"></div><div class="line">CMD [&quot;pm2-docker&quot;, &quot;/usr/local/whistle/webapps/src/index.js&quot;]</div></pre></td></tr></table></figure></p>
<p>我们的index.js和package.json 如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">[root@localhost docker-node]# cat index.js </div><div class="line">var express = require(&apos;express&apos;);</div><div class="line"></div><div class="line">// Constants</div><div class="line">var PORT = 3000;</div><div class="line"></div><div class="line">// App</div><div class="line">var app = express();</div><div class="line">app.get(&apos;/&apos;, function (req, res) &#123;</div><div class="line">  res.send(&apos;Hello World from CentOS6 in Docker\n&apos;);</div><div class="line">&#125;);</div><div class="line"></div><div class="line">app.listen(PORT)</div><div class="line">console.log(&apos;Running on http://localhost:&apos; + PORT);</div><div class="line"></div><div class="line"></div><div class="line">[root@localhost docker-node]# cat package.json </div><div class="line">&#123;</div><div class="line">  &quot;name&quot;: &quot;docker-centos-hello&quot;,</div><div class="line">  &quot;private&quot;: true,</div><div class="line">  &quot;version&quot;: &quot;0.0.1&quot;,</div><div class="line">  &quot;description&quot;: &quot;Node.js Hello World app on CentOS6 using docker, created from the Node.js example on docker.io&quot;,</div><div class="line">  &quot;author&quot;: &quot;Wei Shao &lt;ws@whistle.com.cn&gt;&quot;,</div><div class="line">  &quot;dependencies&quot;: &#123;</div><div class="line">    &quot;express&quot;: &quot;3.x&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>现在我们可以build我们的镜像了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@localhost docker-node]# docker build -t registry.whistle.com.cn/node:8.3.0 .</div></pre></td></tr></table></figure></p>
<p>在等待一会之后就可以看到我们的镜像编译成功了,可以通过docker images查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[root@localhost docker-node]# docker run -d -p 3000:3000 registry.whistle.com.cn/node:8.3.0</div></pre></td></tr></table></figure></p>
<p>现在通过<a href="http://192.168.99.100:3000/" target="_blank" rel="external">http://192.168.99.100:3000/</a> 就可以查看页面了.</p>
<p>如何才能让其他同事用这个镜像呢,这里我们要上传到自己的使用仓库里去<br>因为我们使用的是自签名证书,所以需要设置insecure-registry,执行以下操作<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">docker-machine ssh default</div><div class="line">sudo vi /var/lib/boot2docker/profile</div><div class="line"></div><div class="line">EXTRA_ARGS=&quot;</div><div class="line">--insecure-registry registry.whistle.com.cn</div><div class="line">&quot;</div><div class="line">exit</div><div class="line">docker-machine restart</div><div class="line"></div><div class="line">or</div><div class="line">docker-machine ssh default &quot;sudo sed -i &apos;/EXTRA_ARGS=/a\--insecure-registry registry.whistle.com.cn&apos; /var/lib/boot2docker/profile&quot;</div><div class="line">docker-machine restart</div></pre></td></tr></table></figure></p>
<p>这样,我们就可以pull我们制作的node镜像了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker push registry.whistle.com.cn/node:8.3.0</div></pre></td></tr></table></figure>
<p>可以在浏览器访问 <a href="https://registry.whistle.com.cn/v2/_catalog" target="_blank" rel="external">https://registry.whistle.com.cn/v2/_catalog</a> 查看仓库的镜像列表</p>
<p>其他同事在设置了insecure-registry之后就可以执行以下命令获取相应的镜像了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull registry.whistle.com.cn/node:8.3.0</div></pre></td></tr></table></figure>
<p>FAQ</p>
<ul>
<li>问:运行Kitematic时,卡在waiting for an IP的命令下.<br>答: 检查运行操作系统,win7下运行可能出现此问题,由于没有发布正式版，不推荐win7下使用. win7 下 Docker Quickstart Terminal可以运行正常</li>
<li>问:如何确认当前docker虚拟机状态<br>答: 在命令行里输入 docker-machine ls 查看,如果没有可以通过以下命令建立 docker-machine create –driver=virtualbox default</li>
<li>问: 如何才能自动生成Dockerfile呢<br>答: 可以通过starter来自动生成,还是建议学习下Dockerfile的相关基础知识.自动生成步骤如下<br>wget <a href="https://raw.githubusercontent.com/cloud66/starter/master/install.sh" target="_blank" rel="external">https://raw.githubusercontent.com/cloud66/starter/master/install.sh</a><br>chmod +x install.sh &amp;&amp; ./install.sh<br>cd appdir &amp;&amp; starter -g dockerfile,service<br>进行简单选择后即可在当前目录生成dockerfile文件</li>
<li>问: 如何查看registry 和images version<h1 id="curl-https-registry-whistle-com-cn-v2-catalog"><a href="#curl-https-registry-whistle-com-cn-v2-catalog" class="headerlink" title="curl https://registry.whistle.com.cn/v2/_catalog"></a>curl <a href="https://registry.whistle.com.cn/v2/_catalog" target="_blank" rel="external">https://registry.whistle.com.cn/v2/_catalog</a></h1>{“repositories”:[“hello-world”,”jenkins”,”node”,”svn”]} <h1 id="curl-https-registry-whistle-com-cn-v2-node-tag-list"><a href="#curl-https-registry-whistle-com-cn-v2-node-tag-list" class="headerlink" title="curl https://registry.whistle.com.cn/v2/node/tag/list"></a>curl <a href="https://registry.whistle.com.cn/v2/node/tag/list" target="_blank" rel="external">https://registry.whistle.com.cn/v2/node/tag/list</a></h1>{“name”:”node”,”tags”:[“8.3.0”]}</li>
</ul>
<p>ref<br><a href="http://www.cnblogs.com/studyzy/p/6113221.html" target="_blank" rel="external">在Windows中玩转Docker Toolbox</a><br><a href="https://stackoverflow.com/questions/30654306/allow-insecure-registry-in-host-provisioned-with-docker-machine" target="_blank" rel="external">allow insecure registry in host provisioned with docker-machine</a><br><a href="https://accenture.github.io/adop-docker-compose/docs/tools/docker-registry/" target="_blank" rel="external">Tools - Docker Registry</a><br><a href="http://blog.kazaff.me/2016/06/16/%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E7%A7%81%E6%9C%89docker%E4%BB%93%E5%BA%93/" target="_blank" rel="external">搭建本地私有Docker仓库</a><br><a href="http://www.cnblogs.com/wjoyxt/p/5855405.html" target="_blank" rel="external">Docker私有仓库 Registry中的镜像管理</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;本文运行环境针对Windows 10操作系统,主要解决的痛点是各种平台开发环境的不统一以及多版本共存的问题.主要讲解如何安装docker和使用内网registry&lt;/p&gt;
&lt;p&gt;在windows环境下,如何安装docker呢? Docker Toolbox 是一
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>a simplified command-line interface to VMware vCenter</title>
    <link href="https://t1ger.github.io/2017/08/08/a-simplified-command-line-interface-to-VMware-vCenter/"/>
    <id>https://t1ger.github.io/2017/08/08/a-simplified-command-line-interface-to-VMware-vCenter/</id>
    <published>2017-08-08T07:38:20.000Z</published>
    <updated>2017-08-08T10:03:21.139Z</updated>
    
    <content type="html"><![CDATA[<p>govc allows you to interface with VMware vCenter without the need for the dreaded vClient,Windows machines or to write you own scripts to access the horrible VMware API. This way you can easily automate many tasks on VMware directly from the command line or your bash scripts</p>
<p>by the way ,I don’t like interface with ESX/vCenter,this is so cool tools what I desired</p>
<p>First thing,you can compile it yourself, but there’s  handly binaries already available on the project github page <a href="https://github.com/vmware/govmomi/releases" target="_blank" rel="external">here</a></p>
<p>I downloaded it and created a small wrapper for it:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># curl -LO https://github.com/vmware/govmomi/releases/download/v0.15.0/govc_linux_amd64.gz</div><div class="line"># gunzip govc_linux_amd64.gz</div><div class="line"># cat &gt;govc &lt;&lt;EOF</div><div class="line">#!/bin/bash</div><div class="line"> </div><div class="line">export GOVC_URL=&apos;https://username:password@vsphere-ip-or-hostname/sdk&apos;</div><div class="line">export GOVC_DATACENTER=VSPHERE_DC</div><div class="line">export GOVC_INSECURE=true</div><div class="line"> </div><div class="line">/usr/bin/govc_linux_amd64 \$@</div><div class="line">EOF</div><div class="line"># chmod +x govc*</div><div class="line"># cp -i govc* /usr/bin/</div></pre></td></tr></table></figure></p>
<p>Note that you only need GOVC_INSECURE=true if you are using self-signed certificates and you don’t have CA added to you local trusted certs.</p>
<p>For a start,you can get some basic info about you environment:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@localhost daily]# ./govc about</div><div class="line">Name:         VMware vCenter Server</div><div class="line">Vendor:       VMware, Inc.</div><div class="line">Version:      5.1.0</div><div class="line">Build:        880146</div><div class="line">OS type:      win32-x64</div><div class="line">API type:     VirtualCenter</div><div class="line">API version:  5.1</div><div class="line">Product ID:   vpx</div><div class="line">UUID:         4AC51BFC-DC4E-47D3-A912-B51A1A28BAFA</div><div class="line"></div><div class="line">[root@localhost daily]# ./govc datacenter.info</div><div class="line">Name:                ws_dc01</div><div class="line">  Path:              /ws_dc01</div><div class="line">  Hosts:             5</div><div class="line">  Clusters:          0</div><div class="line">  Virtual Machines:  69</div><div class="line">  Networks:          3</div><div class="line">  Datastores:        10</div><div class="line">Name:                ws_dc02</div><div class="line">  Path:              /ws_dc02</div><div class="line">  Hosts:             5</div><div class="line">  Clusters:          0</div><div class="line">  Virtual Machines:  118</div><div class="line">  Networks:          32</div><div class="line">  Datastores:        5</div></pre></td></tr></table></figure></p>
<p>if you want to get usage about govc,just run govc without any argument. To see what parameters a command supports, run govc command –help </p>
<p>eg,you can easily get some info with one simple command:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line">[root@localhost daily]# ./govc datastore.info </div><div class="line">Name:        datastore21</div><div class="line">  Path:      /ws_dc01/datastore/datastore21</div><div class="line">  Type:      VMFS</div><div class="line">  URL:       ds:///vmfs/volumes/522460d8-f202b496-a69f-90b11c2afe3d/</div><div class="line">  Capacity:  2508.2 GB</div><div class="line">  Free:      470.2 GB</div><div class="line">Name:        datastore20</div><div class="line">  Path:      /ws_dc02/datastore/datastore20</div><div class="line">  Type:      VMFS</div><div class="line">  URL:       ds:///vmfs/volumes/52778cbb-107633af-7209-90b11c2a9f0f/</div><div class="line">  Capacity:  2508.2 GB</div><div class="line">  Free:      176.5 GB</div><div class="line">  </div><div class="line">[root@localhost daily]# ./govc host.info</div><div class="line">/usr/bin/govc_linux_amd64: default host resolves to multiple instances, please specify</div><div class="line">[root@localhost daily]# ./govc host.info -host.ip=192.168.1.20</div><div class="line">Name:              192.168.1.20</div><div class="line">  Path:            /ws_dc01/host/192.168.1.20/192.168.1.20</div><div class="line">  Manufacturer:    Dell Inc.</div><div class="line">  Logical CPUs:    32 CPUs @ 2599MHz</div><div class="line">  Processor type:  Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz</div><div class="line">  CPU usage:       2703 MHz (3.3%)</div><div class="line">  Memory:          130976MB</div><div class="line">  Memory usage:    92697 MB (-1.2%)</div><div class="line">  Boot time:       2017-06-26 11:09:53.406999 +0000 UTC</div><div class="line"></div><div class="line">  </div><div class="line">[root@localhost daily]# ./govc vm.info  -vm.ip=192.168.1.180</div><div class="line">Name:           ws-180</div><div class="line">  Path:         /ws_dc01/vm/ws-180</div><div class="line">  UUID:         4232a9b7-a1de-e45b-453b-beade5b7935a</div><div class="line">  Guest name:   CentOS 4/5/6 (64-bit)</div><div class="line">  Memory:       4096MB</div><div class="line">  CPU:          8 vCPU(s)</div><div class="line">  Power state:  poweredOn</div><div class="line">  Boot time:    2017-06-26 11:34:54.042422 +0000 UTC</div><div class="line">  IP address:   192.168.1.180</div><div class="line">  Host:         192.168.1.20</div></pre></td></tr></table></figure></p>
<p>If you want to look someting , it good way to use ls command<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@localhost daily]# ./govc ls</div><div class="line">/ws_dc01/vm</div><div class="line">/ws_dc01/network</div><div class="line">/ws_dc01/host</div><div class="line">/ws_dc01/datastore</div><div class="line">[root@localhost daily]# ./govc ls /ws_dc01/vm</div><div class="line">/ws_dc01/vm/elk149</div><div class="line">/ws_dc01/vm/elk148</div><div class="line">/ws_dc01/vm/elk147</div><div class="line">...</div><div class="line"></div><div class="line">[root@localhost daily]# ./govc ls /ws_dc01/host</div><div class="line">/ws_dc01/host/192.168.1.20</div><div class="line">/ws_dc01/host/192.168.1.21</div><div class="line">...</div><div class="line"></div><div class="line">[root@localhost daily]# ./govc ls /ws_dc01/datastore</div><div class="line">/ws_dc01/datastore/datastore21</div><div class="line">/ws_dc01/datastore/datastore20</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>govc also allow you to run esxcli on the specified host, for example in one of my many experiments I ran:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@localhost daily]# ./govc host.esxcli  --host.ip=172.16.56.20 vm process list|grep DisplayName | awk &#123;&apos;print $2&apos;&#125; | sort</div><div class="line">debug140</div><div class="line">debug141</div><div class="line">debug142</div><div class="line">elk147</div><div class="line">elk148</div><div class="line">elk149</div><div class="line">...</div></pre></td></tr></table></figure></p>
<p>A very import thing to notice is that every command can be run with the parameters -json=true.This output a machine-parsable format that includes many more details than the normal text output.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line">[root@localhost daily]# ./govc ls -json /ws_dc01/datastore/datastore20|python -m json.tool</div><div class="line">&#123;</div><div class="line">    &quot;DeRef&quot;: false,</div><div class="line">    &quot;Dump&quot;: false,</div><div class="line">    &quot;JSON&quot;: true,</div><div class="line">    &quot;Long&quot;: false,</div><div class="line">    &quot;Out&quot;: &#123;&#125;,</div><div class="line">    &quot;TTY&quot;: false,</div><div class="line">    &quot;ToRef&quot;: false,</div><div class="line">    &quot;Type&quot;: &quot;&quot;,</div><div class="line">    &quot;elements&quot;: [</div><div class="line">        &#123;</div><div class="line">            &quot;Object&quot;: &#123;</div><div class="line">                &quot;AlarmActionsEnabled&quot;: true,</div><div class="line">                &quot;AvailableField&quot;: null,</div><div class="line">                &quot;Browser&quot;: &#123;</div><div class="line">                    &quot;Type&quot;: &quot;HostDatastoreBrowser&quot;,</div><div class="line">                    &quot;Value&quot;: &quot;datastoreBrowser-datastore-514&quot;</div><div class="line">                &#125;,</div><div class="line">                &quot;Capability&quot;: &#123;</div><div class="line">                    &quot;DirectoryHierarchySupported&quot;: true,</div><div class="line">                    &quot;NativeSnapshotSupported&quot;: false,</div><div class="line">                    &quot;PerFileThinProvisioningSupported&quot;: true,</div><div class="line">                    &quot;RawDiskMappingsSupported&quot;: true,</div><div class="line">                    &quot;SeSparseSupported&quot;: null,</div><div class="line">                    &quot;StorageIORMSupported&quot;: true,</div><div class="line">                    &quot;TopLevelDirectoryCreateSupported&quot;: null,</div><div class="line">                    &quot;UpitSupported&quot;: null,</div><div class="line">                    &quot;VmfsSparseSupported&quot;: null,</div><div class="line">                    &quot;VsanSparseSupported&quot;: null</div><div class="line">                &#125;,</div><div class="line">[...]</div></pre></td></tr></table></figure></p>
<p>of course,could be very handy for your scripts!</p>
<p>ref<br><a href="http://www.virtuallyghetto.com/2014/09/govmomi-vsphere-sdk-for-go-govc-cli-kubernetes-on-vsphere-part-1.html" target="_blank" rel="external">govmomi (vSphere SDK for Go), govc CLI &amp; Kubernetes on vSphere</a><br><a href="https://velenux.wordpress.com/2016/09/19/automate-your-vcenter-interactions-from-the-linux-commandline-with-govmomi-and-govc/" target="_blank" rel="external">Automate your vCenter interactions from the Linux commandline with govmomi and govc</a><br><a href="https://dellaert.org/2013/03/04/pysphere-script-to-clone-a-template-into-multiple-vms-with-post-processing/" target="_blank" rel="external">PySphere script to clone a template into multiple VMs with post processing</a><br><a href="https://github.com/tkak/terraform-provider-vsphere" target="_blank" rel="external">terraform-provider-vsphere</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;govc allows you to interface with VMware vCenter without the need for the dreaded vClient,Windows machines or to write you own scripts to
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Prometheus 监控方案</title>
    <link href="https://t1ger.github.io/2017/07/04/Prometheus-%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/"/>
    <id>https://t1ger.github.io/2017/07/04/Prometheus-监控方案/</id>
    <published>2017-07-04T08:01:05.000Z</published>
    <updated>2017-08-09T08:39:23.181Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Prometheus-安装"><a href="#Prometheus-安装" class="headerlink" title="Prometheus 安装"></a><b>Prometheus 安装</b></h5><p>centos6的安装参考<a href="http://deadline.top/2016/11/16/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%B9%8BPrometheus/" target="_blank" rel="external">这里</a>,以下以centos7为例介绍:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">sudo yum install pygpgme yum-utils</div><div class="line">#For centos7</div><div class="line">sudo cat &gt; /etc/yum.repos.d/prometheus-rpm_release.repo &lt;&lt; EOF</div><div class="line">[prometheus]</div><div class="line">name=prometheus</div><div class="line">baseurl=https://packagecloud.io/prometheus-rpm/release/el/7/$basearch</div><div class="line">repo_gpgcheck=1</div><div class="line">enabled=1</div><div class="line">gpgkey=https://packagecloud.io/prometheus-rpm/release/gpgkey</div><div class="line">       https://raw.githubusercontent.com/lest/prometheus-rpm/master/RPM-GPG-KEY-prometheus-rpm</div><div class="line">gpgcheck=1</div><div class="line">sslverify=1</div><div class="line">sslcacert=/etc/pki/tls/certs/ca-bundle.crt</div><div class="line">metadata_expire=300</div><div class="line">EOF</div><div class="line"></div><div class="line">[root@localhost ~]# yum install prometheus -y</div><div class="line">[root@localhost ~]# prometheus -version</div><div class="line">prometheus, version 1.7.1 (branch: master, revision: 3afb3fffa3a29c3de865e1172fb740442e9d0133)</div><div class="line">  build user:       root@0aa1b7fc430d</div><div class="line">  build date:       20170612-11:44:05</div><div class="line">  go version:       go1.8.3</div><div class="line"></div><div class="line">[root@localhost ~]# systemctl start prometheus</div></pre></td></tr></table></figure></p>
<p>可以通过<a href="http://localhost:9090/metrics访问啦" target="_blank" rel="external">http://localhost:9090/metrics访问啦</a></p>
<h5 id="grafana-安装"><a href="#grafana-安装" class="headerlink" title="grafana 安装"></a><b>grafana 安装</b></h5><p>grafana安装方法参考<a href="http://docs.grafana.org/installation/rpm/" target="_blank" rel="external">这里</a>,这里选择yum安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# sudo yum install https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.1-1.x86_64.rpm</div><div class="line">[root@localhost ~]# systemctl start grafana-server.service</div><div class="line">[root@localhost ~]# sudo systemctl enable grafana-server.service</div></pre></td></tr></table></figure></p>
<p>可以通过<a href="http://localhost:3000/metrics访问啦,默认密码admin/admin" target="_blank" rel="external">http://localhost:3000/metrics访问啦,默认密码admin/admin</a><br>如果单独的导入模板,可以忽略以下步骤<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#uncomment config file on /etc/grafana/grafana.ini </div><div class="line">[dashboards.json]</div><div class="line">enabled = true</div><div class="line">path = /var/lib/grafana/dashboards</div><div class="line"></div><div class="line">#install dashboards</div><div class="line">git clone https://github.com/percona/grafana-dashboards.git</div><div class="line">cp -r grafana-dashboards/dashboards /var/lib/grafana/</div><div class="line"></div><div class="line">#Restart Grafana</div><div class="line">systemctl restart grafana-server.service</div></pre></td></tr></table></figure></p>
<p>这里需要注意的是,如果你的grafana数据源名字不是Prometheus,请注意导入数据库模板时重新关联数据源,否则会包模板初始化失败<br>添加数据源和模板参考<a href="https://www.hi-linux.com/posts/25047.html" target="_blank" rel="external">这里</a></p>
<h5 id="Configuring-Prometheus"><a href="#Configuring-Prometheus" class="headerlink" title="Configuring Prometheus"></a><b>Configuring Prometheus</b></h5><ul>
<li><p>linux node监控配置<br>首先,配置好prometheus.repo,如果有防火墙开放9100端口.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">#install node_exporter</div><div class="line">[root@localhost ~]# yum install node_exporter -y</div><div class="line">[root@localhost ~]# systemctl start node_exporter</div><div class="line"></div><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml</div><div class="line"></div><div class="line">  - job_name: &apos;linux&apos;</div><div class="line"></div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;192.168.1.106:9100&apos;]</div><div class="line">        labels:</div><div class="line">          instance: &apos;dev_106&apos;</div></pre></td></tr></table></figure>
</li>
<li><p>mysql node 监控配置,如果有防火墙开放9104端口.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">#install mysqld_exporter</div><div class="line">[root@localhost ~]# yum install mysqld_exporter -y</div><div class="line">[root@localhost ~]# systemctl start mysqld-exporter</div><div class="line"></div><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml</div><div class="line"></div><div class="line">  - job_name: &apos;mysql&apos;</div><div class="line"></div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;192.168.1.106:9104&apos;]</div><div class="line">        labels:</div><div class="line">          instance: &apos;dev_106_db&apos; </div><div class="line"></div><div class="line">#mysqld_exporter需要连接到Mysql，创建用户并赋予所需的权限： </div><div class="line"></div><div class="line">mysql&gt; create user monitor@localhost identified by &apos;monitor&apos; with max_user_connections 3;</div><div class="line">mysql&gt; grant process,replication client,select on *.* to monitor@localhost;</div><div class="line"></div><div class="line">#mysqld_exporter默认会读取~/.my.cnf文件</div><div class="line">#my.cnf file for MySQL exporter should be as follows: </div><div class="line">cat &lt;&lt; EOF &gt; .my.cnf</div><div class="line">[client]</div><div class="line">user=monitor</div><div class="line">password=monitor</div><div class="line">host=192.168.1.106</div><div class="line">EOF</div></pre></td></tr></table></figure>
</li>
<li><p>网络监控,提供 http、dns、tcp、icmp（ping）的监控,如果有防火墙开放9115端口.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># install blackbox_exporter </div><div class="line">[root@localhost ~]# yum install blackbox_exporter -y</div><div class="line">[root@localhost ~]# systemctl start blackbox_exporter</div></pre></td></tr></table></figure>
<p>  1.Ping 应用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml</div><div class="line"></div><div class="line">  - job_name: &apos;ping_all&apos;</div><div class="line">    scrape_interval: 5s</div><div class="line">    metrics_path: /probe</div><div class="line">    params:</div><div class="line">      module: [icmp]  #ping</div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;219.150.32.132&apos;, &apos;219.148.204.66&apos;]</div><div class="line">        labels:</div><div class="line">          group: &apos;一线城市-电信网络监控&apos;</div><div class="line">      - targets: [&apos;218.8.251.163&apos;, &apos;218.107.51.1&apos;]</div><div class="line">        labels:</div><div class="line">          group: &apos;一线城市-联通网络监控&apos;</div><div class="line">    relabel_configs:</div><div class="line">      - source_labels: [__address__]</div><div class="line">        regex: (.*)(:80)?</div><div class="line">        target_label: __param_target</div><div class="line">        replacement: $&#123;1&#125;</div><div class="line">      - source_labels: [__param_target]</div><div class="line">        regex: (.*)</div><div class="line">        target_label: ping</div><div class="line">        replacement: $&#123;1&#125;</div><div class="line">      - source_labels: []</div><div class="line">        regex: .*</div><div class="line">        target_label: __address__</div><div class="line">        replacement: 127.0.0.1:9115  # Blackbox exporter.</div></pre></td></tr></table></figure>
<p>  在 grafana中增加 Data Sources 选 prometheus,然后按照grafana的文档新定制一个面板<br>ROW中指标选probe_duration_seconds{job=”ping_all”}<br>2.检测ssl 证书失效</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml</div><div class="line"></div><div class="line">rule_files:</div><div class="line">  - ssl_expiry.rules</div><div class="line">scrape_configs:</div><div class="line">  - job_name: &apos;blackbox&apos;</div><div class="line">    metrics_path: /probe</div><div class="line">    params:</div><div class="line">      module: [http_2xx]  # Look for a HTTP 200 response.</div><div class="line">    static_configs:</div><div class="line">      - targets:</div><div class="line">        - example.com  # Target to probe</div><div class="line">    relabel_configs:</div><div class="line">      - source_labels: [__address__]</div><div class="line">        regex: (.*?)(:80)?</div><div class="line">        target_label: __param_target</div><div class="line">        replacement: https://$&#123;1&#125;</div><div class="line">      - source_labels: [__param_target]</div><div class="line">        target_label: instance</div><div class="line">      - target_label: __address__</div><div class="line">        replacement: 127.0.0.1:9115  # Blackbox exporter.</div><div class="line"></div><div class="line">cat &lt;&lt; &apos;EOF&apos; &gt; ssl_expiry.rules</div><div class="line">ALERT SSLCertExpiringSoon</div><div class="line"> IF probe_ssl_earliest_cert_expiry&#123;job=&quot;blackbox&quot;&#125; - time() &lt; 86400 * 30</div><div class="line"> FOR 10m</div><div class="line">EOF</div></pre></td></tr></table></figure>
<p>  可以通过 <a href="http://localhost:9090/alerts访问,失效前30天将收到告警" target="_blank" rel="external">http://localhost:9090/alerts访问,失效前30天将收到告警</a>.</p>
</li>
<li><p>snmp_exporter 监控配置,如果有防火墙开放9116端口.<br>安装snmp_exporter,参考<a href="https://github.com/prometheus/snmp_exporter" target="_blank" rel="external">这里</a>,下面为安装脚本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">version=v0.4.0</div><div class="line">file=snmp_exporter-0.4.0.linux-amd64</div><div class="line"> </div><div class="line">wget https://github.com/prometheus/snmp_exporter/releases/download/$version/$file.tar.gz \</div><div class="line">  -O /tmp/$file.tar.gz</div><div class="line">cd /tmp</div><div class="line">tar xvf /tmp/$file.tar.gz</div><div class="line">cp /tmp/$file/snmp_exporter /usr/local/bin/snmp_exporter</div><div class="line"> </div><div class="line">tee /usr/lib/systemd/system/snmp_exporter.service &lt;&lt; EOS</div><div class="line">[Unit]</div><div class="line">Description=SNMP Exporter</div><div class="line">[Service]</div><div class="line">ExecStart=/usr/local/bin/snmp_exporter -config.file /etc/prometheus/snmp.yml</div><div class="line">[Install]</div><div class="line">WantedBy=default.target</div><div class="line">EOS</div><div class="line"> </div><div class="line">systemctl daemon-reload</div><div class="line">systemctl enable snmp_exporter</div><div class="line">systemctl start snmp_exporter </div><div class="line">cd -</div></pre></td></tr></table></figure>
<p>  我们可以通过 <a href="http://localhost:9116来验证是否允许,接下来我们进行prometheus配置" target="_blank" rel="external">http://localhost:9116来验证是否允许,接下来我们进行prometheus配置</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml	</div><div class="line">	scrape_configs:</div><div class="line">  - job_name: &apos;snmp&apos;</div><div class="line">    static_configs:</div><div class="line">      - targets:</div><div class="line">        - 192.168.1.2  # SNMP device.</div><div class="line">    metrics_path: /snmp</div><div class="line">    params:</div><div class="line">      module: [default]</div><div class="line">    relabel_configs:</div><div class="line">      - source_labels: [__address__]</div><div class="line">        target_label: __param_target</div><div class="line">      - source_labels: [__param_target]</div><div class="line">        target_label: instance</div><div class="line">      - target_label: __address__</div><div class="line">        replacement: 127.0.0.1:9116  # SNMP exporter.</div></pre></td></tr></table></figure>
<p>  稍等一会儿,我们就可以通过 <a href="http://localhost:9090/consoles/snmp.html" target="_blank" rel="external">http://localhost:9090/consoles/snmp.html</a> 查看接口统计</p>
</li>
<li><p>redis_exporter 监控配置,如果有防火墙开放9121端口.<br>安装 redis_exporter ,具体参考<a href="https://github.com/oliver006/redis_exporter" target="_blank" rel="external">这里</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ go get</div><div class="line">$ go build</div><div class="line">$ ./redis_exporter &lt;flags&gt;</div><div class="line"></div><div class="line">#prometheus server configure,add to /etc/prometheus/prometheus.yml</div><div class="line">- job_name: redis_exporter</div><div class="line">  static_configs:</div><div class="line">  - targets: [&apos;localhost:9121&apos;]</div></pre></td></tr></table></figure>
<p>  grafana中模板redis模板参考<a href="https://grafana.com/dashboards/763/revisions" target="_blank" rel="external">这里</a></p>
</li>
<li><p>nginx_exporter 监控配置<br>1.通过nginx-vts-exporter 监控,安装参考<a href="https://www.hi-linux.com/posts/27014.html" target="_blank" rel="external">这里</a>,grafana模板参考<a href="https://grafana.com/dashboards/1623" target="_blank" rel="external">这里</a><br>2.通过nginx-lua-prometheus 监控,安装参考<a href="https://github.com/knyar/nginx-lua-prometheus" target="_blank" rel="external">这里</a>,grafana模板参考<a href="https://grafana.com/dashboards/462" target="_blank" rel="external">这里</a><br>3.通过nginx-exporter 监控,安装参考<a href="https://github.com/discordianfish/nginx_exporter" target="_blank" rel="external">这里</a>,未找到相应grafana模板,不推荐<br>4.监控Nginx流量的扩展程序,安装参考<a href="https://github.com/vovolie/lua-nginx-prometheus" target="_blank" rel="external">这里</a><br>5.通过日志监控,参考<a href="https://github.com/martin-helmich/prometheus-nginxlog-exporter" target="_blank" rel="external">这里</a></p>
</li>
<li><p>ceph_exporter 监控配置<br>1.通过ceph_exporter 监控,安装参考<a href="https://github.com/digitalocean/ceph_exporter" target="_blank" rel="external">这里</a>,grafana模板参考<a href="https://grafana.com/dashboards/917" target="_blank" rel="external">这里</a></p>
</li>
<li><p>gluster_exporter 监控配置<br>1.通过gluster_exporter 监控,安装参考<a href="https://github.com/ofesseler/gluster_exporter" target="_blank" rel="external">这里</a></p>
</li>
<li><p>JMX Exporter 监控配置<br>1.通过JMX Exporter 监控,安装参考<a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="external">这里</a></p>
</li>
<li><p>Docker 监控配置</p>
</li>
</ul>
<ol>
<li>通过docker-compose安装, 参考<a href="https://github.com/vegasbrianc/prometheus" target="_blank" rel="external">这里</a></li>
<li>通过cadvisor ,参考<a href="https://www.ctl.io/developers/blog/post/monitoring-docker-services-with-prometheus" target="_blank" rel="external">这里</a></li>
</ol>
<p>ref<br><a href="https://prometheus.io/" target="_blank" rel="external">prometheus</a><br><a href="https://www.iamle.com/archives/2130.html" target="_blank" rel="external">用Prometheus进行网络质量ping监控Grafana进行监控数据展示</a><br><a href="https://www.robustperception.io/get-alerted-before-your-ssl-certificates-expire/" target="_blank" rel="external">Get alerted before your SSL certificates expire</a><br><a href="https://github.com/fstab/prometheus-for-java-developers" target="_blank" rel="external">Prometheus Monitoring for Java Developers</a><br><a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank" rel="external">EXPORTERS AND INTEGRATIONS</a><br><a href="https://www.digitalocean.com/community/tutorials/how-to-add-a-prometheus-dashboard-to-grafana" target="_blank" rel="external">How To Add a Prometheus Dashboard to Grafana</a><br><a href="http://www.cnblogs.com/vovlie/p/Nginx_monitoring.html" target="_blank" rel="external">Prometheus 监控 Nginx 流量</a><br><a href="https://github.com/martin-helmich/prometheus-nginxlog-exporter" target="_blank" rel="external">NGINX Performance Metrics with Prometheus</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Prometheus-安装&quot;&gt;&lt;a href=&quot;#Prometheus-安装&quot; class=&quot;headerlink&quot; title=&quot;Prometheus 安装&quot;&gt;&lt;/a&gt;&lt;b&gt;Prometheus 安装&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;centos6的安装参考&lt;a href
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>增加/删除 OSD</title>
    <link href="https://t1ger.github.io/2017/06/23/%E5%A2%9E%E5%8A%A0-%E5%88%A0%E9%99%A4-OSD/"/>
    <id>https://t1ger.github.io/2017/06/23/增加-删除-OSD/</id>
    <published>2017-06-23T10:51:21.000Z</published>
    <updated>2017-06-30T07:36:24.133Z</updated>
    
    <content type="html"><![CDATA[<h5 id="增加-OSD-手动"><a href="#增加-OSD-手动" class="headerlink" title="增加 OSD(手动)"></a><b>增加 OSD(手动)</b></h5><p>首先修改各个节点的/etc/hosts信息,增加新节点信息,并添加ceph.client.admin.keyring,确保ceph.client.admin.keyring有正确的权限<br>要增加一个 OSD,要依次创建数据目录、把硬盘挂载到数据目录、把 OSD 加入集群、然后把它加入 CRUSH Map<br><b>备注</b>:Ceph 喜欢统一的硬件,与存储池无关。如果你要新增容量不一的硬盘驱动器,还需调整它们的权重。但是,为实现最佳性能，CRUSH 的分级结构最好按类型、容量来组织</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@node4 ~]# parted -s /dev/sdb mklabel gpt</div><div class="line">#删除所有分区</div><div class="line">[root@node4 ~]# sgdisk --zap-all --clear --mbrtogpt /dev/sdb</div><div class="line">GPT data structures destroyed! You may now partition the disk using fdisk or</div><div class="line">other utilities.</div><div class="line">The operation has completed successfully.</div><div class="line">#打印硬盘信息</div><div class="line">[root@node4 ~]# sgdisk -p /dev/sdb   </div><div class="line">[root@node4 ~]# ceph-disk prepare --cluster ceph --fs-type xfs /dev/sdb</div><div class="line">[root@node4 ~]# ceph-disk activate /dev/sdb</div><div class="line">备注:</div><div class="line">ceph-disk prepare --cluster  --cluster-uuid  --fs-type xfs|ext4|btrfs /device </div><div class="line">cluster-uuid ( b71a3eb1-e253-410a-bf11-84ae01bad654 )</div><div class="line">cluster name – default name is ceph unless specified otherwise when ran ceph-deploy</div><div class="line">eg ceph-deploy –cluster=cluster_name</div></pre></td></tr></table></figure>
<p>到这里我们就添加完了osd. 感兴趣的同学可以往下看,这里ceph-disk到底帮我们做了什么操作呢?</p>
<p>1.创建 OSD。如果未指定 UUID,OSD 启动时会自动生成一个。下列命令会输出 OSD 号,后续步骤你会用到<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ceph osd create [&#123;uuid&#125; [&#123;id&#125;]]</div><div class="line"></div><div class="line">[root@node4 ~]# ceph osd create           </div><div class="line">9</div></pre></td></tr></table></figure></p>
<p>如果指定了可选参数 {id} ，那么它将作为 OSD id 。要注意，如果此数字已使用，此命令会出错。<br><b>建议</b>：一般来说,我们不建议指定 {id} 。因为 ID 是按照数组分配的,跳过一些依然会浪费内存；<br>尤其是跳过太多、或者集群很大时，会更明显。若未指定 {id} ,将用最小可用数字。<br>2.在新 OSD 主机上创建数据目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">ssh &#123;new-osd-host&#125;</div><div class="line">sudo mkdir /var/lib/ceph/osd/ceph-&#123;osd-number&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# mkdir /var/lib/ceph/osd/ceph-9</div><div class="line">[root@node4 ~]# chown ceph:ceph -R /var/lib/ceph/osd/ceph-9</div></pre></td></tr></table></figure></p>
<p>3.建立分区,可以参考<a href="http://ceph.com/geen-categorie/creating-a-ceph-osd-from-a-designated-disk-partition/" target="_blank" rel="external">这里</a>,关于sgdisk的用法参考<a href="http://hustcat.github.io/sgdisk-basic" target="_blank" rel="external">这里</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@node4 ~]# sgdisk -n 1:10487808:4194301951 -t 1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -p /dev/sdb</div><div class="line">Disk /dev/sdb: 4194304000 sectors, 2.0 TiB</div><div class="line">Logical sector size: 512 bytes</div><div class="line">Disk identifier (GUID): A996FDA1-5621-45CD-871A-028E30E33027</div><div class="line">Partition table holds up to 128 entries</div><div class="line">First usable sector is 34, last usable sector is 4194303966</div><div class="line">Partitions will be aligned on 2048-sector boundaries</div><div class="line">Total free space is 10489789 sectors (5.0 GiB)</div><div class="line"></div><div class="line">Number  Start (sector)    End (sector)  Size       Code  Name</div><div class="line">   1        10487808      4194301951   1.9 TiB     FFFF  </div><div class="line">The operation has completed successfully.</div><div class="line"></div><div class="line">[root@node4 ~]# sgdisk -n 2:2048:10487807 -t 2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 -p /dev/sdb</div><div class="line">Disk /dev/sdb: 4194304000 sectors, 2.0 TiB</div><div class="line">Logical sector size: 512 bytes</div><div class="line">Disk identifier (GUID): A996FDA1-5621-45CD-871A-028E30E33027</div><div class="line">Partition table holds up to 128 entries</div><div class="line">First usable sector is 34, last usable sector is 4194303966</div><div class="line">Partitions will be aligned on 2048-sector boundaries</div><div class="line">Total free space is 4029 sectors (2.0 MiB)</div><div class="line"></div><div class="line">Number  Start (sector)    End (sector)  Size       Code  Name</div><div class="line">   1        10487808      4194301951   1.9 TiB     FFFF  </div><div class="line">   2            2048        10487807   5.0 GiB     FFFF  </div><div class="line">The operation has completed successfully.</div></pre></td></tr></table></figure></p>
<p>4.给数据盘和日志盘做标记,typecode参考<a href="https://github.com/ceph/ceph/blob/v0.67.4/src/ceph-disk#L65" target="_blank" rel="external">这里</a>,关于磁盘自动挂载的请参考<a href="http://www.zphj1987.com/2016/12/22/Ceph%E6%95%B0%E6%8D%AE%E7%9B%98%E6%80%8E%E6%A0%B7%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%8C%82%E8%BD%BD/" target="_blank" rel="external">这里</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">sgdisk 例子</div><div class="line">#分5120M大小</div><div class="line">/usr/sbin/sgdisk  --new=2:0:5120M --change-name=2:ceph-journal  --partition-guid=2:150f0081-c630-44c9-ad21-7d95613866ea  --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106    --mbrtogpt -- /dev/sdb</div><div class="line">#largest-new 将剩余block全部使用</div><div class="line">/usr/sbin/sgdisk --largest-new=1 --change-name=1:ceph-data --partition-guid=1:db182a1d-f8c6-4660-9c12-0222e2459dd5 --typecode=1:89c57f98-2fe5-4dc0-89c1-f3ad0ceff2be -- /dev/sdb</div><div class="line">#查看udev事件队列，如果所有的events已处理则退出</div><div class="line">/sbin/udevadm settle</div><div class="line"></div><div class="line">[root@node4 ~]# /usr/sbin/sgdisk  --change-name=2:&apos;ceph journal&apos; --typecode=2:45b0969e-9b03-4f30-b4c6-b4b80ceff106  -- /dev/sdb</div><div class="line">The operation has completed successfully.</div><div class="line"></div><div class="line">[root@node4 ~]# /usr/sbin/sgdisk  --change-name=1:&apos;ceph data&apos; --typecode=1:4fbd7e29-9d25-41b8-afd0-062c0ceff05d -- /dev/sdb</div><div class="line">Warning: The kernel is still using the old partition table.</div><div class="line">The new table will be used at the next reboot.</div><div class="line">The operation has completed successfully.</div><div class="line"></div><div class="line">[root@node4 ceph-9]# mkfs.xfs /dev/sdb1</div><div class="line">[root@node4 ceph-9]# mount /dev/sdb1 /var/lib/ceph/osd/ceph-9</div></pre></td></tr></table></figure></p>
<p>5.初始化 OSD 数据目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">ssh &#123;new-osd-host&#125;</div><div class="line">ceph-osd -i &#123;osd-num&#125; --mkfs --mkkey</div><div class="line"></div><div class="line">[root@node4 ~]# ceph-osd -i 9 --mkfs --mkkey </div><div class="line">2017-06-29 16:23:05.161478 7f614226e800 -1 journal FileJournal::_open: disabling aio for non-block journal.  Use journal_force_aio to force use of aio anyway</div><div class="line">2017-06-29 16:23:05.200065 7f614226e800 -1 journal FileJournal::_open: disabling aio for non-block journal.  Use journal_force_aio to force use of aio anyway</div><div class="line">2017-06-29 16:23:05.221105 7f614226e800 -1 filestore(/var/lib/ceph/osd/ceph-9) could not find #-1:7b3f43c4:::osd_superblock:0# in index: (2) No such file or directory</div><div class="line">2017-06-29 16:23:05.237813 7f614226e800 -1 created object store /var/lib/ceph/osd/ceph-9 for osd.9 fsid d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">2017-06-29 16:23:05.237987 7f614226e800 -1 auth: error reading file: /var/lib/ceph/osd/ceph-9/keyring: can&apos;t open /var/lib/ceph/osd/ceph-9/keyring: (2) No such file or directory</div><div class="line">2017-06-29 16:23:05.238397 7f614226e800 -1 created new key in keyring /var/lib/ceph/osd/ceph-9/keyring</div><div class="line"></div><div class="line">[root@node4 ceph-9]# cd /var/lib/ceph/osd/ceph-9</div><div class="line">[root@node4 ceph-9]# rm -f journal</div><div class="line">[root@node4 ceph-9]# ll /dev/disk/by-partuuid/</div><div class="line">total 0</div><div class="line">lrwxrwxrwx 1 root root 10 Jun 30 11:35 c50d9217-c928-49a3-be1b-55990facf2e0 -&gt; ../../sdb2</div><div class="line">lrwxrwxrwx 1 root root 10 Jun 30 11:36 ced5d1bb-568c-4317-954f-efc63fa3bcaa -&gt; ../../sdb1</div><div class="line">[root@node4 ceph-9]# ln -s /dev/disk/by-partuuid/c50d9217-c928-49a3-be1b-55990facf2e0 journal</div><div class="line">[root@node4 ceph-9]# chown ceph:ceph -R /var/lib/ceph/osd/ceph-9</div><div class="line">[root@node4 ceph-9]# chown ceph:ceph /var/lib/ceph/osd/ceph-9/journal</div></pre></td></tr></table></figure></p>
<p>在启动 ceph-osd 前，数据目录必须是空的<br>6.注册 OSD 认证密钥,ceph-{osd-num} 路径里的 ceph 值应该是 $cluster-$id,如果你的集群名字不是 ceph,那就用自己集群的名字<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">ceph auth add osd.&#123;osd-num&#125; osd &apos;allow *&apos; mon &apos;allow rwx&apos; -i /var/lib/ceph/osd/ceph-&#123;osd-num&#125;/keyring</div><div class="line"></div><div class="line">[root@node4 ~]# ceph auth add osd.9 osd &apos;allow *&apos; mon &apos;allow profile osd&apos; -i /var/lib/ceph/osd/ceph-9/keyring</div><div class="line">added key for osd.9</div><div class="line"></div><div class="line">#创建client.bootstrap-osd key文件(本节点新建第一个osd时才需要)</div><div class="line">[root@node4 ~]# ceph auth get-or-create client.bootstrap-osd -o /var/lib/ceph/bootstrap-osd/ceph.keyring</div><div class="line">[root@node4 ~]# chmod 600 /var/lib/ceph/bootstrap-osd/ceph.keyring</div><div class="line">[root@node4 ~]# chown ceph:ceph /var/lib/ceph/bootstrap-osd/ceph.keyring</div></pre></td></tr></table></figure></p>
<p>7.把新 OSD 加入 CRUSH Map 中,以便它可以开始接收数据。用 ceph osd crush add 命令把 OSD 加入 CRUSH 分级结构的合适位置。<br>如果你指定了不止一个 bucket，此命令会把它加入你所指定的 bucket 中最具体的一个，并且把此 bucket 挪到你指定的其它 bucket 之内<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">ceph osd crush add &#123;id-or-name&#125; &#123;weight&#125; [&#123;bucket-type&#125;=&#123;bucket-name&#125; ...]</div><div class="line"></div><div class="line">[root@node4 ~]# ceph osd crush add-bucket node4 host</div><div class="line">added bucket node4 type host to crush map</div><div class="line">[root@node4 ~]# ceph osd crush move node4 root=default</div><div class="line">moved item id -5 name &apos;node4&apos; to location &#123;root=default&#125; in crush map</div><div class="line">[root@node4 ~]# ceph osd crush add osd.9 1.0 host=node4</div><div class="line">add item id 9 name &apos;osd.9&apos; weight 1 at location &#123;host=node4&#125; to crush map</div></pre></td></tr></table></figure></p>
<p>你也可以反编译 CRUSH Map、把 OSD 加入设备列表、以 bucket 的形式加入主机（如果它没在 CRUSH Map 里）、以条目形式把设备加入主机、分配权重、重编译并应用它<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@node4 ~]# ceph osd getcrushmap -o crushmap.txt</div><div class="line">[root@node4 ~]# crushtool -d crushmap.txt -o crushmap-decompile</div><div class="line">[root@node4 ~]# vim crushmap-decompile</div><div class="line">删除掉node4相关的信息</div><div class="line">[root@node4 ~]# crushtool -c crushmap-decompile  -o crushmap-compile</div><div class="line">[root@node4 ~]# ceph osd setcrushmap -i crushmap-compile </div><div class="line">set crush map</div></pre></td></tr></table></figure></p>
<p>8.启动 OSD。把 OSD 加入 Ceph 后， OSD 就在配置里了。然而它还没运行，它现在的状态为 down &amp; out 。你必须先启动 OSD 它才能收数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl start ceph-osd@&#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# systemctl start ceph-osd@9</div></pre></td></tr></table></figure></p>
<p>启动了 OSD ，其状态就变成了 up &amp; in<br>遇到的问题:<br>[root@node4 ~]# systemctl start ceph-osd@9 启动不成功,报错如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">[root@node4 ~]# /usr/bin/ceph-osd -f  --cluster ceph --id 9 --setuser ceph --setgroup ceph</div><div class="line">starting osd.9 at :/0 osd_data /var/lib/ceph/osd/ceph-9 /var/lib/ceph/osd/ceph-9/journal</div><div class="line">2017-06-30 11:49:18.599998 7f3f36afb800 -1 journal FileJournal::open: ondisk fsid 0c8bb770-f16a-4208-91d2-7e659768fbc8 doesn&apos;t match expected 03bba8cd-3765-4364-b727-e4f9269447cc, invalid (someone else&apos;s?) journal</div></pre></td></tr></table></figure></p>
<p>解决方法:Create new journal<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ ceph-osd --mkjournal -i &lt;osd num&gt;</div><div class="line"></div><div class="line">[root@node4 osd]# ceph-osd --mkjournal -i 9</div><div class="line">SG_IO: bad/missing sense data, sb[]:  70 00 05 00 00 00 00 0a 00 00 00 00 20 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</div><div class="line">2017-06-30 11:59:44.328209 7fc180861800 -1 journal check: ondisk fsid 0c8bb770-f16a-4208-91d2-7e659768fbc8 doesn&apos;t match expected 03bba8cd-3765-4364-b727-e4f9269447cc, invalid (someone else&apos;s?) journal</div><div class="line">SG_IO: bad/missing sense data, sb[]:  70 00 05 00 00 00 00 0a 00 00 00 00 20 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</div><div class="line">2017-06-30 11:59:44.338081 7fc180861800 -1 created new journal /var/lib/ceph/osd/ceph-9/journal for object store /var/lib/ceph/osd/ceph-9</div><div class="line"></div><div class="line">#启动成功</div><div class="line">systemctl start ceph-osd@9</div></pre></td></tr></table></figure></p>
<h5 id="增加-OSD-ceph-deploy"><a href="#增加-OSD-ceph-deploy" class="headerlink" title="增加 OSD(ceph-deploy)"></a><b>增加 OSD(ceph-deploy)</b></h5><p>1.登入 ceph-deploy 工具所在的 Ceph admin 节点，进入工作目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ssh &#123;ceph-deploy-node&#125;</div><div class="line">cd /path/ceph-deploy-work-path</div><div class="line"></div><div class="line">[neo@admin ~]$ cd cluster/</div></pre></td></tr></table></figure></p>
<p>2.列举磁盘。<br>执行下列命令列举一节点上的磁盘：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ceph-deploy disk list &#123;node-name [node-name]...&#125;</div><div class="line"></div><div class="line">[neo@admin cluster]$  ceph-deploy disk list node4</div></pre></td></tr></table></figure></p>
<p>3.格式化磁盘。<br>用下列命令格式化（删除分区表）磁盘，以用于 Ceph :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ceph-deploy disk zap &#123;osd-server-name&#125;:&#123;disk-name&#125;</div><div class="line"></div><div class="line">[neo@admin cluster]$  ceph-deploy disk zap node4:sdb</div></pre></td></tr></table></figure></p>
<p><b>重要</b>： 这会删除磁盘上的所有数据<br>4.准备 OSD<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ceph-deploy osd prepare &#123;node-name&#125;:&#123;data-disk&#125;[:&#123;journal-disk&#125;]</div><div class="line"></div><div class="line">[neo@admin cluster]$ ceph-deploy osd prepare node4:sdb</div></pre></td></tr></table></figure></p>
<p>prepare 命令只准备 OSD 。在大多数操作系统中，硬盘分区创建后，不用 activate 命令也会自动执行 activate 阶段（通过 Ceph 的 udev 规则）<br>前例假定一个硬盘只会用于一个 OSD 守护进程，以及一个到 SSD 日志分区的路径。<br>我们建议把日志存储于另外的驱动器以最优化性能；你也可以指定一单独的驱动器用于日志（也许比较昂贵）、或者把日志放到 OSD 数据盘（不建议，因为它有损性能,这里放在一起了）。<br><b>注意</b>： 在一个节点运行多个 OSD 守护进程、且多个 OSD 守护进程共享一个日志分区时，你应该考虑整个节点的最小 CRUSH 故障域，<br>因为如果这个 SSD 坏了，所有用其做日志的 OSD 守护进程也会失效<br>5.准备好 OSD 后，可以用下列命令激活它<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ceph-deploy osd activate &#123;node-name&#125;:&#123;data-disk-partition&#125;[:&#123;journal-disk-partition&#125;]</div><div class="line">[neo@admin cluster]$  ceph-deploy osd activate node4:/dev/sdb1</div></pre></td></tr></table></figure></p>
<p>activate 命令会让 OSD 进入 up 且 in 状态。该命令使用的分区路径是前面 prepare 命令创建的</p>
<h5 id="删除-OSD-手动"><a href="#删除-OSD-手动" class="headerlink" title="删除 OSD(手动)"></a><b>删除 OSD(手动)</b></h5><p>在 Ceph 里，一个 OSD 通常是一台主机上的一个 ceph-osd 守护进程、它运行在一个硬盘之上。<br>如果一台主机上有多个数据盘，你得逐个删除其对应 ceph-osd。<br>通常，操作前应该检查集群容量，看是否快达到上限了，确保删除 OSD 后不会使集群达到 near full 比率<br><b>警告</b>：删除 OSD 时不要让集群达到 full ratio 值，删除 OSD 可能导致集群达到或超过 full ratio 值。</p>
<p>1.调整osd的crush weight<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ssh &#123;osd-host&#125;</div><div class="line">[root@node4 ~]# ceph osd crush reweight osd.10  0.1</div></pre></td></tr></table></figure></p>
<p>备注：可以分几次调整将crush 的weight 减低到0 ，目的就是让数据慢慢的分布到其他节点上，直到完全迁移到其他osd,<br>这个地方不光调整了osd 的crush weight ，实际上同时调整了host 的 weight ，这样会调整集群的整体的crush 分布，在osd 的crush 为0 后， 再对这个osd的任何删除相关操作都不会影响到集群的数据的分布</p>
<p>2.停止需要剔除的 OSD 进程，让其他的 OSD 知道这个 OSD 不提供服务了。停止 OSD 后，状态变为 down<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo systemctl stop  ceph-osd@id=&#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# systemctl stop ceph-osd@10</div></pre></td></tr></table></figure></p>
<p>3.将 OSD 标记为 out 状态，这个一步是告诉 mon，这个 OSD 已经不能服务了，需要在其他的 OSD 上进行数据的均衡和恢复了<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ceph osd out &#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# ceph osd out 10</div><div class="line">marked out osd.10.</div></pre></td></tr></table></figure></p>
<p>执行完这一步后，会触发数据的恢复过程。此时应该等待数据恢复结束，集群恢复到 HEALTH_OK 状态，再进行下一步操作</p>
<p>4.删除 CRUSH Map 中的对应 OSD 条目，它就不再接收数据了。你也可以反编译 CRUSH Map、删除 device 列表条目、删除对应的 host 桶条目或删除 host 桶（如果它在 CRUSH Map 里，而且你想删除主机），重编译 CRUSH Map 并应用它<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ceph osd crush remove &#123;name&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# ceph osd crush remove osd.10</div><div class="line">removed item id 10 name &apos;osd.10&apos; from crush map</div></pre></td></tr></table></figure></p>
<p>该步骤会触发数据的重新分布。等待数据重新分布结束，整个集群会恢复到 HEALTH_OK 状态<br>5.删除 OSD 认证密钥：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ceph auth del osd.&#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# ceph auth del osd.10</div><div class="line">updated</div></pre></td></tr></table></figure></p>
<p>6.删除 OSD<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">ceph osd rm &#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# ceph osd rm 10</div><div class="line">removed osd.10</div></pre></td></tr></table></figure></p>
<p>7.卸载 OSD 的挂载点.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo umount /var/lib/ceph/osd/$cluster-&#123;osd-num&#125;</div><div class="line"></div><div class="line">[root@node4 ~]# umount /var/lib/ceph/osd/ceph-10</div></pre></td></tr></table></figure></p>
<p>8.登录到保存 ceph.conf 主拷贝的主机<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ssh &#123;admin-host&#125;</div><div class="line">cd /etc/ceph</div><div class="line">vim ceph.conf</div></pre></td></tr></table></figure></p>
<p>9.从 ceph.conf 配置文件里删除对应条目<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">[osd.10]</div><div class="line">        host = &#123;hostname&#125;</div></pre></td></tr></table></figure></p>
<p>10.从保存 ceph.conf 主拷贝的主机，把更新过的 ceph.conf 拷贝到集群其他主机的 /etc/ceph 目录下<br>如果在 ceph.conf 中没有定义各 OSD 入口，就不必执行第 8 ~ 10 步</p>
<h5 id="删除-OSD-ceph-deploy"><a href="#删除-OSD-ceph-deploy" class="headerlink" title="删除 OSD(ceph-deploy)"></a><b>删除 OSD(ceph-deploy)</b></h5><p>ref<br><a href="https://lihaijing.gitbooks.io/ceph-handbook/content/Operation/add_rm_osd.html" target="_blank" rel="external">增加/删除 OSD</a><br><a href="https://xiaoquqi.github.io/blog/2015/05/12/ceph-osd-is-full/" target="_blank" rel="external">Ceph集群磁盘没有剩余空间的解决方法</a><br><a href="https://github.com/chenzhongtao/work_summary/blob/master/ceph_doc/Ceph%E5%A6%82%E4%BD%95%E6%B7%BB%E5%8A%A0ssd%E7%A3%81%E7%9B%98%E5%81%9Acache%20tier.txt" target="_blank" rel="external">Ceph如何添加ssd磁盘做cache tier.txt</a><br><a href="http://ceph.com/planet/%E8%AE%B0%E6%9C%80%E8%BF%91%E4%B8%80%E6%AC%A1ceph%E6%95%85%E9%9A%9C%E4%BF%AE%E5%A4%8D/" target="_blank" rel="external">记最近一次ceph故障修复</a><br><a href="https://forest.gitbooks.io/ceph-practice/content/troubleshoot.html" target="_blank" rel="external">故障定位和处理</a><br><a href="http://www.isjian.com/ceph/ceph-cluster-add-or-remove-osd-manual" target="_blank" rel="external">ceph集群中进行osd的手动添加移除</a><br><a href="http://ceph.com/geen-categorie/creating-a-ceph-osd-from-a-designated-disk-partition/" target="_blank" rel="external">Creating a Ceph OSD from a designated disk partition</a><br><a href="http://www.zphj1987.com/2015/11/12/%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E4%B8%80%E5%8F%B0OSD%E4%B8%BB%E6%9C%BA/" target="_blank" rel="external">如何删除一台OSD主机</a><br><a href="https://ekuric.wordpress.com/2016/01/11/addremove-ceph-osd-object-storage-device/" target="_blank" rel="external">add/remove CEPH OSD – Object Storage Device</a><br><a href="https://www.xncoding.com/2017/03/14/ceph/disk-partition.html" target="_blank" rel="external">Linux磁盘分区总结</a><br><a href="http://bbs.ceph.org.cn/article/36" target="_blank" rel="external">Ceph：SSD日志故障后的OSD恢复</a><br><a href="https://lihaijing.gitbooks.io/ceph-handbook/content/Advance_usage/change_osd_journal.html" target="_blank" rel="external">更换 OSD Journal</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;增加-OSD-手动&quot;&gt;&lt;a href=&quot;#增加-OSD-手动&quot; class=&quot;headerlink&quot; title=&quot;增加 OSD(手动)&quot;&gt;&lt;/a&gt;&lt;b&gt;增加 OSD(手动)&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;首先修改各个节点的/etc/hosts信息,增加新节点信息,并添加
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How to change MON IP</title>
    <link href="https://t1ger.github.io/2017/06/21/How-to-change-MON-IP/"/>
    <id>https://t1ger.github.io/2017/06/21/How-to-change-MON-IP/</id>
    <published>2017-06-21T09:12:32.000Z</published>
    <updated>2017-06-23T09:47:53.094Z</updated>
    
    <content type="html"><![CDATA[<p>Ceph 客户端和其他 Ceph 守护进程通过 ceph.conf 来发现 monitor。但是 monitor 之间是通过 mon map 而非 ceph.conf 来发现彼此</p>
<h5 id="修改-MON-IP-推荐-方法一"><a href="#修改-MON-IP-推荐-方法一" class="headerlink" title="修改 MON IP (推荐)方法一 "></a><b>修改 MON IP (推荐)方法一 </b></h5><p>仅修改 ceoh.conf 中 mon 的 IP 是不足以确保集群中的其他 monitor 收到更新的。<br>要修改一个 mon 的 IP，你必须先新增一个使用新 IP 的 monitor，确保这个新 mon 成功加入集群并形成法定人数。<br>然后，删除使用旧 IP 的 mon。最后，更新 ceph.conf ，以便客户端和其他守护进程可以知道新 mon 的 IP。<br>比如，假设现有 3 个 monitors：<br>[mon.node1]<br>        host = node1<br>        addr = 192.168.138.141:6789<br>[mon.node2]<br>        host = node2<br>        addr = 192.168.138.142:6789<br>[mon.node3]<br>        host = node3<br>        addr = 192.168.138.143:6789</p>
<p>把 mon.node3 变更为 mon.node4 。增加一个 mon.node4 ，host 设为 node4，IP 地址设为 192.168.138.144。先启动 mon.node4 ，再 删除 mon.node3 ，否则会破坏法定人数。</p>
<h5 id="修改-MON-IP-方法二"><a href="#修改-MON-IP-方法二" class="headerlink" title="修改 MON IP 方法二 "></a><b>修改 MON IP 方法二 </b></h5><p>有时，monitor 需要迁移到一个新的网络中、数据中心的其他位置或另一个数据中心。这时，需要为集群中所有的 monitors 生成一个新的 mon map （指定了新的 MON IP），再注入每一个 monitor 中</p>
<p>还以前面的 mon 配置为例。假定想把 monitor 从 192.168.138.x 网段改为 192.168.139.x 网段，这两个网段直接是不通的。执行下列步骤：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line">1、获取 mon map</div><div class="line">ceph mon getmap -o &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">2、下面的例子说明了 monmap 的内容。</div><div class="line">monmaptool --print &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">3、删除已有的 monitors</div><div class="line">monmaptool --rm a --rm b --rm c &#123;tmp&#125;/&#123;filename&#125;</div><div class="line"></div><div class="line">monmaptool: monmap file &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">monmaptool: removing a</div><div class="line">monmaptool: removing b</div><div class="line">monmaptool: removing c</div><div class="line">monmaptool: writing epoch 1 to &#123;tmp&#125;/&#123;filename&#125; (0 monitors)</div><div class="line">4、新增 monitor</div><div class="line">monmaptool --add node1 192.168.139.141:6789 --add node2 192.168.139.142:6789 --add node3 192.168.139.143:6789 &#123;tmp&#125;/&#123;filename&#125;</div><div class="line"></div><div class="line">monmaptool: monmap file &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">monmaptool: writing epoch 1 to &#123;tmp&#125;/&#123;filename&#125; (3 monitors)</div><div class="line">5、检查 monmap 的新内容</div><div class="line">$ monmaptool --print &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">monmaptool: monmap file &#123;tmp&#125;/&#123;filename&#125;</div><div class="line"></div><div class="line">此时，我们假定 monitor 已在新位置安装完毕。下面的步骤就是分发新的 monmap 并注入到各新 monitor 中。</div><div class="line">1、停止所有的 monitor 。必须停止 mon 守护进程才能进行 monmap 注入。</div><div class="line">2、注入 monmap。</div><div class="line">ceph-mon -i &#123;mon-id&#125; --inject-monmap &#123;tmp&#125;/&#123;filename&#125;</div><div class="line">3、重启各 monitors </div><div class="line"></div><div class="line"></div><div class="line">[root@admin ~]# ceph mon getmap -o /tmp/map</div><div class="line">got monmap epoch 5</div><div class="line">[root@admin ~]#  monmaptool --print /tmp/map </div><div class="line">monmaptool: monmap file /tmp/map</div><div class="line">epoch 5</div><div class="line">fsid d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">last_changed 2017-06-21 12:59:00.947896</div><div class="line">created 2017-05-27 11:43:56.428001</div><div class="line">0: 192.168.138.141:6789/0 mon.node1</div><div class="line">1: 192.168.138.142:6789/0 mon.node2</div><div class="line">2: 192.168.138.143:6789/0 mon.node3</div><div class="line">[root@admin ~]# monmaptool --rm node1 --rm node2 --rm node3 /tmp/map </div><div class="line">monmaptool: removing node1</div><div class="line">monmaptool: removing node2</div><div class="line">monmaptool: removing node3</div><div class="line">monmaptool: writing epoch 5 to tmp/map (0 monitors)</div><div class="line">[root@admin ~]# monmaptool --add node1 192.168.139.141:6789 --add node2 192.168.139.142:6789 --add node3 192.168.139.143:6789 /tmp/map</div><div class="line">monmaptool: monmap file /tmp/map</div><div class="line">monmaptool: writing epoch 5 to /tmp/map (3 monitors)</div><div class="line"></div><div class="line">[root@admin ~]#  monmaptool --print /tmp/map </div><div class="line">epoch 5</div><div class="line">fsid 224e376d-c5fe-4504-96bb-ea6332a19e61</div><div class="line">last_changed 2017-06-21 12:59:00.947896</div><div class="line">created 2017-05-27 11:43:56.428001</div><div class="line">0: 192.168.139.141:6789/0 mon.node1</div><div class="line">1: 192.168.139.142:6789/0 mon.node2</div><div class="line">2: 192.168.139.143:6789/0 mon.node3</div><div class="line"></div><div class="line"></div><div class="line">systemctl stop ceph-mon@node1</div><div class="line">systemctl stop ceph-mon@node2</div><div class="line">systemctl stop ceph-mon@node3</div><div class="line">ceph-mon -i node1 --inject-monmap tmp/map</div><div class="line">ceph-mon -i node2 --inject-monmap tmp/map</div><div class="line">ceph-mon -i node3 --inject-monmap tmp/map</div><div class="line">systemctl restart ceph-mon@node1</div><div class="line">systemctl restart ceph-mon@node2</div><div class="line">systemctl restart ceph-mon@node3</div></pre></td></tr></table></figure></p>
<h5 id="修改-MON-IP-方法三"><a href="#修改-MON-IP-方法三" class="headerlink" title="修改 MON IP 方法三 "></a><b>修改 MON IP 方法三 </b></h5><p>假如我们在机房迁移时候没有导出monmap,我们如何修改ip呢<br>这里我放弃使用导出monmap的方法而选择新建monmap，因为新建可以解决这里MON修改IP后无法启动提取monmap的问题。</p>
<p>假定，MON的IP从192.168.56.x 迁到了172.16.56.x ，我们首先创建一个使用新的IP的monmap，这里还是使用了三个MON：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# cat /etc/ceph/ceph.conf |grep fsid</div><div class="line">fsid = d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">[root@node1 ~]# monmaptool -h</div><div class="line"> usage: [--print] [--create [--clobber][--fsid uuid]] [--generate] [--set-initial-members] [--add name 1.2.3.4:567] [--rm name] &lt;mapfilename&gt;</div><div class="line"> </div><div class="line">[root@node1 ~]# monmaptool --create --fsid d6d92de4-2a08-4bd6-a749-6c104c88fc40 --add node1 172.16.56.141 --add node2 172.16.56.142 --add  node3 172.16.56.143 /tmp/monmap</div><div class="line">monmaptool: monmap file /tmp/monmap</div><div class="line">monmaptool: set fsid to d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">monmaptool: writing epoch 0 to /tmp/monmap (3 monitors)</div><div class="line"></div><div class="line">[root@ceph-1 ~]# monmaptool --print /tmp/monmap </div><div class="line">monmaptool: monmap file /tmp/monmap</div><div class="line">epoch 0</div><div class="line">fsid d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">last_changed 2017-06-21 12:59:00.947896</div><div class="line">created 2017-05-27 11:43:56.428001</div><div class="line">0: 172.16.56.141:6789/0 mon.node1</div><div class="line">1: 172.16.56.142:6789/0 mon.node2</div><div class="line">2: 172.16.56.143:6789/0 mon.node3</div><div class="line"></div><div class="line">通过打印monmap可以看到已经成功添加了三个MON，只是这里的epoch为0，实际的epoch肯定大于0的，</div><div class="line">不用担心，monmaptool的代码里面写死了是0，并且不影响注入到MON的数据库里</div><div class="line"></div><div class="line">[root@node1 ~]# scp /tmp/monmap node2:/tmp/monmap</div><div class="line">[root@node1 ~]# scp /tmp/monmap node3:/tmp/monmap</div><div class="line">[root@node1 ~]# ceph-mon -i node1 --inject-monmap /tmp/monmap </div><div class="line">[root@node2 ~]# ceph-mon -i node2 --inject-monmap /tmp/monmap </div><div class="line">[root@node3 ~]# ceph-mon -i node3 --inject-monmap /tmp/monmap</div><div class="line"></div><div class="line">注意这里是在三个主机上分别注入的，最后修改配置文件，发放到各个节点，开启MON服务</div><div class="line"></div><div class="line">[root@node1 cluster]# vim ceph.conf </div><div class="line">[root@node1 cluster]# cat /root/cluster/ceph.conf |grep mon</div><div class="line">mon_initial_members = node1,node2,node3</div><div class="line">mon_host = 172.16.56.141,172.16.56.142,172.16.56.143</div><div class="line">[root@node1 cluster]# ceph-deploy --overwrite-conf config push node1 node2 node3</div><div class="line">[root@node1 ~]# systemctl start ceph.target</div><div class="line">[root@node2 ~]# systemctl start ceph.target</div><div class="line">[root@node3 ~]# systemctl start ceph.target</div><div class="line">[root@node1 cluster]# ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_WARN</div><div class="line">            clock skew detected on mon.node2, mon.node3</div><div class="line">            Monitor clock skew detected </div><div class="line">     monmap e6: 3 mons at &#123;node1=172.16.56.141:6789/0,node2=172.16.56.142:6789/0,node3=172.16.56.143:6789/0&#125;</div><div class="line">            election epoch 6, quorum 0,1,2 node1,node2,node3</div><div class="line">     osdmap e30: 3 osds: 3 up, 3 in</div><div class="line">      pgmap v48: 64 pgs, 1 pools, 0 bytes data, 0 objects</div><div class="line">            101 MB used, 6125 GB / 6125 GB avail</div><div class="line">                  64 active+clean</div><div class="line"></div><div class="line">这样我们就完成了MON的IP迁移</div></pre></td></tr></table></figure>
<h5 id="修改-MON-IP-方法四"><a href="#修改-MON-IP-方法四" class="headerlink" title="修改 MON IP 方法四"></a><b>修改 MON IP 方法四</b></h5><p>如果三个MON的数据库都被损坏了,我们可以参考<a href="http://www.zphj1987.com/2016/09/20/Ceph%E7%9A%84Mon%E6%95%B0%E6%8D%AE%E9%87%8D%E6%96%B0%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7/" target="_blank" rel="external">这里</a>重建MON<br>主要使用新工具ceph-monstore-tool来重建丢失的MON数据库。当然，如果每天备份一次MON数据库，就不用担心故障了</p>
<h5 id="Monitor的备份"><a href="#Monitor的备份" class="headerlink" title="Monitor的备份 "></a><b>Monitor的备份 </b></h5><p>备份,重要的事情强调三遍.简单讲基本思路就是，停止一个MON，然后将这个MON的数据库压缩保存到其他路径，再开启MON，文中提到了之所以要停止MON是要保证levelDB数据库的完整性.</p>
<p>当某个集群的所有的MON节点都挂掉之后，我们可以将最新的备份的数据库解压到任意一个节点上，用同样的方法新建monmap，注入，开启MON，推送config,重启OSD就好了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">systemctl stop ceph-mon@node1</div><div class="line">tar czf /var/backups/ceph-mon-backup_$(date +&apos;%a&apos;).tar.gz /var/lib/ceph/mon</div><div class="line">systemctl start ceph-mon@node1</div><div class="line">#for safety, copy it to other nodes</div><div class="line">scp /var/backups/* someNode:/backup/</div></pre></td></tr></table></figure>
<p>ref</p>
<p><a href="http://www.xuxiaopang.com/2016/10/26/exp-monitor-operation/" target="_blank" rel="external">monitor的增删改备</a><br><a href="https://lihaijing.gitbooks.io/ceph-handbook/content/Operation/modify_mon_ip.html" target="_blank" rel="external">修改 MON IP</a><br><a href="https://github.com/angapov/ceph-systemd" target="_blank" rel="external">Systemd script for CEPH object storage</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Ceph 客户端和其他 Ceph 守护进程通过 ceph.conf 来发现 monitor。但是 monitor 之间是通过 mon map 而非 ceph.conf 来发现彼此&lt;/p&gt;
&lt;h5 id=&quot;修改-MON-IP-推荐-方法一&quot;&gt;&lt;a href=&quot;#修改-MON-
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>monitor的添加或删除</title>
    <link href="https://t1ger.github.io/2017/06/15/monitor%E7%9A%84%E6%B7%BB%E5%8A%A0%E6%88%96%E5%88%A0%E9%99%A4/"/>
    <id>https://t1ger.github.io/2017/06/15/monitor的添加或删除/</id>
    <published>2017-06-15T11:09:13.000Z</published>
    <updated>2017-06-21T07:07:49.788Z</updated>
    
    <content type="html"><![CDATA[<p>一般来说，在实际运行中，ceph monitor的个数是2n+1(n&gt;=0)个，在线上至少3个，只要正常的节点数&gt;=n+1，ceph的paxos算法能保证系统的正常运行。所以,对于3个节点，同时只能挂掉一个。建议（但不是强制）部署奇数个 monitor ,不建议把监视器和 OSD 置于同一主机上,后续如果要增加，请一次增加 2 个</p>
<p>一般来说，同时挂掉2个节点的概率比较小，但是万一挂掉2个呢？<br>如果ceph的monitor节点超过半数挂掉，paxos算法就无法正常进行仲裁(quorum)，此时，ceph集群会阻塞对集群的操作，直到超过半数的monitor节点恢复</p>
<ul>
<li>如果挂掉的2个节点至少有一个可以恢复，也就是monitor的监控数据还是OK的，那么只需要重启ceph-mon进程即可。所以，对于monitor，最好运行在RAID的机器上。这样，即使机器出现故障，恢复也比较容易</li>
<li>如果挂掉的2个节点的监控数据都损坏了呢？</li>
</ul>
<p>带着这些疑问,后续几篇文章我们来提供了一些常见场景的处理方法，包括增加monitor，移除某个monitor，机房搬迁需要修改IP，备份MON的数据库等</p>
<p>本文讲一下如何对一个已经存在的ceph storage cluster添加或删除一个监控节点.<br>用 ceph-deploy 增加和删除监视器很简单，只要一个命令就可以增加或删除一或多个监视器<br>大致步骤:<br>1.环境准备<br>2.安装软件<br>3.添加节点</p>
<h5 id="添加一个monitor-ceph-deploy"><a href="#添加一个monitor-ceph-deploy" class="headerlink" title="添加一个monitor(ceph-deploy )"></a><b>添加一个monitor(ceph-deploy )</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div></pre></td><td class="code"><pre><div class="line">[neo@admin cluster]$ sudo ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_OK</div><div class="line">     monmap e2: 2 mons at &#123;node1=192.168.138.141:6789/0,node2=192.168.138.142:6789/0&#125;</div><div class="line">            election epoch 62, quorum 0,1 node1,node2</div><div class="line">     osdmap e246: 9 osds: 9 up, 9 in</div><div class="line">            flags sortbitwise,require_jewel_osds</div><div class="line">      pgmap v1167: 256 pgs, 1 pools, 4 bytes data, 1 objects</div><div class="line">            350 MB used, 18377 GB / 18378 GB avail</div><div class="line">                 256 active+clean</div><div class="line">[neo@admin cluster]$ cat ~/cluster/ceph.conf |grep mon     </div><div class="line">mon_initial_members = node1, node2</div><div class="line">mon_host = 192.168.138.141,192.168.138.142</div><div class="line"></div><div class="line">#修改配置文件,添加新的节点</div><div class="line">[neo@admin cluster]$ vi ceph.conf </div><div class="line">[neo@admin cluster]$ cat ~/cluster/ceph.conf |grep mon</div><div class="line">mon_initial_members = node1, node2, node3</div><div class="line">mon_host = 192.168.138.141,192.168.138.142,192.168.138.143</div><div class="line"></div><div class="line">[neo@admin cluster]$ ceph-deploy --overwrite-conf config push  node1 node2</div><div class="line"></div><div class="line">#添加MON，注意如果如果要添加多个MON，需要一个个add</div><div class="line">需要注意,往存在的cluster里添加monitor时，需要修改配置文件ceph.conf在global章节中</div><div class="line">指定public network或者mon.nodeX中指定public addr，配置文件中写成代</div><div class="line">下划线的public_network =也是可以的</div><div class="line"></div><div class="line">[neo@admin cluster]$ ceph-deploy --overwrite-conf mon add node3</div><div class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /home/neo/.cephdeploy.conf</div><div class="line">[ceph_deploy.cli][INFO  ] Invoked (1.5.37): /usr/bin/ceph-deploy --overwrite-conf mon add node3</div><div class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</div><div class="line">[ceph_deploy.cli][INFO  ]  username                      : None</div><div class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</div><div class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : True</div><div class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : add</div><div class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</div><div class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x164fc68&gt;</div><div class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</div><div class="line">[ceph_deploy.cli][INFO  ]  mon                           : [&apos;node3&apos;]</div><div class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x1647320&gt;</div><div class="line">[ceph_deploy.cli][INFO  ]  address                       : None</div><div class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</div><div class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</div><div class="line">[ceph_deploy.mon][INFO  ] ensuring configuration of new mon host: node3</div><div class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to node3</div><div class="line">[node3][DEBUG ] connection detected need for sudo</div><div class="line">[node3][DEBUG ] connected to host: node3 </div><div class="line">[node3][DEBUG ] detect platform information from remote host</div><div class="line">[node3][DEBUG ] detect machine type</div><div class="line">[node3][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</div><div class="line">[ceph_deploy.mon][DEBUG ] Adding mon to cluster ceph, host node3</div><div class="line">[ceph_deploy.mon][DEBUG ] using mon address by resolving host: 192.168.138.143</div><div class="line">[ceph_deploy.mon][DEBUG ] detecting platform for host node3 ...</div><div class="line">[node3][DEBUG ] connection detected need for sudo</div><div class="line">[node3][DEBUG ] connected to host: node3 </div><div class="line">[node3][DEBUG ] detect platform information from remote host</div><div class="line">[node3][DEBUG ] detect machine type</div><div class="line">[node3][DEBUG ] find the location of an executable</div><div class="line">[ceph_deploy.mon][INFO  ] distro info: CentOS Linux 7.3.1611 Core</div><div class="line">[node3][DEBUG ] determining if provided host has same hostname in remote</div><div class="line">[node3][DEBUG ] get remote short hostname</div><div class="line">[node3][DEBUG ] adding mon to node3</div><div class="line">[node3][DEBUG ] get remote short hostname</div><div class="line">[node3][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</div><div class="line">[node3][DEBUG ] create the mon path if it does not exist</div><div class="line">[node3][DEBUG ] checking for done path: /var/lib/ceph/mon/ceph-node3/done</div><div class="line">[node3][DEBUG ] create a done file to avoid re-doing the mon deployment</div><div class="line">[node3][DEBUG ] create the init path if it does not exist</div><div class="line">[node3][INFO  ] Running command: sudo systemctl enable ceph.target</div><div class="line">[node3][INFO  ] Running command: sudo systemctl enable ceph-mon@node3</div><div class="line">[node3][INFO  ] Running command: sudo systemctl start ceph-mon@node3</div><div class="line">[node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.node3.asok mon_status</div><div class="line">[node3][WARNIN] monitor node3 does not exist in monmap</div><div class="line">[node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.node3.asok mon_status</div><div class="line">[node3][DEBUG ] ********************************************************************************</div><div class="line">[node3][DEBUG ] status for monitor: mon.node3</div><div class="line">[node3][DEBUG ] &#123;</div><div class="line">[node3][DEBUG ]   &quot;election_epoch&quot;: 0, </div><div class="line">[node3][DEBUG ]   &quot;extra_probe_peers&quot;: [], </div><div class="line">[node3][DEBUG ]   &quot;monmap&quot;: &#123;</div><div class="line">[node3][DEBUG ]     &quot;created&quot;: &quot;2017-05-27 11:43:56.428001&quot;, </div><div class="line">[node3][DEBUG ]     &quot;epoch&quot;: 2, </div><div class="line">[node3][DEBUG ]     &quot;fsid&quot;: &quot;d6d92de4-2a08-4bd6-a749-6c104c88fc40&quot;, </div><div class="line">[node3][DEBUG ]     &quot;modified&quot;: &quot;2017-06-20 11:52:25.801159&quot;, </div><div class="line">[node3][DEBUG ]     &quot;mons&quot;: [</div><div class="line">[node3][DEBUG ]       &#123;</div><div class="line">[node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.138.141:6789/0&quot;, </div><div class="line">[node3][DEBUG ]         &quot;name&quot;: &quot;node1&quot;, </div><div class="line">[node3][DEBUG ]         &quot;rank&quot;: 0</div><div class="line">[node3][DEBUG ]       &#125;, </div><div class="line">[node3][DEBUG ]       &#123;</div><div class="line">[node3][DEBUG ]         &quot;addr&quot;: &quot;192.168.138.142:6789/0&quot;, </div><div class="line">[node3][DEBUG ]         &quot;name&quot;: &quot;node2&quot;, </div><div class="line">[node3][DEBUG ]         &quot;rank&quot;: 1</div><div class="line">[node3][DEBUG ]       &#125;</div><div class="line">[node3][DEBUG ]     ]</div><div class="line">[node3][DEBUG ]   &#125;, </div><div class="line">[node3][DEBUG ]   &quot;name&quot;: &quot;node3&quot;, </div><div class="line">[node3][DEBUG ]   &quot;outside_quorum&quot;: [], </div><div class="line">[node3][DEBUG ]   &quot;quorum&quot;: [], </div><div class="line">[node3][DEBUG ]   &quot;rank&quot;: -1, </div><div class="line">[node3][DEBUG ]   &quot;state&quot;: &quot;synchronizing&quot;, </div><div class="line">[node3][DEBUG ]   &quot;sync&quot;: &#123;</div><div class="line">[node3][DEBUG ]     &quot;sync_cookie&quot;: 1040187393, </div><div class="line">[node3][DEBUG ]     &quot;sync_provider&quot;: &quot;mon.0 192.168.138.141:6789/0&quot;, </div><div class="line">[node3][DEBUG ]     &quot;sync_start_version&quot;: 2944</div><div class="line">[node3][DEBUG ]   &#125;, </div><div class="line">[node3][DEBUG ]   &quot;sync_provider&quot;: []</div><div class="line">[node3][DEBUG ] &#125;</div><div class="line">[node3][DEBUG ] ********************************************************************************</div><div class="line">[node3][INFO  ] monitor: mon.node3 is currently at the state of synchronizing</div></pre></td></tr></table></figure>
<p>错误1:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[node3][ERROR ] admin_socket: exception getting command descriptions: [Errno 2] No such file or directory</div><div class="line">[node3][WARNIN] monitor: mon.node3, might not be running yet</div><div class="line">[node3][INFO  ] Running command: sudo ceph --cluster=ceph --admin-daemon /var/run/ceph/ceph-mon.node3.asok mon_status</div><div class="line">[node3][ERROR ] admin_socket: exception getting command descriptions: [Errno 2] No such file or directory</div><div class="line">[node3][WARNIN] monitor node3 does not exist in monmap</div><div class="line">[node3][WARNIN] neither `public_addr` nor `public_network` keys are defined for monitors</div><div class="line">[node3][WARNIN] monitors may not be able to form quorum</div></pre></td></tr></table></figure></p>
<p>原因: 未配置public network</p>
<h5 id="添加一个monitor-手动"><a href="#添加一个monitor-手动" class="headerlink" title="添加一个monitor(手动)"></a><b>添加一个monitor(手动)</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">添加之前查看当前节点 ceph mon stat</div><div class="line"></div><div class="line">1、在目标节点上，新建 mon 的默认目录。&#123;mon-id&#125; 一般取为节点的 hostname 。</div><div class="line">ssh &#123;new-mon-host&#125;</div><div class="line">sudo mkdir /var/lib/ceph/mon/ceph-&#123;mon-id&#125;</div><div class="line">2、创建一个临时目录（和第 1 步中的目录不同，添加 mon 完毕后需要删除该临时目录），来存放新增 mon 所需的各种文件，</div><div class="line">mkdir &#123;tmp&#125;</div><div class="line">3、获取 mon 的 keyring 文件，保存在临时目录下。</div><div class="line">ceph auth get mon. -o &#123;tmp&#125;/&#123;key-filename&#125;</div><div class="line">4、获取集群的 mon map 并保存到临时目录下。</div><div class="line">ceph mon getmap -o &#123;tmp&#125;/&#123;map-filename&#125;</div><div class="line">5.Optional. 更新所有mon节点的配置文件，添加新节点的IP地址到ceph.conf [global]字段的mon_host</div><div class="line">[mon.node3] </div><div class="line">        host                  = node3</div><div class="line">        mon addr              = 192.168.138.143:6789</div><div class="line">		</div><div class="line">6、格式化在第 1 步中建立的 mon 数据目录。需要指定 mon map 文件的路径（获取法定人数的信息和集群的 fsid ）和 keyring 文件的路径。</div><div class="line">sudo ceph-mon -i &#123;mon-id&#125; --mkfs --monmap &#123;tmp&#125;/&#123;map-filename&#125; --keyring &#123;tmp&#125;/&#123;key-filename&#125;</div><div class="line">7、启动节点上的 mon 进程，它会自动加入集群。守护进程需要知道绑定到哪个 IP 地址，可以通过 --public-addr &#123;ip:port&#125; 选择指定，或在 ceph.conf 文件中进行配置 mon addr。</div><div class="line">ceph-mon -i &#123;mon-id&#125; --public-addr &#123;ip:port&#125;</div><div class="line"></div><div class="line">[root@node3 ~]# mkdir /var/lib/ceph/mon/ceph-node3/ -p</div><div class="line">[root@node3 ~]# mkdir /var/lib/ceph/tmp -p</div><div class="line">[root@node3 ~]# cd /var/lib/ceph/mon/ceph-node3/</div><div class="line">[root@node3 ceph-node3]# ceph auth get mon. -o ../../tmp/key-node3</div><div class="line">exported keyring for mon.</div><div class="line">[root@node3 ceph-node3]# ceph mon getmap -o ../../tmp/map-node3</div><div class="line">2017-06-21 12:56:30.078870 7fd654086700  0 -- :/2208778235 &gt;&gt; 192.168.138.143:6789/0 pipe(0x7fd65805cc80 sd=3 :0 s=1 pgs=0 cs=0 l=1 c=0x7fd65805df40).fault</div><div class="line">got monmap epoch 4</div><div class="line">[root@node3 ceph-node3]# ceph-mon  -i node3 --mkfs --monmap ../../tmp/map-node3  --keyring ../../tmp/key-node3 </div><div class="line">ceph-mon: set fsid to d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">ceph-mon: created monfs at /var/lib/ceph/mon/ceph-node3 for mon.node3</div><div class="line"></div><div class="line">#启动节点上的 mon 进程，它会自动加入集群,此步骤可略</div><div class="line">[root@node3 ceph-node3]# ceph mon add node3 192.169.138.143:6789</div><div class="line">[root@node3 ceph-node3]# ceph-mon -i node3 --public-addr 192.169.138.143:6789</div></pre></td></tr></table></figure>
<h5 id="删除一个monitor-ceph-deploy"><a href="#删除一个monitor-ceph-deploy" class="headerlink" title="删除一个monitor(ceph-deploy )"></a><b>删除一个monitor(ceph-deploy )</b></h5><p>这里我们删除node3节点的mon,修改部署目录的配置文件，去除node3及其IP,再推送到三个节点<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">[neo@admin cluster]$ cat ~/cluster/ceph.conf |grep mon     </div><div class="line">mon_initial_members = node1, node2, node3</div><div class="line">mon_host = 192.168.138.141,192.168.138.142,192.168.138.143</div><div class="line"></div><div class="line">[neo@admin cluster]$ ceph-deploy --overwrite-conf config push node1 node2 node3</div><div class="line">[neo@admin cluster]$ ceph-deploy mon destroy node3</div><div class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /home/neo/.cephdeploy.conf</div><div class="line">[ceph_deploy.cli][INFO  ] Invoked (1.5.37): /usr/bin/ceph-deploy mon destroy node3</div><div class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</div><div class="line">[ceph_deploy.cli][INFO  ]  username                      : None</div><div class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</div><div class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</div><div class="line">[ceph_deploy.cli][INFO  ]  subcommand                    : destroy</div><div class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</div><div class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x1481c68&gt;</div><div class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</div><div class="line">[ceph_deploy.cli][INFO  ]  mon                           : [&apos;node3&apos;]</div><div class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function mon at 0x1479320&gt;</div><div class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</div><div class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</div><div class="line">[ceph_deploy.mon][DEBUG ] Removing mon from node3</div><div class="line">[node3][DEBUG ] connection detected need for sudo</div><div class="line">[node3][DEBUG ] connected to host: node3 </div><div class="line">[node3][DEBUG ] detect platform information from remote host</div><div class="line">[node3][DEBUG ] detect machine type</div><div class="line">[node3][DEBUG ] find the location of an executable</div><div class="line">[node3][DEBUG ] get remote short hostname</div><div class="line">[node3][INFO  ] Running command: sudo ceph --cluster=ceph -n mon. -k /var/lib/ceph/mon/ceph-node3/keyring mon remove node3</div><div class="line">[node3][WARNIN] removing mon.node3 at 192.168.138.143:6789/0, there will be 2 monitors</div><div class="line">[node3][INFO  ] polling the daemon to verify it stopped</div><div class="line">[node3][INFO  ] Running command: sudo systemctl stop ceph-mon@node3.service</div><div class="line">[node3][INFO  ] Running command: sudo mkdir -p /var/lib/ceph/mon-removed</div><div class="line">[node3][DEBUG ] move old monitor data</div><div class="line"></div><div class="line">[neo@admin cluster]$ sudo ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_OK</div><div class="line">     monmap e2: 2 mons at &#123;node1=192.168.138.141:6789/0,node2=192.168.138.142:6789/0&#125;</div><div class="line">            election epoch 62, quorum 0,1 node1,node2</div><div class="line">     osdmap e246: 9 osds: 9 up, 9 in</div><div class="line">            flags sortbitwise,require_jewel_osds</div><div class="line">      pgmap v1167: 256 pgs, 1 pools, 4 bytes data, 1 objects</div><div class="line">            350 MB used, 18377 GB / 18378 GB avail</div><div class="line">                 256 active+clean</div><div class="line">				 </div><div class="line">备注:</div><div class="line">ceph-deploy删除MON的时候调用的指令是ceph mon remove node3,删除的MON的文件夹被移到了/var/lib/ceph/mon-removed</div></pre></td></tr></table></figure></p>
<p>注意： 确保你删除某个 Mon 后，其余 Mon 仍能达成一致。如果不可能，删除它之前可能需要先增加一个</p>
<h5 id="删除一个monitor-手动"><a href="#删除一个monitor-手动" class="headerlink" title="删除一个monitor(手动)"></a><b>删除一个monitor(手动)</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">1、停止 mon 进程。</div><div class="line">[neo@admin cluster]$ sudo systemctl stop ceph-mon@node3</div><div class="line">2、从集群中删除 monitor。</div><div class="line">[neo@admin cluster]$ sudo ceph mon remove node3</div><div class="line">removing mon.node3 at 192.168.138.143:6789/0, there will be 2 monitors</div><div class="line">[neo@admin cluster]$ sudo ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_OK</div><div class="line">     monmap e4: 2 mons at &#123;node1=192.168.138.141:6789/0,node2=192.168.138.142:6789/0&#125;</div><div class="line">            election epoch 74, quorum 0,1 node1,node2</div><div class="line">     osdmap e264: 9 osds: 9 up, 9 in</div><div class="line">            flags sortbitwise,require_jewel_osds</div><div class="line">      pgmap v1218: 256 pgs, 1 pools, 4 bytes data, 1 objects</div><div class="line">            354 MB used, 18377 GB / 18378 GB avail</div><div class="line">                 256 active+clean</div><div class="line"></div><div class="line">3、从 ceph.conf 中移除 mon 的入口部分（如果有）。</div></pre></td></tr></table></figure>
<h5 id="删除-Monitor（从不健康的集群中）"><a href="#删除-Monitor（从不健康的集群中）" class="headerlink" title="删除 Monitor（从不健康的集群中）"></a><b>删除 Monitor（从不健康的集群中）</b></h5><p>从一个不健康的集群（比如集群中的 monitor 无法达成法定人数）中删除 ceph-mon 守护进程。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">1、停止集群中所有的 ceph-mon 守护进程。</div><div class="line">ssh &#123;mon-host&#125;</div><div class="line">systemctl stop ceph-mon@mon-host</div><div class="line"># and repeat for all mons</div><div class="line">2、确认存活的 mon 并登录该节点。</div><div class="line">ssh &#123;mon-host&#125;</div><div class="line">3、提取 mon map。</div><div class="line">ceph-mon -i &#123;mon-id&#125; --extract-monmap &#123;map-path&#125;</div><div class="line"># in most cases, that&apos;s</div><div class="line">ceph-mon -i `hostname` --extract-monmap /tmp/monmap</div><div class="line">4、删除未存活或有问题的的 monitor。比如，有 3 个 monitors，mon.node1 、mon.node2 和 mon.node3，现在仅有 mon.node1 存活，执行下列步骤：</div><div class="line">monmaptool &#123;map-path&#125; --rm &#123;mon-id&#125;</div><div class="line"># for example,</div><div class="line">monmaptool /tmp/monmap --rm node2</div><div class="line">monmaptool /tmp/monmap --rm node3</div><div class="line">5、向存活的 monitor(s) 注入修改后的 mon map。比如，把 mon map 注入 mon.node1，执行下列步骤：</div><div class="line">ceph-mon -i &#123;mon-id&#125; --inject-monmap &#123;map-path&#125;</div><div class="line"># for example,</div><div class="line">ceph-mon -i a --inject-monmap /tmp/monmap</div><div class="line">6、启动存活的 monitor。</div><div class="line">7、确认 monitor 是否达到法定人数（ ceph -s ）。</div><div class="line">8、你可能需要把已删除的 monitor 的数据目录 /var/lib/ceph/mon 归档到一个安全的位置。或者，如果你确定剩下的 monitor 是健康的且数量足够，也可以直接删除数据目录。</div></pre></td></tr></table></figure>
<h5 id="挂掉的2个节点的监控数据的恢复"><a href="#挂掉的2个节点的监控数据的恢复" class="headerlink" title="挂掉的2个节点的监控数据的恢复"></a><b>挂掉的2个节点的监控数据的恢复</b></h5><p>前边我们说如果挂掉的2个节点的监控数据都损坏了呢？恢复方法请参考<a href="http://www.cnblogs.com/hustcat/p/3925971.html" target="_blank" rel="external">这里</a></p>
<p>ref<br><a href="http://www.xuxiaopang.com/2016/10/26/exp-monitor-operation/" target="_blank" rel="external">monitor的增删改备</a><br><a href="http://blog.csdn.net/scaleqiao/article/details/50513655" target="_blank" rel="external">Ceph Monitor挂了之后对集群的影响</a><br><a href="https://lihaijing.gitbooks.io/ceph-handbook/content/Operation/add_rm_mon.html" target="_blank" rel="external">增加/删除 Monitor</a><br><a href="https://github.com/thesues/cephdoc/blob/master/ceph-deploy-cn.markdown" target="_blank" rel="external">thesues/cephdoc</a><br><a href="http://blog.sina.com.cn/s/blog_8ea8e9d50102xhbq.html" target="_blank" rel="external">Ceph集群</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。    </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一般来说，在实际运行中，ceph monitor的个数是2n+1(n&amp;gt;=0)个，在线上至少3个，只要正常的节点数&amp;gt;=n+1，ceph的paxos算法能保证系统的正常运行。所以,对于3个节点，同时只能挂掉一个。建议（但不是强制）部署奇数个 monitor ,不建议
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ceph-Monitor clock skew detected</title>
    <link href="https://t1ger.github.io/2017/06/13/ceph-Monitor-clock-skew-detected/"/>
    <id>https://t1ger.github.io/2017/06/13/ceph-Monitor-clock-skew-detected/</id>
    <published>2017-06-13T07:00:09.000Z</published>
    <updated>2017-06-13T06:59:44.990Z</updated>
    
    <content type="html"><![CDATA[<p>ceph异常警告:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">[root@admin ~]# ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_WARN</div><div class="line">            clock skew detected on mon.node2</div><div class="line">            Monitor clock skew detected </div><div class="line">     monmap e1: 3 mons at &#123;node1=192.168.138.141:6789/0,node2=192.168.138.142:6789/0,node3=192.168.138.143:6789/0&#125;</div><div class="line">            election epoch 46, quorum 0,1,2 node1,node2,node3</div><div class="line">     osdmap e218: 9 osds: 9 up, 9 in</div><div class="line">            flags sortbitwise,require_jewel_osds</div><div class="line">      pgmap v1007: 256 pgs, 1 pools, 4 bytes data, 1 objects</div><div class="line">            345 MB used, 18377 GB / 18378 GB avail</div><div class="line">                 256 active+clean</div><div class="line">				 			 </div><div class="line">[root@admin ~]# ceph health detail</div><div class="line">HEALTH_WARN clock skew detected on mon.node2, mon.node3; Monitor clock skew detected </div><div class="line">mon.node2 addr 192.168.138.142:6789/0 clock skew 0.434161s &gt; max 0.05s (latency 0.00740637s)</div><div class="line">mon.node3 addr 192.168.138.143:6789/0 clock skew 0.687451s &gt; max 0.05s (latency 0.00722567s)</div></pre></td></tr></table></figure></p>
<p>解决方法:</p>
<ul>
<li><p>方法一:配置ntp server<br>本来以为配置ntp server了,时间应该就一致了,原来ceph默认容忍的时间偏差不到1秒,随意只能用本地的ntp server了<br>下面来说说配置ntp server(If Iptables is running, allow NTP port. NTP uses 123/UDP.)<br>chrony_server</p>
<p>  1.install chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install chrony</div></pre></td></tr></table></figure>
<p>  2.config chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">[root@admin ~]# cat /etc/chrony.conf </div><div class="line"># These servers were defined in the installation:</div><div class="line">server 3.centos.pool.ntp.org iburst</div><div class="line">server 0.centos.pool.ntp.org iburst</div><div class="line">server cn.pool.ntp.org iburst</div><div class="line">server 1.centos.pool.ntp.org iburst</div><div class="line">server 2.centos.pool.ntp.org iburst</div><div class="line"># Serve time even if not synchronized to any NTP server.</div><div class="line">local stratum 10</div><div class="line">....</div><div class="line">allow 192.168/16</div></pre></td></tr></table></figure>
<p>  3.run chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">systemctl enable chronyd</div><div class="line">systemctl start chronyd</div></pre></td></tr></table></figure>
<p>  4.timedatectl</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">## 查看时间</div><div class="line">timedatectl</div><div class="line">## 开启ntp时间同步</div><div class="line">timedatectl set-ntp true</div></pre></td></tr></table></figure>
<p>  5.chronyc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">## 查看ntp_servers状态</div><div class="line">chronyc sources -v</div><div class="line">## 查看ntp_sync状态</div><div class="line">chronyc sourcestats -v</div><div class="line">## 查看ntp_servers 是否在线</div><div class="line">chronyc activity -v</div><div class="line">## 查看ntp时间详细信息</div><div class="line">chronyc tracking -v</div></pre></td></tr></table></figure>
<p>  chrony_client<br>  1.install chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install chrony</div></pre></td></tr></table></figure>
<p>  2.config chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@node3 ~]# cat /etc/chrony.conf</div><div class="line"># These servers were defined in the installation:</div><div class="line">server 192.168.138.140 iburst</div></pre></td></tr></table></figure>
<p>  3.run chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">systemctl enable chronyd</div><div class="line">systemctl start chronyd</div></pre></td></tr></table></figure>
<p>  4.timedatectl</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">## 查看时间</div><div class="line">timedatectl</div><div class="line">## 开启ntp时间同步</div><div class="line">timedatectl set-ntp true</div></pre></td></tr></table></figure>
<p>  5.chronyc</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line">## 查看ntp_servers状态</div><div class="line">chronyc sources -v</div><div class="line">## 查看ntp_sync状态</div><div class="line">chronyc sourcestats -v</div><div class="line">## 查看ntp_servers 是否在线</div><div class="line">chronyc activity -v</div><div class="line">## 查看ntp时间详细信息</div><div class="line">chronyc tracking -v</div><div class="line"></div><div class="line">[root@node3 ~]# chronyc tracking</div><div class="line">Reference ID    : 192.168.138.140 (192.168.138.140)</div><div class="line">Stratum         : 5</div><div class="line">Ref time (UTC)  : Tue Jun 13 05:52:48 2017</div><div class="line">System time     : 0.000494327 seconds fast of NTP time</div><div class="line">Last offset     : +0.000704829 seconds</div><div class="line">RMS offset      : 0.001765276 seconds</div><div class="line">Frequency       : 71.667 ppm slow</div><div class="line">Residual freq   : +0.269 ppm</div><div class="line">Skew            : 6.979 ppm</div><div class="line">Root delay      : 0.324675 seconds</div><div class="line">Root dispersion : 0.039305 seconds</div><div class="line">Update interval : 64.8 seconds</div><div class="line">Leap status     : Normal</div></pre></td></tr></table></figure>
<p>  备注:chrony手动校时</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chronyc -a makestep</div></pre></td></tr></table></figure>
</li>
<li><p>方法二:调整ceph参数避免<br>1.在admin结点上，修改ceph.conf，添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mon_clock_drift_allowed = 5</div><div class="line">mon_clock_drift_warn_backoff = 30</div></pre></td></tr></table></figure>
<p>  详细参数参考<a href="http://docs.ceph.com/docs/hammer/rados/configuration/mon-config-ref/#clock" target="_blank" rel="external">这里</a></p>
<p>  2.执行下面命令，node1等是monitor结点的名称</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ceph-deploy --overwrite-conf admin node1 node2 node3</div></pre></td></tr></table></figure>
<p>  3.重启monitor</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">systemctl restart ceph-mon@node1</div><div class="line">systemctl restart ceph-mon@node2</div><div class="line">systemctl restart ceph-mon@node3</div></pre></td></tr></table></figure>
<p>  4.验证</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@admin ~]# ceph -s</div><div class="line">    cluster d6d92de4-2a08-4bd6-a749-6c104c88fc40</div><div class="line">     health HEALTH_OK</div><div class="line">     monmap e1: 3 mons at &#123;node1=192.168.138.141:6789/0,node2=192.168.138.142:6789/0,node3=192.168.138.143:6789/0&#125;</div><div class="line">            election epoch 48, quorum 0,1,2 node1,node2,node3</div><div class="line">     osdmap e218: 9 osds: 9 up, 9 in</div><div class="line">            flags sortbitwise,require_jewel_osds</div><div class="line">      pgmap v1007: 256 pgs, 1 pools, 4 bytes data, 1 objects</div><div class="line">            345 MB used, 18377 GB / 18378 GB avail</div><div class="line">                 256 active+clean</div></pre></td></tr></table></figure>
</li>
</ul>
<p>ref<br><a href="https://www.zfl9.com/chrony.html" target="_blank" rel="external">chrony时间同步</a><br><a href="https://dywang.csie.cyut.edu.tw/dywang/rhel7/node70.html" target="_blank" rel="external">chronyd 使用</a><br><a href="https://www.server-world.info/en/note?os=CentOS_6&amp;p=ntp&amp;f=3" target="_blank" rel="external">Chrony : Configure NTP Server</a><br><a href="https://my.oschina.net/u/2475751/blog/704375" target="_blank" rel="external">ceph: HEALTH_WARN: Monitor clock skew detected</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。    </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ceph异常警告:&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div cl
    
    </summary>
    
    
  </entry>
  
</feed>
