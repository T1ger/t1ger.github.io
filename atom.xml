<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2020-09-15T14:09:21.039Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="https://t1ger.github.io/2020/09/15/how-to-install-k8s-cluster/"/>
    <id>https://t1ger.github.io/2020/09/15/how-to-install-k8s-cluster/</id>
    <published>2020-09-15T14:09:21.039Z</published>
    <updated>2020-09-15T14:09:21.039Z</updated>
    
    <content type="html"><![CDATA[<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.8.0"><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="date" content="2020-08-15 17:58:55">
<meta name="tags" content=""><style>body {
  max-width: 980px;
  border: 1px solid #ddd;
  outline: 1300px solid #fff;
  margin: 16px auto;
}

body .markdown-body
{
  padding: 45px;
}

@font-face {
  font-family: fontawesome-mini;
  src: url(data:font/woff;charset=utf-8;base64,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) format('woff');
}

.markdown-body {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #333333;
  overflow: hidden;
  font-family: "Helvetica Neue", Helvetica, "Segoe UI", Arial, freesans, sans-serif;
  font-size: 16px;
  line-height: 1.6;
  word-wrap: break-word;
}

.markdown-body a {
  background: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline: 0;
}

.markdown-body b,
.markdown-body strong {
  font-weight: bold;
}

.markdown-body mark {
  background: #ff0;
  color: #000;
  font-style: italic;
  font-weight: bold;
}

.markdown-body sub,
.markdown-body sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
.markdown-body sup {
  top: -0.5em;
}
.markdown-body sub {
  bottom: -0.25em;
}

.markdown-body h1 {
  font-size: 2em;
  margin: 0.67em 0;
}

.markdown-body img {
  border: 0;
}

.markdown-body hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}

.markdown-body pre {
  overflow: auto;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre,
.markdown-body samp {
  font-family: monospace, monospace;
  font-size: 1em;
}

.markdown-body input {
  color: inherit;
  font: inherit;
  margin: 0;
}

.markdown-body html input[disabled] {
  cursor: default;
}

.markdown-body input {
  line-height: normal;
}

.markdown-body input[type="checkbox"] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body .codehilitetable {
  border: 0;
  border-spacing: 0;
}

.markdown-body .codehilitetable tr {
  border: 0;
}

.markdown-body .codehilitetable pre,
.markdown-body .codehilitetable div.codehilite {
  margin: 0;
}

.markdown-body .linenos,
.markdown-body .code,
.markdown-body .codehilitetable td {
  border: 0;
  padding: 0;
}

.markdown-body td:not(.linenos) .linenodiv {
  padding: 0 !important;
}

.markdown-body .code {
  width: 100%;
}

.markdown-body .linenos div pre,
.markdown-body .linenodiv pre,
.markdown-body .linenodiv {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-left-radius: 3px;
  -webkit-border-bottom-left-radius: 3px;
  -moz-border-radius-topleft: 3px;
  -moz-border-radius-bottomleft: 3px;
  border-top-left-radius: 3px;
  border-bottom-left-radius: 3px;
}

.markdown-body .code div pre,
.markdown-body .code div {
  border: 0;
  -webkit-border-radius: 0;
  -moz-border-radius: 0;
  border-radius: 0;
  -webkit-border-top-right-radius: 3px;
  -webkit-border-bottom-right-radius: 3px;
  -moz-border-radius-topright: 3px;
  -moz-border-radius-bottomright: 3px;
  border-top-right-radius: 3px;
  border-bottom-right-radius: 3px;
}

.markdown-body * {
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body input {
  font: 13px Helvetica, arial, freesans, clean, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol";
  line-height: 1.4;
}

.markdown-body a {
  color: #4183c4;
  text-decoration: none;
}

.markdown-body a:hover,
.markdown-body a:focus,
.markdown-body a:active {
  text-decoration: underline;
}

.markdown-body hr {
  height: 0;
  margin: 15px 0;
  overflow: hidden;
  background: transparent;
  border: 0;
  border-bottom: 1px solid #ddd;
}

.markdown-body hr:before,
.markdown-body hr:after {
  display: table;
  content: " ";
}

.markdown-body hr:after {
  clear: both;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-top: 15px;
  margin-bottom: 15px;
  line-height: 1.1;
}

.markdown-body h1 {
  font-size: 30px;
}

.markdown-body h2 {
  font-size: 21px;
}

.markdown-body h3 {
  font-size: 16px;
}

.markdown-body h4 {
  font-size: 14px;
}

.markdown-body h5 {
  font-size: 12px;
}

.markdown-body h6 {
  font-size: 11px;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ul,
.markdown-body ol {
  padding: 0;
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ul ul ol,
.markdown-body ul ol ol,
.markdown-body ol ul ol,
.markdown-body ol ol ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre,
.markdown-body samp {
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #e7e7e7;
  background-image: -moz-linear-gradient(#fefefe, #e7e7e7);
  background-image: -webkit-linear-gradient(#fefefe, #e7e7e7);
  background-image: linear-gradient(#fefefe, #e7e7e7);
  background-repeat: repeat-x;
  border-radius: 2px;
  border: 1px solid #cfcfcf;
  color: #000;
  padding: 3px 5px;
  line-height: 10px;
  font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
  display: inline-block;
}

.markdown-body>*:first-child {
  margin-top: 0 !important;
}

.markdown-body>*:last-child {
  margin-bottom: 0 !important;
}

.markdown-body .headerlink {
  font: normal 400 16px fontawesome-mini;
  vertical-align: middle;
  margin-left: -16px;
  float: left;
  display: inline-block;
  text-decoration: none;
  opacity: 0;
  color: #333;
}

.markdown-body .headerlink:focus {
  outline: none;
}

.markdown-body h1 .headerlink {
  margin-top: 0.8rem;
}

.markdown-body h2 .headerlink,
.markdown-body h3 .headerlink {
  margin-top: 0.6rem;
}

.markdown-body h4 .headerlink {
  margin-top: 0.2rem;
}

.markdown-body h5 .headerlink,
.markdown-body h6 .headerlink {
  margin-top: 0;
}

.markdown-body .headerlink:hover,
.markdown-body h1:hover .headerlink,
.markdown-body h2:hover .headerlink,
.markdown-body h3:hover .headerlink,
.markdown-body h4:hover .headerlink,
.markdown-body h5:hover .headerlink,
.markdown-body h6:hover .headerlink {
  opacity: 1;
  text-decoration: none;
}

.markdown-body h1 {
  padding-bottom: 0.3em;
  font-size: 2.25em;
  line-height: 1.2;
  border-bottom: 1px solid #eee;
}

.markdown-body h2 {
  padding-bottom: 0.3em;
  font-size: 1.75em;
  line-height: 1.225;
  border-bottom: 1px solid #eee;
}

.markdown-body h3 {
  font-size: 1.5em;
  line-height: 1.43;
}

.markdown-body h4 {
  font-size: 1.25em;
}

.markdown-body h5 {
  font-size: 1em;
}

.markdown-body h6 {
  font-size: 1em;
  color: #777;
}

.markdown-body p,
.markdown-body blockquote,
.markdown-body ul,
.markdown-body ol,
.markdown-body dl,
.markdown-body table,
.markdown-body pre,
.markdown-body .admonition {
  margin-top: 0;
  margin-bottom: 16px;
}

.markdown-body hr {
  height: 4px;
  padding: 0;
  margin: 16px 0;
  background-color: #e7e7e7;
  border: 0 none;
}

.markdown-body ul,
.markdown-body ol {
  padding-left: 2em;
}

.markdown-body ul ul,
.markdown-body ul ol,
.markdown-body ol ol,
.markdown-body ol ul {
  margin-top: 0;
  margin-bottom: 0;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  padding: 0;
  margin-top: 16px;
  font-size: 1em;
  font-style: italic;
  font-weight: bold;
}

.markdown-body dl dd {
  padding: 0 16px;
  margin-bottom: 16px;
}

.markdown-body blockquote {
  padding: 0 15px;
  color: #777;
  border-left: 4px solid #ddd;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body table {
  display: block;
  width: 100%;
  overflow: auto;
  word-break: normal;
  word-break: keep-all;
}

.markdown-body table th {
  font-weight: bold;
}

.markdown-body table th,
.markdown-body table td {
  padding: 6px 13px;
  border: 1px solid #ddd;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #ccc;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

.markdown-body img {
  max-width: 100%;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}

.markdown-body code,
.markdown-body samp {
  padding: 0;
  padding-top: 0.2em;
  padding-bottom: 0.2em;
  margin: 0;
  font-size: 85%;
  background-color: rgba(0,0,0,0.04);
  border-radius: 3px;
}

.markdown-body code:before,
.markdown-body code:after {
  letter-spacing: -0.2em;
  content: "\00a0";
}

.markdown-body pre>code {
  padding: 0;
  margin: 0;
  font-size: 100%;
  word-break: normal;
  white-space: pre;
  background: transparent;
  border: 0;
}

.markdown-body .codehilite {
  margin-bottom: 16px;
}

.markdown-body .codehilite pre,
.markdown-body pre {
  padding: 16px;
  overflow: auto;
  font-size: 85%;
  line-height: 1.45;
  background-color: #f7f7f7;
  border-radius: 3px;
}

.markdown-body .codehilite pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre code {
  display: inline;
  max-width: initial;
  padding: 0;
  margin: 0;
  overflow: initial;
  line-height: inherit;
  word-wrap: normal;
  background-color: transparent;
  border: 0;
}

.markdown-body pre code:before,
.markdown-body pre code:after {
  content: normal;
}

/* Admonition */
.markdown-body .admonition {
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  position: relative;
  border-radius: 3px;
  border: 1px solid #e0e0e0;
  border-left: 6px solid #333;
  padding: 10px 10px 10px 30px;
}

.markdown-body .admonition table {
  color: #333;
}

.markdown-body .admonition p {
  padding: 0;
}

.markdown-body .admonition-title {
  font-weight: bold;
  margin: 0;
}

.markdown-body .admonition>.admonition-title {
  color: #333;
}

.markdown-body .attention>.admonition-title {
  color: #a6d796;
}

.markdown-body .caution>.admonition-title {
  color: #d7a796;
}

.markdown-body .hint>.admonition-title {
  color: #96c6d7;
}

.markdown-body .danger>.admonition-title {
  color: #c25f77;
}

.markdown-body .question>.admonition-title {
  color: #96a6d7;
}

.markdown-body .note>.admonition-title {
  color: #d7c896;
}

.markdown-body .admonition:before,
.markdown-body .attention:before,
.markdown-body .caution:before,
.markdown-body .hint:before,
.markdown-body .danger:before,
.markdown-body .question:before,
.markdown-body .note:before {
  font: normal normal 16px fontawesome-mini;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  line-height: 1.5;
  color: #333;
  position: absolute;
  left: 0;
  top: 0;
  padding-top: 10px;
  padding-left: 10px;
}

.markdown-body .admonition:before {
  content: "\f056\00a0";
  color: 333;
}

.markdown-body .attention:before {
  content: "\f058\00a0";
  color: #a6d796;
}

.markdown-body .caution:before {
  content: "\f06a\00a0";
  color: #d7a796;
}

.markdown-body .hint:before {
  content: "\f05a\00a0";
  color: #96c6d7;
}

.markdown-body .danger:before {
  content: "\f057\00a0";
  color: #c25f77;
}

.markdown-body .question:before {
  content: "\f059\00a0";
  color: #96a6d7;
}

.markdown-body .note:before {
  content: "\f040\00a0";
  color: #d7c896;
}

.markdown-body .admonition::after {
  content: normal;
}

.markdown-body .attention {
  border-left: 6px solid #a6d796;
}

.markdown-body .caution {
  border-left: 6px solid #d7a796;
}

.markdown-body .hint {
  border-left: 6px solid #96c6d7;
}

.markdown-body .danger {
  border-left: 6px solid #c25f77;
}

.markdown-body .question {
  border-left: 6px solid #96a6d7;
}

.markdown-body .note {
  border-left: 6px solid #d7c896;
}

.markdown-body .admonition>*:first-child {
  margin-top: 0 !important;
}

.markdown-body .admonition>*:last-child {
  margin-bottom: 0 !important;
}

/* progress bar*/
.markdown-body .progress {
  display: block;
  width: 300px;
  margin: 10px 0;
  height: 24px;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #ededed;
  position: relative;
  box-shadow: inset -1px 1px 3px rgba(0, 0, 0, .1);
}

.markdown-body .progress-label {
  position: absolute;
  text-align: center;
  font-weight: bold;
  width: 100%; margin: 0;
  line-height: 24px;
  color: #333;
  text-shadow: 1px 1px 0 #fefefe, -1px -1px 0 #fefefe, -1px 1px 0 #fefefe, 1px -1px 0 #fefefe, 0 1px 0 #fefefe, 0 -1px 0 #fefefe, 1px 0 0 #fefefe, -1px 0 0 #fefefe, 1px 1px 2px #000;
  -webkit-font-smoothing: antialiased !important;
  white-space: nowrap;
  overflow: hidden;
}

.markdown-body .progress-bar {
  height: 24px;
  float: left;
  -webkit-border-radius: 3px;
  -moz-border-radius: 3px;
  border-radius: 3px;
  background-color: #96c6d7;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, .5), inset 0 -1px 0 rgba(0, 0, 0, .1);
  background-size: 30px 30px;
  background-image: -webkit-linear-gradient(
    135deg, rgba(255, 255, 255, .4) 27%,
    transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%,
    transparent 77%, transparent
  );
  background-image: -moz-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -ms-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: -o-linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
  background-image: linear-gradient(
    135deg,
    rgba(255, 255, 255, .4) 27%, transparent 27%,
    transparent 52%, rgba(255, 255, 255, .4) 52%,
    rgba(255, 255, 255, .4) 77%, transparent 77%,
    transparent
  );
}

.markdown-body .progress-100plus .progress-bar {
  background-color: #a6d796;
}

.markdown-body .progress-80plus .progress-bar {
  background-color: #c6d796;
}

.markdown-body .progress-60plus .progress-bar {
  background-color: #d7c896;
}

.markdown-body .progress-40plus .progress-bar {
  background-color: #d7a796;
}

.markdown-body .progress-20plus .progress-bar {
  background-color: #d796a6;
}

.markdown-body .progress-0plus .progress-bar {
  background-color: #c25f77;
}

.markdown-body .candystripe-animate .progress-bar{
  -webkit-animation: animate-stripes 3s linear infinite;
  -moz-animation: animate-stripes 3s linear infinite;
  animation: animate-stripes 3s linear infinite;
}

@-webkit-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@-moz-keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

@keyframes animate-stripes {
  0% {
    background-position: 0 0;
  }

  100% {
    background-position: 60px 0;
  }
}

.markdown-body .gloss .progress-bar {
  box-shadow:
    inset 0 4px 12px rgba(255, 255, 255, .7),
    inset 0 -12px 0 rgba(0, 0, 0, .05);
}

/* MultiMarkdown Critic Blocks */
.markdown-body .critic_mark {
  background: #ff0;
}

.markdown-body .critic_delete {
  color: #c82829;
  text-decoration: line-through;
}

.markdown-body .critic_insert {
  color: #718c00 ;
  text-decoration: underline;
}

.markdown-body .critic_comment {
  color: #8e908c;
  font-style: italic;
}

.markdown-body .headeranchor {
  font: normal normal 16px fontawesome-mini;
  line-height: 1;
  display: inline-block;
  text-decoration: none;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}

.headeranchor:before {
  content: '\e157';
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 4px 0.25em -20px;
  vertical-align: middle;
}

/* Media */
@media only screen and (min-width: 480px) {
  .markdown-body {
    font-size:14px;
  }
}

@media only screen and (min-width: 768px) {
  .markdown-body {
    font-size:16px;
  }
}

@media print {
  .markdown-body * {
    background: transparent !important;
    color: black !important;
    filter:none !important;
    -ms-filter: none !important;
  }

  .markdown-body {
    font-size:12pt;
    max-width:100%;
    outline:none;
    border: 0;
  }

  .markdown-body a,
  .markdown-body a:visited {
    text-decoration: underline;
  }

  .markdown-body .headeranchor-link {
    display: none;
  }

  .markdown-body a[href]:after {
    content: " (" attr(href) ")";
  }

  .markdown-body abbr[title]:after {
    content: " (" attr(title) ")";
  }

  .markdown-body .ir a:after,
  .markdown-body a[href^="javascript:"]:after,
  .markdown-body a[href^="#"]:after {
    content: "";
  }

  .markdown-body pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  .markdown-body pre,
  .markdown-body blockquote {
    border: 1px solid #999;
    padding-right: 1em;
    page-break-inside: avoid;
  }

  .markdown-body .progress,
  .markdown-body .progress-bar {
    -moz-box-shadow: none;
    -webkit-box-shadow: none;
    box-shadow: none;
  }

  .markdown-body .progress {
    border: 1px solid #ddd;
  }

  .markdown-body .progress-bar {
    height: 22px;
    border-right: 1px solid #ddd;
  }

  .markdown-body tr,
  .markdown-body img {
    page-break-inside: avoid;
  }

  .markdown-body img {
    max-width: 100% !important;
  }

  .markdown-body p,
  .markdown-body h2,
  .markdown-body h3 {
    orphans: 3;
    widows: 3;
  }

  .markdown-body h2,
  .markdown-body h3 {
    page-break-after: avoid;
  }
}
</style><style>/*GitHub*/
.codehilite {background-color:#fff;color:#333333;}
.codehilite .hll {background-color:#ffffcc;}
.codehilite .c{color:#999988;font-style:italic}
.codehilite .err{color:#a61717;background-color:#e3d2d2}
.codehilite .k{font-weight:bold}
.codehilite .o{font-weight:bold}
.codehilite .cm{color:#999988;font-style:italic}
.codehilite .cp{color:#999999;font-weight:bold}
.codehilite .c1{color:#999988;font-style:italic}
.codehilite .cs{color:#999999;font-weight:bold;font-style:italic}
.codehilite .gd{color:#000000;background-color:#ffdddd}
.codehilite .ge{font-style:italic}
.codehilite .gr{color:#aa0000}
.codehilite .gh{color:#999999}
.codehilite .gi{color:#000000;background-color:#ddffdd}
.codehilite .go{color:#888888}
.codehilite .gp{color:#555555}
.codehilite .gs{font-weight:bold}
.codehilite .gu{color:#800080;font-weight:bold}
.codehilite .gt{color:#aa0000}
.codehilite .kc{font-weight:bold}
.codehilite .kd{font-weight:bold}
.codehilite .kn{font-weight:bold}
.codehilite .kp{font-weight:bold}
.codehilite .kr{font-weight:bold}
.codehilite .kt{color:#445588;font-weight:bold}
.codehilite .m{color:#009999}
.codehilite .s{color:#dd1144}
.codehilite .n{color:#333333}
.codehilite .na{color:teal}
.codehilite .nb{color:#0086b3}
.codehilite .nc{color:#445588;font-weight:bold}
.codehilite .no{color:teal}
.codehilite .ni{color:purple}
.codehilite .ne{color:#990000;font-weight:bold}
.codehilite .nf{color:#990000;font-weight:bold}
.codehilite .nn{color:#555555}
.codehilite .nt{color:navy}
.codehilite .nv{color:teal}
.codehilite .ow{font-weight:bold}
.codehilite .w{color:#bbbbbb}
.codehilite .mf{color:#009999}
.codehilite .mh{color:#009999}
.codehilite .mi{color:#009999}
.codehilite .mo{color:#009999}
.codehilite .sb{color:#dd1144}
.codehilite .sc{color:#dd1144}
.codehilite .sd{color:#dd1144}
.codehilite .s2{color:#dd1144}
.codehilite .se{color:#dd1144}
.codehilite .sh{color:#dd1144}
.codehilite .si{color:#dd1144}
.codehilite .sx{color:#dd1144}
.codehilite .sr{color:#009926}
.codehilite .s1{color:#dd1144}
.codehilite .ss{color:#990073}
.codehilite .bp{color:#999999}
.codehilite .vc{color:teal}
.codehilite .vg{color:teal}
.codehilite .vi{color:teal}
.codehilite .il{color:#009999}
.codehilite .gc{color:#999;background-color:#EAF2F5}
</style><title>how to install k8s cluster</title></head><body><article class="markdown-body"><h5 id="_1">环境和版本说明<a class="headerlink" href="#_1" title="Permanent link"></a></h5>
<p>系统： CentOS Linux release 7.8.2003 (Core)
etcd: etcd-v3.4.7
k8s:  v1.18.6
Calico: v3.15.1
docker: docker-ce-19.03
负载均衡生产一般建议采用阿里云slb，测试环境可以使用nginx代替
service-cluster-ip 10.10.0.0/16
pods-ip 10.20.0.0/16 
集群dns  10.10.0.2
k8s svc 10.10.0.1
集群使用默认 svc.cluster.local
<div class="codehilite"><pre>[root@master01 ~]# kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.10.0.1    &lt;none&gt;        443/TCP   33h
</pre></div></p>
<p>master和etcd在同一台主机上
<div class="codehilite"><pre>master01   192.168.1.101    kube-apiserver kube-controller-manager kube-scheduler
master02   192.168.1.102    kube-apiserver kube-controller-manager kube-scheduler
master03   192.168.1.103    kube-apiserver kube-controller-manager kube-scheduler
slb   　　　192.168.1.31     nginx
node1      192.168.1.104    kubelet kube-proxy  calico
node2      192.168.1.105    kubelet kube-proxy  calico
node3      192.168.1.106    kubelet kube-proxy  calico
</pre></div></p>
<h4 id="_2">初始化<a class="headerlink" href="#_2" title="Permanent link"></a></h4>
<p>升级内核
<div class="codehilite"><pre>rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm
yum --enablerepo=elrepo-kernel install -y kernel-lt
#查看可用内核
cat /boot/grub2/grub.cfg |grep menuentry
#设置开机从新内核启动
grub2-set-default &quot;CentOS Linux (4.4.232-1.el7.elrepo.x86_64) 7 (Core)&quot;
#查看内核启动项
grub2-editenv list
#重启系统使内核生效
reboot
#查看内核版本是否生效
uname -r
</pre></div></p>
<p>初始化系统
<div class="codehilite"><pre>systemctl stop firewalld
systemctl disable firewalld
swapoff -a 
sed -i &#39;s/.*swap.*/#&amp;/&#39; /etc/fstab
setenforce  0 
sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux 
sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config
sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux
sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config

# 将桥接的IPv4流量传递到iptables的链
cat&gt;/etc/sysctl.d/k8s.conf&lt;&lt; EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1１
net.ipv6.conf.all.disable_ipv6=１
net.ipv6.conf.default.disable_ipv6=1
net.ipv6.conf.lo.disable_ipv6=1
net.ipv6.conf.all.forwarding=1
net.ipv4.ip_forward=1
vm.swappiness=0
EOF
sysctl --system  # 生效

yum install -y yum-utils
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
yum install -y docker-ce docker-ce-cli containerd.io
systemctl enable docker &amp;&amp; systemctl start docker
</pre></div></p>
<h5 id="etcd">部署etcd集群<a class="headerlink" href="#etcd" title="Permanent link"></a></h5>
<p>在部署之前先自签证书，参考上一篇
<div class="codehilite"><pre>mkdir /data/etcd/ -p
mkdir /opt/kubernetes/{bin,cfg,ssl}  -p
cd /data/etcd/
wget https://github.com/etcd-io/etcd/releases/download/v3.4.7/etcd-v3.4.7-linux-amd64.tar.gz
tar zxvf etcd-v3.4.7-linux-amd64.tar.gz
cd etcd-v3.4.7-linux-amd64
cp -a etcd etcdctl /opt/kubernetes/bin/
echo &#39;export PATH=$PATH:/opt/kubernetes/bin&#39; &gt;&gt; /etc/profile
source /etc/profile
</pre></div>
分发证书，并依次在master01,master02,master03执行,并注意替换相应ip
<div class="codehilite"><pre>[root@master01 etcd]# cat etcd.sh 
#!/bin/bash
ETCD_NAME=${1:-&quot;etcd01&quot;}
ETCD_IP=${2:-&quot;127.0.0.1&quot;}
ETCD_CLUSTER=${3:-&quot;etcd01=https://127.0.0.1:2379&quot;}

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/etcd.yml
name: ${ETCD_NAME}
data-dir: /var/lib/etcd/default.etcd
listen-peer-urls: https://${ETCD_IP}:2380
listen-client-urls: https://${ETCD_IP}:2379,https://127.0.0.1:2379
advertise-client-urls: https://${ETCD_IP}:2379
initial-advertise-peer-urls: https://${ETCD_IP}:2380
initial-cluster: ${ETCD_CLUSTER}
initial-cluster-token: etcd-cluster
initial-cluster-state: new
client-transport-security:
  cert-file: /opt/kubernetes/ssl/server.pem
  key-file: /opt/kubernetes/ssl/server-key.pem
  client-cert-auth: false
  trusted-ca-file: /opt/kubernetes/ssl/ca.pem
  auto-tls: false
peer-transport-security:
  cert-file: /opt/kubernetes/ssl/server.pem
  key-file: /opt/kubernetes/ssl/server-key.pem
  client-cert-auth: false
  trusted-ca-file: /opt/kubernetes/ssl/ca.pem
  auto-tls: false
debug: false
logger: zap
log-outputs: [stderr]
EOF

cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/etcd.service
[Unit]
Description=Etcd Server
Documentation=https://github.com/etcd-io/etcd
Conflicts=etcd.service
After=network.target
After=network-online.target
Wants=network-online.target

[Service]
Type=notify
LimitNOFILE=65536
Restart=on-failure
RestartSec=5s
TimeoutStartSec=0
ExecStart=/opt/kubernetes/bin/etcd --config-file=/opt/kubernetes/cfg/etcd.yml

[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable etcd
systemctl restart etcd

#master01
./etcd.sh etcd01 192.168.1.101 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380

#master02
./etcd.sh etcd02 192.168.1.102 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380

#master03
./etcd.sh etcd03 192.168.1.103 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380


#健康状态
[root@master01 etcd]# /opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 endpoint status
https://192.168.1.101:2379, f592173020929e13, 3.4.7, 1.8 MB, false, false, 19, 53478, 53478, 
https://192.168.1.102:2379, 4eb9518f73eaf60f, 3.4.7, 1.8 MB, false, false, 19, 53478, 53478, 
https://192.168.1.103:2379, 2123e126fcaeb456, 3.4.7, 1.8 MB, true, false, 19, 53478, 53478, 

＃写入foo
/opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 put foo &quot;Hello World&quot;
#取出foo
[root@master02 ~]# /opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 get foo
foo
Hello World
</pre></div></p>
<h5 id="k8s">k8s安装<a class="headerlink" href="#k8s" title="Permanent link"></a></h5>
<p>K8S二进制包
<div class="codehilite"><pre>mkdir /data/k8s-package
cd /data/k8s-package
wget https://dl.k8s.io/v1.18.6/kubernetes-server-linux-amd64.tar.gz
tar xf kubernetes-server-linux-amd64.tar.gz
cd /data/k8s-package/kubernetes/server/bin
cp -a kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy /opt/kubernetes/bin

# copy 执行文件到 master02 master03 机器 /opt/kubernetes/bin
scp kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy root@master02:/opt/kubernetes/bin/
scp kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy root@master03:/opt/kubernetes/bin/
</pre></div>
创建Node节点kubeconfig文件
<div class="codehilite"><pre>[root@master01 ~]# cat /data/ssl/kubeconfig.sh 
export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &#39; &#39;)
cat&gt;token.csv&lt;&lt;EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;
EOF

export KUBE_APISERVER=&quot;https://lb.abc.com.cn:6443&quot;

kubectl config set-cluster kubernetes \
  --certificate-authority=./ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=bootstrap.kubeconfig

kubectl config set-credentials kubelet-bootstrap \
  --token=${BOOTSTRAP_TOKEN} \
  --kubeconfig=bootstrap.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kubelet-bootstrap \
  --kubeconfig=bootstrap.kubeconfig

kubectl config use-context default --kubeconfig=bootstrap.kubeconfig



kubectl -n kube-system create serviceaccount kube-proxy
kubectl create clusterrolebinding system:kube-proxy --clusterrole system:node-proxier --serviceaccount kube-system:kube-proxy

kubectl config set-cluster kubernetes \
  --certificate-authority=./ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-credentials kube-proxy \
  --client-certificate=./kube-proxy.pem \
  --client-key=./kube-proxy-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config set-context default \
  --cluster=kubernetes \
  --user=kube-proxy \
  --kubeconfig=kube-proxy.kubeconfig

kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig

#sh kubeconfig.sh
#cp *kubeconfig /opt/kubernetes/cfg
#scp *kubeconfig root@master02:/opt/kubernetes/cfg
#scp *kubeconfig root@master03:/opt/kubernetes/cfg
</pre></div></p>
<p>配置master组件
<div class="codehilite"><pre>mkdir /data/k8s-master
[root@master01 k8s-master]# cat apiserver.sh 
#!/bin/bash

MASTER_ADDRESS=${1:-&quot;192.168.1.101&quot;}
ETCD_SERVERS=${2:-&quot;https://127.0.0.1:2379&quot;}

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-apiserver
KUBE_APISERVER_OPTS=&quot;--logtostderr=false \\
--v=2 \\
--log-dir=/var/log/kubernetes \\
--etcd-servers=${ETCD_SERVERS} \\
--bind-address=0.0.0.0 \\
--secure-port=6443 \\
--advertise-address=${MASTER_ADDRESS} \\
--allow-privileged=true \\
--service-cluster-ip-range=10.10.0.0/16 \\
--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction \\
--authorization-mode=Node,RBAC \\
--kubelet-https=true \\
--enable-bootstrap-token-auth=true \\
--token-auth-file=/opt/kubernetes/cfg/token.csv \\
--service-node-port-range=30000-50000 \\
--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\
--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\
--tls-cert-file=/opt/kubernetes/ssl/server.pem \\
--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\
--client-ca-file=/opt/kubernetes/ssl/ca.pem \\
--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\
--etcd-cafile=/opt/kubernetes/ssl/ca.pem \\
--etcd-certfile=/opt/kubernetes/ssl/server.pem \\
--etcd-keyfile=/opt/kubernetes/ssl/server-key.pem \\
--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\
--requestheader-extra-headers-prefix=X-Remote-Extra- \\
--requestheader-group-headers=X-Remote-Group \\
--requestheader-username-headers=X-Remote-User \\
--proxy-client-cert-file=/opt/kubernetes/ssl/metrics-server.pem \\
--proxy-client-key-file=/opt/kubernetes/ssl/metrics-server-key.pem \\
--runtime-config=api/all=true \\
--audit-log-maxage=30 \\
--audit-log-maxbackup=3 \\
--audit-log-maxsize=100 \\
--audit-log-truncate-enabled=true \\
--audit-log-path=/var/log/kubernetes/k8s-audit.log&quot;
EOF


cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-apiserver.service
[Unit]
Description=Kubernetes API Server
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserver
ExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTS
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF


systemctl daemon-reload
systemctl enable kube-apiserver
systemctl restart kube-apiserver



[root@master01 k8s-master]# cat controller-manager.sh 
#!/bin/bash

MASTER_ADDRESS=${1:-&quot;127.0.0.1&quot;}

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-controller-manager

KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=true \\
--v=2 \\
--master=${MASTER_ADDRESS}:8080 \\
--leader-elect=true \\
--bind-address=0.0.0.0 \\
--service-cluster-ip-range=10.10.0.0/16 \\
--cluster-name=kubernetes \\
--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\
--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\
--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\
--experimental-cluster-signing-duration=87600h0m0s \\
--feature-gates=RotateKubeletServerCertificate=true \\
--feature-gates=RotateKubeletClientCertificate=true \\
--allocate-node-cidrs=true \\
--cluster-cidr=10.20.0.0/16 \\
--root-ca-file=/opt/kubernetes/ssl/ca.pem&quot;
EOF

cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-controller-manager.service
[Unit]
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-manager
ExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable kube-controller-manager
systemctl restart kube-controller-manager


[root@master01 k8s-master]# cat scheduler.sh 
#!/bin/bash

MASTER_ADDRESS=${1:-&quot;127.0.0.1&quot;}

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-scheduler
KUBE_SCHEDULER_OPTS=&quot;--logtostderr=true \\
--v=2 \\
--master=${MASTER_ADDRESS}:8080 \\
--address=0.0.0.0 \\
--leader-elect&quot;
EOF

cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-scheduler.service
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-scheduler
ExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable kube-scheduler
systemctl restart kube-scheduler

#分发token.csv,依次在master01 master02 master03执行相应的脚本
#master01
./apiserver.sh 192.168.1.101 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1
./scheduler.sh 127.0.0.1

#master02
./apiserver.sh 192.168.1.102 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1
./scheduler.sh 127.0.0.1

#master03
./apiserver.sh 192.168.1.103 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1
./scheduler.sh 127.0.0.1

[root@master01 k8s-master]# ps -ef | grep kube
root      4148     1  3 17:50 ?        00:01:24 /opt/kubernetes/bin/etcd --config-file=/opt/kubernetes/cfg/etcd.yml
root      4174     1  3 17:50 ?        00:01:22 /opt/kubernetes/bin/kube-apiserver --logtostderr=false --v=2 --log-dir=/var/log/kubernetes --etcd-servers=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 --bind-address=0.0.0.0 --secure-port=6443 --advertise-address=192.168.1.101 --allow-privileged=true --service-cluster-ip-range=10.10.0.0/16 --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction --authorization-mode=RBAC,Node --kubelet-https=true --enable-bootstrap-token-auth=true --token-auth-file=/opt/kubernetes/cfg/token.csv --service-node-port-range=30000-50000 --kubelet-client-certificate=/optkubernetes/ssl/server.pem --kubelet-client-key=/opt/kubernetes/ssl/server.pem --tls-cert-file=/opt/kubernetes/ssl/server.pem --tls-private-key-file=/opt/kubernetes/ssl/server-key.pem --client-ca-file=/opt/kubernetes/ssl/ca.pem --service-account-key-file=/opt/kubernetes/ssl/ca-key.pem --etcd-cafile=/opt/kubernetes/ssl/ca.pem --etcd-certfile=/opt/kubernetes/ssl/server.pem --etcd-keyfile=/optkubernetes/ssl/server-key.pem --requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --proxy-client-cert-file=/opt/kubernetes/ssl/metrics-server.pem --proxy-client-key-file=/opt/kubernetes/ssl/metrics-server-key.pem --runtime-config=api/all=true --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-truncate-enabled=true --audit-log-path=/var/logkubernetes/k8s-audit.log
root      4281     1  0 17:52 ?        00:00:04 /opt/kubernetes/bin/kube-controller-manager --logtostderr=true --v=2 --master=127.0.0.1:8080 --leader-elect=true --bind-address=0.0.0.0 --service-cluster-ip-range=10.10.0.0/16 --cluster-name=kubernetes --cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem --cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem --service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem --experimental-cluster-signing-duration=87600h0m0s --feature-gates=RotateKubeletServerCertificate=true --feature-gates=RotateKubeletClientCertificate=true --allocate-node-cidrs=true --cluster-cidr=10.20.0.0/16 --root-ca-file=/opt/kubernetes/ssl/ca.pem
root      4302     1  0 17:52 ?        00:00:05 /opt/kubernetes/bin/kube-scheduler --logtostderr=true --v=2 --master=127.0.0.1:8080 --address=0.0.0.0 --leader-elect

#查看写入etcd内容，用于排查错误
/opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 get /registry/ --prefix --keys-only


[root@master01 k8s-master]# kubectl  get cs
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok                  
controller-manager   Healthy   ok                  
etcd-1               Healthy   {&quot;health&quot;:&quot;true&quot;}   
etcd-2               Healthy   {&quot;health&quot;:&quot;true&quot;}   
etcd-0               Healthy   {&quot;health&quot;:&quot;true&quot;}   

[root@master01 k8s-master]# kubectl cluster-info
Kubernetes master is running at http://localhost:8080

To further debug and diagnose cluster problems, use &#39;kubectl cluster-info dump&#39;.
</pre></div></p>
<h5 id="nginx">nginx相关配置<a class="headerlink" href="#nginx" title="Permanent link"></a></h5>
<p>开启tcp代理
<div class="codehilite"><pre>stream{
log_format proxy &#39;$remote_addr [$time_local] &#39;
                     &#39;$protocol $status $bytes_sent $bytes_received &#39;
                     &#39;$session_time &quot;$upstream_addr&quot; &#39;
                     &#39;&quot;$upstream_bytes_sent&quot; &quot;$upstream_bytes_received&quot; &quot;$upstream_connect_time&quot;&#39;;
upstream k8s-apiserver {
        hash $remote_addr consistent;
        server 192.168.1.101:6443;
        server 192.168.1.102:6443;
        server 192.168.1.103:6443;
       }
server {
        listen 6443;
        proxy_pass k8s-apiserver;                                                       
        access_log logs/apiserver.log proxy;
   }
}
</pre></div></p>
<h5 id="kubeletnode">kubelet证书自动续期和创建Node授权用户<a class="headerlink" href="#kubeletnode" title="Permanent link"></a></h5>
<p>Node节点 授权用户 kubelet-bootstrap
<div class="codehilite"><pre>kubectl create clusterrolebinding  kubelet-bootstrap --clusterrole=system:node-bootstrapper  --user=kubelet-bootstrap
</pre></div></p>
<p>具有自动批准 selfnodeserver 类型 CSR 请求的能力
<div class="codehilite"><pre>[root@master01 kubelet-certificate-rotating]# cat tls-instructs-csr.yaml 
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata: 
  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver
rules:
- apiGroups: [&quot;certificates.k8s.io&quot;]
  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]
  verbs: [&quot;create&quot;]


kubectl apply -f tls-instructs-csr.yaml

#自动批准 kubelet-bootstrap 用户 TLS bootstrapping 首次申请证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-approve-csr --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --user=kubelet-bootstrap

#自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求
kubectl create clusterrolebinding node-client-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes


#自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求
kubectl create clusterrolebinding node-server-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes


[root@master01 kubelet-certificate-rotating]# kubectl get clusterrolebinding|egrep &quot;node-(.*)-auto&quot;
node-client-auto-approve-csr                           ClusterRole/system:certificates.k8s.io:certificatesigningrequests:nodeclient       2m4s
node-client-auto-renew-crt                             ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeclient   109s
node-server-auto-renew-crt                             ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeserver   93s
</pre></div></p>
<h5 id="node">配置Node组件并运行<a class="headerlink" href="#node" title="Permanent link"></a></h5>
<p><div class="codehilite"><pre>mkdir /data/k8s-node
cd /data/k8s-node/

[root@node01 k8s-node]# cat kubelet.sh 
#!/bin/bash
#create static pod directory
mkdir -p /etc/kubernetes/manifests

DNS_SERVER_IP=${1:-&quot;10.10.0.2&quot;}
HOSTNAME=${2:-&quot;`hostname`&quot;}
CLUETERDOMAIN=${3:-&quot;cluster.local&quot;}
cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kubelet.conf
KUBELET_OPTS=&quot;--logtostderr=false \\
--v=2 \\
--hostname-override=${HOSTNAME} \\
--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\
--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\
--config=/opt/kubernetes/cfg/kubelet-config.yml \\
--cert-dir=/opt/kubernetes/ssl \\
--network-plugin=cni \\
--cni-conf-dir=/etc/cni/net.d \\
--cni-bin-dir=/opt/cni/bin \\
--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2&quot;
EOF

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kubelet-config.yml
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 0s
    enabled: true
  x509:
    clientCAFile: /opt/kubernetes/ssl/ca.pem
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
clusterDNS:
- ${DNS_SERVER_IP}
clusterDomain: ${CLUETERDOMAIN}
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
rotateCertificates: true
runtimeRequestTimeout: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s
featureGates: 
  RotateKubeletServerCertificate: true
  RotateKubeletClientCertificate: true
EOF

cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kubelet.service
[Unit]
Description=Kubernetes Kubelet
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kubelet.conf
ExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTS
Restart=on-failure
KillMode=process
RestartSec=10
[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable kubelet
systemctl restart kubelet



[root@node01 k8s-node]# cat proxy.sh 
#!/bin/bash

HOSTNAME=${1:-&quot;`hostname`&quot;}

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-proxy.conf
KUBE_PROXY_OPTS=&quot;--logtostderr=true \\
--v=2 \\
--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;
EOF

cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-proxy-config.yml
apiVersion: kubeproxy.config.k8s.io/v1alpha1
bindAddress: 0.0.0.0
clientConnection:
  acceptContentTypes: &quot;&quot;
  burst: 0
  contentType: &quot;&quot;
  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig
  qps: 0
clusterCIDR: 10.20.0.0/16
configSyncPeriod: 0s
conntrack:
  maxPerCore: null
  min: null
  tcpCloseWaitTimeout: null
  tcpEstablishedTimeout: null
enableProfiling: false
healthzBindAddress: &quot;&quot;
hostnameOverride: ${HOSTNAME}
iptables:
  masqueradeAll: false
  masqueradeBit: null
  minSyncPeriod: 0s
  syncPeriod: 0s
ipvs:
  excludeCIDRs: null
  minSyncPeriod: 0s
  scheduler: &quot;&quot;
  strictARP: false
  syncPeriod: 0s
kind: KubeProxyConfiguration
metricsBindAddress: &quot;&quot;
mode: &quot;ipvs&quot;
nodePortAddresses: null
oomScoreAdj: null
portRange: &quot;&quot;
udpIdleTimeout: 0s
winkernel:
  enableDSR: false
  networkName: &quot;&quot;
  sourceVip: &quot;&quot;
EOF

cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-proxy.service
[Unit]
Description=Kubernetes Proxy
After=network.target
[Service]
EnvironmentFile=-/opt/kubernetes/cfg/kube-proxy.conf
ExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF

systemctl daemon-reload
systemctl enable kube-proxy
systemctl restart kube-proxy

#node01
./kubelet.sh 10.10.0.2 node01 cluster.local
./proxy.sh 
#node02
./kubelet.sh 10.10.0.2 node02 cluster.local
./proxy.sh 
#node03
./kubelet.sh 10.10.0.2 node03 cluster.local
./proxy.sh 

#在任意master查看
[root@master01 k8s-node]# kubectl get node
NAME     STATUS     ROLES    AGE   VERSION
node01   NotReady   &lt;none&gt;   13h   v1.18.6
node02   NotReady   &lt;none&gt;   27m   v1.18.6
node03   NotReady   &lt;none&gt;   27m   v1.18.6
</pre></div>
节点处理 NoReady 状态，是因为目前还没有安装网络组件</p>
<p>解决无法查询pods日志问题
<div class="codehilite"><pre>[root@master01 yaml]# cat rbac/apiserver-to-kubelet-rbac.yml 
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: kubelet-api-admin
subjects: 
- kind: User
  name: kubernetes
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: system:kubelet-api-admin
  apiGroup: rbac.authorization.k8s.io

kubectl apply -f ~/yaml/rbac/apiserver-to-kubelet-rbac.yml
</pre></div></p>
<p>RBAC DENY解决办法
<div class="codehilite"><pre>I0905 16:15:47.988359   22403 rbac.go:119] RBAC DENY: user &quot;system:node:node01&quot; groups [&quot;system:nodes&quot; &quot;system:authenticated&quot;] cannot &quot;update&quot; resource &quot;leases.coordination.k8s.io&quot; named &quot;node01&quot; in namespace &quot;kube-node-lease&quot;
解决方法1
[root@master01 kubernetes]# kubectl describe clusterrolebindings system:node  
Name:         system:node
Labels:       kubernetes.io/bootstrapping=rbac-defaults
Annotations:  rbac.authorization.kubernetes.io/autoupdate: true
Role:
  Kind:  ClusterRole
  Name:  system:node
Subjects:
  Kind  Name  Namespace
  ----  ----  ---------

[root@master01 metrics]# kubectl create clusterrolebinding kubelet-node-clusterbinding --clusterrole=system:node --group=system:nodes  
clusterrolebinding.rbac.authorization.k8s.io/kubelet-node-clusterbinding created
[root@master01 metrics]# kubectl describe clusterrolebindings kubelet-node-clusterbinding  
Name:         kubelet-node-clusterbinding
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;
Role:
  Kind:  ClusterRole
  Name:  system:node
Subjects:
  Kind   Name          Namespace
  ----   ----          ---------
  Group  system:nodes  

解决方法2
参考[这里](https://github.com/kubernetes/kubernetes/issues/61511)
Ensure Node authorization comes first in the authorizer mode arguments:

--authorization-mode=Node,RBAC

If you reverse those, RBAC will attempt to authorize, fail and log, then the Node authorizer will succeed. The RBAC message is harmless in this case, but is annoying.

Don&#39;t grant the system:node role to the system:nodes group or you will undo the protection of the Node authorizer.
</pre></div></p>
<h5 id="kubernetesipvs">kubernetes启用ipvs,在所有节点执行<a class="headerlink" href="#kubernetesipvs" title="Permanent link"></a></h5>
<div class="codehilite"><pre>yum -y install ipvsadm

cat&lt;&lt;EOF&gt;/etc/sysconfig/modules/ipvs.modules 
#!/bin/bash
ipvs_modules_dir=&quot;/usr/lib/modules/\`uname -r\`/kernel/net/netfilter/ipvs&quot;
for i in \`ls \$ipvs_modules_dir | sed  -r &#39;s#(.*).ko.xz#\1#&#39;\`; do
    /sbin/modinfo -F filename \$i  &amp;&gt; /dev/null
    if [ \$? -eq 0 ]; then
        /sbin/modprobe \$i
    fi
done
EOF

chmod +x /etc/sysconfig/modules/ipvs.modules 
bash /etc/sysconfig/modules/ipvs.modules
</pre></div>

<h5 id="flannel-calico">网络部署,(Flannel &amp;&amp; calico)任选其一<a class="headerlink" href="#flannel-calico" title="Permanent link"></a></h5>
<p>Calico网络方式
* IPIP
是把一个IP数据包又套在一个IP包里，即把 IP 层封装到 IP 层的一个 tunnel,作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需 IP，而这个 ipip 则是通过两端的路由做一个 tunnel，把两个本来不通的网络通过点对点连接起来。ipip 的源代码在内核 net/ipv4/ipip.c 中可以找到
* BGP
边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护IP路由表或‘前缀’表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。BGP，通俗的讲就是讲接入到机房的多条线路（如电信、联通、移动等）融合为一体，实现多线单IP，BGP 机房的优点：服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其它技术指标来确定的，不会占用服务器的任何系统</p>
<p>Calico 的核心组件：
* Felix，Calico agent，跑在每台需要运行 workload 的节点上，主要负责配置路由及 ACLs 等信息来确保 endpoint 的连通状态；
* etcd，分布式键值存储，主要负责网络元数据一致性，确保 Calico 网络状态的准确性；
* BGP Client(BIRD), 主要负责把 Felix 写入 kernel 的路由信息分发到当前 Calico 网络，确保 workload 间的通信的有效性；</p>
<p>BGP Route Reflector(BIRD), 大规模部署时使用，摒弃所有节点互联的 mesh 模式，通过一个或者多个BGP Route Reflector来完成集中式的路由分发；
通过将整个互联网的可扩展 IP 网络原则压缩到数据中心级别，Calico 在每一个计算节点利用Linux kernel实现了一个高效的vRouter来负责数据转发而每个vRouter通过BGP
协议负责把自己上运行的 workload 的路由信息像整个 Calico 网络内传播 － 小规模部署可以直接互联，大规模下可通过指定的
BGP route reflector 来完成。这样保证最终所有的 workload 之间的数据流量都是通过 IP 包的方式完成互联的。</p>
<p>当容器创建时，calico为容器生成veth pair，一端作为容器网卡加入到容器的网络命名空间，并设置IP和掩码，一端直接暴露在宿主机上，
并通过设置路由规则，将容器IP暴露到宿主机的通信路由上。于此同时，calico为每个主机分配了一段子网作为容器可分配的IP范围，这样就可以根据子网的
CIDR为每个主机生成比较固定的路由规则。
当容器需要跨主机通信时，主要经过下面的简单步骤：
1）容器流量通过veth pair到达宿主机的网络命名空间上。
2）根据容器要访问的IP所在的子网CIDR和主机上的路由规则，找到下一跳要到达的宿主机IP。
3）流量到达下一跳的宿主机后，根据当前宿主机上的路由规则，直接到达对端容器的veth pair插在宿主机的一端，最终进入容器。</p>
<p>从上面的通信过程来看，跨主机通信时，整个通信路径完全没有使用NAT或者UDP封装，性能上的损耗确实比较低。但正式由于calico的通信机制是完全基于三层的，这种机制也带来了一些缺陷，例如：
1）calico目前只支持TCP、UDP、ICMP、ICMPv6协议，如果使用其他四层协议（例如NetBIOS协议），建议使用weave、原生overlay等其他overlay网络实现
2）基于三层实现通信，在二层上没有任何加密包装，因此只能在私有的可靠网络上使用。
3）流量隔离基于iptables实现，并且从etcd中获取需要生成的隔离规则，有一些性能上的隐患</p>
<p>calico/nodedocker容器运行在k8s的master和每个node节点上。由于它包含用于calico路由的BGPagent
calico-cni插件与kubelet组件一起部署在每个node节点上，用于当pod创建后，添加该pod到calico网路
calico/kube-policy-controller运行在k8s的pod里</p>
<div class="codehilite"><pre>配置NetworkManager
NetworkManager管理默认网络命名空间中接口的路由表的功能，可能会干扰Calico正确处理网络路由的能力。
创建一个配置文件/etc/NetworkManager/conf.d/calico.conf，来制止这种干扰：
[keyfile]
unmanaged-devices=interface-name:cali*;interface-name:tunl*



#node上执行
mkdir /opt/cni/bin /etc/cni/net.d -p
wget https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz
tar xvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin/

#以下在master01上执行
mkdir -p ~/yaml/calico$ cd ~/yaml/calico
# 注意：下面是基于自建etcd做为存储的配置文件
curl https://docs.projectcalico.org/manifests/calico-etcd.yaml -O
</pre></div>

<p>calico-etcd.yaml需要修改如下配置
<div class="codehilite"><pre>#Secret 配置修改
apiVersion: v1
kind: Secrettype: Opaque
metadata:  
  name: calico-etcd-secrets
  namespace: kube-system
data:  
  etcd-key: (cat /opt/kubernetes/ssl/server-key.pem | base64 -w 0) # 将输出结果填写在这里
  etcd-cert: (cat /opt/kubernetes/ssl/server.pem | base64 -w 0) # 将输出结果填写在这里
  etcd-ca: (cat /opt/kubernetes/ssl/ca.pem | base64 -w 0) # 将输出结果填写在这里


#ConfigMap 配置修改
# You must also populate the Secret below with these files.
etcd_ca: &quot;/calico-secrets/etcd-ca&quot;
etcd_cert: &quot;/calico-secrets/etcd-cert&quot;
etcd_key: &quot;/calico-secrets/etcd-key

#配置网卡自动发现规则
- name: IP_AUTODETECTION_METHOD
  value: &quot;interface=eth.*&quot;
- name: IP6_AUTODETECTION_METHOD
  value: &quot;interface=eth.*&quot;
- name: KUBERNETES_SERVICE_HOST
  value: &quot;lb.abc.com.cn&quot;
- name: KUBERNETES_SERVICE_PORT
  value: &quot;6443&quot;
- name: KUBERNETES_SERVICE_PORT_HTTPS
  value: &quot;6443&quot;

#检查Calico 模式设置，默认为ipip
- name: CALICO_IPV4POOL_IPIP
　value: &quot;Always

[root@master01 calico]# kubectl apply -f calico-etcd.yaml
secret/calico-etcd-secrets created
configmap/calico-config created
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created
clusterrole.rbac.authorization.k8s.io/calico-node created
clusterrolebinding.rbac.authorization.k8s.io/calico-node created
daemonset.apps/calico-node created
serviceaccount/calico-node created
deployment.apps/calico-kube-controllers created
serviceaccount/calico-kube-controllers created

#这里需要注意,如果calico-kube-controllers报如下错误，需要在service里env添加KUBERNETES_SERVICE_HOST和KUBERNETES_SERVICE_PORT环境变量

E0820 02:39:51.732885       1 reflector.go:153] pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/reflector.go:105: Failed to list *v1.ServiceAccount: Get https://10.10.0.1:443/api/v1/serviceaccounts?limit=500&amp;resourceVersion=0: dial tcp 10.10.0.1:443: i/o timeout

此外，这里也和网络插件选择有关系，如果选择的是flannel默认工作方式，工作是正常的.如果选择的是calico的ipip模式，需要在calico　init环境里添加KUBERNETES_SERVICE_HOST和KUBERNETES_SERVICE_PORT环境变量，否则在添加pod时候会提示无法连接apiserver.
网络结构方面的因素:本文的测试环境为master和node不在同一个机器，用nginx负载均衡给后边三台主机，nginx未在三台master上，所以才需要calico　init添加相关环境变量。

[root@master01 calico]# kubectl  get pods -n kube-system  | grep calico
calico-kube-controllers-cdd76d5d-qh8lj   1/1     Running   0          51s
calico-node-8qntz                        1/1     Running   0          51s
calico-node-c7d5k                        1/1     Running   0          51s
calico-node-xrxb5                        1/1     Running   0          51s

[root@master01 calico]# kubectl get node
NAME     STATUS   ROLES    AGE    VERSION
node01   Ready    &lt;none&gt;   18h    v1.18.6
node02   Ready    &lt;none&gt;   6h7m   v1.18.6
node03   Ready    &lt;none&gt;   6h7m   v1.18.6
</pre></div>
Calico 管理工具
<div class="codehilite"><pre>wget wget -O /usr/local/bin/calicoctl https://github.com/projectcalico/calicoctl/releases/download/v3.14.2/calicoctl
chmod +x /usr/local/bin/calicoctl

[root@node01 ~]# calicoctl node status
Calico process is running.

IPv4 BGP status
+----------------+-------------------+-------+----------+-------------+
|  PEER ADDRESS  |     PEER TYPE     | STATE |  SINCE   |    INFO     |
+----------------+-------------------+-------+----------+-------------+
| 192.168.1.104 | node-to-node mesh | up    | 10:27:12 | Established |
| 192.168.1.105 | node-to-node mesh | up    | 10:27:13 | Established |
+----------------+-------------------+-------+----------+-------------+

IPv6 BGP status
No IPv6 peers found.
</pre></div></p>
<p>如果是用flannel，参考如下
<div class="codehilite"><pre>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

添加环境变量和修改Network为kube-control-manager里cluster-cidr一致
- name: KUBERNETES_SERVICE_HOST
  value: lb.abc.com.cn
- name: KUBERNETES_SERVICE_PORT
  value: &quot;6443&quot;

  net-conf.json: |
    {
      &quot;Network&quot;: &quot;10.20.0.0/16&quot;,
      &quot;Backend&quot;: {
        &quot;Type&quot;: &quot;vxlan&quot;
      }
    }
kubectl apply -f kube-flannel.yml 
kubectl get pods -n kube-system
</pre></div></p>
<h5 id="coredns">CoreDNS部署<a class="headerlink" href="#coredns" title="Permanent link"></a></h5>
<div class="codehilite"><pre>yum install jq -y
cd ~/yaml
mkdir coredns
cd coredns
wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
chmod +x deploy.sh
#默认情况下 CLUSTER_DNS_IP 是自动获取kube-dns的集群ip的，但是由于没有部署kube-dns所以只能手动指定一个集群ip
./deploy.sh -i 10.10.0.2 &gt; coredns.yml
kubectl apply -f coredns.yml
kubectl get pods --namespace kube-system
kubectl get svc --namespace kube-system

#测试 Coredns 解析
[root@master01 coredns]# cat busybox.yml 
apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - name: busybox
    image: busybox:1.28.4
    command:
      - sleep
      - &quot;3600&quot;
    imagePullPolicy: IfNotPresent
  restartPolicy: Always

[root@master01 coredns]# kubectl apply -f busybox.yml 
[root@master01 coredns]# kubectl exec -i busybox -n default nslookup kubernetes
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.
Server:    10.10.0.2
Address 1: 10.10.0.2 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes
Address 1: 10.10.0.1 kubernetes.default.svc.cluster.local
</pre></div>

<h5 id="_3">验证集群状态<a class="headerlink" href="#_3" title="Permanent link"></a></h5>
<div class="codehilite"><pre>#打node 或者master 节点的标签
kubectl label node 192.168.1.101  node-role.kubernetes.io/master=&#39;master&#39;
kubectl label node 192.168.1.104  node-role.kubernetes.io/node=&#39;node&#39;
kubectl label node 192.168.1.105  node-role.kubernetes.io/node=&#39;node&#39;
kubectl label node 192.168.1.106  node-role.kubernetes.io/node=&#39;node&#39;

kubectl get node,cs
</pre></div>

<h6 id="metrics">metrics遇到的问题<a class="headerlink" href="#metrics" title="Permanent link"></a></h6>
<ul>
<li>使用flannel网络，部署metrics</li>
</ul>
<div class="codehilite"><pre>E0904 14:56:32.791786     852 available_controller.go:420] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.10.22.87:443/apis/metrics.k8s.io/v1beta1: bad status from https://10.10.22.87:443/apis/metrics.k8s.io/v1beta1: 403

解决有两个方式:
1.给system:annonymous权限
kubectl create clusterrolebinding system:anonymous   --clusterrole=cluster-admin   --user=system:anonymous

2.创建system:metrics-server角色并授权,参考[官网文档](https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/)

cat &lt;&lt;EOF &gt; /opt/kubernetes/ssl/front-proxy-ca-csr.json
{
    &quot;CN&quot;: &quot;kubernetes&quot;,
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    }
}
EOF

cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca

[root@master01 000]# cat front-proxy-client-csr.json
{
    &quot;CN&quot;: &quot;front-proxy-client&quot;,
    &quot;key&quot;: {
        &quot;algo&quot;: &quot;rsa&quot;,
        &quot;size&quot;: 2048
    }
}



kube-apiserver添加如下参数，重启服务
--proxy-client-cert-file=/opt/kubernetes/ssl/front-proxy-client.pem \
--proxy-client-key-file=/opt/kubernetes/ssl/front-proxy-client-key.pem \
--requestheader-allowed-names=front-proxy-client \
--requestheader-client-ca-file=/opt/kubernetes/ssl/front-proxy-ca.pem \
--requestheader-extra-headers-prefix=X-Remote-Extra- \
--requestheader-group-headers=X-Remote-Group \
--requestheader-username-headers=X-Remote-User \
--runtime-config=api/all=true&quot;
</pre></div>

<p>[ref]
<a href="https://www.cnblogs.com/centos-python/articles/13168559.html" target="_blank" rel="noopener">Kubelet 证书如何自动续期</a>
<a href="https://www.cnblogs.com/ainimore/p/12972858.html" target="_blank" rel="noopener">kubelet 证书自动续期</a>
<a href="https://blog.51cto.com/14143894/2483207" target="_blank" rel="noopener">k8s高可用二进制部署使用Calico网络方案</a>
<a href="https://juejin.im/post/6844904163785211911#heading-21" target="_blank" rel="noopener">Kubernetes v1.18.2 二进制高可用部署</a>
<a href="https://my.oschina.net/xueyi28/blog/3071431" target="_blank" rel="noopener">calico网络原理、组网方式和使用</a>
<a href="https://www.cnblogs.com/zerchin/p/CentOS7_kernel_update.html" target="_blank" rel="noopener">CentOS7升级系统内核至4.4.xx版本</a>
<a href="https://juejin.im/entry/6844903613332996110" target="_blank" rel="noopener">kubernetes实验:k8s与各网络插件集成</a>
<a href="https://blog.fanfengqiang.com/2019/07/27/kubernetes%E7%8E%AF%E5%A2%83%E4%B8%ADflannel%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E7%9A%84DNS%E4%B8%8Ehosts%E6%96%87%E4%BB%B6%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">kubernetes环境中flannel网络插件的DNS与hosts文件的优先级问题</a>
<a href="https://juejin.im/entry/6844903665879220231" target="_blank" rel="noopener">Kubernetes DNS 高阶指南</a>
<a href="https://stackoverflow.com/questions/58194119/kubeadm-failed-to-create-subnetmanager-error-retrieving-pod-spec-for-kube-syste" target="_blank" rel="noopener">Kubeadm Failed to create SubnetManager: error retrieving pod spec for kube-system</a>
<a href="https://blog.51cto.com/foxhound/2121569" target="_blank" rel="noopener">RBAC DENY 解决办法</a>
<a href="https://xigang.github.io/2019/03/15/metrics-servere/" target="_blank" rel="noopener">Kubernetes Metrics-Server介绍及源码分析</a>
<a href="https://aws.amazon.com/cn/premiumsupport/knowledge-center/eks-metrics-server/" target="_blank" rel="noopener">为什么我无法在 Amazon EKS 中使用 Metrics Server 从容器、pod 或节点收集指标？</a>
<a href="https://www.lijiaocn.com/%E9%97%AE%E9%A2%98/2019/02/28/kubernetes-node-cannot-access-service.html" target="_blank" rel="noopener">Kubernetes集群node无法访问service：kube-proxy没有正确设置cluster-cidr</a></p>
<hr></article></body></html>]]></content>
    
    <summary type="html">
    
      &lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta name=&quot;generator&quot; content=&quot;Hexo 3.8.0&quot;&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-wid
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to config calico BGP</title>
    <link href="https://t1ger.github.io/2020/08/22/how-to-config-calico-BGP/"/>
    <id>https://t1ger.github.io/2020/08/22/how-to-config-calico-BGP/</id>
    <published>2020-08-22T09:50:33.000Z</published>
    <updated>2020-09-06T12:53:55.432Z</updated>
    
    <content type="html"><![CDATA[<p>默认为读者已经有一个运行正常的 Kubernetes 集群，并且采用 Calico 作为 CNI 组件，且 Calico 工作正常；同时应当在某个节点完成了 calicoctl 命令行工具的配置</p>
<h5 id="BGP基本概念"><a href="#BGP基本概念" class="headerlink" title="ＢＧＰ基本概念"></a>ＢＧＰ基本概念</h5><p>动态路由协议可以按照工作范围分为IGP以及EGP。<br>IGP工作在同一个AS内，主要用来发现和计算路由，为AS内提供路由信息的交换；而EGP工作在AS与AS之间，在AS间提供无环路的路由信息交换。</p>
<p>BGP则是EGP的一种。边界网关协议BGP（Border Gateway Protocol）是一种实现自治系统AS（Autonomous System）之间的路由可达，并选择最佳路由的距离矢量路由协议。</p>
<p>AS（Autonomous system）：自治系统，在一个实体管辖下的拥有相同选路策略的IP网络。BGP网络中的每个AS都被分配一个唯一的AS号，用于区分不同的AS。AS号分为2字节AS号和4字节AS号，其中2字节AS号的范围为1至65535，4字节AS号的范围为1至4294967295。支持4字节AS号的设备能够与支持2字节AS号的设备兼容</p>
<p>IGP（Interior Gateway Protocol）：内部网关协议，在一个AS内部所使用的一种路由协议。一个AS内部也可以有多个路由器管理多个网络。各个路由器之间需要路由信息以知道子网络的可达信息。IGP就是用来管理这些路由。代表的实现有RIP和OSPF。</p>
<p>EGP（Exterior Gateway Protocol）：外部网关协议，在多个AS之间使用的一种路由协议，但是EGP设计得比较简单，只发布网络可达的路由信息，而不对路由信息进行优选，同时也没有考虑环路避免等问题，很快就无法满足网络管理的要求。现在已经淘汰，被BGP取而代之</p>
<p>BGP按照运行方式分为EBGP（External/Exterior BGP）和IBGP（Internal/Interior BGP）<br>EBGP：运行于不同AS之间的BGP称为EBGP。为了防止AS间产生环路，当BGP设备接收EBGP对等体发送的路由时，会将带有本地AS号的路由丢弃。</p>
<p>IBGP：运行于同一AS内部的BGP称为IBGP。为了防止AS内产生环路，BGP设备不将从IBGP对等体学到的路由通告给其他IBGP对等体，并与所有IBGP对等体建立全连接。为了解决IBGP对等体的连接数量太多的问题，BGP设计了路由反射器(RR)和BGP联盟</p>
<p>BGP报文交互中的角色分为 Speaker 和 Peer 两种角色<br>Speaker：发送BGP报文的设备称为BGP发言者（Speaker），它接收或产生新的报文信息，并发布（Advertise）给其它BGP Speaker。</p>
<p>Peer：相互交换报文的Speaker之间互称对等体（Peer）。</p>
<p>BGP的Router ID是一个用于标识BGP设备的32位值，通常是IPv4地址的形式，在BGP会话建立时发送的Open报文中携带。对等体之间建立BGP会话时，每个BGP设备都必须有唯一的Router ID，否则对等体之间不能建立BGP连接。BGP的Router ID在BGP网络中必须是唯一的，可以采用手工配置，也可以让设备自动选取。缺省情况下，BGP选择设备上的Loopback接口的IPv4地址作为BGP的Router ID。如果设备上没有配置Loopback接口，系统会选择接口中最大的IPv4地址作为BGP的Router ID。一旦选出Router ID，除非发生接口地址删除等事件，否则即使配置了更大的地址，也保持原来的Router ID</p>
<p>在一个AS内部关于路由反射器有以下几种角色：</p>
<ul>
<li>路由反射器RR（Route Reflector）：允许把从IBGP对等体学到的路由反射到其他IBGP对等体的BGP设备，类似OSPF网络中的DR。</li>
<li>客户机（Client）：与RR形成反射邻居关系的IBGP设备。在AS内部客户机只需要与RR直连。</li>
<li>非客户机（Non-Client）：既不是RR也不是客户机的IBGP设备。在AS内部非客户机与RR之间，以及所有的非客户机之间仍然必须建立全连接关系。</li>
<li>始发者（Originator）：在AS内部始发路由的设备。Originator_ID属性用于防止集群内产生路由环路。</li>
<li>集群（Cluster）：路由反射器及其客户机的集合。Cluster_List属性用于防止集群间产生路由环路。</li>
</ul>
<p>路由反射器原理<br>同一集群内的客户机只需要与该集群的RR直接交换路由信息，因此客户机只需要与RR之间建立IBGP连接，不需要与其他客户机建立IBGP连接，从而减少了IBGP连接数量。</p>
<p>RR突破了“从IBGP对等体获得的BGP路由，BGP设备只发布给它的EBGP对等体。”的限制，并采用独有的Cluster_List属性和Originator_ID属性防止路由环路。RR向IBGP邻居发布路由规则如下：</p>
<ul>
<li>从非客户机学到的路由，发布给所有客户机。</li>
<li>从客户机学到的路由，发布给所有非客户机和客户机（发起此路由的客户机除外）。</li>
<li>从EBGP对等体学到的路由，发布给所有的非客户机和客户机</li>
</ul>
<p>BGP联盟是解决AS内部的IBGP网络连接激增问题，除了使用路由反射器之外，还可以使用联盟（Confederation）。联盟将一个AS划分为若干个子AS。每个子AS内部建立IBGP全连接关系，子AS之间建立联盟EBGP连接关系，但联盟外部AS仍认为联盟是一个AS。配置联盟后，原AS号将作为每个路由器的联盟ID</p>
<h5 id="Calico策略实践"><a href="#Calico策略实践" class="headerlink" title="Calico策略实践"></a>Calico策略实践</h5><ul>
<li>BGP</li>
<li>RR （Route Reflector模式)</li>
<li>IPIP</li>
</ul>
<p>BGP模式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line">|  PEER ADDRESS  |     PEER TYPE     | STATE |  SINCE   |    INFO     |</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line">| 172.17.207.194 | node-to-node mesh | up    | 02:10:25 | Established |</span><br><span class="line">| 172.17.207.195 | node-to-node mesh | up    | 02:10:25 | Established |</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br><span class="line"></span><br><span class="line">node-to-node mesh是BGP的全互连模式</span><br><span class="line"></span><br><span class="line">[root@node01 ~]# ss -tan | grep 179</span><br><span class="line">LISTEN     0      8            *:179                      *:*                  </span><br><span class="line">ESTAB      0      0      172.17.207.193:179                172.17.207.195:61815              </span><br><span class="line">ESTAB      0      0      172.17.207.193:179                172.17.207.194:28190</span><br></pre></td></tr></table></figure></p>
<p>这种情况下节点数量越多，网络中的连接数就会成倍增加，而且在100个节点左右会遇到性能瓶颈<br>解决办法就是把其中的几个calico节点当做路由反射器(route reflector), 然后其他节点只需要把这几个节点当做对等体建立连接就可以。<br>路由器反射器会把传递过来的路由，在传递给其他节点，来实现路由交换</p>
<p>IPIP模式<br>calico默认为IPIP模式,如果有安全组策略需要开放TCP179端口；官方推荐使用在Node小于100的集群，IPIP模式能支撑了100-200规模的集群稳定运行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 ~]# calicoctl get ippool -o yaml</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">items:</span><br><span class="line">- apiVersion: projectcalico.org/v3</span><br><span class="line">  kind: IPPool</span><br><span class="line">  metadata:</span><br><span class="line">    creationTimestamp: &quot;2020-08-19T08:32:03Z&quot;</span><br><span class="line">    name: default-ipv4-ippool</span><br><span class="line">    resourceVersion: &quot;170581&quot;</span><br><span class="line">    uid: c4d037b3-2542-4628-a18f-7c1636a039bb</span><br><span class="line">  spec:</span><br><span class="line">    blockSize: 26</span><br><span class="line">    cidr: 10.20.0.0/16</span><br><span class="line">    ipipMode: Always</span><br><span class="line">    natOutgoing: true</span><br><span class="line">    nodeSelector: all()</span><br><span class="line">    vxlanMode: Never</span><br><span class="line">kind: IPPoolList</span><br><span class="line">metadata:</span><br><span class="line">  resourceVersion: &quot;972246&quot;</span><br><span class="line"></span><br><span class="line">[root@node01 ~]# calicoctl get ippool -o wide</span><br><span class="line">NAME                  CIDR           NAT    IPIPMODE   VXLANMODE   DISABLED   SELECTOR   </span><br><span class="line">default-ipv4-ippool   10.20.0.0/16   true   Always     Never       false      all()</span><br></pre></td></tr></table></figure></p>
<p>Route Reflector 模式</p>
<ul>
<li><p>关键配置</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 设置 CALICO_IPV4POOL_IPIP=“Never”,可以提高网络性能</span><br><span class="line">CALICO_IPV4POOL_IPIP: &quot;Never&quot;</span><br><span class="line">安装完成后会发现，网卡并未像开启IPIP那样生成tunl0网卡，而是通过物理网卡获取到各节点POD网段的路由，说明配置成功</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭 node-to-node BGP网格<br>禁用node-to-node mesh的时候，网络立马就会断，因此断的话要提早作好影响的范围，也就是切换这个网络是须要断网的，使用node-to-node BGP这种也是建议100个节点如下，当超过100台节点必定要使用路由反射RR模式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查询默认节点ASN</span><br><span class="line">[root@node01 ~]# calicoctl get nodes -o wide</span><br><span class="line">NAME     ASN       IPV4                IPV6   </span><br><span class="line">node01   (64512)   172.17.207.193/24          </span><br><span class="line">node02   (64512)   172.17.207.194/24          </span><br><span class="line">node03   (64512)   172.17.207.195/24 </span><br><span class="line"></span><br><span class="line">#首先执行以下命令查看是否存在默认的 BGP 配置</span><br><span class="line">calicoctl get bgpconfig default</span><br><span class="line">#如果存在则将其保存为配置文件</span><br><span class="line">calicoctl get bgpconfig default -o yaml &gt; bgp.yaml</span><br><span class="line">#修改其中的 spec.nodeToNodeMeshEnabled 为 false，然后进行替换</span><br><span class="line">calicoctl apply -f bgp.yaml</span><br><span class="line"></span><br><span class="line">#如果不存在则手动创建一个配置，然后应用</span><br><span class="line"> cat &lt;&lt; EOF | calicoctl create -f -</span><br><span class="line"> apiVersion: projectcalico.org/v3</span><br><span class="line"> kind: BGPConfiguration</span><br><span class="line"> metadata:</span><br><span class="line">   name: default</span><br><span class="line"> spec:</span><br><span class="line">   logSeverityScreen: Info</span><br><span class="line">   nodeToNodeMeshEnabled: false</span><br><span class="line">   asNumber: 64512</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">BGPConfiguration: BGPConfiguration是全局的配置资源。</span><br><span class="line">nodeToNodeMeshEnabled: 就是是否开启全互连模式。</span><br><span class="line">asNumber: as表示自治系统，asN自治系统编号。 默认是64512。 这里必须提供，不然asNumber好像就变成空了。</span><br><span class="line">64512-65535也是私有的ASN，不能出现在公网。ASN在外网是唯一的，由IANA 地址授权委员会统一分配, 不过在内网就无所谓了。官网的例子是63400,同样没问题</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node01 calico]# calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">No IPv4 peers found.</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br><span class="line">应用以后, bgp之间的连接就断了，然后路由也没了，网络也断了</span><br><span class="line">如果把nodeToNodeMeshEnabled改为true再次应用，就会再次启用全互连模式，网络也会恢复</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建对等规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@node01 calico]# cat rr.yml </span><br><span class="line">kind: BGPPeer</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">metadata:</span><br><span class="line">  name: peer-to-rrs</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector: &quot;!has(i-am-a-route-reflector)&quot;</span><br><span class="line">  peerSelector: has(i-am-a-route-reflector)</span><br><span class="line">---</span><br><span class="line">kind: BGPPeer</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">metadata:</span><br><span class="line">  name: rr-mesh</span><br><span class="line">spec:</span><br><span class="line">  nodeSelector: has(i-am-a-route-reflector)</span><br><span class="line">  peerSelector: has(i-am-a-route-reflector)</span><br><span class="line"></span><br><span class="line">calicoctl create -f rr.yaml</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置对等体<br>为方便让BGPPeer轻松选择节点，经过标签选择器匹配，也就是能够去调用k8s里面的标签进行关联，给那个节点打个标签，我这将node1打上标签</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">导出node02 node03配置</span><br><span class="line">[root@node01 calico]# calicoctl get node node03 --export -oyaml &gt; node03.yml</span><br><span class="line">[root@node01 calico]# cat node03.yml </span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: Node</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    projectcalico.org/kube-labels: &apos;&#123;&quot;beta.kubernetes.io/arch&quot;:&quot;amd64&quot;,&quot;beta.kubernetes.io/os&quot;:&quot;linux&quot;,&quot;kubernetes.io/arch&quot;:&quot;amd64&quot;,&quot;kubernetes.io/hostname&quot;:&quot;node03&quot;,&quot;kubernetes.io/os&quot;:&quot;linux&quot;&#125;&apos;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    beta.kubernetes.io/arch: amd64</span><br><span class="line">    beta.kubernetes.io/os: linux</span><br><span class="line">    kubernetes.io/arch: amd64</span><br><span class="line">    kubernetes.io/hostname: node03</span><br><span class="line">    kubernetes.io/os: linux</span><br><span class="line">  name: node03</span><br><span class="line">spec:</span><br><span class="line">  bgp:</span><br><span class="line">    ipv4Address: 172.17.207.195/24</span><br><span class="line">    ipv4IPIPTunnelAddr: 10.20.186.192</span><br><span class="line">  orchRefs:</span><br><span class="line">  - nodeName: node03</span><br><span class="line">    orchestrator: k8s</span><br><span class="line">status: &#123;&#125;</span><br><span class="line"></span><br><span class="line"># 增加标签，将rr标签置为true,也可以通过命令行添加kubectl label node 　node03 i-am-a-route-reflector=true,标签名自己确定，前后一致就可以，</span><br><span class="line"># 增加标签，确保同一个反射簇配置ID一致，即node01与node02一致，用于冗余和防环</span><br><span class="line">[root@node01 calico]# cat node03.yml </span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: Node</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    projectcalico.org/kube-labels: &apos;&#123;&quot;beta.kubernetes.io/arch&quot;:&quot;amd64&quot;,&quot;beta.kubernetes.io/os&quot;:&quot;linux&quot;,&quot;kubernetes.io/arch&quot;:&quot;amd64&quot;,&quot;kubernetes.io/hostname&quot;:&quot;node03&quot;,&quot;kubernetes.io/os&quot;:&quot;linux&quot;&#125;&apos;</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    beta.kubernetes.io/arch: amd64</span><br><span class="line">    beta.kubernetes.io/os: linux</span><br><span class="line">    kubernetes.io/arch: amd64</span><br><span class="line">    kubernetes.io/hostname: node03</span><br><span class="line">    kubernetes.io/os: linux</span><br><span class="line">    i-am-a-route-reflector: true</span><br><span class="line">  name: node03</span><br><span class="line">spec:</span><br><span class="line">  bgp:</span><br><span class="line">    ipv4Address: 172.17.207.195/24</span><br><span class="line">    ipv4IPIPTunnelAddr: 10.20.186.192</span><br><span class="line">    routeReflectorClusterID: 224.0.0.1</span><br><span class="line">  orchRefs:</span><br><span class="line">  - nodeName: node03</span><br><span class="line">    orchestrator: k8s</span><br><span class="line">status: &#123;&#125;</span><br><span class="line"></span><br><span class="line">calicoctl apply -f node03.yml</span><br><span class="line"></span><br><span class="line">[root@node01 calico]# calicoctl apply -f rr.yml       </span><br><span class="line">Successfully applied 2 &apos;BGPPeer&apos; resource(s)</span><br><span class="line">[root@node01 calico]# calicoctl node status     </span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">|  PEER ADDRESS  |   PEER TYPE   | STATE |  SINCE   |    INFO     |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">| 172.17.207.195 | node specific | up    | 16:21:43 | Established |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">calicoctl apply -f node02.yml</span><br><span class="line">[root@node01 calico]# calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">|  PEER ADDRESS  |   PEER TYPE   | STATE |  SINCE   |    INFO     |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">| 172.17.207.195 | node specific | up    | 16:21:43 | Established |</span><br><span class="line">| 172.17.207.194 | node specific | up    | 16:29:48 | Established |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br><span class="line"></span><br><span class="line">同时在非 RR 节点上使用 calicoctl node status 应该能看到以下输出</span><br><span class="line">[root@node02 bin]# calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">|  PEER ADDRESS  |   PEER TYPE   | STATE |  SINCE   |    INFO     |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line">| 172.17.207.190 | node specific | up    | 09:44:19 | Established |</span><br><span class="line">| 172.17.207.193 | node specific | up    | 09:44:22 | Established |</span><br><span class="line">| 172.17.207.195 | node specific | up    | 09:28:19 | Established |</span><br><span class="line">+----------------+---------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br></pre></td></tr></table></figure>
</li>
<li><p>调整 IPIP 规则</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Calico IPIP 模式的三个可选项:</span><br><span class="line">Always: 永远进行 IPIP 封装(默认)</span><br><span class="line">CrossSubnet: 只在跨网段时才进行 IPIP 封装，适合有 Kubernetes 节点在其他网段的情况，属于中肯友好方案</span><br><span class="line">Never: 从不进行 IPIP 封装，适合确认所有 Kubernetes 节点都在同一个网段下的情况</span><br><span class="line"></span><br><span class="line">[root@node01 calico]#calicoctl get ippool default-ipv4-ippool -o yaml &gt; ippool.yaml</span><br><span class="line"></span><br><span class="line">[root@node01 calico]# calicoctl get ippool default-ipv4-ippool -o yaml</span><br><span class="line">apiVersion: projectcalico.org/v3</span><br><span class="line">kind: IPPool</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: &quot;2020-08-19T08:32:03Z&quot;</span><br><span class="line">  name: default-ipv4-ippool</span><br><span class="line">  resourceVersion: &quot;170581&quot;</span><br><span class="line">  uid: c4d037b3-2542-4628-a18f-7c1636a039bb</span><br><span class="line">spec:</span><br><span class="line">  blockSize: 26</span><br><span class="line">  cidr: 10.20.0.0/16</span><br><span class="line">  ipipMode: Always</span><br><span class="line">  natOutgoing: true</span><br><span class="line">  nodeSelector: all()</span><br><span class="line">  vxlanMode: Never</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>修改 ipipMode 值为 CrossSubnet<br>重新使用 calicoctl apply -f ippool.yaml 应用既可</p>
<ul>
<li>增加路由联通网络<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">在开发机器添加路由既可，将 Pod IP 10.20.0.0/16 和 Service IP 10.254.0.0/16 路由到 RR 节点 172.16.0.13</span><br><span class="line"># Pod IP</span><br><span class="line">ip route add 10.20.0.0/16 via 172.16.0.13</span><br><span class="line"># Service IP</span><br><span class="line">ip route add 10.254.0.0/16 via 172.16.0.13</span><br><span class="line">最省事的方法是在开发网络的路由上做，设置完成后就可以直连集群内的 Pod IP 和 Service IP,至于想直接访问 Service Name 只需要调整上游 DNS 解析</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="办公网络与k8s网络方案"><a href="#办公网络与k8s网络方案" class="headerlink" title="办公网络与k8s网络方案"></a>办公网络与k8s网络方案</h5><p>网络环境假定如下:pod的ip是10.244.0.0/16这个网段，那么service是10.0.0.10/24，宿主机是172.17.0.0/24，那么办公网络是192.168.1.0/24</p>
<p>第一种状况，k8s集群测试环境在办公网络的子网里面，那么这个实现就比较简单了，只须要在子网中上层的路由器添加一个规则就好了，ip route add,目的IP为10.244.0.0/16，到达的下一跳via为其中的k8s节点，好比k8s-node1 dev 接口A<br>ip route add 10.244.0.0/16 via <k8s-node1> dev A<br>添加这么一个规则，办公网络就能直接访问k8s的节点，直接就能访问pod IP,也就是下一跳地址以后，就能直接访问都podIP了</k8s-node1></p>
<p>第二种状况，k8s集群与办公网络在不一样VLAN中，不一样机房 前提是k8s集群与办公网络是互通的，三层可达</p>
<ul>
<li>方案1 在路由器上添加路由表，10.244.0.0/16 <k8s-node1></k8s-node1></li>
<li>方案２ 采用BGP，若是三层的路由支持BGP协议的话，直接就可让路由器BGP与路由反射器BGP创建链接，这样的话路由器上的BGP就能获取到了k8s上的路由表信息了，而后通过下一跳来转发到目的的node的pod中</li>
</ul>
<p>总结：只要是不一样vlan，必须是三层可达，能在上层的路由器上，访问集群的网段，pod网段仍是service网段，必定要告知它，帮它转发到下一跳是谁，下一跳若是是目的的节点，那就直接转发数据包。</p>
<h5 id="网络策略"><a href="#网络策略" class="headerlink" title="网络策略"></a>网络策略</h5><p>网络的限制也就是ACP访问控制，天然是有两个方向，一个是入口方向<br>使用network policy对Pod网络进行隔离。支持对Pod级别和Namespace级别网络访问控制。<br>Pod网络入口方向隔离</p>
<ul>
<li>基于Pod级网络隔离：只容许特定对象访问Pod（使用标签订义），容许白名单上的IP地址或者IP段访问Pod</li>
<li>基于Namespace级网络隔离：多个命名空间，A和B命名空间Pod彻底隔离</li>
</ul>
<p>Pod网络出口方向隔离</p>
<ul>
<li>拒绝某个Namespace上全部Pod访问外部</li>
<li>基于目的IP的网络隔离：只容许Pod访问白名单上的IP地址或者IP段</li>
<li>基于目标端口的网络隔离：只容许Pod访问白名单上的端口</li>
</ul>
<p><a href="https://cshihong.github.io/2018/01/23/BGP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" target="_blank" rel="noopener">BGP基础知识</a><br><a href="https://blog.kelu.org/tech/2020/01/10/calico-series-2-bgp-tutorial.html" target="_blank" rel="noopener">BGP入门笔记</a><br><a href="http://dockone.io/article/10382" target="_blank" rel="noopener">谐云Calico大规模场景落地实践</a><br><a href="https://mritd.me/2019/06/18/calico-3.6-forward-network-traffic/" target="_blank" rel="noopener">Calico 3.6 转发外部流量到集群 Pod</a><br><a href="https://blog.csdn.net/nexus124/article/details/105005240" target="_blank" rel="noopener">Calico配置双RR架构</a></p>
<hr>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;默认为读者已经有一个运行正常的 Kubernetes 集群，并且采用 Calico 作为 CNI 组件，且 Calico 工作正常；同时应当在某个节点完成了 calicoctl 命令行工具的配置&lt;/p&gt;
&lt;h5 id=&quot;BGP基本概念&quot;&gt;&lt;a href=&quot;#BGP基本概念&quot;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to install k8s cluster</title>
    <link href="https://t1ger.github.io/2020/08/15/how-to-install-k8s-cluster/"/>
    <id>https://t1ger.github.io/2020/08/15/how-to-install-k8s-cluster/</id>
    <published>2020-08-15T09:58:55.000Z</published>
    <updated>2020-09-15T14:25:59.858Z</updated>
    
    <content type="html"><![CDATA[<h5 id="环境和版本说明"><a href="#环境和版本说明" class="headerlink" title="环境和版本说明"></a>环境和版本说明</h5><p>系统： CentOS Linux release 7.8.2003 (Core)<br>etcd: etcd-v3.4.7<br>k8s:  v1.18.6<br>Calico: v3.15.1<br>docker: docker-ce-19.03<br>负载均衡生产一般建议采用阿里云slb，测试环境可以使用nginx代替<br>service-cluster-ip 10.10.0.0/16<br>pods-ip 10.20.0.0/16<br>集群dns  10.10.0.2<br>k8s svc 10.10.0.1<br>集群使用默认 svc.cluster.local<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# kubectl get svc</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.10.0.1    &lt;none&gt;        443/TCP   33h</span><br></pre></td></tr></table></figure></p>
<p>master和etcd在同一台主机上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">master01   192.168.1.101    kube-apiserver kube-controller-manager kube-scheduler</span><br><span class="line">master02   192.168.1.102    kube-apiserver kube-controller-manager kube-scheduler</span><br><span class="line">master03   192.168.1.103    kube-apiserver kube-controller-manager kube-scheduler</span><br><span class="line">slb   　　　192.168.1.31     nginx</span><br><span class="line">node1      192.168.1.104    kubelet kube-proxy  calico</span><br><span class="line">node2      192.168.1.105    kubelet kube-proxy  calico</span><br><span class="line">node3      192.168.1.106    kubelet kube-proxy  calico</span><br></pre></td></tr></table></figure></p>
<h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p>升级内核<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm</span><br><span class="line">yum --enablerepo=elrepo-kernel install -y kernel-lt</span><br><span class="line">#查看可用内核</span><br><span class="line">cat /boot/grub2/grub.cfg |grep menuentry</span><br><span class="line">#设置开机从新内核启动</span><br><span class="line">grub2-set-default &quot;CentOS Linux (4.4.232-1.el7.elrepo.x86_64) 7 (Core)&quot;</span><br><span class="line">#查看内核启动项</span><br><span class="line">grub2-editenv list</span><br><span class="line">#重启系统使内核生效</span><br><span class="line">reboot</span><br><span class="line">#查看内核版本是否生效</span><br><span class="line">uname -r</span><br></pre></td></tr></table></figure></p>
<p>初始化系统<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">swapoff -a </span><br><span class="line">sed -i &apos;s/.*swap.*/#&amp;/&apos; /etc/fstab</span><br><span class="line">setenforce  0 </span><br><span class="line">sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/sysconfig/selinux </span><br><span class="line">sed -i &quot;s/^SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config</span><br><span class="line">sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/sysconfig/selinux</span><br><span class="line">sed -i &quot;s/^SELINUX=permissive/SELINUX=disabled/g&quot; /etc/selinux/config</span><br><span class="line"></span><br><span class="line"># 将桥接的IPv4流量传递到iptables的链</span><br><span class="line">cat&gt;/etc/sysctl.d/k8s.conf&lt;&lt; EOF</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1１</span><br><span class="line">net.ipv6.conf.all.disable_ipv6=１</span><br><span class="line">net.ipv6.conf.default.disable_ipv6=1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6=1</span><br><span class="line">net.ipv6.conf.all.forwarding=1</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">vm.swappiness=0</span><br><span class="line">EOF</span><br><span class="line">sysctl --system  # 生效</span><br><span class="line"></span><br><span class="line">yum install -y yum-utils</span><br><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line">systemctl enable docker &amp;&amp; systemctl start docker</span><br></pre></td></tr></table></figure></p>
<h5 id="部署etcd集群"><a href="#部署etcd集群" class="headerlink" title="部署etcd集群"></a>部署etcd集群</h5><p>在部署之前先自签证书，参考上一篇<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/etcd/ -p</span><br><span class="line">mkdir /opt/kubernetes/&#123;bin,cfg,ssl&#125;  -p</span><br><span class="line">cd /data/etcd/</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/v3.4.7/etcd-v3.4.7-linux-amd64.tar.gz</span><br><span class="line">tar zxvf etcd-v3.4.7-linux-amd64.tar.gz</span><br><span class="line">cd etcd-v3.4.7-linux-amd64</span><br><span class="line">cp -a etcd etcdctl /opt/kubernetes/bin/</span><br><span class="line">echo &apos;export PATH=$PATH:/opt/kubernetes/bin&apos; &gt;&gt; /etc/profile</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>分发证书，并依次在master01,master02,master03执行,并注意替换相应ip<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 etcd]# cat etcd.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line">ETCD_NAME=$&#123;1:-&quot;etcd01&quot;&#125;</span><br><span class="line">ETCD_IP=$&#123;2:-&quot;127.0.0.1&quot;&#125;</span><br><span class="line">ETCD_CLUSTER=$&#123;3:-&quot;etcd01=https://127.0.0.1:2379&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/etcd.yml</span><br><span class="line">name: $&#123;ETCD_NAME&#125;</span><br><span class="line">data-dir: /var/lib/etcd/default.etcd</span><br><span class="line">listen-peer-urls: https://$&#123;ETCD_IP&#125;:2380</span><br><span class="line">listen-client-urls: https://$&#123;ETCD_IP&#125;:2379,https://127.0.0.1:2379</span><br><span class="line">advertise-client-urls: https://$&#123;ETCD_IP&#125;:2379</span><br><span class="line">initial-advertise-peer-urls: https://$&#123;ETCD_IP&#125;:2380</span><br><span class="line">initial-cluster: $&#123;ETCD_CLUSTER&#125;</span><br><span class="line">initial-cluster-token: etcd-cluster</span><br><span class="line">initial-cluster-state: new</span><br><span class="line">client-transport-security:</span><br><span class="line">  cert-file: /opt/kubernetes/ssl/server.pem</span><br><span class="line">  key-file: /opt/kubernetes/ssl/server-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /opt/kubernetes/ssl/ca.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line">peer-transport-security:</span><br><span class="line">  cert-file: /opt/kubernetes/ssl/server.pem</span><br><span class="line">  key-file: /opt/kubernetes/ssl/server-key.pem</span><br><span class="line">  client-cert-auth: false</span><br><span class="line">  trusted-ca-file: /opt/kubernetes/ssl/ca.pem</span><br><span class="line">  auto-tls: false</span><br><span class="line">debug: false</span><br><span class="line">logger: zap</span><br><span class="line">log-outputs: [stderr]</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/etcd.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">Documentation=https://github.com/etcd-io/etcd</span><br><span class="line">Conflicts=etcd.service</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5s</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">ExecStart=/opt/kubernetes/bin/etcd --config-file=/opt/kubernetes/cfg/etcd.yml</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd</span><br><span class="line">systemctl restart etcd</span><br><span class="line"></span><br><span class="line">#master01</span><br><span class="line">./etcd.sh etcd01 192.168.1.101 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380</span><br><span class="line"></span><br><span class="line">#master02</span><br><span class="line">./etcd.sh etcd02 192.168.1.102 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380</span><br><span class="line"></span><br><span class="line">#master03</span><br><span class="line">./etcd.sh etcd03 192.168.1.103 etcd01=https://192.168.1.101:2380,etcd02=https://192.168.1.102:2380,etcd03=https://192.168.1.103:2380</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#健康状态</span><br><span class="line">[root@master01 etcd]# /opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 endpoint status</span><br><span class="line">https://192.168.1.101:2379, f592173020929e13, 3.4.7, 1.8 MB, false, false, 19, 53478, 53478, </span><br><span class="line">https://192.168.1.102:2379, 4eb9518f73eaf60f, 3.4.7, 1.8 MB, false, false, 19, 53478, 53478, </span><br><span class="line">https://192.168.1.103:2379, 2123e126fcaeb456, 3.4.7, 1.8 MB, true, false, 19, 53478, 53478, </span><br><span class="line"></span><br><span class="line">＃写入foo</span><br><span class="line">/opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 put foo &quot;Hello World&quot;</span><br><span class="line">#取出foo</span><br><span class="line">[root@master02 ~]# /opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 get foo</span><br><span class="line">foo</span><br><span class="line">Hello World</span><br></pre></td></tr></table></figure></p>
<h5 id="k8s安装"><a href="#k8s安装" class="headerlink" title="k8s安装"></a>k8s安装</h5><p>K8S二进制包<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/k8s-package</span><br><span class="line">cd /data/k8s-package</span><br><span class="line">wget https://dl.k8s.io/v1.18.6/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar xf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">cd /data/k8s-package/kubernetes/server/bin</span><br><span class="line">cp -a kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy /opt/kubernetes/bin</span><br><span class="line"></span><br><span class="line"># copy 执行文件到 master02 master03 机器 /opt/kubernetes/bin</span><br><span class="line">scp kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy root@master02:/opt/kubernetes/bin/</span><br><span class="line">scp kube-apiserver kube-controller-manager kube-scheduler kubectl kubelet kube-proxy root@master03:/opt/kubernetes/bin/</span><br></pre></td></tr></table></figure></p>
<p>创建Node节点kubeconfig文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ~]# cat /data/ssl/kubeconfig.sh </span><br><span class="line">export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &apos; &apos;)</span><br><span class="line">cat&gt;token.csv&lt;&lt;EOF</span><br><span class="line">$&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">export KUBE_APISERVER=&quot;https://lb.abc.com.cn:6443&quot;</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=./ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system create serviceaccount kube-proxy</span><br><span class="line">kubectl create clusterrolebinding system:kube-proxy --clusterrole system:node-proxier --serviceaccount kube-system:kube-proxy</span><br><span class="line"></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=./ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate=./kube-proxy.pem \</span><br><span class="line">  --client-key=./kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">#sh kubeconfig.sh</span><br><span class="line">#cp *kubeconfig /opt/kubernetes/cfg</span><br><span class="line">#scp *kubeconfig root@master02:/opt/kubernetes/cfg</span><br><span class="line">#scp *kubeconfig root@master03:/opt/kubernetes/cfg</span><br></pre></td></tr></table></figure></p>
<p>配置master组件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/k8s-master</span><br><span class="line">[root@master01 k8s-master]# cat apiserver.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;192.168.1.101&quot;&#125;</span><br><span class="line">ETCD_SERVERS=$&#123;2:-&quot;https://127.0.0.1:2379&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-apiserver</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--logtostderr=false \\</span><br><span class="line">--v=2 \\</span><br><span class="line">--log-dir=/var/log/kubernetes \\</span><br><span class="line">--etcd-servers=$&#123;ETCD_SERVERS&#125; \\</span><br><span class="line">--bind-address=0.0.0.0 \\</span><br><span class="line">--secure-port=6443 \\</span><br><span class="line">--advertise-address=$&#123;MASTER_ADDRESS&#125; \\</span><br><span class="line">--allow-privileged=true \\</span><br><span class="line">--service-cluster-ip-range=10.10.0.0/16 \\</span><br><span class="line">--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction \\</span><br><span class="line">--authorization-mode=Node,RBAC \\</span><br><span class="line">--kubelet-https=true \\</span><br><span class="line">--enable-bootstrap-token-auth=true \\</span><br><span class="line">--token-auth-file=/opt/kubernetes/cfg/token.csv \\</span><br><span class="line">--service-node-port-range=30000-50000 \\</span><br><span class="line">--kubelet-client-certificate=/opt/kubernetes/ssl/server.pem \\</span><br><span class="line">--kubelet-client-key=/opt/kubernetes/ssl/server-key.pem \\</span><br><span class="line">--tls-cert-file=/opt/kubernetes/ssl/server.pem \\</span><br><span class="line">--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\</span><br><span class="line">--client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">--etcd-cafile=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--etcd-certfile=/opt/kubernetes/ssl/server.pem \\</span><br><span class="line">--etcd-keyfile=/opt/kubernetes/ssl/server-key.pem \\</span><br><span class="line">--requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra- \\</span><br><span class="line">--requestheader-group-headers=X-Remote-Group \\</span><br><span class="line">--requestheader-username-headers=X-Remote-User \\</span><br><span class="line">--proxy-client-cert-file=/opt/kubernetes/ssl/metrics-server.pem \\</span><br><span class="line">--proxy-client-key-file=/opt/kubernetes/ssl/metrics-server-key.pem \\</span><br><span class="line">--runtime-config=api/all=true \\</span><br><span class="line">--audit-log-maxage=30 \\</span><br><span class="line">--audit-log-maxbackup=3 \\</span><br><span class="line">--audit-log-maxsize=100 \\</span><br><span class="line">--audit-log-truncate-enabled=true \\</span><br><span class="line">--audit-log-path=/var/log/kubernetes/k8s-audit.log&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserver</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver</span><br><span class="line">systemctl restart kube-apiserver</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@master01 k8s-master]# cat controller-manager.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-controller-manager</span><br><span class="line"></span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">--master=$&#123;MASTER_ADDRESS&#125;:8080 \\</span><br><span class="line">--leader-elect=true \\</span><br><span class="line">--bind-address=0.0.0.0 \\</span><br><span class="line">--service-cluster-ip-range=10.10.0.0/16 \\</span><br><span class="line">--cluster-name=kubernetes \\</span><br><span class="line">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\</span><br><span class="line">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">--experimental-cluster-signing-duration=87600h0m0s \\</span><br><span class="line">--feature-gates=RotateKubeletServerCertificate=true \\</span><br><span class="line">--feature-gates=RotateKubeletClientCertificate=true \\</span><br><span class="line">--allocate-node-cidrs=true \\</span><br><span class="line">--cluster-cidr=10.20.0.0/16 \\</span><br><span class="line">--root-ca-file=/opt/kubernetes/ssl/ca.pem&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-manager</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-controller-manager</span><br><span class="line">systemctl restart kube-controller-manager</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@master01 k8s-master]# cat scheduler.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-scheduler</span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;--logtostderr=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">--master=$&#123;MASTER_ADDRESS&#125;:8080 \\</span><br><span class="line">--address=0.0.0.0 \\</span><br><span class="line">--leader-elect&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-scheduler</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-scheduler</span><br><span class="line">systemctl restart kube-scheduler</span><br><span class="line"></span><br><span class="line">#分发token.csv,依次在master01 master02 master03执行相应的脚本</span><br><span class="line">#master01</span><br><span class="line">./apiserver.sh 192.168.1.101 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1</span><br><span class="line">./scheduler.sh 127.0.0.1</span><br><span class="line"></span><br><span class="line">#master02</span><br><span class="line">./apiserver.sh 192.168.1.102 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1</span><br><span class="line">./scheduler.sh 127.0.0.1</span><br><span class="line"></span><br><span class="line">#master03</span><br><span class="line">./apiserver.sh 192.168.1.103 https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 ./controller-manager.sh 127.0.0.1</span><br><span class="line">./scheduler.sh 127.0.0.1</span><br><span class="line"></span><br><span class="line">[root@master01 k8s-master]# ps -ef | grep kube</span><br><span class="line">root      4148     1  3 17:50 ?        00:01:24 /opt/kubernetes/bin/etcd --config-file=/opt/kubernetes/cfg/etcd.yml</span><br><span class="line">root      4174     1  3 17:50 ?        00:01:22 /opt/kubernetes/bin/kube-apiserver --logtostderr=false --v=2 --log-dir=/var/log/kubernetes --etcd-servers=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 --bind-address=0.0.0.0 --secure-port=6443 --advertise-address=192.168.1.101 --allow-privileged=true --service-cluster-ip-range=10.10.0.0/16 --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,NodeRestriction --authorization-mode=RBAC,Node --kubelet-https=true --enable-bootstrap-token-auth=true --token-auth-file=/opt/kubernetes/cfg/token.csv --service-node-port-range=30000-50000 --kubelet-client-certificate=/optkubernetes/ssl/server.pem --kubelet-client-key=/opt/kubernetes/ssl/server.pem --tls-cert-file=/opt/kubernetes/ssl/server.pem --tls-private-key-file=/opt/kubernetes/ssl/server-key.pem --client-ca-file=/opt/kubernetes/ssl/ca.pem --service-account-key-file=/opt/kubernetes/ssl/ca-key.pem --etcd-cafile=/opt/kubernetes/ssl/ca.pem --etcd-certfile=/opt/kubernetes/ssl/server.pem --etcd-keyfile=/optkubernetes/ssl/server-key.pem --requestheader-client-ca-file=/opt/kubernetes/ssl/ca.pem --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --proxy-client-cert-file=/opt/kubernetes/ssl/metrics-server.pem --proxy-client-key-file=/opt/kubernetes/ssl/metrics-server-key.pem --runtime-config=api/all=true --audit-log-maxage=30 --audit-log-maxbackup=3 --audit-log-maxsize=100 --audit-log-truncate-enabled=true --audit-log-path=/var/logkubernetes/k8s-audit.log</span><br><span class="line">root      4281     1  0 17:52 ?        00:00:04 /opt/kubernetes/bin/kube-controller-manager --logtostderr=true --v=2 --master=127.0.0.1:8080 --leader-elect=true --bind-address=0.0.0.0 --service-cluster-ip-range=10.10.0.0/16 --cluster-name=kubernetes --cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem --cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem --service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem --experimental-cluster-signing-duration=87600h0m0s --feature-gates=RotateKubeletServerCertificate=true --feature-gates=RotateKubeletClientCertificate=true --allocate-node-cidrs=true --cluster-cidr=10.20.0.0/16 --root-ca-file=/opt/kubernetes/ssl/ca.pem</span><br><span class="line">root      4302     1  0 17:52 ?        00:00:05 /opt/kubernetes/bin/kube-scheduler --logtostderr=true --v=2 --master=127.0.0.1:8080 --address=0.0.0.0 --leader-elect</span><br><span class="line"></span><br><span class="line">#查看写入etcd内容，用于排查错误</span><br><span class="line">/opt/kubernetes/bin/etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.101:2379,https://192.168.1.102:2379,https://192.168.1.103:2379 get /registry/ --prefix --keys-only</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@master01 k8s-master]# kubectl  get cs</span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">etcd-1               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-2               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;&quot;health&quot;:&quot;true&quot;&#125;   </span><br><span class="line"></span><br><span class="line">[root@master01 k8s-master]# kubectl cluster-info</span><br><span class="line">Kubernetes master is running at http://localhost:8080</span><br><span class="line"></span><br><span class="line">To further debug and diagnose cluster problems, use &apos;kubectl cluster-info dump&apos;.</span><br></pre></td></tr></table></figure></p>
<h5 id="nginx相关配置"><a href="#nginx相关配置" class="headerlink" title="nginx相关配置"></a>nginx相关配置</h5><p>开启tcp代理<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">stream&#123;</span><br><span class="line">log_format proxy &apos;$remote_addr [$time_local] &apos;</span><br><span class="line">                     &apos;$protocol $status $bytes_sent $bytes_received &apos;</span><br><span class="line">                     &apos;$session_time &quot;$upstream_addr&quot; &apos;</span><br><span class="line">                     &apos;&quot;$upstream_bytes_sent&quot; &quot;$upstream_bytes_received&quot; &quot;$upstream_connect_time&quot;&apos;;</span><br><span class="line">upstream k8s-apiserver &#123;</span><br><span class="line">        hash $remote_addr consistent;</span><br><span class="line">        server 192.168.1.101:6443;</span><br><span class="line">        server 192.168.1.102:6443;</span><br><span class="line">        server 192.168.1.103:6443;</span><br><span class="line">       &#125;</span><br><span class="line">server &#123;</span><br><span class="line">        listen 6443;</span><br><span class="line">        proxy_pass k8s-apiserver;                                                       </span><br><span class="line">        access_log logs/apiserver.log proxy;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h5 id="kubelet证书自动续期和创建Node授权用户"><a href="#kubelet证书自动续期和创建Node授权用户" class="headerlink" title="kubelet证书自动续期和创建Node授权用户"></a>kubelet证书自动续期和创建Node授权用户</h5><p>Node节点 授权用户 kubelet-bootstrap<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create clusterrolebinding  kubelet-bootstrap --clusterrole=system:node-bootstrapper  --user=kubelet-bootstrap</span><br></pre></td></tr></table></figure></p>
<p>具有自动批准 selfnodeserver 类型 CSR 请求的能力<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 kubelet-certificate-rotating]# cat tls-instructs-csr.yaml </span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata: </span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [&quot;certificates.k8s.io&quot;]</span><br><span class="line">  resources: [&quot;certificatesigningrequests/selfnodeserver&quot;]</span><br><span class="line">  verbs: [&quot;create&quot;]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl apply -f tls-instructs-csr.yaml</span><br><span class="line"></span><br><span class="line">#自动批准 kubelet-bootstrap 用户 TLS bootstrapping 首次申请证书的 CSR 请求</span><br><span class="line">kubectl create clusterrolebinding node-client-auto-approve-csr --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --user=kubelet-bootstrap</span><br><span class="line"></span><br><span class="line">#自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span><br><span class="line">kubectl create clusterrolebinding node-client-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span><br><span class="line">kubectl create clusterrolebinding node-server-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@master01 kubelet-certificate-rotating]# kubectl get clusterrolebinding|egrep &quot;node-(.*)-auto&quot;</span><br><span class="line">node-client-auto-approve-csr                           ClusterRole/system:certificates.k8s.io:certificatesigningrequests:nodeclient       2m4s</span><br><span class="line">node-client-auto-renew-crt                             ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeclient   109s</span><br><span class="line">node-server-auto-renew-crt                             ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeserver   93s</span><br></pre></td></tr></table></figure></p>
<h5 id="配置Node组件并运行"><a href="#配置Node组件并运行" class="headerlink" title="配置Node组件并运行"></a>配置Node组件并运行</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/k8s-node</span><br><span class="line">cd /data/k8s-node/</span><br><span class="line"></span><br><span class="line">[root@node01 k8s-node]# cat kubelet.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line">#create static pod directory</span><br><span class="line">mkdir -p /etc/kubernetes/manifests</span><br><span class="line"></span><br><span class="line">DNS_SERVER_IP=$&#123;1:-&quot;10.10.0.2&quot;&#125;</span><br><span class="line">HOSTNAME=$&#123;2:-&quot;`hostname`&quot;&#125;</span><br><span class="line">CLUETERDOMAIN=$&#123;3:-&quot;cluster.local&quot;&#125;</span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">KUBELET_OPTS=&quot;--logtostderr=false \\</span><br><span class="line">--v=2 \\</span><br><span class="line">--hostname-override=$&#123;HOSTNAME&#125; \\</span><br><span class="line">--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\</span><br><span class="line">--bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\</span><br><span class="line">--config=/opt/kubernetes/cfg/kubelet-config.yml \\</span><br><span class="line">--cert-dir=/opt/kubernetes/ssl \\</span><br><span class="line">--network-plugin=cni \\</span><br><span class="line">--cni-conf-dir=/etc/cni/net.d \\</span><br><span class="line">--cni-bin-dir=/opt/cni/bin \\</span><br><span class="line">--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.2&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kubelet-config.yml</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">authentication:</span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    clientCAFile: /opt/kubernetes/ssl/ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 0s</span><br><span class="line">    cacheUnauthorizedTTL: 0s</span><br><span class="line">clusterDNS:</span><br><span class="line">- $&#123;DNS_SERVER_IP&#125;</span><br><span class="line">clusterDomain: $&#123;CLUETERDOMAIN&#125;</span><br><span class="line">cpuManagerReconcilePeriod: 0s</span><br><span class="line">evictionPressureTransitionPeriod: 0s</span><br><span class="line">fileCheckFrequency: 0s</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 0s</span><br><span class="line">imageMinimumGCAge: 0s</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">nodeStatusReportFrequency: 0s</span><br><span class="line">nodeStatusUpdateFrequency: 0s</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 0s</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 0s</span><br><span class="line">syncFrequency: 0s</span><br><span class="line">volumeStatsAggPeriod: 0s</span><br><span class="line">featureGates: </span><br><span class="line">  RotateKubeletServerCertificate: true</span><br><span class="line">  RotateKubeletClientCertificate: true</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kubelet.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line">RestartSec=10</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet</span><br><span class="line">systemctl restart kubelet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@node01 k8s-node]# cat proxy.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">HOSTNAME=$&#123;1:-&quot;`hostname`&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-proxy.conf</span><br><span class="line">KUBE_PROXY_OPTS=&quot;--logtostderr=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">--config=/opt/kubernetes/cfg/kube-proxy-config.yml&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/opt/kubernetes/cfg/kube-proxy-config.yml</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: &quot;&quot;</span><br><span class="line">  burst: 0</span><br><span class="line">  contentType: &quot;&quot;</span><br><span class="line">  kubeconfig: /opt/kubernetes/cfg/kube-proxy.kubeconfig</span><br><span class="line">  qps: 0</span><br><span class="line">clusterCIDR: 10.20.0.0/16</span><br><span class="line">configSyncPeriod: 0s</span><br><span class="line">conntrack:</span><br><span class="line">  maxPerCore: null</span><br><span class="line">  min: null</span><br><span class="line">  tcpCloseWaitTimeout: null</span><br><span class="line">  tcpEstablishedTimeout: null</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: &quot;&quot;</span><br><span class="line">hostnameOverride: $&#123;HOSTNAME&#125;</span><br><span class="line">iptables:</span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  scheduler: &quot;&quot;</span><br><span class="line">  strictARP: false</span><br><span class="line">  syncPeriod: 0s</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">metricsBindAddress: &quot;&quot;</span><br><span class="line">mode: &quot;ipvs&quot;</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: null</span><br><span class="line">portRange: &quot;&quot;</span><br><span class="line">udpIdleTimeout: 0s</span><br><span class="line">winkernel:</span><br><span class="line">  enableDSR: false</span><br><span class="line">  networkName: &quot;&quot;</span><br><span class="line">  sourceVip: &quot;&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-proxy.conf</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-proxy</span><br><span class="line">systemctl restart kube-proxy</span><br><span class="line"></span><br><span class="line">#node01</span><br><span class="line">./kubelet.sh 10.10.0.2 node01 cluster.local</span><br><span class="line">./proxy.sh </span><br><span class="line">#node02</span><br><span class="line">./kubelet.sh 10.10.0.2 node02 cluster.local</span><br><span class="line">./proxy.sh </span><br><span class="line">#node03</span><br><span class="line">./kubelet.sh 10.10.0.2 node03 cluster.local</span><br><span class="line">./proxy.sh </span><br><span class="line"></span><br><span class="line">#在任意master查看</span><br><span class="line">[root@master01 k8s-node]# kubectl get node</span><br><span class="line">NAME     STATUS     ROLES    AGE   VERSION</span><br><span class="line">node01   NotReady   &lt;none&gt;   13h   v1.18.6</span><br><span class="line">node02   NotReady   &lt;none&gt;   27m   v1.18.6</span><br><span class="line">node03   NotReady   &lt;none&gt;   27m   v1.18.6</span><br></pre></td></tr></table></figure>
<p>节点处理 NoReady 状态，是因为目前还没有安装网络组件</p>
<p>解决无法查询pods日志问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 yaml]# cat rbac/apiserver-to-kubelet-rbac.yml </span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-api-admin</span><br><span class="line">subjects: </span><br><span class="line">- kind: User</span><br><span class="line">  name: kubernetes</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kubelet-api-admin</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line"></span><br><span class="line">kubectl apply -f ~/yaml/rbac/apiserver-to-kubelet-rbac.yml</span><br></pre></td></tr></table></figure></p>
<p> RBAC DENY解决办法<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">I0905 16:15:47.988359   22403 rbac.go:119] RBAC DENY: user &quot;system:node:node01&quot; groups [&quot;system:nodes&quot; &quot;system:authenticated&quot;] cannot &quot;update&quot; resource &quot;leases.coordination.k8s.io&quot; named &quot;node01&quot; in namespace &quot;kube-node-lease&quot;</span><br><span class="line">解决方法1</span><br><span class="line">[root@master01 kubernetes]# kubectl describe clusterrolebindings system:node  </span><br><span class="line">Name:         system:node</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate: true</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  system:node</span><br><span class="line">Subjects:</span><br><span class="line">  Kind  Name  Namespace</span><br><span class="line">  ----  ----  ---------</span><br><span class="line"></span><br><span class="line">[root@master01 metrics]# kubectl create clusterrolebinding kubelet-node-clusterbinding --clusterrole=system:node --group=system:nodes  </span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubelet-node-clusterbinding created</span><br><span class="line">[root@master01 metrics]# kubectl describe clusterrolebindings kubelet-node-clusterbinding  </span><br><span class="line">Name:         kubelet-node-clusterbinding</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  &lt;none&gt;</span><br><span class="line">Role:</span><br><span class="line">  Kind:  ClusterRole</span><br><span class="line">  Name:  system:node</span><br><span class="line">Subjects:</span><br><span class="line">  Kind   Name          Namespace</span><br><span class="line">  ----   ----          ---------</span><br><span class="line">  Group  system:nodes  </span><br><span class="line"></span><br><span class="line">解决方法2</span><br><span class="line">参考[这里](https://github.com/kubernetes/kubernetes/issues/61511)</span><br><span class="line">Ensure Node authorization comes first in the authorizer mode arguments:</span><br><span class="line"></span><br><span class="line">--authorization-mode=Node,RBAC</span><br><span class="line"></span><br><span class="line">If you reverse those, RBAC will attempt to authorize, fail and log, then the Node authorizer will succeed. The RBAC message is harmless in this case, but is annoying.</span><br><span class="line"></span><br><span class="line">Don&apos;t grant the system:node role to the system:nodes group or you will undo the protection of the Node authorizer.</span><br></pre></td></tr></table></figure></p>
<h5 id="kubernetes启用ipvs-在所有节点执行"><a href="#kubernetes启用ipvs-在所有节点执行" class="headerlink" title="kubernetes启用ipvs,在所有节点执行"></a>kubernetes启用ipvs,在所有节点执行</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ipvsadm</span><br><span class="line"></span><br><span class="line">cat&lt;&lt;EOF&gt;/etc/sysconfig/modules/ipvs.modules </span><br><span class="line">#!/bin/bash</span><br><span class="line">ipvs_modules_dir=&quot;/usr/lib/modules/\`uname -r\`/kernel/net/netfilter/ipvs&quot;</span><br><span class="line">for i in \`ls \$ipvs_modules_dir | sed  -r &apos;s#(.*).ko.xz#\1#&apos;\`; do</span><br><span class="line">    /sbin/modinfo -F filename \$i  &amp;&gt; /dev/null</span><br><span class="line">    if [ \$? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe \$i</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod +x /etc/sysconfig/modules/ipvs.modules </span><br><span class="line">bash /etc/sysconfig/modules/ipvs.modules</span><br></pre></td></tr></table></figure>
<h5 id="网络部署-Flannel-amp-amp-calico-任选其一"><a href="#网络部署-Flannel-amp-amp-calico-任选其一" class="headerlink" title="网络部署,(Flannel &amp;&amp; calico)任选其一"></a>网络部署,(Flannel &amp;&amp; calico)任选其一</h5><p>Calico网络方式</p>
<ul>
<li>IPIP<br>是把一个IP数据包又套在一个IP包里，即把 IP 层封装到 IP 层的一个 tunnel,作用其实基本上就相当于一个基于IP层的网桥！一般来说，普通的网桥是基于mac层的，根本不需 IP，而这个 ipip 则是通过两端的路由做一个 tunnel，把两个本来不通的网络通过点对点连接起来。ipip 的源代码在内核 net/ipv4/ipip.c 中可以找到</li>
<li>BGP<br>边界网关协议（Border Gateway Protocol, BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护IP路由表或‘前缀’表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。BGP，通俗的讲就是讲接入到机房的多条线路（如电信、联通、移动等）融合为一体，实现多线单IP，BGP 机房的优点：服务器只需要设置一个IP地址，最佳访问路由是由网络上的骨干路由器根据路由跳数与其它技术指标来确定的，不会占用服务器的任何系统</li>
</ul>
<p>Calico 的核心组件：</p>
<ul>
<li>Felix，Calico agent，跑在每台需要运行 workload 的节点上，主要负责配置路由及 ACLs 等信息来确保 endpoint 的连通状态；</li>
<li>etcd，分布式键值存储，主要负责网络元数据一致性，确保 Calico 网络状态的准确性；</li>
<li>BGP Client(BIRD), 主要负责把 Felix 写入 kernel 的路由信息分发到当前 Calico 网络，确保 workload 间的通信的有效性；</li>
</ul>
<p>BGP Route Reflector(BIRD), 大规模部署时使用，摒弃所有节点互联的 mesh 模式，通过一个或者多个BGP Route Reflector来完成集中式的路由分发；<br>通过将整个互联网的可扩展 IP 网络原则压缩到数据中心级别，Calico 在每一个计算节点利用Linux kernel实现了一个高效的vRouter来负责数据转发而每个vRouter通过BGP<br>协议负责把自己上运行的 workload 的路由信息像整个 Calico 网络内传播 － 小规模部署可以直接互联，大规模下可通过指定的<br>BGP route reflector 来完成。这样保证最终所有的 workload 之间的数据流量都是通过 IP 包的方式完成互联的。</p>
<p>当容器创建时，calico为容器生成veth pair，一端作为容器网卡加入到容器的网络命名空间，并设置IP和掩码，一端直接暴露在宿主机上，<br>并通过设置路由规则，将容器IP暴露到宿主机的通信路由上。于此同时，calico为每个主机分配了一段子网作为容器可分配的IP范围，这样就可以根据子网的<br>CIDR为每个主机生成比较固定的路由规则。<br>当容器需要跨主机通信时，主要经过下面的简单步骤：<br>1）容器流量通过veth pair到达宿主机的网络命名空间上。<br>2）根据容器要访问的IP所在的子网CIDR和主机上的路由规则，找到下一跳要到达的宿主机IP。<br>3）流量到达下一跳的宿主机后，根据当前宿主机上的路由规则，直接到达对端容器的veth pair插在宿主机的一端，最终进入容器。</p>
<p>从上面的通信过程来看，跨主机通信时，整个通信路径完全没有使用NAT或者UDP封装，性能上的损耗确实比较低。但正式由于calico的通信机制是完全基于三层的，这种机制也带来了一些缺陷，例如：<br>1）calico目前只支持TCP、UDP、ICMP、ICMPv6协议，如果使用其他四层协议（例如NetBIOS协议），建议使用weave、原生overlay等其他overlay网络实现<br>2）基于三层实现通信，在二层上没有任何加密包装，因此只能在私有的可靠网络上使用。<br>3）流量隔离基于iptables实现，并且从etcd中获取需要生成的隔离规则，有一些性能上的隐患</p>
<p>calico/nodedocker容器运行在k8s的master和每个node节点上。由于它包含用于calico路由的BGPagent<br>calico-cni插件与kubelet组件一起部署在每个node节点上，用于当pod创建后，添加该pod到calico网路<br>calico/kube-policy-controller运行在k8s的pod里</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">配置NetworkManager</span><br><span class="line">NetworkManager管理默认网络命名空间中接口的路由表的功能，可能会干扰Calico正确处理网络路由的能力。</span><br><span class="line">创建一个配置文件/etc/NetworkManager/conf.d/calico.conf，来制止这种干扰：</span><br><span class="line">[keyfile]</span><br><span class="line">unmanaged-devices=interface-name:cali*;interface-name:tunl*</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#node上执行</span><br><span class="line">mkdir /opt/cni/bin /etc/cni/net.d -p</span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz</span><br><span class="line">tar xvf cni-plugins-linux-amd64-v0.8.6.tgz -C /opt/cni/bin/</span><br><span class="line"></span><br><span class="line">#以下在master01上执行</span><br><span class="line">mkdir -p ~/yaml/calico$ cd ~/yaml/calico</span><br><span class="line"># 注意：下面是基于自建etcd做为存储的配置文件</span><br><span class="line">curl https://docs.projectcalico.org/manifests/calico-etcd.yaml -O</span><br></pre></td></tr></table></figure>
<p>calico-etcd.yaml需要修改如下配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">#Secret 配置修改</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secrettype: Opaque</span><br><span class="line">metadata:  </span><br><span class="line">  name: calico-etcd-secrets</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:  </span><br><span class="line">  etcd-key: (cat /opt/kubernetes/ssl/server-key.pem | base64 -w 0) # 将输出结果填写在这里</span><br><span class="line">  etcd-cert: (cat /opt/kubernetes/ssl/server.pem | base64 -w 0) # 将输出结果填写在这里</span><br><span class="line">  etcd-ca: (cat /opt/kubernetes/ssl/ca.pem | base64 -w 0) # 将输出结果填写在这里</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#ConfigMap 配置修改</span><br><span class="line"># You must also populate the Secret below with these files.</span><br><span class="line">etcd_ca: &quot;/calico-secrets/etcd-ca&quot;</span><br><span class="line">etcd_cert: &quot;/calico-secrets/etcd-cert&quot;</span><br><span class="line">etcd_key: &quot;/calico-secrets/etcd-key</span><br><span class="line"></span><br><span class="line">#配置网卡自动发现规则</span><br><span class="line">- name: IP_AUTODETECTION_METHOD</span><br><span class="line">  value: &quot;interface=eth.*&quot;</span><br><span class="line">- name: IP6_AUTODETECTION_METHOD</span><br><span class="line">  value: &quot;interface=eth.*&quot;</span><br><span class="line">- name: KUBERNETES_SERVICE_HOST</span><br><span class="line">  value: &quot;lb.abc.com.cn&quot;</span><br><span class="line">- name: KUBERNETES_SERVICE_PORT</span><br><span class="line">  value: &quot;6443&quot;</span><br><span class="line">- name: KUBERNETES_SERVICE_PORT_HTTPS</span><br><span class="line">  value: &quot;6443&quot;</span><br><span class="line"></span><br><span class="line">#检查Calico 模式设置，默认为ipip</span><br><span class="line">- name: CALICO_IPV4POOL_IPIP</span><br><span class="line">　value: &quot;Always</span><br><span class="line"></span><br><span class="line">[root@master01 calico]# kubectl apply -f calico-etcd.yaml</span><br><span class="line">secret/calico-etcd-secrets created</span><br><span class="line">configmap/calico-config created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/calico-node created</span><br><span class="line">daemonset.apps/calico-node created</span><br><span class="line">serviceaccount/calico-node created</span><br><span class="line">deployment.apps/calico-kube-controllers created</span><br><span class="line">serviceaccount/calico-kube-controllers created</span><br><span class="line"></span><br><span class="line">#这里需要注意,如果calico-kube-controllers报如下错误，需要在service里env添加KUBERNETES_SERVICE_HOST和KUBERNETES_SERVICE_PORT环境变量</span><br><span class="line"></span><br><span class="line">E0820 02:39:51.732885       1 reflector.go:153] pkg/mod/k8s.io/client-go@v0.17.2/tools/cache/reflector.go:105: Failed to list *v1.ServiceAccount: Get https://10.10.0.1:443/api/v1/serviceaccounts?limit=500&amp;resourceVersion=0: dial tcp 10.10.0.1:443: i/o timeout</span><br><span class="line"></span><br><span class="line">此外，这里也和网络插件选择有关系，如果选择的是flannel默认工作方式，工作是正常的.如果选择的是calico的ipip模式，需要在calico　init环境里添加KUBERNETES_SERVICE_HOST和KUBERNETES_SERVICE_PORT环境变量，否则在添加pod时候会提示无法连接apiserver.</span><br><span class="line">网络结构方面的因素:本文的测试环境为master和node不在同一个机器，用nginx负载均衡给后边三台主机，nginx未在三台master上，所以才需要calico　init添加相关环境变量。</span><br><span class="line"></span><br><span class="line">[root@master01 calico]# kubectl  get pods -n kube-system  | grep calico</span><br><span class="line">calico-kube-controllers-cdd76d5d-qh8lj   1/1     Running   0          51s</span><br><span class="line">calico-node-8qntz                        1/1     Running   0          51s</span><br><span class="line">calico-node-c7d5k                        1/1     Running   0          51s</span><br><span class="line">calico-node-xrxb5                        1/1     Running   0          51s</span><br><span class="line"></span><br><span class="line">[root@master01 calico]# kubectl get node</span><br><span class="line">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class="line">node01   Ready    &lt;none&gt;   18h    v1.18.6</span><br><span class="line">node02   Ready    &lt;none&gt;   6h7m   v1.18.6</span><br><span class="line">node03   Ready    &lt;none&gt;   6h7m   v1.18.6</span><br></pre></td></tr></table></figure></p>
<p>Calico 管理工具<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">wget wget -O /usr/local/bin/calicoctl https://github.com/projectcalico/calicoctl/releases/download/v3.14.2/calicoctl</span><br><span class="line">chmod +x /usr/local/bin/calicoctl</span><br><span class="line"></span><br><span class="line">[root@node01 ~]# calicoctl node status</span><br><span class="line">Calico process is running.</span><br><span class="line"></span><br><span class="line">IPv4 BGP status</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line">|  PEER ADDRESS  |     PEER TYPE     | STATE |  SINCE   |    INFO     |</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line">| 192.168.1.104 | node-to-node mesh | up    | 10:27:12 | Established |</span><br><span class="line">| 192.168.1.105 | node-to-node mesh | up    | 10:27:13 | Established |</span><br><span class="line">+----------------+-------------------+-------+----------+-------------+</span><br><span class="line"></span><br><span class="line">IPv6 BGP status</span><br><span class="line">No IPv6 peers found.</span><br></pre></td></tr></table></figure></p>
<p>如果是用flannel，参考如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"></span><br><span class="line">添加环境变量和修改Network为kube-control-manager里cluster-cidr一致</span><br><span class="line">- name: KUBERNETES_SERVICE_HOST</span><br><span class="line">  value: lb.abc.com.cn</span><br><span class="line">- name: KUBERNETES_SERVICE_PORT</span><br><span class="line">  value: &quot;6443&quot;</span><br><span class="line"></span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;Network&quot;: &quot;10.20.0.0/16&quot;,</span><br><span class="line">      &quot;Backend&quot;: &#123;</span><br><span class="line">        &quot;Type&quot;: &quot;vxlan&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">kubectl apply -f kube-flannel.yml </span><br><span class="line">kubectl get pods -n kube-system</span><br></pre></td></tr></table></figure></p>
<h5 id="CoreDNS部署"><a href="#CoreDNS部署" class="headerlink" title="CoreDNS部署"></a>CoreDNS部署</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">yum install jq -y</span><br><span class="line">cd ~/yaml</span><br><span class="line">mkdir coredns</span><br><span class="line">cd coredns</span><br><span class="line">wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed</span><br><span class="line">wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh</span><br><span class="line">chmod +x deploy.sh</span><br><span class="line">#默认情况下 CLUSTER_DNS_IP 是自动获取kube-dns的集群ip的，但是由于没有部署kube-dns所以只能手动指定一个集群ip</span><br><span class="line">./deploy.sh -i 10.10.0.2 &gt; coredns.yml</span><br><span class="line">kubectl apply -f coredns.yml</span><br><span class="line">kubectl get pods --namespace kube-system</span><br><span class="line">kubectl get svc --namespace kube-system</span><br><span class="line"></span><br><span class="line">#测试 Coredns 解析</span><br><span class="line">[root@master01 coredns]# cat busybox.yml </span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28.4</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br><span class="line"></span><br><span class="line">[root@master01 coredns]# kubectl apply -f busybox.yml </span><br><span class="line">[root@master01 coredns]# kubectl exec -i busybox -n default nslookup kubernetes</span><br><span class="line">kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.</span><br><span class="line">Server:    10.10.0.2</span><br><span class="line">Address 1: 10.10.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.10.0.1 kubernetes.default.svc.cluster.local</span><br></pre></td></tr></table></figure>
<h5 id="验证集群状态"><a href="#验证集群状态" class="headerlink" title="验证集群状态"></a>验证集群状态</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#打node 或者master 节点的标签</span><br><span class="line">kubectl label node 192.168.1.101  node-role.kubernetes.io/master=&apos;master&apos;</span><br><span class="line">kubectl label node 192.168.1.104  node-role.kubernetes.io/node=&apos;node&apos;</span><br><span class="line">kubectl label node 192.168.1.105  node-role.kubernetes.io/node=&apos;node&apos;</span><br><span class="line">kubectl label node 192.168.1.106  node-role.kubernetes.io/node=&apos;node&apos;</span><br><span class="line"></span><br><span class="line">kubectl get node,cs</span><br></pre></td></tr></table></figure>
<h5 id="metrics遇到的问题"><a href="#metrics遇到的问题" class="headerlink" title="metrics遇到的问题"></a>metrics遇到的问题</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">E0904 14:56:32.791786     852 available_controller.go:420] v1beta1.metrics.k8s.io failed with: failing or missing response from https://10.10.22.87:443/apis/metrics.k8s.io/v1beta1: bad status from https://10.10.22.87:443/apis/metrics.k8s.io/v1beta1: 403</span><br><span class="line"></span><br><span class="line">解决有两个方式:</span><br><span class="line">1.给system:annonymous权限</span><br><span class="line">kubectl create clusterrolebinding system:anonymous   --clusterrole=cluster-admin   --user=system:anonymous</span><br><span class="line"></span><br><span class="line">2.创建system:metrics-server角色并授权,参考[官网文档](https://kubernetes.io/docs/tasks/extend-kubernetes/configure-aggregation-layer/)</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /opt/kubernetes/ssl/front-proxy-ca-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca</span><br><span class="line"></span><br><span class="line">cat front-proxy-client-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cfssl gencert   -ca=front-proxy-ca.pem  -ca-key=front-proxy-ca-key.pem -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare front-proxy-client</span><br><span class="line"></span><br><span class="line">kube-apiserver添加如下参数，重启服务</span><br><span class="line">--proxy-client-cert-file=/opt/kubernetes/ssl/front-proxy-client.pem \</span><br><span class="line">--proxy-client-key-file=/opt/kubernetes/ssl/front-proxy-client-key.pem \</span><br><span class="line">--requestheader-allowed-names=front-proxy-client \</span><br><span class="line">--requestheader-client-ca-file=/opt/kubernetes/ssl/front-proxy-ca.pem \</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra- \</span><br><span class="line">--requestheader-group-headers=X-Remote-Group \</span><br><span class="line">--requestheader-username-headers=X-Remote-User \</span><br><span class="line">--runtime-config=api/all=true&quot;</span><br><span class="line"></span><br><span class="line">重启服务后通过一下命令查看配置是否生成相应configmap</span><br><span class="line">kubectl get configmap extension-apiserver-authentication -nkube-system -o yaml</span><br></pre></td></tr></table></figure>
<p>[ref]<br><a href="https://www.cnblogs.com/centos-python/articles/13168559.html" target="_blank" rel="noopener">Kubelet 证书如何自动续期</a><br><a href="https://www.cnblogs.com/ainimore/p/12972858.html" target="_blank" rel="noopener">kubelet 证书自动续期</a><br><a href="https://blog.51cto.com/14143894/2483207" target="_blank" rel="noopener">k8s高可用二进制部署使用Calico网络方案</a><br><a href="https://juejin.im/post/6844904163785211911#heading-21" target="_blank" rel="noopener">Kubernetes v1.18.2 二进制高可用部署</a><br><a href="https://my.oschina.net/xueyi28/blog/3071431" target="_blank" rel="noopener">calico网络原理、组网方式和使用</a><br><a href="https://www.cnblogs.com/zerchin/p/CentOS7_kernel_update.html" target="_blank" rel="noopener">CentOS7升级系统内核至4.4.xx版本</a><br><a href="https://juejin.im/entry/6844903613332996110" target="_blank" rel="noopener">kubernetes实验:k8s与各网络插件集成</a><br><a href="https://blog.fanfengqiang.com/2019/07/27/kubernetes%E7%8E%AF%E5%A2%83%E4%B8%ADflannel%E7%BD%91%E7%BB%9C%E6%8F%92%E4%BB%B6%E7%9A%84DNS%E4%B8%8Ehosts%E6%96%87%E4%BB%B6%E7%9A%84%E4%BC%98%E5%85%88%E7%BA%A7%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">kubernetes环境中flannel网络插件的DNS与hosts文件的优先级问题</a><br><a href="https://juejin.im/entry/6844903665879220231" target="_blank" rel="noopener">Kubernetes DNS 高阶指南</a><br><a href="https://stackoverflow.com/questions/58194119/kubeadm-failed-to-create-subnetmanager-error-retrieving-pod-spec-for-kube-syste" target="_blank" rel="noopener">Kubeadm Failed to create SubnetManager: error retrieving pod spec for kube-system</a><br><a href="https://blog.51cto.com/foxhound/2121569" target="_blank" rel="noopener">RBAC DENY 解决办法</a><br><a href="https://xigang.github.io/2019/03/15/metrics-servere/" target="_blank" rel="noopener">Kubernetes Metrics-Server介绍及源码分析</a><br><a href="https://aws.amazon.com/cn/premiumsupport/knowledge-center/eks-metrics-server/" target="_blank" rel="noopener">为什么我无法在 Amazon EKS 中使用 Metrics Server 从容器、pod 或节点收集指标？</a><br><a href="https://www.lijiaocn.com/%E9%97%AE%E9%A2%98/2019/02/28/kubernetes-node-cannot-access-service.html" target="_blank" rel="noopener">Kubernetes集群node无法访问service：kube-proxy没有正确设置cluster-cidr</a></p>
<hr>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;环境和版本说明&quot;&gt;&lt;a href=&quot;#环境和版本说明&quot; class=&quot;headerlink&quot; title=&quot;环境和版本说明&quot;&gt;&lt;/a&gt;环境和版本说明&lt;/h5&gt;&lt;p&gt;系统： CentOS Linux release 7.8.2003 (Core)&lt;br&gt;etcd: 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How certificates are used by k8s</title>
    <link href="https://t1ger.github.io/2020/08/10/How-certificates-are-used-by-k8s/"/>
    <id>https://t1ger.github.io/2020/08/10/How-certificates-are-used-by-k8s/</id>
    <published>2020-08-10T06:49:12.000Z</published>
    <updated>2020-09-15T14:50:54.441Z</updated>
    
    <content type="html"><![CDATA[<h4 id="k8s需要多少证书呢，参考这里"><a href="#k8s需要多少证书呢，参考这里" class="headerlink" title="k8s需要多少证书呢，参考这里"></a>k8s需要多少证书呢，参考<a href="https://kubernetes.io/docs/setup/best-practices/certificates/" target="_blank" rel="noopener">这里</a></h4><p>主要包括</p>
<ul>
<li>etcd 包括 etcd server、etcd peer、etcd client</li>
<li>kube-apiserver 需要kube-apiserver server证书</li>
<li>kube-scheduler 、kube-controller-manager、kube-proxy、kubelet　需要kube-apiserver client证书</li>
<li>kube-controller-manager 　需要service account证书</li>
<li>kubelet 需要kubelet server证书</li>
<li>kube-apiserver 需要kubelet client证书</li>
</ul>
<p>由于验证证书只能指定一共root ca,需要同一系统内的证书都是同一个ca签署</p>
<h4 id="TLS-bootstrapping-简化kubelet证书制作"><a href="#TLS-bootstrapping-简化kubelet证书制作" class="headerlink" title="TLS bootstrapping 简化kubelet证书制作"></a>TLS bootstrapping 简化kubelet证书制作</h4><p>kubelet第一次启动，先使用bootstarp token,并将token设置属于system:bootstrappers,在认证通过后，kubelet申请<br>到kubelet server、kube-apiserver client for kubelet证书，之后在用证书做认证，取得kubelet权限，并且可以自动更新，具体可以参考<a href="https://kubernetes.io/docs/tasks/tls/certificate-rotation/" target="_blank" rel="noopener">这里</a></p>
<p>为了安全和审计，每个kubelet都有服务端和客户端两组证书，服务端和客户端与所在机器ip绑定，防止伪造认证证书<br>在kubelet启动后，本地的bootstrap token会被删除。</p>
<h4 id="证书组件"><a href="#证书组件" class="headerlink" title="证书组件"></a>证书组件</h4><ul>
<li>etcd：使用 ca.pem、server-key.pem、server.pem</li>
<li>kube-apiserver：使用 ca.pem、server-key.pem、server.pem</li>
<li>kubelet：使用 ca.pem</li>
<li>kube-proxy：使用 ca.pem、kube-proxy-key.pem、kube-proxy.pem</li>
<li>kubectl：使用 ca.pem、admin-key.pem、admin.pem</li>
<li>kube-controller-manager：使用 ca-key.pem、ca.pem</li>
</ul>
<p>cfssl是cloudflare开发的一个开源的PKI工具,k8s中证书只需要创建一次，以后在向集群中添加新节点时只要将/etc/kubernetes/ssl目录下的证书拷贝到新节点上即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/ssl -p</span><br><span class="line"></span><br><span class="line">curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl_1.4.1_linux_amd64 -o cfssl</span><br><span class="line">chmod +x cfssl</span><br><span class="line">curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssljson_1.4.1_linux_amd64 -o cfssljson</span><br><span class="line">chmod +x cfssljson</span><br><span class="line">curl -L https://github.com/cloudflare/cfssl/releases/download/v1.4.1/cfssl-certinfo_1.4.1_linux_amd64 -o cfssl-certinfo</span><br><span class="line">chmod +x cfssl-certinfo</span><br><span class="line"></span><br><span class="line">#移动到 /usr/local/bin目录下</span><br><span class="line">mv cfssl /usr/local/bin/cfssl</span><br><span class="line">mv cfssljson /usr/local/bin/cfssljson</span><br><span class="line">mv cfssl-certinfo /usr/bin/cfssl-certinfo</span><br></pre></td></tr></table></figure></p>
<p>先创建ca证书，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ssl]# cat cert.sh </span><br><span class="line">#创建证书配置文件</span><br><span class="line">cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">          &quot;signing&quot;,</span><br><span class="line">          &quot;key encipherment&quot;,</span><br><span class="line">          &quot;server auth&quot;,</span><br><span class="line">          &quot;client auth&quot;</span><br><span class="line">        ]</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">#创建CA证书签名请求文件</span><br><span class="line">cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">          &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">          &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">          &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">          &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">          &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    &quot;ca&quot;: &#123;</span><br><span class="line">        &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">#生成CA证书和私钥</span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br><span class="line"></span><br><span class="line">#-----------------------</span><br><span class="line">#创建kubernetes证书签名请求文件 kubernetes-csr.json</span><br><span class="line">cat &gt; server-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;hosts&quot;: [</span><br><span class="line">      &quot;127.0.0.1&quot;,</span><br><span class="line">      &quot;192.168.1.101&quot;,</span><br><span class="line">      &quot;192.168.1.102&quot;,</span><br><span class="line">      &quot;192.168.1.103&quot;,</span><br><span class="line">      &quot;192.168.1.104&quot;,</span><br><span class="line">      &quot;192.168.1.105&quot;,</span><br><span class="line">      &quot;192.168.1.106&quot;,</span><br><span class="line">      &quot;192.168.1.31&quot;,</span><br><span class="line">      &quot;10.10.0.1&quot;,</span><br><span class="line">      &quot;lb.abc.com.cn&quot;,</span><br><span class="line">      &quot;kubernetes&quot;,</span><br><span class="line">      &quot;kubernetes.default&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">      &quot;kubernetes.default.svc.cluster.local&quot;</span><br><span class="line">    ],</span><br><span class="line">    &quot;keys&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">     ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">#生成kubernetes证书和私钥</span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server</span><br><span class="line"></span><br><span class="line">#-----------------------</span><br><span class="line">#创建admin证书签名请求文件admin-csr.json</span><br><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;names&quot;: [</span><br><span class="line">     &#123;</span><br><span class="line">       &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">       &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">       &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">       &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">       &quot;OU&quot;: &quot;System&quot; </span><br><span class="line">     &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">#生成admin证书和私钥</span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br><span class="line"></span><br><span class="line">#-----------------------</span><br><span class="line">#创建 kube-proxy 证书签名请求文件 kube-proxy-csr.json</span><br><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;system:kube-proxy&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">#生成kube-proxy证书和私钥</span><br><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt; /opt/kubernetes/ssl/front-proxy-ca-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cfssl gencert   -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca</span><br><span class="line"></span><br><span class="line">cat front-proxy-client-csr.json</span><br><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;front-proxy-client&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cfssl gencert   -ca=front-proxy-ca.pem  -ca-key=front-proxy-ca-key.pem -config=ca-config.json   -profile=kubernetes   front-proxy-client-csr.json | cfssljson -bare front-proxy-client</span><br></pre></td></tr></table></figure></p>
<p>经过上述操作，我们会用到如下文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">[root@master01 ssl]# ls | grep pem</span><br><span class="line">admin-key.pem</span><br><span class="line">admin.pem</span><br><span class="line">ca-key.pem</span><br><span class="line">ca.pem</span><br><span class="line">kube-proxy-key.pem</span><br><span class="line">kube-proxy.pem</span><br><span class="line">front-proxy-ca.pem</span><br><span class="line">front-proxy-client-key.pem</span><br><span class="line">front-proxy-client.pem</span><br><span class="line">server-key.pem</span><br><span class="line">server.pem</span><br><span class="line"></span><br><span class="line">[root@master01 ssl]#  cfssl-certinfo -cert server.pem </span><br><span class="line">&#123;</span><br><span class="line">  &quot;subject&quot;: &#123;</span><br><span class="line">    &quot;common_name&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;country&quot;: &quot;CN&quot;,</span><br><span class="line">    &quot;organization&quot;: &quot;k8s&quot;,</span><br><span class="line">    &quot;organizational_unit&quot;: &quot;System&quot;,</span><br><span class="line">    &quot;locality&quot;: &quot;BeiJing&quot;,</span><br><span class="line">    &quot;province&quot;: &quot;BeiJing&quot;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &quot;CN&quot;,</span><br><span class="line">      &quot;BeiJing&quot;,</span><br><span class="line">      &quot;BeiJing&quot;,</span><br><span class="line">      &quot;k8s&quot;,</span><br><span class="line">      &quot;System&quot;,</span><br><span class="line">      &quot;kubernetes&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;issuer&quot;: &#123;</span><br><span class="line">    &quot;common_name&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;country&quot;: &quot;CN&quot;,</span><br><span class="line">    &quot;organization&quot;: &quot;k8s&quot;,</span><br><span class="line">    &quot;organizational_unit&quot;: &quot;System&quot;,</span><br><span class="line">    &quot;locality&quot;: &quot;BeiJing&quot;,</span><br><span class="line">    &quot;province&quot;: &quot;BeiJing&quot;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">      &quot;CN&quot;,</span><br><span class="line">      &quot;BeiJing&quot;,</span><br><span class="line">      &quot;BeiJing&quot;,</span><br><span class="line">      &quot;k8s&quot;,</span><br><span class="line">      &quot;System&quot;,</span><br><span class="line">      &quot;kubernetes&quot;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;serial_number&quot;: &quot;19274655049576197307596686114763105929787949774&quot;,</span><br><span class="line">  &quot;sans&quot;: [</span><br><span class="line">    &quot;lb.abc.com.cn&quot;,</span><br><span class="line">    &quot;kubernetes&quot;,</span><br><span class="line">    &quot;kubernetes.default&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster.local&quot;,</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;192.168.1.101&quot;,</span><br><span class="line">    &quot;192.168.1.102&quot;,</span><br><span class="line">    &quot;192.168.1.103&quot;,</span><br><span class="line">    &quot;192.168.1.104&quot;,</span><br><span class="line">    &quot;192.168.1.105&quot;,</span><br><span class="line">    &quot;192.168.1.106&quot;,</span><br><span class="line">    &quot;192.168.1.31&quot;,</span><br><span class="line">    &quot;10.10.0.1&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;not_before&quot;: &quot;2020-08-11T02:00:00Z&quot;,</span><br><span class="line">  &quot;not_after&quot;: &quot;2030-08-09T02:00:00Z&quot;,</span><br><span class="line">  &quot;sigalg&quot;: &quot;SHA256WithRSA&quot;,</span><br><span class="line">  &quot;authority_key_id&quot;: &quot;6E:10:7:8A:76:12:FB:BA:1D:E7:FE:1:64:F3:91:27:84:11:B1:2F&quot;,</span><br><span class="line">  &quot;subject_key_id&quot;: &quot;7C:9:71:B8:4A:44:67:B3:AF:2A:7E:AF:6E:85:25:CA:45:42:F1:4B&quot;,</span><br><span class="line">  &quot;pem&quot;: &quot;-----BEGIN CERTIFICATE-----\nMIID7DCCAtSgAwIBAgIUA2BOME/jWBL4uij8QyiWoDZJQs4wDQYJKoZIhvcNAQEL\nBQAwZTELMAkGA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0Jl\naUppbmcxDDAKBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwpr\ndWJlcm5ldGVzMB4XDTIwMDgxMTAyMDAwMFoXDTMwMDgwOTAyMDAwMFowZTELMAkG\nA1UEBhMCQ04xEDAOBgNVBAgTB0JlaUppbmcxEDAOBgNVBAcTB0JlaUppbmcxDDAK\nBgNVBAoTA2s4czEPMA0GA1UECxMGU3lzdGVtMRMwEQYDVQQDEwprdWJlcm5ldGVz\nMFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAER9TcihsMPkH269/9NFBZq0pghd4T\n2IdWRmmpyA8THsaguBq8sWjwOfmXbm8SYMJvFJmcsdFRM4gGpeeCrCEsQKOCAV0w\nggFZMA4GA1UdDwEB/wQEAwIFoDAdBgNVHSUEFjAUBggrBgEFBQcDAQYIKwYBBQUH\nAwIwDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUfAlxuEpEZ7OvKn6vboUlykVC8Usw\nHwYDVR0jBBgwFoAUbhAHinYS+7od5/4BZPORJ4QRsS8wgdkGA1UdEQSB0TCBzoIY\nbGIud2hpc3RsZS5ydWlqaWUuY29tLmNuggprdWJlcm5ldGVzghJrdWJlcm5ldGVz\nLmRlZmF1bHSCFmt1YmVybmV0ZXMuZGVmYXVsdC5zdmOCHmt1YmVybmV0ZXMuZGVm\nYXVsdC5zdmMuY2x1c3RlcoIka3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVy\nLmxvY2FshwR/AAABhwSsEc++hwSsEc+/hwSsEc/AhwSsEc+9hwSsEc+8hwSsEc+7\nhwSsEc8nhwQKCgABMA0GCSqGSIb3DQEBCwUAA4IBAQBJxUjmgxDdGl2dxnCJIS5B\nOSG2OqTtVi3TygkZESGKbD264TMD7VzrxXORSgxv87lEOrj6ktz4/gFLNJ19Z3gF\n3bl0DqCOO/ONHNnTLtxto/23dOF2KKMzERaJreFN1a1KyIBAGCyJdBQvQLwiYydj\nfnLxHmJKELUrCOZ8YLtYnHFm/24VcFoeqSHMCC+Csh0gsSHFTml9SJILQO7y+5uU\nD4ym2Hg5JPXmyW7CubsS6snTy9RgW0ptXoiCvIPdyIAtq7uEhHPXbNwAv21dXUg7\n/TLqimS6UdBVopsR5Fv9NKKvhoysHtQ9FPN/xwF/eezcXtJnKGONmi+NX8/Aq6ES\n-----END CERTIFICATE-----\n&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>搭建k8s集群的时候，将这些文件分发到至此集群中其他节点机器中即可<br>kubeadm 证书期限有两种方案；第一种直接修改源码；第二种在启动集群时调整 kube-controller-manager 组件的 –experimental-cluster-signing-duration 参数，集群创建.可以查看参考链接</p>
<p>参考<br><a href="https://mritd.me/2020/01/21/how-to-extend-the-validity-of-your-kubeadm-certificate/" target="_blank" rel="noopener">kubeadm 证书期限调整</a><br><a href="https://blog.fanfengqiang.com/2019/09/11/%E8%AE%BE%E7%BD%AEkubeadm%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6%E4%B8%BA100%E5%B9%B4/" target="_blank" rel="noopener">设置kubeadm自签证书为100年</a></p>
<hr>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;k8s需要多少证书呢，参考这里&quot;&gt;&lt;a href=&quot;#k8s需要多少证书呢，参考这里&quot; class=&quot;headerlink&quot; title=&quot;k8s需要多少证书呢，参考这里&quot;&gt;&lt;/a&gt;k8s需要多少证书呢，参考&lt;a href=&quot;https://kubernetes.
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Welcome to GoCD - an open-source Continuous Integration and Continuous Delivery system</title>
    <link href="https://t1ger.github.io/2020/07/17/Welcome-to-GoCD-an-open-source-Continuous-Integration-and-Continuous-Delivery-system/"/>
    <id>https://t1ger.github.io/2020/07/17/Welcome-to-GoCD-an-open-source-Continuous-Integration-and-Continuous-Delivery-system/</id>
    <published>2020-07-17T07:45:21.000Z</published>
    <updated>2020-07-17T08:38:34.537Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Install"><a href="#Install" class="headerlink" title="Install"></a><b>Install</b></h3><h5 id="GoCD-Server-requirements"><a href="#GoCD-Server-requirements" class="headerlink" title="GoCD Server requirements"></a>GoCD Server requirements</h5><p>Hardware</p>
<ul>
<li>RAM - minimum 1GB, 2GB recommended</li>
<li>CPU - minimum 2 cores, 2GHz</li>
<li>Disk - minimum 1GB free space</li>
</ul>
<h5 id="GoCD-Agent-requirements"><a href="#GoCD-Agent-requirements" class="headerlink" title="GoCD Agent requirements"></a>GoCD Agent requirements</h5><ul>
<li>RAM - minimum 128MB, 256MB recommended</li>
<li>CPU - minimum 2GHz</li>
</ul>
<p>Supported Source Control Tools</p>
<ul>
<li>Git &gt;= 1.9</li>
<li>Mercurial &gt;= 2.2.2</li>
<li>Subversion &gt;= 1.6.11</li>
<li>TFS SDK 14.0.3 (TFS 2012, 2013, 2015 and Visual Studio Team Services are supported by GoCD)</li>
<li>Perforce &gt;= 2016.1</li>
</ul>
<p>Java Dependencies for GoCD (Server and Agent)<br>This version of GoCD works with Java Runtime Environment (JRE) versions 11 and 12</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#server</span><br><span class="line">docker run -d -p8153:8153 -p8154:8154 gocd/gocd-server:v20.5.0</span><br><span class="line"></span><br><span class="line">#agent</span><br><span class="line">docker run -d -e GO_SERVER_URL=... gocd/gocd-agent-alpine-3.11:v20.5.0</span><br></pre></td></tr></table></figure>
<h3 id="Config"><a href="#Config" class="headerlink" title="Config"></a><b>Config</b></h3><ul>
<li>Task 基本上为一个命令，如执行一个ls系统命令,ant构建命令</li>
<li>Job  由多个Task组合而成，Task命令的执行是相互独立的.Task会按照配置顺序依次执行，但如果一个Task失败，后续task将会取消执行<br>Job的成功与否取决于所有Task是否全部执行成功</li>
<li>Stage 由多个Job组合而成,成功与否由全部Task是否成功决定</li>
<li>Pipeline 由多个Stage组合而成,执行方式为依次执行，其中一个Stage执行失败，将不会执行后续Stage</li>
<li>Material  使用Git,Svn</li>
<li>Fan-out and fan-in<br>Fan-out 表示一个Stage的结束可以触发多个Pipeline的Stage开始<br>Fan-in 表示一个Pipeline的开始可以等待多个Stage完成后才被触发</li>
<li>VSM 数据驱动流图，即复杂的Fan-out和Fan-in的视图</li>
<li>Artifacts 在Job上配置，默认会有console.log生成(所有的Job都会在agent上执行，Artifacts存在的意义就是将文件上传到server端，再供使用)</li>
<li>Environment Variables</li>
<li>Resource 可以将Agent进行别名命名，以在配置Job的执行位置时使用,可以将多个Agent命为相同名称</li>
</ul>
<p>以springboot项目为例，分为几部实现自动打包,参考<a href="https://docs.gocd.org/current/configuration/admin_add_job.html" target="_blank" rel="noopener">这里</a></p>
<ul>
<li>实现项目自动打包，自动重启</li>
<li>创建tasks<br>Task1：执行maven打包操作，GoCD已内置了mvn命令，但是代理服务器上需要安装maven客户端<br>Task2：将打包后的jar文件，复制到项目部署目录<br>Task3：重启jar包，需要借助shell 命令来完成。</li>
</ul>
<p>Once the agent is started, switching to the agents tab by clicking on the “Agents” link in the header should take you to a screen where the agent shows up and is idle</p>
<h3 id="Jenkins-VS-GoCD"><a href="#Jenkins-VS-GoCD" class="headerlink" title="Jenkins VS GoCD"></a><b>Jenkins VS GoCD</b></h3><table>
<thead>
<tr>
<th>Jenkins</th>
<th>GoCD</th>
</tr>
</thead>
<tbody>
<tr>
<td>Jenkins是通用自动化工具, 它是为持续集成（CI）构建的</td>
<td>GoCD是连续交付工具</td>
</tr>
<tr>
<td>可扩展性是Jenkins的核心特征,归因于插件对于Jenkins功能至关重要</td>
<td>GoCD旨在支持无需安装任何插件即可立即使用的最常见的连续交付方案</td>
</tr>
<tr>
<td>可以使用任何配置设置随时启用和禁用作业</td>
<td>这种功能在GoCD中不可用</td>
</tr>
<tr>
<td>Jenkins专为持续集成（CI）而设计。除此之外, 还需要插件</td>
<td>尽管GoCD是专门为持续交付（CD）而设计的, 但它是用于持续集成的复杂功能</td>
</tr>
</tbody>
</table>
<hr>
<p><a href="https://docs.gocd.org/current/" target="_blank" rel="noopener">GoCD User Documentation</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Install&quot;&gt;&lt;a href=&quot;#Install&quot; class=&quot;headerlink&quot; title=&quot;Install&quot;&gt;&lt;/a&gt;&lt;b&gt;Install&lt;/b&gt;&lt;/h3&gt;&lt;h5 id=&quot;GoCD-Server-requirements&quot;&gt;&lt;a href=&quot;#Go
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to install and config kong2.0</title>
    <link href="https://t1ger.github.io/2020/04/10/how-to-install-and-config-kong2-0/"/>
    <id>https://t1ger.github.io/2020/04/10/how-to-install-and-config-kong2-0/</id>
    <published>2020-04-10T07:26:20.000Z</published>
    <updated>2020-04-10T08:08:23.236Z</updated>
    
    <content type="html"><![CDATA[<h5 id="k8s环境如下"><a href="#k8s环境如下" class="headerlink" title="k8s环境如下"></a><b>k8s环境如下</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get nodes</span><br><span class="line">NAME     STATUS   ROLES    AGE    VERSION</span><br><span class="line">master   Ready    master   115d   v1.17.0</span><br><span class="line">node01   Ready    &lt;none&gt;   115d   v1.17.0</span><br><span class="line">node02   Ready    &lt;none&gt;   115d   v1.17.0</span><br></pre></td></tr></table></figure>
<h5 id="install-using-YAMLs"><a href="#install-using-YAMLs" class="headerlink" title="install using YAMLs"></a><b>install using YAMLs</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dbless 安装</span><br><span class="line">kubectl apply -f https://bit.ly/k4k8s</span><br><span class="line"></span><br><span class="line">db安装参考(注意kong版本为2.0,官网此处为1.3，没有安装成功)</span><br><span class="line">https://github.com/Kong/kubernetes-ingress-controller/blob/master/deploy/single/all-in-one-postgres.yaml</span><br><span class="line">kubectl apply -f all-in-one-postgres.yaml</span><br></pre></td></tr></table></figure>
<p>需要调整配置如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  annotations: &#123;&#125;</span><br><span class="line">    #service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp</span><br><span class="line">    #service.beta.kubernetes.io/aws-load-balancer-type: nlb</span><br><span class="line">  name: kong-proxy</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  externalTrafficPolicy: Local</span><br><span class="line">  ports:</span><br><span class="line">  - name: proxy</span><br><span class="line">    port: 80</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8000</span><br><span class="line">    nodePort: 80</span><br><span class="line">  - name: proxy-ssl</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8443</span><br><span class="line">    nodePort: 443</span><br><span class="line">  selector:</span><br><span class="line">    app: ingress-kong</span><br><span class="line">  #type: LoadBalancer</span><br><span class="line">  type: NodePort</span><br></pre></td></tr></table></figure></p>
<p>需要增加配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-proxy-admin</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-proxy-admin</span><br><span class="line">    port: 8001</span><br><span class="line">    targetPort: 8001</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: kong-proxy-admin-ssl</span><br><span class="line">    port: 8444</span><br><span class="line">    targetPort: 8444</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: ingress-kong</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kong-validation-webhook</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - name: webhook</span><br><span class="line">    port: 443</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 8080</span><br><span class="line">  selector:</span><br><span class="line">    app: ingress-kong</span><br></pre></td></tr></table></figure></p>
<p>为node2节点打上标签，增加nodeSelector,便于dns指向固定的IP<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl label nodes node02 ingress=proxy </span><br><span class="line">node/node02 labeled</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: ingress-kong</span><br><span class="line">  name: ingress-kong</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: ingress-kong</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations: </span><br><span class="line">#        kuma.io/gateway: enabled</span><br><span class="line">        prometheus.io/port: &quot;9542&quot;</span><br><span class="line">        prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">        traffic.sidecar.istio.io/includeInboundPorts: &quot;&quot;</span><br><span class="line">      labels:</span><br><span class="line">        app: ingress-kong</span><br><span class="line">    spec:</span><br><span class="line">      nodeSelector:</span><br><span class="line">        ingress: proxy</span><br></pre></td></tr></table></figure></p>
<p>安装完成后查看服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@master ~]# kubectl get svc -nkong </span><br><span class="line">NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                 AGE</span><br><span class="line">kong-proxy                NodePort    10.96.3.92      &lt;none&gt;        80:80/TCP,443:443/TCP   45h</span><br><span class="line">kong-proxy-admin          ClusterIP   10.96.208.161   &lt;none&gt;        8001/TCP,8444/TCP       21h</span><br><span class="line">kong-validation-webhook   ClusterIP   10.96.173.105   &lt;none&gt;        443/TCP                 45h</span><br><span class="line">postgres                  ClusterIP   10.96.23.49     &lt;none&gt;        5432/TCP                45h</span><br></pre></td></tr></table></figure></p>
<h5 id="install-kong-dashboard-konga"><a href="#install-kong-dashboard-konga" class="headerlink" title="install kong dashboard konga"></a><b>install kong dashboard konga</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">[root@master kong]# cat konga.yaml </span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: konga</span><br><span class="line">  labels:</span><br><span class="line">    app: konga</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: konga</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: konga</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: konga</span><br><span class="line">        image: pantsel/konga</span><br><span class="line">        env:</span><br><span class="line">        - name: DB_ADAPTER</span><br><span class="line">          value: postgres</span><br><span class="line">        - name: DB_HOST</span><br><span class="line">          value: postgres.kong.svc.cluster.local</span><br><span class="line">        - name: DB_USER</span><br><span class="line">          value: kong</span><br><span class="line">        - name: DB_PASSWORD</span><br><span class="line">          value: kong</span><br><span class="line">        - name: DB_DATABASE</span><br><span class="line">          value: kong</span><br><span class="line">        - name: TOKEN_SECRET</span><br><span class="line">          value: kongadmin</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 1337</span><br><span class="line">          protocol: TCP</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: konga-svc</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - name: kong-proxy</span><br><span class="line">    port: 1337</span><br><span class="line">    targetPort: 1337</span><br><span class="line">    nodePort: 30337</span><br><span class="line">    protocol: TCP</span><br><span class="line">  selector:</span><br><span class="line">    app: konga</span><br><span class="line">---</span><br><span class="line">kind: Ingress</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    kubernetes.io/ingress.class: nginx</span><br><span class="line">  name: konga-ingress</span><br><span class="line">  namespace: kong</span><br><span class="line">spec:</span><br><span class="line">  rules:</span><br><span class="line">  - host: konga.whistle.ruijie.com.cn</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - path: /</span><br><span class="line">        backend:</span><br><span class="line">          serviceName: konga-svc</span><br><span class="line">          servicePort: 80</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f  konga.yaml </span><br><span class="line"></span><br><span class="line">[root@master kong]# kubectl get svc -nkong </span><br><span class="line">NAME                      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                 AGE</span><br><span class="line">kong-proxy                NodePort    10.96.3.92      &lt;none&gt;        80:80/TCP,443:443/TCP   45h</span><br><span class="line">kong-proxy-admin          ClusterIP   10.96.208.161   &lt;none&gt;        8001/TCP,8444/TCP       21h</span><br><span class="line">kong-validation-webhook   ClusterIP   10.96.173.105   &lt;none&gt;        443/TCP                 45h</span><br><span class="line">konga-svc                 NodePort    10.96.223.218   &lt;none&gt;        1337:30337/TCP          24h</span><br><span class="line">postgres                  ClusterIP   10.96.23.49     &lt;none&gt;        5432/TCP                45h</span><br></pre></td></tr></table></figure>
<p>之后就可以访问<a href="http://node1:30337/" target="_blank" rel="noopener">http://node1:30337/</a> 访问konga 相关使用参考<a href="https://www.liangzl.com/get-article-detail-126833.html" target="_blank" rel="noopener">这里</a></p>
<p>可能遇到问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">provided port is not in the valid range. The range of valid ports is 30000-32767</span><br></pre></td></tr></table></figure>
<p>解决：<br>vi /etc/kubernetes/manifests/kube-apiserver.yaml<br> –service-cluster-ip-range 这一行，在这一行的下一行增加 如下内容<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">- --service-node-port-range=1-65535</span><br></pre></td></tr></table></figure></p>
<p>systemctl daemon-reload<br>systemctl restart kubelet</p>
<hr>
<p>ref<br><a href="https://www.zhongzp.com/archives/konga-install/" target="_blank" rel="noopener">konga的安装与配置</a><br><a href="https://github.com/pantsel/konga" target="_blank" rel="noopener">konga</a><br><a href="https://docs.konghq.com/" target="_blank" rel="noopener">kong</a><br><a href="https://blog.csdn.net/hhj724/article/details/103187882" target="_blank" rel="noopener">konga–添加service和rouce详细步骤</a>konga–添加service和rouce详细步骤</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;k8s环境如下&quot;&gt;&lt;a href=&quot;#k8s环境如下&quot; class=&quot;headerlink&quot; title=&quot;k8s环境如下&quot;&gt;&lt;/a&gt;&lt;b&gt;k8s环境如下&lt;/b&gt;&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>How to install ceph-nautilus on CentOS7</title>
    <link href="https://t1ger.github.io/2020/01/02/How-to-install-ceph-nautilus-on-CentOS7/"/>
    <id>https://t1ger.github.io/2020/01/02/How-to-install-ceph-nautilus-on-CentOS7/</id>
    <published>2020-01-02T07:45:04.000Z</published>
    <updated>2020-01-02T09:57:24.490Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a><b>Prepare</b></h5><p>System: CentOS 7.5<br>IP: 192.168.1.129-132<br>Hostname: admin node1-3<br>Disk:/dev/sdb 100G<br>Role: admin osd</p>
<ul>
<li><p>replace ali yum source</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">sed -i -e &apos;/mirrors.cloud.aliyuncs.com/d&apos; -e &apos;/mirrors.aliyuncs.com/d&apos; /etc/yum.repos.d/CentOS-Base.repo</span><br><span class="line">yum clean up &amp;&amp; yum makecache &amp;&amp; yum update -y</span><br></pre></td></tr></table></figure>
</li>
<li><p>set ceph source and epel source, turn off firewalld</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rpm -Uvh https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/ceph-release-1-1.el7.noarch.rpm</span><br><span class="line">yum install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</span><br><span class="line"></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>
</li>
<li><p>make sure time sync,all node install chrony</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">yum install -y chrony</span><br><span class="line"></span><br><span class="line">#admin node sync aliyun ntp server</span><br><span class="line">sudo sed -i &apos;/^server .*/d&apos; /etc/chrony.conf</span><br><span class="line">sudo sed -ri &apos;3s#^$#server ntp1.aliyun.com iburst\nallow 192.168.1.0/24#&apos; /etc/chrony.conf</span><br><span class="line">sudo systemctl enable chronyd</span><br><span class="line">sudo systemctl restart chronyd</span><br><span class="line"></span><br><span class="line"># other node sync admin node</span><br><span class="line">ssh node1 &quot;sudo sed -i &apos;/^server .*/d&apos; /etc/chrony.conf&quot;</span><br><span class="line">ssh node1 &quot;sudo sed -ri &apos;3s#^\$#server 192.168.1.129 iburst#&apos; /etc/chrony.conf&quot;</span><br><span class="line">ssh node2 &quot;sudo sed -i &apos;/^server .*/d&apos; /etc/chrony.conf&quot;</span><br><span class="line">ssh node2 &quot;sudo sed -ri &apos;3s#^\$#server 192.168.1.129 iburst#&apos; /etc/chrony.conf&quot;</span><br><span class="line">ssh node3 &quot;sudo sed -i &apos;/^server .*/d&apos; /etc/chrony.conf&quot;</span><br><span class="line">ssh node3 &quot;sudo sed -ri &apos;3s#^\$#server 192.168.1.129 iburst#&apos; /etc/chrony.conf&quot;</span><br><span class="line"></span><br><span class="line">#reboot chrony service</span><br><span class="line">ssh node1 sudo systemctl enable chronyd</span><br><span class="line">ssh node1 sudo systemctl restart chronyd</span><br><span class="line">ssh node2 sudo systemctl enable chronyd</span><br><span class="line">ssh node2 sudo systemctl restart chronyd</span><br><span class="line">ssh node3 sudo systemctl enable chronyd</span><br><span class="line">ssh node3 sudo systemctl restart chronyd</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="Install-ceph"><a href="#Install-ceph" class="headerlink" title="Install ceph"></a><b>Install ceph</b></h5><ul>
<li><p>install ceph-deploy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y https://mirrors.aliyun.com/ceph/rpm-nautilus/el7/noarch/ceph-deploy-2.0.1-0.noarch.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>install ceph</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy install admin node1 node2 node3</span><br></pre></td></tr></table></figure>
</li>
<li><p>add mon</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy new node1 node2 node3</span><br><span class="line">ceph-deploy mon create-initial</span><br></pre></td></tr></table></figure>
</li>
<li><p>create ceph admin node</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy mgr create node1 node2 node3</span><br></pre></td></tr></table></figure>
</li>
<li><p>create osd node</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy osd create --data /dev/sdb node1</span><br><span class="line">ceph-deploy osd create --data /dev/sdb node2</span><br><span class="line">ceph-deploy osd create --data /dev/sdb node3</span><br></pre></td></tr></table></figure>
</li>
<li><p>enable dashboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#from nautilus, dashboard as Independent Modules. need install on all mgr node</span><br><span class="line">yum install -y ceph-mgr-dashboard</span><br><span class="line"># if error</span><br><span class="line">pip uninstall urllib3</span><br><span class="line">yum install python-urllib3 -y</span><br><span class="line"></span><br><span class="line">#enable dashboard</span><br><span class="line">ceph mgr module enable dashboard　--force</span><br><span class="line"></span><br><span class="line"># enable ssl/tls</span><br><span class="line">ceph mgr module enable dashboard　--force</span><br><span class="line"></span><br><span class="line"># create admin user</span><br><span class="line">ceph dashboard ac-user-create admin admin administrator</span><br><span class="line"></span><br><span class="line"># view ceph-mgr service</span><br><span class="line">ceph mgr services</span><br></pre></td></tr></table></figure>
</li>
<li><p>sync conf to all node and copy mgr file to admin</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"># only push config</span><br><span class="line">[root@admin ~]#ceph-deploy --overwrite-conf admin node1 node2 node3</span><br><span class="line"></span><br><span class="line"># push config and client.admin key</span><br><span class="line">[root@admin ~]# ceph-deploy admin admin</span><br><span class="line"></span><br><span class="line">[ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf</span><br><span class="line">[ceph_deploy.cli][INFO  ] Invoked (2.0.1): /usr/bin/ceph-deploy admin admin</span><br><span class="line">[ceph_deploy.cli][INFO  ] ceph-deploy options:</span><br><span class="line">[ceph_deploy.cli][INFO  ]  username                      : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  verbose                       : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  overwrite_conf                : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  quiet                         : False</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cd_conf                       : &lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x7f21349cad40&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  cluster                       : ceph</span><br><span class="line">[ceph_deploy.cli][INFO  ]  client                        : [&apos;admin&apos;]</span><br><span class="line">[ceph_deploy.cli][INFO  ]  func                          : &lt;function admin at 0x7f21356e01b8&gt;</span><br><span class="line">[ceph_deploy.cli][INFO  ]  ceph_conf                     : None</span><br><span class="line">[ceph_deploy.cli][INFO  ]  default_release               : False</span><br><span class="line">[ceph_deploy.admin][DEBUG ] Pushing admin keys and conf to admin</span><br><span class="line">[admin][DEBUG ] connected to host: admin </span><br><span class="line">[admin][DEBUG ] detect platform information from remote host</span><br><span class="line">[admin][DEBUG ] detect machine type</span><br><span class="line">[admin][DEBUG ] write cluster configuration to /etc/ceph/&#123;cluster&#125;.conf</span><br><span class="line"></span><br><span class="line">[root@admin ~]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     376a41f4-2aa1-4f96-9bcb-700f2787ebd8</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">[root@admin ~]#  ceph osd tree</span><br><span class="line">ID CLASS WEIGHT  TYPE NAME      STATUS REWEIGHT PRI-AFF </span><br><span class="line">-1       0.29008 root default                           </span><br><span class="line">-3       0.09669     host node1                         </span><br><span class="line"> 0   hdd 0.09669         osd.0      up  1.00000 1.00000 </span><br><span class="line">-5       0.09669     host node2                         </span><br><span class="line"> 1   hdd 0.09669         osd.1      up  1.00000 1.00000 </span><br><span class="line">-7       0.09669     host node3                         </span><br><span class="line"> 2   hdd 0.09669         osd.2      up  1.00000 1.00000</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="how-to-clear-if-you-reinstall"><a href="#how-to-clear-if-you-reinstall" class="headerlink" title=" how to clear,if you reinstall"></a><b> how to clear,if you reinstall</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@admin ~]#  ceph-deploy purge admin node1 node2 node3</span><br><span class="line">[root@admin ~]#  ceph-deploy purgedata admin node1 node2 node3</span><br><span class="line">[root@admin ~]#  ceph-deploy forgetkeys</span><br></pre></td></tr></table></figure>
<p>ref<br><a href="https://docs.ceph.com/docs/nautilus/mgr/dashboard/" target="_blank" rel="noopener">ceph dashboard</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Prepare&quot;&gt;&lt;a href=&quot;#Prepare&quot; class=&quot;headerlink&quot; title=&quot;Prepare&quot;&gt;&lt;/a&gt;&lt;b&gt;Prepare&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;System: CentOS 7.5&lt;br&gt;IP: 192.168.1.129-132
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Ldap新增用户无法登录GitLab排查</title>
    <link href="https://t1ger.github.io/2019/09/19/Ldap%E6%96%B0%E5%A2%9E%E7%94%A8%E6%88%B7%E6%97%A0%E6%B3%95%E7%99%BB%E5%BD%95GitLab%E6%8E%92%E6%9F%A5/"/>
    <id>https://t1ger.github.io/2019/09/19/Ldap新增用户无法登录GitLab排查/</id>
    <published>2019-09-19T04:53:48.000Z</published>
    <updated>2019-09-19T05:38:56.789Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">问题背景,Gitlab通过ldap方式认证,今天想新增加一个新用户cibot,用于jenkins拉取代码. 通过工具复制了一个用户,修改uid,登录的时候发现用户无法登录.</span><br><span class="line">报错信息如下:</span><br><span class="line">Undefined method `provider&apos; for nil:nilclass</span><br><span class="line">通过搜索发现大部分人都碰到过这个错误,有的是邮箱地址没填写,有的是版本过低,也有说是gitlab bug的</span><br></pre></td></tr></table></figure>
<p>首先，登录 GitLab 所在服务器，发现正常输出<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo gitlab-rake gitlab:ldap:check</span><br><span class="line">Checking LDAP ...</span><br><span class="line"></span><br><span class="line">LDAP: ... Server: ldapmain</span><br><span class="line">LDAP authentication... Success</span><br><span class="line">LDAP users with access to your GitLab server (only showing the first 100 results)</span><br></pre></td></tr></table></figure></p>
<p>由于GitLab 使用 PostgreSQL 数据库存储用户等相关数据,查看一下 GitLab 数据库 PostgreSQL 的配置文件，看下相关的配置信息，一般来说，GitLab 服务会专门创建一个系统用户来管理该数据库服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon ~]# cat /var/opt/gitlab/gitlab-rails/etc/database.yml</span><br><span class="line"># This file is managed by gitlab-ctl. Manual changes will be</span><br><span class="line"># erased! To change the contents below, edit /etc/gitlab/gitlab.rb</span><br><span class="line"># and run `sudo gitlab-ctl reconfigure`.</span><br><span class="line"></span><br><span class="line">production:</span><br><span class="line">  adapter: postgresql</span><br><span class="line">  encoding: unicode</span><br><span class="line">  collation: </span><br><span class="line">  database: gitlabhq_production</span><br><span class="line">  pool: 10</span><br><span class="line">  username: &quot;gitlab&quot;</span><br><span class="line">  password: </span><br><span class="line">  host: &quot;/var/opt/gitlab/postgresql&quot;</span><br><span class="line">  port: 5432</span><br><span class="line">  socket: </span><br><span class="line">  sslmode: </span><br><span class="line">  sslcompression: 0</span><br><span class="line">  sslrootcert: </span><br><span class="line">  sslca: </span><br><span class="line">  load_balancing: &#123;&quot;hosts&quot;:[]&#125;</span><br><span class="line">  prepared_statements: false</span><br><span class="line">  statements_limit: 1000</span><br><span class="line">  fdw:</span><br></pre></td></tr></table></figure></p>
<p>看到 username: “gitlab，那么查看下当前系统有哪些跟 gitlab 相关的用户<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon ~]# cat /etc/passwd | grep &apos;gitlab-&apos;</span><br><span class="line">gitlab-www:x:996:993::/var/opt/gitlab/nginx:/bin/false</span><br><span class="line">gitlab-redis:x:994:991::/var/opt/gitlab/redis:/bin/false</span><br><span class="line">gitlab-psql:x:993:990::/var/opt/gitlab/postgresql:/bin/sh</span><br><span class="line">gitlab-prometheus:x:992:989::/var/opt/gitlab/prometheus:/bin/sh</span><br></pre></td></tr></table></figure></p>
<p>看到 gitlab-psql 账户就是我们要使用的用户，接下来就切换到该用户，并连接到 gitlabhq_production 数据库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon ~]#  su - gitlab-psql</span><br><span class="line">Last login: Thu Sep 19 10:53:57 CST 2019 on pts/0</span><br><span class="line">-sh-4.2$ psql -h /var/opt/gitlab/postgresql -d gitlabhq_production</span><br><span class="line">psql (9.6.11)</span><br><span class="line">Type &quot;help&quot; for help.</span><br><span class="line"></span><br><span class="line">gitlabhq_production=# \h</span><br><span class="line">Available help:</span><br><span class="line">  ABORT                            COMMENT                          DECLARE                          EXECUTE</span><br><span class="line">  ALTER AGGREGATE                  COMMIT                           DELETE                           EXPLAIN</span><br><span class="line">  ALTER COLLATION                  COMMIT PREPARED                  DISCARD                          FETCH</span><br><span class="line">  ALTER CONVERSION                 COPY                             DO                               GRANT</span><br><span class="line">  ALTER DATABASE                   CREATE ACCESS METHOD             DROP ACCESS METHOD               IMPORT FOREIGN SCHEMA</span><br><span class="line">  ALTER DEFAULT PRIVILEGES         CREATE AGGREGATE                 DROP AGGREGATE                   INSERT</span><br><span class="line">  ALTER DOMAIN                     CREATE CAST                      DROP CAST                        LISTEN</span><br><span class="line"></span><br><span class="line"># \l 列举所有的数据库列表，相当于 mysql 的 show databases</span><br><span class="line"># 因为连接时指定了 -d gitlabhq_production，默认进去的就是 gitlabhq_production 数据库，不需要切换。</span><br><span class="line">gitlabhq_production=# \l</span><br><span class="line">                                             List of databases</span><br><span class="line">        Name         |    Owner    | Encoding |   Collate   |    Ctype    |        Access privileges        </span><br><span class="line">---------------------+-------------+----------+-------------+-------------+---------------------------------</span><br><span class="line"> gitlabhq_production | gitlab      | UTF8     | en_US.UTF-8 | en_US.UTF-8 | </span><br><span class="line"> postgres            | gitlab-psql | UTF8     | en_US.UTF-8 | en_US.UTF-8 | </span><br><span class="line"> template0           | gitlab-psql | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/&quot;gitlab-psql&quot;               +</span><br><span class="line">                     |             |          |             |             | &quot;gitlab-psql&quot;=CTc/&quot;gitlab-psql&quot;</span><br><span class="line"> template1           | gitlab-psql | UTF8     | en_US.UTF-8 | en_US.UTF-8 | =c/&quot;gitlab-psql&quot;               +</span><br><span class="line">                     |             |          |             |             | &quot;gitlab-psql&quot;=CTc/&quot;gitlab-psql&quot;</span><br><span class="line">(4 rows)</span><br><span class="line"># 列举当前数据库所有表，相当于 mysql 的 show tables</span><br><span class="line">gitlabhq_production=# \dt</span><br><span class="line">                         List of relations</span><br><span class="line"> Schema |                   Name                   | Type  | Owner  </span><br><span class="line">--------+------------------------------------------+-------+--------</span><br><span class="line"> public | abuse_reports                            | table | gitlab</span><br><span class="line"> public | appearances                              | table | gitlab</span><br><span class="line"> public | application_setting_terms                | table | gitlab</span><br><span class="line"> public | application_settings                     | table | gitlab</span><br><span class="line"> public | ar_internal_metadata                     | table | gitlab</span><br><span class="line"> public | audit_events                             | table | gitlab</span><br><span class="line"> public | award_emoji                              | table | gitlab</span><br><span class="line"> public | badges                                   | table | gitlab</span><br><span class="line"> public | board_group_recent_visits                | table | gitlab</span><br><span class="line"> public | board_project_recent_visits              | table | gitlab</span><br><span class="line"> public | boards                                   | table | gitlab</span><br><span class="line"> public | broadcast_messages                       | table | gitlab</span><br><span class="line"> ......</span><br><span class="line"></span><br><span class="line"> # 查看单表结构，相当于 desc tblname, show columns from tbname</span><br><span class="line">gitlabhq_production=# \d users</span><br><span class="line">                                                      Table &quot;public.users&quot;</span><br><span class="line">                    Column                    |            Type             |                     Modifiers                      </span><br><span class="line">----------------------------------------------+-----------------------------+----------------------------------------------------</span><br><span class="line"> id                                           | integer                     | not null default nextval(&apos;users_id_seq&apos;::regclass)</span><br><span class="line"> email                                        | character varying           | not null default &apos;&apos;::character varying</span><br><span class="line"> encrypted_password                           | character varying           | not null default &apos;&apos;::character varying</span><br><span class="line"> reset_password_token                         | character varying           | </span><br><span class="line"> reset_password_sent_at                       | timestamp without time zone | </span><br><span class="line"> remember_created_at                          | timestamp without time zone | </span><br><span class="line"> sign_in_count                                | integer                     | default 0</span><br><span class="line"> current_sign_in_at                           | timestamp without time zone | </span><br><span class="line"> last_sign_in_at                              | timestamp without time zone | </span><br><span class="line"> current_sign_in_ip                           | character varying           | </span><br><span class="line"> last_sign_in_ip                              | character varying           | </span><br><span class="line"> created_at                                   | timestamp without time zone | </span><br><span class="line"> updated_at                                   | timestamp without time zone | </span><br><span class="line">.....</span><br><span class="line"></span><br><span class="line">看下 users 表，这里面存储的就是所有的用户信息，接下来，我们可以查看验证一下新增用户信息:</span><br><span class="line"># users 表查看用户信息</span><br><span class="line">gitlabhq_production=# SELECT id,email,name,username FROM users WHERE username=&apos;cibot&apos;;</span><br><span class="line"> id | email | name | username </span><br><span class="line">----+-------+------+----------</span><br><span class="line">(0 rows)</span><br></pre></td></tr></table></figure></p>
<p>发现cibot用户信息为空,说明数据库中还未存储用户信息.在/var/log/gitlab/gitlab-rails/application.log日志里看到错误信息<br>September 19, 2019 11:02: (LDAP) Error saving user uid=cibot,ou=user,dc=company,dc=com,dc=cn (<a href="mailto:cibot@company.com.cn" target="_blank" rel="noopener">cibot@company.com.cn</a>): [“Email has already been taken”]</p>
<p>仔细查看新增用户信息,发现使用的邮箱地址是同一地址,gitlab认为已经使用,无法登录.<br>通过工具修改email地址,登录成功</p>
]]></content>
    
    <summary type="html">
    
      &lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据分析小白入门之从Tushare获取财经数据</title>
    <link href="https://t1ger.github.io/2019/07/31/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B0%8F%E7%99%BD%E5%85%A5%E9%97%A8%E4%B9%8B%E4%BB%8ETushare%E8%8E%B7%E5%8F%96%E8%B4%A2%E7%BB%8F%E6%95%B0%E6%8D%AE/"/>
    <id>https://t1ger.github.io/2019/07/31/数据分析小白入门之从Tushare获取财经数据/</id>
    <published>2019-07-31T02:52:13.000Z</published>
    <updated>2019-07-31T03:58:31.108Z</updated>
    
    <content type="html"><![CDATA[<h5 id="tushare简介"><a href="#tushare简介" class="headerlink" title="tushare简介"></a><b>tushare简介</b></h5><p>下面是官网对其的介绍,详细参考<a href="http://tushare.org/" target="_blank" rel="noopener">http://tushare.org/</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Tushare是一个免费、开源的python财经数据接口包。</span><br><span class="line">主要实现对股票等金融数据从数据采集、清洗加工 到 数据存储的过程，能够为金融分析人员提供快速、整洁、</span><br><span class="line">和多样的便于分析的数据，为他们在数据获取方面极大地减轻工作量，</span><br><span class="line">使他们更加专注于策略和模型的研究与实现上。</span><br><span class="line">考虑到Python pandas包在金融量化分析中体现出的优势，Tushare返回的绝大部分的数据格式都是</span><br><span class="line">pandas DataFrame类型，非常便于用pandas/NumPy/Matplotlib进行数据分析和可视化。</span><br><span class="line">当然，如果您习惯了用Excel或者关系型数据库做分析，您也可以通过Tushare的数据存储功能，</span><br><span class="line">将数据全部保存到本地后进行分析。</span><br><span class="line">应一些用户的请求，从0.2.5版本开始，Tushare同时兼容Python 2.x和Python 3.x，</span><br><span class="line">对部分代码进行了重构，并优化了一些算法，确保数据获取的高效和稳定。</span><br></pre></td></tr></table></figure></p>
<h5 id="tushare安装"><a href="#tushare安装" class="headerlink" title="tushare安装"></a><b>tushare安装</b></h5><p>不论是linux 还是window系统，在命令行里直接执行相关的pip命令即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pip install tushare</span><br><span class="line">pip install matplotlib </span><br><span class="line">pip install openpyxl</span><br><span class="line"></span><br><span class="line">pip install jupyter</span><br></pre></td></tr></table></figure></p>
<p>一切静待执行完毕<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure></p>
<p>在浏览器打开的页面中选择“new” 创建一个新的python2文件，执行下面这行语句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line"></span><br><span class="line">print(ts.__version__)</span><br></pre></td></tr></table></figure></p>
<p>正常输出的话就可以使用了</p>
<h5 id="tushare简单使用"><a href="#tushare简单使用" class="headerlink" title="tushare简单使用"></a><b>tushare简单使用</b></h5><p>最新版本需要token来进行验证，而这个只要注册一个账户即可，下面就是注册链接<br><a href="https://tushare.pro/register?reg=289223" target="_blank" rel="noopener">https://tushare.pro/register?reg=289223</a><br>根据提示，根据我们日常的经验，轻松就可以注册完成</p>
<p>我们可以在我们刚才注册过网站的右上角点击个人主页,在接口TOKEN中我们就可以复制到token<br>获取到token之后，就是设置token了，直接上代码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line"></span><br><span class="line">#方式一</span><br><span class="line">ts.set_token(&apos;复制的token填在这里&apos;)</span><br><span class="line">#这种方式设置会保存token到本地,所以只需设置一次,失效之后,可以替换为新的token</span><br><span class="line"></span><br><span class="line">#方式二</span><br><span class="line">pro = ts.pro_api()</span><br><span class="line">pro = ts.pro_api(&apos;复制的token填在这里&apos;)</span><br><span class="line">这种在初始化接口的时候设置token</span><br></pre></td></tr></table></figure></p>
<p>设置过token之后，就是使用tushare获取数据</p>
<h5 id="基础功能"><a href="#基础功能" class="headerlink" title="基础功能"></a><b>基础功能</b></h5><ul>
<li><p>get_hist_data<br>获取股票历史数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line">ts.get_hist_data(&apos;601006&apos;)</span><br><span class="line"></span><br><span class="line">date		open	high	close	low	volume	price_change	p_change	ma5	ma10	ma20	v_ma5	v_ma10	v_ma20</span><br><span class="line">													</span><br><span class="line">2019-07-30	7.90	7.95	7.92	7.89	185306.34	0.03	0.38	7.882	7.847	7.906	206837.68	205383.95	253866.89</span><br><span class="line">2019-07-29	7.84	7.90	7.89	7.84	174947.23	0.04	0.51	7.862	7.839	7.924	207086.78	211223.57	264796.92</span><br><span class="line">2019-07-26	7.86	7.88	7.85	7.83	183398.98	-0.02	-0.25	7.840	7.838	7.939	218223.60	216809.15	275667.15</span><br><span class="line">2019-07-25	7.89	7.90	7.87	7.83	195916.06	-0.01	-0.13	7.828	7.838	7.951	218596.59	220304.86	285239.61</span><br><span class="line">2019-07-24	7.82	7.91	7.88	7.81	294619.81	0.06	0.77	7.812	7.838	7.965	227321.78	222894.04	308046.28</span><br><span class="line">2019-07-23	7.76	7.83	7.82	7.75	186551.83	0.04	0.51	7.812	7.837	8.009	203930.21	215005.02	323511.71</span><br><span class="line">2019-07-22	7.80	7.82	7.78	7.72	230631.33	-0.01	-0.13	7.816	7.849	8.056	215360.36	224992.43	333106.69</span><br><span class="line">2019-07-19	7.79	7.85	7.79	7.78	185263.91	0.00	0.00	7.836	7.870	8.107	215394.70	254050.48	341493.82</span><br><span class="line">2019-07-18	7.85	7.86	7.79	7.77	239542.00	-0.09	-1.14	7.848	7.902	8.156	222013.13	268792.96	354813.18</span><br><span class="line">2019-07-17	7.84	7.88	7.88	7.81	177661.97	0.04	0.51	7.864	7.933	8.204	218466.30	284275.44	370840.09</span><br><span class="line">2019-07-16	7.88	7.88	7.84	7.82	243702.58	-0.04	-0.51	7.862	7.965	8.241	226079.84	302349.83	395746.08</span><br><span class="line">2019-07-15	7.85	7.89	7.88	7.77	230803.05	0.03	0.38	7.882	8.008	8.272	234624.51	318370.28	394510.21</span><br><span class="line">2019-07-12	7.89	7.90	7.85	7.83	218356.06	-0.02	-0.25	7.904	8.040	8.298	292706.26	334525.14	403332.35</span><br><span class="line">2019-07-11	7.91	7.92	7.87	7.87	221807.84	0.00	0.00	7.956	8.064	8.329	315572.78	350174.36	422860.53</span><br><span class="line">2019-07-10	7.95	7.96	7.87	7.86	215729.67	-0.07	-0.88	8.002	8.092	8.356	350084.58	393198.52	427026.92</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_realtime_quotes<br>获取股票实时行情</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line">ts.get_realtime_quotes(&apos;601006&apos;)</span><br><span class="line"></span><br><span class="line">	name	open	pre_close	price	high	low	    bid	    ask	    volume	 amount	    ...	   a2_p	  a3_v	  a3_p	  a4_v	  a4_p	   a5_v	   a5_p	    date	   time	        code</span><br><span class="line">0	大秦铁路	7.910	7.920		7.920	7.940	7.900	7.920	7.930	8712132	69009119.000 ...	7.940	6582	7.950	4530	7.960	1752 7.970 2019-07-31	   11:16:02	       601006</span><br></pre></td></tr></table></figure>
</li>
<li><p>get_deposit_rate<br>除了股票，TuShare 还提供了多种数据，比如宏观经济数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line">ts.get_deposit_rate()</span><br><span class="line"></span><br><span class="line">	date	deposit_type	rate</span><br><span class="line">0	2015-10-24	定活两便(定期)	--</span><br><span class="line">1	2015-10-24	定期存款整存整取(半年)	1.30</span><br><span class="line">2	2015-10-24	定期存款整存整取(二年)	2.10</span><br><span class="line">3	2015-10-24	定期存款整存整取(三个月)	1.10</span><br><span class="line">4	2015-10-24	定期存款整存整取(三年)	2.75</span><br><span class="line">5	2015-10-24	定期存款整存整取(五年)	--</span><br><span class="line">6	2015-10-24	定期存款整存整取(一年)	1.50</span><br><span class="line">7	2015-10-24	活期存款(不定期)	0.35</span><br></pre></td></tr></table></figure>
</li>
<li><p>realtime_boxoffice<br>电影票房</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line">ts.realtime_boxoffice()</span><br><span class="line"></span><br><span class="line">	BoxOffice	Irank	MovieName	boxPer	default_url	larger_url	moblie_url	movieDay	sumBoxOffice	time</span><br><span class="line">0		4143.16	1	哪吒之魔童降世	81.56	http://images.entgroup.cn/group2/M00/02/8A/wKg...	http://images.entgroup.cn/group1/M00/05/13/wKg...	http://images.entgroup.cn/group2/M00/02/8A/wKg...	6	112864.35	2019-07-31 11:24:57</span><br><span class="line">1		428.82	2	银河补习班	8.44	http://images.entgroup.cn/group1/M00/05/0E/wKg...	http://images.entgroup.cn/group2/M00/02/8A/wKg...	http://images.entgroup.cn/group1/M00/05/0E/wKg...	14	78734.09	2019-07-31 11:24:57</span><br><span class="line">2		173.57	3	狮子王	3.42	http://images.entgroup.cn/group1/M00/05/0C/wKg...	http://images.entgroup.cn/group2/M00/02/8A/wKg...	http://images.entgroup.cn/group1/M00/05/0C/wKg...	20	80458.95	2019-07-31 11:24:57</span><br><span class="line">3		83.24	4	扫毒2：天地对决	1.64	http://images.entgroup.cn/group2/M00/00/59/wKg...	http://images.entgroup.cn/group1/M00/05/10/wKg...	http://images.entgroup.cn/group2/M00/00/9B/wKg...	27	128413.41	2019-07-31 11:24:57</span><br><span class="line">4		55.68	5	跳舞吧！大象	1.10	http://images.entgroup.cn/group2/M00/02/8A/wKg...		http://images.entgroup.cn/group1/M00/05/13/wKg...	6	3723.65	2019-07-31 11:24:57</span><br><span class="line">5		34.51	6	回到过去拥抱你	0.68	http://images.entgroup.cn/group1/M00/05/10/wKg...		http://images.entgroup.cn/group1/M00/05/10/wKg...	6	1703.80	2019-07-31 11:24:57</span><br><span class="line">6		28.01	7	烈火英雄	0.55	http://images.entgroup.cn/group1/M00/00/CA/wKg...		http://images.entgroup.cn/group1/M00/01/46/wKg...	0	5422.26	2019-07-31 11:24:57</span><br><span class="line">7		22.08	8	蜘蛛侠：英雄远征	0.43	http://images.entgroup.cn/group1/M00/05/0D/wKg...	http://images.entgroup.cn/group1/M00/05/0D/wKg...	http://images.entgroup.cn/group1/M00/05/0D/wKg...	34	140925.20	2019-07-31 11:24:57</span><br><span class="line">8		17.48	9	爱宠大机密2	0.34	http://images.entgroup.cn/group2/M00/00/4D/wKg...	http://images.entgroup.cn/group1/M00/05/10/wKg...	http://images.entgroup.cn/group1/M00/01/0A/wKg...	27	15257.41	2019-07-31 11:24:57</span><br><span class="line">9		15.14	10	猪八戒·传说	0.30	http://images.entgroup.cn/group1/M00/05/08/wKg...		http://images.entgroup.cn/group1/M00/05/08/wKg...	13	5802.09	2019-07-31 11:24:57</span><br><span class="line">10		78.23	11	其它	1.00				0	0.00	2019-07-31 11:24:57</span><br></pre></td></tr></table></figure>
</li>
<li><p>演示<br>下面的代码来演示下 TuShare 的使用。这里我将获取今年上证指数的日K信息，然后保存成 excel 文件，再画出每日的收盘指数的折线图</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import tushare as ts</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">df=ts.get_hist_data(&apos;sh&apos;, start=&apos;2019-01-01&apos;)</span><br><span class="line">df.to_excel(&apos;stock_sh.xlsx&apos;)</span><br><span class="line">df.close.plot()</span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.invert_xaxis()</span><br><span class="line">plt.figure()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="data:image/png;base64,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" alt="image"></p>
<ul>
<li>后续的思考<br>通过接口我们看到的是冷冰冰数据，所以，接下来数据的可视化才是重头戏，将这些数据之间的联系结合起来更是具有挑战的事情，对所涉及到的金融概念及他们的意义需要领会，可以根据这些数据实现一些自己的想法。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;tushare简介&quot;&gt;&lt;a href=&quot;#tushare简介&quot; class=&quot;headerlink&quot; title=&quot;tushare简介&quot;&gt;&lt;/a&gt;&lt;b&gt;tushare简介&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;下面是官网对其的介绍,详细参考&lt;a href=&quot;http://tush
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>如何进行jvm故障排查定位</title>
    <link href="https://t1ger.github.io/2019/07/25/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8Cjvm%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%9A%E4%BD%8D/"/>
    <id>https://t1ger.github.io/2019/07/25/如何进行jvm故障排查定位/</id>
    <published>2019-07-25T05:01:33.000Z</published>
    <updated>2019-07-25T06:56:20.423Z</updated>
    
    <content type="html"><![CDATA[<h3 id="故障类型分析"><a href="#故障类型分析" class="headerlink" title="故障类型分析"></a><b>故障类型分析</b></h3><p>线上的jvm故障基本可以分为两大类:</p>
<ul>
<li>CPU占用过高</li>
<li>内存问题,通常可以理解为gc的问题,因为java的内存有gc进行管理.</li>
</ul>
<h3 id="故障排查兵器谱"><a href="#故障排查兵器谱" class="headerlink" title="故障排查兵器谱"></a><b>故障排查兵器谱</b></h3><p>命令行工具<br>jps等工具都是对tools.jar类的包装,使用起来方便简单.在下边的故障排查中会用到我们这里提到的工具,大家平时应该熟记于心.</p>
<ul>
<li>top</li>
<li><p>jps: JVM Process Status Tool，显示指定系统内所有的HotSpot虚拟机进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jps </span><br><span class="line">jps -l pid #输出主类的全名，如果进程执行的是jar包，输出jar包路径</span><br><span class="line">jps -v pid #输出虚拟机进程启动时JVM参数</span><br></pre></td></tr></table></figure>
</li>
<li><p>jstat: JVM Statistics Monitoring Tool，用于收集HotSpot虚拟机各方面的运行数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#我想监控gc，每250ms查询一次，一共查询20次，进程号为123</span><br><span class="line">jstat -gc 123 250 20</span><br></pre></td></tr></table></figure>
</li>
<li><p>jinfo: Configuration Info for Java，显示虚拟机配置信息</p>
</li>
<li><p>jmap: Memory Map for Java，生成虚拟机的内存转储快照(heap dump文件),jmap dump文件的时候会触发 FGC ，使用的时候注意场景)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jmap pid</span><br><span class="line">jmap -histo:live pid &gt; a.log  #当前Java进程创建的活跃对象数目和占用内存大小</span><br><span class="line">jmap -dump:live, format=b,file=xxx.xxx pid #当前Java进程的内存占用情况导出来</span><br></pre></td></tr></table></figure>
</li>
<li><p>jstack: Stack Trace for Java，显示虚拟机的线程快照</p>
</li>
</ul>
<p>图形工具</p>
<ul>
<li>jconsole: JVM各状态查看工具</li>
<li>visualVM</li>
</ul>
<h3 id="CPU问题"><a href="#CPU问题" class="headerlink" title="CPU问题"></a>CPU问题</h3><p>CPU负载比较高的时候,我们需要先找到那个java进程,然后根据找到的那个”问题线程”,根据线程的堆栈信息找到代码,最后进行代码排查</p>
<ul>
<li>top命令定位到cpu消耗最高的进程,并记住进程pid</li>
<li>通过 top -Hp pid 找到问题线程,记住线程 tid</li>
<li>通过jstack -l tid &gt;jstack.log 将线程堆栈信息dump到指定文件中</li>
<li>线程tid 是十进制的,堆栈中的线程id是16进制,使用 printf “%x\n” tid 转化</li>
<li>通过转化的16进制数字从堆栈信息中找到对应的线程堆栈.</li>
<li>如果有gc线程,可以推断内存泄露导致频发的gc,可以通过 jstat -gcutil pid 1s查看<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# jstat -gcutil 27534 1s    </span><br><span class="line">  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   </span><br><span class="line"> 0.00   0.00  100.00  99.34  91.25  82.89  52648  463.968   1439   3701.045  3473.868</span><br><span class="line">  0.00  0.00   89.65  99.34  91.25  82.89  52649  463.975   1440   3711.702  3476.880</span><br><span class="line">  0.00  0.00  100.00  99.34  91.25  82.89  52649  463.975   1440   3711.702  3476.880</span><br><span class="line">  0.00  0.00  100.00   99.34  91.25  82.89  52649  463.975  1443   3714.241  3479.891</span><br><span class="line">  0.00  0.00  100.00  99.34  91.25  82.89  52649  463.975   1443   3714.241 3479.891</span><br><span class="line">  0.00  0.00  100.00  99.34  91.25  82.89  52649  463.975   1443   3714.241  3479.891</span><br><span class="line">  0.00  0.00  100.00  99.34  91.25  82.89  52649  463.975   1444   3719.604  3483.889</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>可以看到每隔几秒就会full gc，而且Eden和Old都是99%，就是说每次full gc都没有回收到多少内存，所以一直在反复的跑</p>
<p>jinfo用来查看运行中的虚拟机的参数,甚至在运行时动态修改一些JVM参数,选项-XX:+PrintFlagsFinal可以列出所有的JVM flag,而其中的标注为manageable的flag则是可通过JDK management interface(-XX:+PrintFlagsFinal)动态修改<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# java -XX:+PrintFlagsFinal -version | grep manageable</span><br><span class="line">     intx CMSAbortablePrecleanWaitMillis            = 100                                 &#123;manageable&#125;</span><br><span class="line">     intx CMSTriggerInterval                        = -1                                  &#123;manageable&#125;</span><br><span class="line">     intx CMSWaitDuration                           = 2000                                &#123;manageable&#125;</span><br><span class="line">     bool HeapDumpAfterFullGC                       = false                               &#123;manageable&#125;</span><br><span class="line">     bool HeapDumpBeforeFullGC                      = false                               &#123;manageable&#125;</span><br><span class="line">     bool HeapDumpOnOutOfMemoryError                = false                               &#123;manageable&#125;</span><br><span class="line">    ccstr HeapDumpPath                              =                                     &#123;manageable&#125;</span><br><span class="line">    uintx MaxHeapFreeRatio                          = 100                                 &#123;manageable&#125;</span><br><span class="line">    uintx MinHeapFreeRatio                          = 0                                   &#123;manageable&#125;</span><br><span class="line">     bool PrintClassHistogram                       = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintClassHistogramAfterFullGC            = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintClassHistogramBeforeFullGC           = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintConcurrentLocks                      = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintGC                                   = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintGCDateStamps                         = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintGCDetails                            = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintGCID                                 = false                               &#123;manageable&#125;</span><br><span class="line">     bool PrintGCTimeStamps                         = false                               &#123;manageable&#125;</span><br><span class="line">java version &quot;1.8.0_112&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_112-b15)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.112-b15, mixed mode)</span><br></pre></td></tr></table></figure></p>
<p>用jinfo打开以下选项，把full gc前后的虚拟机内存dump下来<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">jinfo -flag +PrintGC pid</span><br><span class="line">jinfo -flag +PrintGCDetails pid</span><br><span class="line">jinfo -flag HeapDumpPath=/home/rain/heapdump pid</span><br><span class="line">jinfo -flag +HeapDumpBeforeFullGC pid</span><br><span class="line">jinfo -flag +HeapDumpAfterFullGC pid</span><br></pre></td></tr></table></figure></p>
<p>PrintGC和PrintGCDetails把gc日志输出到了nohup.out，查看nohup文件，可以看到full gc前后各dump了一次虚拟机内存，然后赶紧用jinfo关掉gc选项，选项前+号表示打开，-号表示关闭.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">jinfo -flag -HeapDumpBeforeFullGC pid</span><br><span class="line">jinfo -flag -HeapDumpAfterFullGC pid</span><br></pre></td></tr></table></figure></p>
<p>在HeapDumpPath下找到dump下来的hprof文件,下载下来用Jprofile，jvisualvm 等工具都可以分析</p>
<h3 id="内存问题"><a href="#内存问题" class="headerlink" title="内存问题"></a>内存问题</h3><p>这里简单的说下,在java虚拟机中,内存分为: 新生代(Eden), 老年代(Old),永久代.<br>新生代存放朝生夕死的对象<br>老年代存放从新生代迁移过来的周期较久的对象.<br>永久代是非堆内存的组成部分.主要存放加载类的class类级对象,比如说class本身,method,field等等</p>
<p>在进行内存问题处理的时候,我们经常会碰到以下两种异常:<br>java.lang.OutOfMemoryError: PermGen space<br>如果出现这个异常,一般都是程序启动需要加载大量的第三方jar包,需要调整perm的内存设置<br>java.lang.OutOfMemoryError: Java heap space<br>如果出现这个异常,一般是由于虚拟机设置堆内存过小或者代码创建了大量的大对象,并且长时间不能被回收.</p>
<p>通常gc管理内存,一种是内存溢出,一种是内存没有溢出,gc处于亚健康情况<br>内存溢出的情况可以通过加上 -XX:+HeapDumpOnOutOfMemoryError 参数，该参数作用是：在程序内存溢出时输出 dump 文件</p>
<p>内存不溢出的情况比较复杂,一般gc会将内存分为一块较大的Eden空间和两块较小的Survivor空间,每次使用Eden和其中的一块Survivor.当回收时,将Eden和Survivor中还存活着的对象一次性拷贝到另外一块Survivor空间上,最后清理掉Eden和刚才用过的Survivor的空间.HotSpot虚拟机默认Eden和Survivor的大小比例是8:1</p>
<p>YGC会经过两个过程,一个是扫描,一个是复制,扫描比较快,复制相对慢一些,如果每次都有大量的对象复制,STW(stop the world)时间会延长,另外一种情况是gc和系统的swap同时进行,也会延长STW时间<br>FGC触发原因有以下几个方面:<br>1.Old区内存不足<br>2.元数据区内存不足<br>3.cms promotion failed<br>4.concurrent mode failure.<br>5.jvm基于悲观策略认为ygc后old区无法放下晋升对象<br>6.jmap触发或者系统触发System.gc()</p>
<p>一般gc健康的情况下,YGC 5秒一次左右，每次不超过50毫秒，FGC 最好没有，CMS GC 一天一次左右<br>gc超过5秒,说明系统内存过大,如果YGC频率过高,说明Eden区过小,可以增加Eden去</p>
<p>内存问题的排查思路和cpu类似,在进行cpu分析的时候也顺带说了下内存:</p>
<ul>
<li>通过top命令定位内存消耗最高的进程,并记住进程pid</li>
<li>jmap -histo:live pid查看当前进程创建的活跃对象的数目和占用内存的大小,从而定位代码</li>
</ul>
<p>对于一般的问题，通过这几个方面的思考，大致可以锁定问题所在，或是缩小问题可能发生的范围。例如对某些特定类型的内存泄漏来说，到这一步已经可以分析出是什么类型导致内存泄漏</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;故障类型分析&quot;&gt;&lt;a href=&quot;#故障类型分析&quot; class=&quot;headerlink&quot; title=&quot;故障类型分析&quot;&gt;&lt;/a&gt;&lt;b&gt;故障类型分析&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;线上的jvm故障基本可以分为两大类:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU占用过高&lt;/li&gt;
&lt;l
    
    </summary>
    
    
  </entry>
  
</feed>
