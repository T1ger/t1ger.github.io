<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>t1ger的茶馆</title>
  <subtitle>头顶有光终是幻，足下生云未是仙</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://t1ger.github.io/"/>
  <updated>2018-01-25T04:06:31.446Z</updated>
  <id>https://t1ger.github.io/</id>
  
  <author>
    <name>t1ger</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>高可用的MongoDB集群</title>
    <link href="https://t1ger.github.io/2018/01/23/%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84MongoDB%E9%9B%86%E7%BE%A4/"/>
    <id>https://t1ger.github.io/2018/01/23/高可用的MongoDB集群/</id>
    <published>2018-01-23T01:53:10.000Z</published>
    <updated>2018-01-25T04:06:31.446Z</updated>
    
    <content type="html"><![CDATA[<h5 id="前言"><a href="#前言" class="headerlink" title="前言"></a><b>前言</b></h5><p>MongoDB是一个介于关系数据库和非关系数据库之间的产品，适合存储对象及JSON形式的数据。支持丰富的查询方式，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。</p>
<p>mongo适用的场景：</p>
<ul>
<li>网站数据:Mongo 非常适合实时的插入,更新与查询,并具备网站实时数据存储所需的复制及高度伸缩性</li>
<li>缓存:由于性能很高,Mongo 也适合作为信息基础设施的缓存层</li>
<li>高伸缩性的场景:Mongo非常适合由数十或数百台服务器组成的数据库</li>
<li>用于对象及JSON数据的存储:Mongo的BSON数据格式非常适合文档格式化的存储及查询</li>
</ul>
<p>MongDB不适合的场景:</p>
<ul>
<li>高度事务性的系统:例如银行或会计系统。</li>
<li>传统的商业智能应用:针对特定问题的 BI 数据库会对产生高度优化的查询方式。对于此类应用,数据仓库可能时更适合的选择(如Hadoop套件中的Hive)</li>
</ul>
<h5 id="MongDB-概念"><a href="#MongDB-概念" class="headerlink" title="MongDB 概念"></a><b>MongDB 概念</b></h5><p>首先了解几个概念：路由，分片、副本集、配置服务器等<br>mongodb支持数据的分布式存储，将collection作数据分片，减少每个节点的数据负载。<br>每个节点可以位于不同的物理机器上，一个简单的sharding集群如下图所示（引用自mongodb官网）<br><img src="https://docs.mongodb.com/manual/_images/sharded-cluster-production-architecture.bakedsvg.svg" alt="mongdb"><br>从图中可以看到有四个组件：mongos、config server、shard、replica set。</p>
<p>mongos，数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的mongodb请求都没有办法操作。</p>
<p>config server，顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从 config server 加载配置信息，以后如果配置服务器信息变化会通知到所有的 mongos 更新自己的状态，这样 mongos 就能继续准确路由。在生产环境通常有多个 config server 配置服务器，因为它存储了分片路由的元数据，防止数据丢失！</p>
<p>shard，分片（sharding）是指将数据库拆分，将其分散在不同的机器上的过程。将数据分散到不同的机器上，不需要功能强大的服务器就可以存储更多的数据和处理更大的负载。基本思想就是将集合切成小块，这些块分散到若干片里，每个片只负责总数据的一部分，最后通过一个均衡器来对各个分片进行均衡（数据迁移）。</p>
<p>replica set，中文翻译副本集，其实就是shard的备份，防止shard挂掉之后数据丢失。复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。</p>
<p>仲裁者（Arbiter），是复制集中的一个MongoDB实例，它并不保存数据。仲裁节点使用最小的资源并且不要求硬件设备，不能将Arbiter部署在同一个数据集节点中，可以部署在其他应用服务器或者监视服务器中，也可部署在单独的虚拟机中。为了确保复制集中有奇数的投票成员（包括primary），需要添加仲裁节点做为投票，否则primary不能运行时不会自动切换primary。</p>
<p>简单了解之后，我们可以这样总结一下，应用请求mongos来操作mongodb的增删改查，配置服务器存储数据库元信息，并且和mongos做同步，数据最终存入在shard（分片）上，为了防止数据丢失同步在副本集中存储了一份，仲裁在数据存储到分片的时候决定存储到哪个节点。</p>
<h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a><b>环境准备</b></h5><p>九台测试服务器，操作系统centos6.8， MongoDB 3.6</p>
<p>服务器角色分配<br>192.168.1.100 config server<br>192.168.1.101 config server<br>192.168.1.102 config server</p>
<p>192.168.1.103 shard server1<br>192.168.1.104 shard server1 副节点<br>192.168.1.105 shard server1 仲裁</p>
<p>192.168.1.107 shard server2<br>192.168.1.108 shard server2 副节点<br>192.168.1.109 shard server2 仲裁</p>
<p>192.168.1.110 mongos</p>
<h5 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a><b>集群搭建</b></h5><ul>
<li><p>Install MongoDB on All Nodes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">cat &gt; /etc/yum.repos.d/mongodb-org-3.6.repo &lt;&lt; &apos;EOF&apos;</div><div class="line">[mongodb-org-3.6]</div><div class="line">name=MongoDB Repository</div><div class="line">baseurl=https://repo.mongodb.org/yum/redhat/$releasever/mongodb-org/3.6/x86_64/</div><div class="line">gpgcheck=1</div><div class="line">enabled=1</div><div class="line">gpgkey=https://www.mongodb.org/static/pgp/server-3.6.asc</div><div class="line">EOF</div><div class="line"></div><div class="line">Package Name		Description</div><div class="line">mongodb-org		A metapackage that will automatically install the four component packages listed below.</div><div class="line">mongodb-org-server	Contains the mongod daemon and associated configuration and init scripts.</div><div class="line">mongodb-org-mongos	Contains the mongos daemon.</div><div class="line">mongodb-org-shell	Contains the mongo shell.</div><div class="line">mongodb-org-tools	Contains the following MongoDB tools: mongoimport bsondump, mongodump, mongoexport, mongofiles, mongoperf, mongorestore, mongostat, and mongotop.</div><div class="line"></div><div class="line"></div><div class="line">yum -y install mongodb-org</div></pre></td></tr></table></figure>
</li>
<li><p>Configure Firewalld</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">#for centos6，add under to file  /etc/sysconfig/iptables</div><div class="line">cat /etc/sysconfig/iptables</div><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT </div><div class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 27017 -j ACCEPT </div><div class="line">service iptables restart</div><div class="line">#for centos7</div><div class="line">yum -y install firewalld</div><div class="line">systemctl start firewalld</div><div class="line">systemctl enable firewalld</div><div class="line"></div><div class="line">firewall-cmd --permanent --add-port=22/tcp</div><div class="line">firewall-cmd --permanent --add-port=27017/tcp</div><div class="line">firewall-cmd --reload</div></pre></td></tr></table></figure>
</li>
<li><p>Configure MongoDB config server </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">net:</div><div class="line">  port: 27017</div><div class="line">  bindIP: 127.0.0.1,192.168.1.101  </div><div class="line">  #declare this is a config db of a cluster;  </div><div class="line">sharding:</div><div class="line">   clusterRole: configsvr</div><div class="line">replication:</div><div class="line">   replSetName: configs  </div><div class="line"></div><div class="line">#登录任意一台配置服务器，初始化配置副本集</div><div class="line"></div><div class="line">#连接</div><div class="line">mongo --port 27017</div><div class="line">#config变量</div><div class="line">config = &#123;</div><div class="line">		_id : &quot;configs&quot;,</div><div class="line">		members : [</div><div class="line">		&#123;_id : 0, host : &quot;192.168.1.100:27017&quot; &#125;,</div><div class="line">		&#123;_id : 0, host : &quot;192.168.1.101:27017&quot; &#125;,</div><div class="line">		&#123;_id : 1, host : &quot;192.168.1.102:27017&quot; &#125;</div><div class="line">		]</div><div class="line">	&#125;</div><div class="line"></div><div class="line">#初始化副本集</div><div class="line">rs.initiate(config)</div></pre></td></tr></table></figure>
<p>  其中，”_id” : “configs”应与配置文件中配置的 replicaction.replSetName 一致，”members” 中的 “host” 为三个节点的 ip 和 port</p>
</li>
<li><p>Configure MongoDB Replica Set </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">vim /etc/mongod.conf</div><div class="line"></div><div class="line">net:</div><div class="line">  port: 27017</div><div class="line">  bindIP: 127.0.0.1,192.168.1.103</div><div class="line">  </div><div class="line">replication:</div><div class="line">  replSetName: &quot;shard1&quot;</div><div class="line">sharding:</div><div class="line">  clusterRole: shardsvr</div><div class="line">  </div><div class="line">mongo --port 27017</div><div class="line">#使用admin数据库</div><div class="line">use admin</div><div class="line">#定义副本集配置</div><div class="line">config = &#123;</div><div class="line"> 	 _id : &quot;shard1&quot;,</div><div class="line">	 members : [</div><div class="line">         &#123;_id : 0, host : &quot;192.168.1.103:27017&quot; &#125;,</div><div class="line">         &#123;_id : 1, host : &quot;192.168.1.104:27017&quot; &#125;,</div><div class="line">         &#123;_id : 2, host : &quot;192.168.1.105:27017&quot;, arbiterOnly: true &#125;</div><div class="line">     ]</div><div class="line">&#125;</div><div class="line">#初始化副本集配置</div><div class="line">rs.initiate(config);</div></pre></td></tr></table></figure>
<p>  第二个Replica Set也执行类似操作</p>
</li>
</ul>
<ul>
<li><p>Configure MongoDB mongos</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# cat mongos.conf </div><div class="line"># where to write logging data.</div><div class="line">systemLog:</div><div class="line">destination: file</div><div class="line">logAppend: true</div><div class="line">path: /var/log/mongodb/mongos.log</div><div class="line"></div><div class="line">#security:</div><div class="line">#keyFile: /opt/mongo/mongodb-keyfile</div><div class="line"></div><div class="line">port=27017</div><div class="line">bind_ip=127.0.0.1,172.16.56.233</div><div class="line">#监听的配置服务器,只能有1个或者3个 configs为配置服务器的副本集名字</div><div class="line">configdb=configs/192.1688.1.100:27017,192.1688.1.101:27017,192.168.1.102:27017</div><div class="line"></div><div class="line">mongos --config mongos.conf  --fork</div></pre></td></tr></table></figure>
</li>
<li><p>MongoDB Replica Set initiate</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">登陆任意一台mongos</div><div class="line"></div><div class="line">mongo --port 27017</div><div class="line">#使用admin数据库</div><div class="line">use  admin</div><div class="line">#串联路由服务器与分配副本集</div><div class="line">sh.addShard(&quot;shard1/192.168.1.103:27017,192.168.1.104:27017,192.168.1.105:27017&quot;)</div><div class="line">sh.addShard(&quot;shard2/192.168.1.106:27017,192.168.1.107:27017,192.168.1.108:27017&quot;)</div><div class="line">#查看集群状态</div><div class="line">sh.status()</div></pre></td></tr></table></figure>
</li>
<li><p>Test the Replication</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">use admin</div><div class="line">#指定testdb分片生效</div><div class="line">sh.enableSharding( &quot;testdb&quot; )</div><div class="line"></div><div class="line">#Before sharding a non-empty collection, create an index on the shard key.</div><div class="line">use testdb</div><div class="line">db.table1.createIndex( &#123; id : 1 &#125; )</div><div class="line"></div><div class="line">#指定数据库里需要分片的集合和片键</div><div class="line">use testdb</div><div class="line">sh.shardCollection( &quot;testdb.table1&quot;, &#123; id : 1 &#125; )</div><div class="line"></div><div class="line">#Confirm the shard is balancing</div><div class="line">use testdb</div><div class="line">db.stats()</div><div class="line">db.printShardingStatus()</div></pre></td></tr></table></figure>
<p>  我们设置testdb的 table1 表需要分片，根据 id 自动分片到 shard1 ，shard2 上面去。要这样设置是因为不是所有mongodb 的数据库和表 都需要分片！<br>测试分片配置结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">mongo  127.0.0.1:27017</div><div class="line">#使用testdb</div><div class="line">use  testdb;</div><div class="line">#插入测试数据</div><div class="line">for (var i = 1; i &lt;= 600000; i++)db.table1.save(&#123;id:i,&quot;test1&quot;:&quot;testval1&quot;&#125;);</div><div class="line">#查看分片情况如下，部分无关信息省掉了</div><div class="line">mongos&gt; db.printShardingStatus()</div><div class="line">--- Sharding Status --- </div><div class="line">  sharding version: &#123;</div><div class="line">        &quot;_id&quot; : 1,</div><div class="line">        &quot;minCompatibleVersion&quot; : 5,</div><div class="line">        &quot;currentVersion&quot; : 6,</div><div class="line">        &quot;clusterId&quot; : ObjectId(&quot;5a674706887e9c5d977acacc&quot;)</div><div class="line">  &#125;</div><div class="line">  shards:</div><div class="line">        &#123;  &quot;_id&quot; : &quot;shard1&quot;,  &quot;host&quot; : &quot;shard1/192.168.1.103:27017,192.168.1.104:27017&quot;,  &quot;state&quot; : 1 &#125;</div><div class="line">        &#123;  &quot;_id&quot; : &quot;shard2&quot;,  &quot;host&quot; : &quot;shard2/192.168.1.106:27017,192.168.1.107:27017&quot;,  &quot;state&quot; : 1 &#125;</div><div class="line">  active mongoses:</div><div class="line">        &quot;3.6.2&quot; : 1</div><div class="line">  autosplit:</div><div class="line">        Currently enabled: yes</div><div class="line">  balancer:</div><div class="line">        Currently enabled:  yes</div><div class="line">        Currently running:  no</div><div class="line">        Failed balancer rounds in last 5 attempts:  0</div><div class="line">        Migration Results for the last 24 hours: </div><div class="line">                No recent migrations</div><div class="line">  databases:</div><div class="line">        &#123;  &quot;_id&quot; : &quot;config&quot;,  &quot;primary&quot; : &quot;config&quot;,  &quot;partitioned&quot; : true &#125;</div><div class="line">                config.system.sessions</div><div class="line">                        shard key: &#123; &quot;_id&quot; : 1 &#125;</div><div class="line">                        unique: false</div><div class="line">                        balancing: true</div><div class="line">                        chunks:</div><div class="line">                                shard1  1</div><div class="line">                        &#123; &quot;_id&quot; : &#123; &quot;$minKey&quot; : 1 &#125; &#125; --&gt;&gt; &#123; &quot;_id&quot; : &#123; &quot;$maxKey&quot; : 1 &#125; &#125; on : shard1 Timestamp(1, 0) </div><div class="line"></div><div class="line">        &#123;  &quot;_id&quot; : &quot;testdb&quot;,  &quot;primary&quot; : &quot;shard1&quot;,  &quot;partitioned&quot; : true &#125;</div><div class="line">                testdb.table1</div><div class="line">                        shard key: &#123; &quot;id&quot; : 1 &#125;</div><div class="line">                        unique: false</div><div class="line">                        balancing: true</div><div class="line">                        chunks:</div><div class="line">                                shard1  1</div><div class="line">                        &#123; &quot;id&quot; : &#123; &quot;$minKey&quot; : 1 &#125; &#125; --&gt;&gt; &#123; &quot;id&quot; : &#123; &quot;$maxKey&quot; : 1 &#125; &#125; on : shard1 Timestamp(1, 0)</div></pre></td></tr></table></figure>
<p>  可以看到目前只有一个chunk在shard1整个shard上</p>
</li>
</ul>
<h5 id="遇到的错误"><a href="#遇到的错误" class="headerlink" title="遇到的错误"></a><b>遇到的错误</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"> rs.initiate(config);</div><div class="line">&#123;</div><div class="line">        &quot;ok&quot; : 0,</div><div class="line">        &quot;errmsg&quot; : &quot;Attempting to initiate a replica set with name shard2, but command line reports shard1; rejecting&quot;,</div><div class="line">        &quot;code&quot; : 93,</div><div class="line">        &quot;codeName&quot; : &quot;InvalidReplicaSetConfig&quot;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>解决方案： 由于配置replSetName错误引起</p>
<h5 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a><b>常用命令</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">#List Databases with Sharding Enabled</div><div class="line">use config</div><div class="line">db.databases.find( &#123; &quot;partitioned&quot;: true &#125; )</div><div class="line"></div><div class="line">#List Shards</div><div class="line">db.adminCommand( &#123; listShards: 1 &#125; )</div><div class="line">#remove shard</div><div class="line">db.adminCommand( &#123; removeShard: &quot;testdb&quot; &#125; )</div><div class="line"></div><div class="line">#View Cluster Details</div><div class="line">db.printShardingStatus() or sh.status()</div><div class="line"></div><div class="line">#drop database</div><div class="line">use newdb</div><div class="line">switched to db newdb</div><div class="line">db.dropDatabase()</div></pre></td></tr></table></figure>
<p>ref<br><a href="http://blog.sina.com.cn/s/blog_8ea8e9d50102wl8x.html" target="_blank" rel="external">mongoDB-3.x Sharding with Replica</a><br><a href="https://docs.mongodb.com/manual/tutorial/convert-replica-set-to-replicated-shard-cluster/" target="_blank" rel="external">From Replica Set to Sharding</a><br><a href="http://www.cnblogs.com/xybaby/p/6832296.html" target="_blank" rel="external">通过一步步创建sharded cluster来认识mongodb</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;&lt;b&gt;前言&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;MongoDB是一个介于关系数据库和非关系数据库之间的产品，适合存储对象及JSON形式的数据。支持丰富的查询方式，几乎可以实现
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>浅谈Redis Cluster</title>
    <link href="https://t1ger.github.io/2018/01/19/%E6%B5%85%E8%B0%88Redis-Cluster/"/>
    <id>https://t1ger.github.io/2018/01/19/浅谈Redis-Cluster/</id>
    <published>2018-01-19T07:10:04.000Z</published>
    <updated>2018-01-19T09:20:11.288Z</updated>
    
    <content type="html"><![CDATA[<h5 id="redis-集群方案概述"><a href="#redis-集群方案概述" class="headerlink" title="redis 集群方案概述"></a><b>redis 集群方案概述</b></h5><p>自从redis3.0起，redis官方就推出了redis cluster,是一个可以在多个 Redis 节点之间进行数据共享的设施.Redis 集群不支持那些需要同时处理多个键的 Redis 命令， 因为执行这些命令需要在多个 Redis 节点之间移动数据， 并且在高负载的情况下， 这些命令将降低 Redis 集群的性能， 并导致不可预测的行为</p>
<p>当然，也有一些开源的解决方案来提供redis的高可用性，主要有</p>
<ul>
<li><p>Twitter的Redis/Memcached代理服务Twemproxy<br>Twemproxy是一个轻量级的Redis代理服务器，它通过引入一个代理层，将应用程序后端的多台Redis实例进行统一管理，使应用程序只需要在Twemproxy上进行操作，而不用关心后面具体有多少个真实的Redis或Memcached实例，从而实现了基于Redis和Memcached的集群服务。当某个节点宕掉时，Twemproxy可以自动将它从集群中剔除，而当它恢复服务时，Twemproxy也会自动连接。由于是代理，所以Twemproxy会有微小的性能损失。根据 Redis作者的测试结果，在大多数情况下，Twemproxy的性能相当不错，同直接操作Redis相比，最多只有20%的性能损失</p>
</li>
<li><p>豌豆荚的 Redis 集群解决方案Codis<br>它由 codis-server、codis-proxy、codis Dashboard、codis Admin、Codis FE、Storage组成,<br>基于proxy的codis，客户端对路由表变化无感知。客户端需要从codis dashhoard调用list proxy命令获取所有proxy列表，并根据自身的轮询策略决定访问哪个proxy节点以实现负载均衡，codis release 版本为 codis-3.2，codis-server 基于 redis-3.2.8,同时实现 select 命令,支持多db, 详细介绍参考<a href="https://github.com/CodisLabs/codis/blob/release3.2/doc/tutorial_zh.md" target="_blank" rel="external">这里</a></p>
</li>
<li><p>redis_sentinel<br>Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换</p>
</li>
<li><p>redis+keepalive<br>通过keepalived实现redis的高可用。keepalived利用shell脚本，定期检测redis服务是否正常。当redis服务异常时，利用虚拟IP的漂移实现故障切换</p>
</li>
</ul>
<p>如果你使用的是云平台，会提供类似的产品，有兴趣的请参考<a href="https://yq.aliyun.com/articles/68593" target="_blank" rel="external">这里</a></p>
<h5 id="redis-集群方案对比"><a href="#redis-集群方案对比" class="headerlink" title="redis 集群方案对比"></a><b>redis 集群方案对比</b></h5><p>redis_sentinel 和 redis+keepalive  两个方案都是基于redis主从实现，都不是基于分布式的解决方案，前者可以一主多从，后者基本是一主一从。<br>如果redis写入压力比较大，在碰到网络问题导致闪断切换，redis_sentinel切换需要1-2s的时间，则客户端有可能因此约10w记录无法写入，需要客户端在编码中有异常处理机制，在返回失败是尝试延时重写. keepalive则切换较快，但由于只有一主一从，在读写压力比较大时依然无法满足性能要求，并且在master出现故障，需要人工干预才能重新形成新的主从关系。</p>
<p>codis和twemproxy都是比较稳定的生产集群解决方案，随着官方redis4.x的推出，官方的redis cluster集群也是一个不错的选择方案</p>
<h5 id="redis-集群方案安装"><a href="#redis-集群方案安装" class="headerlink" title="redis 集群方案安装"></a><b>redis 集群方案安装</b></h5><p>这样主要讲解redis cluster集群的部署，基于redis4.0.6版本。</p>
<ul>
<li><p>redis_sentinel<br>redis_sentinel 的部署配置参考<a href="https://github.com/alisaifee/limits/tree/master/tests/redis-configurations/sentinel" target="_blank" rel="external">这里</a></p>
</li>
<li><p>redis cluster<br>集群部署官方推荐3主3从,这里用两台机器模拟 172.168.10.44 建立3个master，172.168.10.45建立3个slave</p>
</li>
</ul>
<ol>
<li><p>install</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/src</div><div class="line">wget http://download.redis.io/releases/redis-4.0.6.tar.gz</div><div class="line">tar zxf redis-4.0.6.tar.gz</div><div class="line">cd redis-4.0.6</div><div class="line">make</div></pre></td></tr></table></figure>
</li>
<li><p>config<br>redis cluster 的部署配置参考<a href="https://github.com/alisaifee/limits/tree/master/tests/redis-configurations/cluster" target="_blank" rel="external">这里</a></p>
</li>
<li><p>create cluster</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"># yum install ruby ruby-devel rubygems  -y</div><div class="line"># gem install redis</div><div class="line">#注意master和slave的顺序是一一对应的</div><div class="line"># redis-trib.rb create  --replicas  1 192.168.10.44:7000 192.168.10.44:7001  192.168.10.44:7002   192.168.10.45:7003  192.168.10.45:7004  192.168.10.45:7005</div><div class="line">yes</div><div class="line"></div><div class="line"># redis-cli -h 192.168.10.45 -c -p 7005</div><div class="line"></div><div class="line"># 查看集群节点情况</div><div class="line">192.168.10.45:7005&gt; cluster info</div></pre></td></tr></table></figure>
</li>
<li><p>新添加redis 主节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"># 查看集群节点槽占用情况</div><div class="line">192.168.10.45:7005&gt;  cluster nodes</div><div class="line"></div><div class="line"># 添加7006节点作为新节点</div><div class="line"># ./redis-trib.rb add-node 192.168.10.44:7006 192.168.10.44:7000</div><div class="line">add-node是加入指令，192.168.10.44:7006 表示新加入的节点，</div><div class="line">192.168.10.45:7000 表示加入的集群的一个节点，用来辨识是哪个集群，理论上哪个都可以</div><div class="line"></div><div class="line"># 给刚添加的7006结点分配槽</div><div class="line">./redis-trib.rb reshard 192.168.10.44:7006</div><div class="line">## 第二步：输入要分配的槽数量（输入：500，表示要分配500个槽）</div><div class="line">How many slots do you want to move (from 1 to 16384)? 500</div><div class="line"></div><div class="line">## 第三步：输入接收槽的结点id 7006的ID是：065c9c2223949e77f407d20aefa6408aa1bcd181</div><div class="line">What is the receiving node ID? 065c9c2223949e77f407d20aefa6408aa1bcd181</div><div class="line">## 第四步：输入源结点id（槽点会从源节点中拿，输入all从所有源节点中获取槽，输入done取消分配）</div><div class="line">Please enter all the source node IDs.</div><div class="line">  Type &apos;all&apos; to use all the nodes as source nodes for the hash slots.</div><div class="line">  Type &apos;done&apos; once you entered all the source nodes IDs.</div><div class="line">Source node #1:all</div><div class="line">## 输入yes开始移动槽到目标结点id</div><div class="line">Do you want to proceed with the proposed reshard plan (yes/no)? yes</div><div class="line"># 查看集群中槽占用情况</div><div class="line">192.168.10.44:7006&gt; cluster nodes</div></pre></td></tr></table></figure>
</li>
<li><p>添加从节点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">./redis-trib.rb add-node --slave 192.168.10.45:7007 192.168.10.45:7000</div><div class="line">add-node的时候加上--slave表示是加入到从节点中，但是这样加，是随机的。</div><div class="line">这里的命令行完全像我们在添加一个新主服务器时使用的一样，</div><div class="line">所以我们没有指定要给哪个主服 务器添加副本。</div><div class="line">这种情况下，redis-trib 会将7006作为一个具有较少副本的随机的主服务器的副本</div><div class="line"></div><div class="line">我如果想指定一个主节点行不行？当然可以。我们再建一个7008节点。</div><div class="line">./redis-trib.rb add-node –slave –master-id 主节点id 新节点的ip和端口 旧节点ip和端口</div><div class="line"></div><div class="line">./redis-trib.rb add-node --slave --master-id 065c9c2223949e77f407d20aefa6408aa1bcd181 192.168.10.45:7008 192.168.10.44:7000</div></pre></td></tr></table></figure>
</li>
</ol>
<h5 id="后记"><a href="#后记" class="headerlink" title="后记"></a><b>后记</b></h5><p>这里推荐个redis集群的运维工具 CacheCloud，有兴趣的可以参考<a href="https://github.com/sohutv/cachecloud" target="_blank" rel="external">这里</a><br>一般影响cluster failover失败有：<br>(1)从节点超时过长,查看cluster-node-timeout和cluster-slave-validity-factor相关参数<br>(2)从节点的无法获取到集群中其他主节点的投票<br>(3)参与领导者选举的主节点不够一半以上<br>(3)从节点数达不到cluster-migration-barrier数量。<br>另外，需要注意的是没有负责任何槽的主节点没有投票权</p>
<p>ref<br><a href="https://redis.io/topics/cluster-tutorial" target="_blank" rel="external">Redis cluster tutorial</a><br><a href="http://magic_duck.oschina.io/2017/09/07/redis4.4.0_primary_05/" target="_blank" rel="external">Redis集群</a><br><a href="https://www.zybuluo.com/phper/note/195558" target="_blank" rel="external">Redis集群研究和实践（基于redis 3.0.5）</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;redis-集群方案概述&quot;&gt;&lt;a href=&quot;#redis-集群方案概述&quot; class=&quot;headerlink&quot; title=&quot;redis 集群方案概述&quot;&gt;&lt;/a&gt;&lt;b&gt;redis 集群方案概述&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;自从redis3.0起，redis官方就推出了
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Why Datanode is Denied Communication With Namenode</title>
    <link href="https://t1ger.github.io/2017/12/20/Why-Datanode-is-Denied-Communication-With-Namenode/"/>
    <id>https://t1ger.github.io/2017/12/20/Why-Datanode-is-Denied-Communication-With-Namenode/</id>
    <published>2017-12-20T06:51:08.000Z</published>
    <updated>2017-12-20T07:54:06.282Z</updated>
    
    <content type="html"><![CDATA[<p>So for those trying to setup HDFS out there, and are struggling with this kind of error where it said datanode denied communication with namenode:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">2017-12-20 14:26:26,108 INFO org.apache.hadoop.ipc.Server: IPC Server handler 29 on 8020, call Call#9 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.registerDatanode from 172.16.56.238:27481</div><div class="line">org.apache.hadoop.hdfs.server.protocol.DisallowedDatanodeException: Datanode denied communication with namenode because hostname cannot be resolved (ip=172.16.56.238, hostname=172.16.56.238): DatanodeRegistration(0.0.0.0:50010, datanodeUuid=95e30839-4e7b-4918-98bb-f125b0c932c7, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-57;cid=CID-d26bb3c5-ffa5-466c-a3be-fe16d8b84e73;nsid=1832233914;c=1513750982825)</div><div class="line">        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:952)</div><div class="line">        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.registerDatanode(BlockManager.java:2014)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerDatanode(FSNamesystem.java:3656)</div><div class="line">        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.registerDatanode(NameNodeRpcServer.java:1418)</div><div class="line">        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.registerDatanode(DatanodeProtocolServerSideTranslatorPB.java:101)</div><div class="line">        at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:30583)</div><div class="line">        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:503)</div><div class="line">        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:989)</div><div class="line">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:868)</div><div class="line">        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:814)</div><div class="line">        at java.security.AccessController.doPrivileged(Native Method)</div><div class="line">        at javax.security.auth.Subject.doAs(Subject.java:422)</div><div class="line">        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1886)</div><div class="line">        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2603)</div></pre></td></tr></table></figure></p>
<p>It could actually be because of many configurations problem, but in the end it boils to one thing and that’s what I am going to tell you. It costed me one day just to fix this problem when I was running test-kitchen to provision hadoop servers.</p>
<p>So we have a namenode up and running, now we boot up a datanode. We have the defaultFS correct, so the datanode knows where the namenode is. It tries to connect to namenode. The connection happens through IP, so namenode only see the datanode’s ip. The problem is, in this process. Namenode has a list of blacklisted hostnames, which should not connect to it. This list can be empty, but namenode will keep checking it anyway, so it will try to do a reverse dns lookup to see which hostname the ip has. If it fails, then namenode will throw the exception you saw, and this it the source of all problems.</p>
<p>So basically, we have a few options to fix this: </p>
<ol>
<li>Fix the reverse dns thing in namenode, so that it could do the reverse dns lookup properly. </li>
<li>Think that it doesn’t make sense to block anything in your case and turn off the checking.</li>
</ol>
<p>Well, if your cluster is in a private network (which usually is), what is the chance that the datanode which is trying to connect to your namenode is not your datanodes? Not big. So let’s just turn it off.</p>
<p>You will have to add this setting in namenode’s hdfs-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;</div><div class="line">  &lt;value&gt;false&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>It was really confusing for me at first, because it is not clear whether denied communication was a result of misconfiguration in datanode or namenode. There are some <a href="https://stackoverflow.com/questions/17252955/getting-the-following-error-datanode-denied-communication-with-namenode-while" target="_blank" rel="external">stackoverflow</a> entry about this, but they are single machine setup, and confused me even more because the solution is not working. I hope if you are experiencing same trouble, this post has helped you to understand a bit of the picture.</p>
<p>ref<br><a href="https://log.rowanto.com/why-datanode-is-denied-communication-with-namenode/" target="_blank" rel="external">Why Datanode is Denied Communication With Namenode</a><br><a href="https://stackoverflow.com/questions/17252955/getting-the-following-error-datanode-denied-communication-with-namenode-while" target="_blank" rel="external">Getting the following error “Datanode denied communication with namenode” while configuring hadoop 0.23.8</a><br><a href="https://ooon.me/2016/03/Hadoop-dns/" target="_blank" rel="external">Hadoop 使用 DNS 的问题</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;So for those trying to setup HDFS out there, and are struggling with this kind of error where it said datanode denied communication with 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>HDFS Short-Circuit Local Reads</title>
    <link href="https://t1ger.github.io/2017/12/15/HDFS-Short-Circuit-Local-Reads/"/>
    <id>https://t1ger.github.io/2017/12/15/HDFS-Short-Circuit-Local-Reads/</id>
    <published>2017-12-15T02:14:40.000Z</published>
    <updated>2017-12-25T14:37:46.017Z</updated>
    
    <content type="html"><![CDATA[<h5 id="Background"><a href="#Background" class="headerlink" title="Background"></a><b>Background</b></h5><p>In HDFS, reads normally go through the DataNode. Thus, when the client asks the DataNode to read a file, the DataNode reads that file off of the disk and sends the data to the client over a TCP socket. So-called “short-circuit” reads bypass the DataNode, allowing the client to read the file directly. Obviously, this is only possible in cases where the client is co-located with the data. Short-circuit reads provide a substantial performance boost to many applications</p>
<h5 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a><b>Setup</b></h5><p>To configure short-circuit local reads, you will need to enable libhadoop.so. See <a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/NativeLibraries.html" target="_blank" rel="external">Native Libraries</a> for details on enabling this library. if you don’t compile yourself, may be use complile binary version ,see <a href="http://dl.bintray.com/sequenceiq/sequenceiq-bin/" target="_blank" rel="external">here</a><br>Short-circuit reads make use of a UNIX domain socket. This is a special path in the filesystem that allows the client and the DataNodes to communicate. You will need to set a path to this socket. The DataNode needs to be able to create this path. On the other hand, it should not be possible for any user except the HDFS user or root to create this path. For this reason, paths under /var/run or /var/lib are often used.</p>
<p>The client and the DataNode exchange information via a shared memory segment on /dev/shm.</p>
<p>Short-circuit local reads need to be configured on both the DataNode and the client.</p>
<p>Java can not use Unix Domain Socket directly，so you need install Hadoop native package libhadoop.so。if you use Pivotal HD，CDH and so on, native package will be install at you install hadoop package. you can use command to check native package like this</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">$ hadoop checknative</div><div class="line">hadoop: true /usr/lib/hadoop/lib/native/libhadoop.so.1.0.0</div><div class="line">zlib:   true /lib64/libz.so.1</div><div class="line">snappy: true /usr/lib64/libsnappy.so.1</div><div class="line">lz4:    true revision:99</div><div class="line">bzip2:  true /lib64/libbz2.so.1</div><div class="line"></div><div class="line"></div><div class="line">#如果要排查问题,可以更改日志级别，进行相应排查</div><div class="line">export HADOOP_ROOT_LOGGER=DEBUG,console</div><div class="line">$ hadoop checknative -a</div></pre></td></tr></table></figure>
<p>#打开short-circuit local reads 功能</p>
<p>dfs.client.read.shortcircuit:  false </p>
<p>#可选。该参数是一个指向UNIX域套接字的路径，用于DataNode和本地HDFS客户端通信。如果在该路径中出现了字符串”_PORT”，会被替换成DataNode的TCP端口。</p>
<p>dfs.domain.socket.path: </p>
<p>#设置了该参数，short-circuit local reads功能将跳过checksums校验。通常不推荐这么做，但是该参数对于特殊场合可能有用。如果你在HDFS之外自己做checksum校验，那么就该考虑设置该参数。</p>
<p>dfs.client.read.shortcircuit.skip.checksum: false</p>
<p>#DFSClient维护着一个用于保存最近已打开的文件描述符的缓存。该参数控制着此缓存的容量。增大该缓存的容量就可以使用更多文件描述符，但是，在涉及大量seek操作的负载上可能带来更好的性能</p>
<p>dfs.client.read.shortcircuit.streams.cache.size: 256</p>
<p>#该参数控制着文件描述符因为长期不活跃而被关闭之前需要在客户端缓存上下文中驻留的最小时间</p>
<p>dfs.client.read.shortcircuit.streams.cache.expiry.ms: 300000</p>
<h5 id="Example-Configuration"><a href="#Example-Configuration" class="headerlink" title="Example Configuration"></a><b>Example Configuration</b></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.domain.socket.path&lt;/name&gt;</div><div class="line">    &lt;value&gt;/var/lib/hadoop-hdfs/dn_socket&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="Legacy-HDFS-Short-Circuit-Local-Reads"><a href="#Legacy-HDFS-Short-Circuit-Local-Reads" class="headerlink" title="Legacy HDFS Short-Circuit Local Reads"></a><b>Legacy HDFS Short-Circuit Local Reads</b></h5><p>Legacy implementation of short-circuit local reads on which the clients directly open the HDFS block files is still available for platforms other than the Linux. Setting the value of dfs.client.use.legacy.blockreader.local in addition to dfs.client.read.shortcircuit to true enables this feature.</p>
<p>You also need to set the value of dfs.datanode.data.dir.perm to 750 instead of the default 700 and chmod/chown the directory tree under dfs.datanode.data.dir as readable to the client and the DataNode. You must take caution because this means that the client can read all of the block files bypassing HDFS permission.</p>
<p>Because Legacy short-circuit local reads is insecure, access to this feature is limited to the users listed in the value of dfs.block.local-path-access.user.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">&lt;configuration&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.read.shortcircuit&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.client.use.legacy.blockreader.local&lt;/name&gt;</div><div class="line">    &lt;value&gt;true&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;</div><div class="line">    &lt;value&gt;750&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">  &lt;property&gt;</div><div class="line">    &lt;name&gt;dfs.block.local-path-access.user&lt;/name&gt;</div><div class="line">    &lt;value&gt;foo,bar&lt;/value&gt;</div><div class="line">  &lt;/property&gt;</div><div class="line">&lt;/configuration&gt;</div></pre></td></tr></table></figure>
<h5 id="碰到的问题-centos7-hadoop2-9"><a href="#碰到的问题-centos7-hadoop2-9" class="headerlink" title="碰到的问题(centos7 hadoop2.9)"></a><b>碰到的问题(centos7 hadoop2.9)</b></h5><p>1.openssl问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line">[root@namenode ~]# export HADOOP_OPTS=-Djava.library.path=/usr/local/hadoop-2.9.0/lib/native</div><div class="line">[root@namenode ~]# hadoop checknative -a</div><div class="line">17/12/25 15:46:06 DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...</div><div class="line">17/12/25 15:46:06 DEBUG util.NativeCodeLoader: Loaded the native-hadoop library</div><div class="line">17/12/25 15:46:07 DEBUG util.Shell: setsid exited with exit code 0</div><div class="line">17/12/25 15:46:07 INFO bzip2.Bzip2Factory: Successfully loaded &amp; initialized native-bzip2 library system-native</div><div class="line">17/12/25 15:46:07 INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</div><div class="line">17/12/25 15:46:07 DEBUG crypto.OpensslCipher: Failed to load OpenSSL Cipher.</div><div class="line">java.lang.UnsatisfiedLinkError: Cannot load libcrypto.so (libcrypto.so: cannot open shared object file: No such file or directory)!</div><div class="line">        at org.apache.hadoop.crypto.OpensslCipher.initIDs(Native Method)</div><div class="line">        at org.apache.hadoop.crypto.OpensslCipher.&lt;clinit&gt;(OpensslCipher.java:87)</div><div class="line">        at org.apache.hadoop.util.NativeLibraryChecker.main(NativeLibraryChecker.java:101)</div><div class="line">Native library checking:</div><div class="line">hadoop:  true /usr/local/hadoop-2.9.0/lib/native/libhadoop.so.1.0.0</div><div class="line">zlib:    true /lib64/libz.so.1</div><div class="line">snappy:  true /lib64/libsnappy.so.1</div><div class="line">zstd  :  false </div><div class="line">lz4:     true revision:10301</div><div class="line">bzip2:   true /lib64/libbz2.so.1</div><div class="line">openssl: false Cannot load libcrypto.so (libcrypto.so: cannot open shared object file: No such file or directory)!</div><div class="line">17/12/25 15:46:07 DEBUG util.ExitUtil: Exiting with status 1: ExitException</div><div class="line">1: ExitException</div><div class="line">        at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:304)</div><div class="line">        at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:292)</div><div class="line">        at org.apache.hadoop.util.NativeLibraryChecker.main(NativeLibraryChecker.java:145)</div><div class="line">17/12/25 15:46:07 INFO util.ExitUtil: Exiting with status 1: ExitException</div></pre></td></tr></table></figure></p>
<p>解决方法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -s /usr/lib64/libcrypto.so.1.0.1e /usr/lib64/libcrypto.so</div></pre></td></tr></table></figure></p>
<p>2.zstd问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">[root@namenode ~]# hadoop checknative -a</div><div class="line">17/12/25 17:24:43 DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...</div><div class="line">17/12/25 17:24:43 DEBUG util.NativeCodeLoader: Loaded the native-hadoop library</div><div class="line">17/12/25 17:24:43 DEBUG util.Shell: setsid exited with exit code 0</div><div class="line">17/12/25 17:24:43 INFO bzip2.Bzip2Factory: Successfully loaded &amp; initialized native-bzip2 library system-native</div><div class="line">17/12/25 17:24:43 INFO zlib.ZlibFactory: Successfully loaded &amp; initialized native-zlib library</div><div class="line">Native library checking:</div><div class="line">hadoop:  true /usr/local/hadoop-2.9.0/lib/native/libhadoop.so.1.0.0</div><div class="line">zlib:    true /lib64/libz.so.1</div><div class="line">snappy:  true /lib64/libsnappy.so.1</div><div class="line">zstd  :  false </div><div class="line">lz4:     true revision:10301</div><div class="line">bzip2:   true /lib64/libbz2.so.1</div><div class="line">openssl: true /lib64/libcrypto.so</div><div class="line">17/12/25 17:24:43 DEBUG util.ExitUtil: Exiting with status 1: ExitException</div><div class="line">1: ExitException</div><div class="line">        at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:304)</div><div class="line">        at org.apache.hadoop.util.ExitUtil.terminate(ExitUtil.java:292)</div><div class="line">        at org.apache.hadoop.util.NativeLibraryChecker.main(NativeLibraryChecker.java:145)</div><div class="line">17/12/25 17:24:43 INFO util.ExitUtil: Exiting with status 1: ExitException</div></pre></td></tr></table></figure></p>
<p>解决方法：无,做了以下尝试，无结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">yum install epel-release -y</div><div class="line">yum install libzstd -y</div></pre></td></tr></table></figure></p>
<p>后查看源代码，在源码包中查看BUILDING.txt文件，发现编译环境没有libzstd，猜测可能编译时没有安装，但代码里有检测，所以有提示<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div></pre></td><td class="code"><pre><div class="line">public class NativeCodeLoader &#123;</div><div class="line"></div><div class="line">  private static final Logger LOG =</div><div class="line">      LoggerFactory.getLogger(NativeCodeLoader.class);</div><div class="line">  </div><div class="line">  private static boolean nativeCodeLoaded = false;</div><div class="line">  </div><div class="line">  static &#123;</div><div class="line">    // Try to load native hadoop library and set fallback flag appropriately</div><div class="line">    if(LOG.isDebugEnabled()) &#123;</div><div class="line">      LOG.debug(&quot;Trying to load the custom-built native-hadoop library...&quot;);</div><div class="line">    &#125;</div><div class="line">    try &#123;</div><div class="line">      System.loadLibrary(&quot;hadoop&quot;);</div><div class="line">      LOG.debug(&quot;Loaded the native-hadoop library&quot;);</div><div class="line">      nativeCodeLoaded = true;</div><div class="line">    &#125; catch (Throwable t) &#123;</div><div class="line">      // Ignore failure to load</div><div class="line">      if(LOG.isDebugEnabled()) &#123;</div><div class="line">        LOG.debug(&quot;Failed to load native-hadoop with error: &quot; + t);</div><div class="line">        LOG.debug(&quot;java.library.path=&quot; +</div><div class="line">            System.getProperty(&quot;java.library.path&quot;));</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    if (!nativeCodeLoaded) &#123;</div><div class="line">      LOG.warn(&quot;Unable to load native-hadoop library for your platform... &quot; +</div><div class="line">               &quot;using builtin-java classes where applicable&quot;);</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  /**</div><div class="line">   * Check if native-hadoop code is loaded for this platform.</div><div class="line">   * </div><div class="line">   * @return &lt;code&gt;true&lt;/code&gt; if native-hadoop is loaded, </div><div class="line">   *         else &lt;code&gt;false&lt;/code&gt;</div><div class="line">   */</div><div class="line">  public static boolean isNativeCodeLoaded() &#123;</div><div class="line">    return nativeCodeLoaded;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  /**</div><div class="line">   * Returns true only if this build was compiled with support for snappy.</div><div class="line">   */</div><div class="line">  public static native boolean buildSupportsSnappy();</div><div class="line">  </div><div class="line">  /**</div><div class="line">   * Returns true only if this build was compiled with support for ZStandard.</div><div class="line">   */</div><div class="line">  public static native boolean buildSupportsZstd();</div><div class="line"></div><div class="line">  /**</div><div class="line">   * Returns true only if this build was compiled with support for openssl.</div><div class="line">   */</div><div class="line">  public static native boolean buildSupportsOpenssl();</div><div class="line"></div><div class="line">  public static native String getLibraryName();</div><div class="line"></div><div class="line">  /**</div><div class="line">   * Return if native hadoop libraries, if present, can be used for this job.</div><div class="line">   * @param conf configuration</div><div class="line">   * </div><div class="line">   * @return &lt;code&gt;true&lt;/code&gt; if native hadoop libraries, if present, can be </div><div class="line">   *         used for this job; &lt;code&gt;false&lt;/code&gt; otherwise.</div><div class="line">   */</div><div class="line">  public boolean getLoadNativeLibraries(Configuration conf) &#123;</div><div class="line">    return conf.getBoolean(CommonConfigurationKeys.IO_NATIVE_LIB_AVAILABLE_KEY, </div><div class="line">                           CommonConfigurationKeys.IO_NATIVE_LIB_AVAILABLE_DEFAULT);</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  /**</div><div class="line">   * Set if native hadoop libraries, if present, can be used for this job.</div><div class="line">   * </div><div class="line">   * @param conf configuration</div><div class="line">   * @param loadNativeLibraries can native hadoop libraries be loaded</div><div class="line">   */</div><div class="line">  public void setLoadNativeLibraries(Configuration conf, </div><div class="line">                                     boolean loadNativeLibraries) &#123;</div><div class="line">    conf.setBoolean(CommonConfigurationKeys.IO_NATIVE_LIB_AVAILABLE_KEY,</div><div class="line">                    loadNativeLibraries);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>ref<br><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html" target="_blank" rel="external">Short-Circuit Local Reads</a><br><a href="https://www.zybuluo.com/jewes/note/37713" target="_blank" rel="external">详解HDFS Short Circuit Local Reads</a><br><a href="http://blog.csdn.net/jack85986370/article/details/51902871" target="_blank" rel="external">Unable to load native-hadoop library for your platform</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;Background&quot;&gt;&lt;a href=&quot;#Background&quot; class=&quot;headerlink&quot; title=&quot;Background&quot;&gt;&lt;/a&gt;&lt;b&gt;Background&lt;/b&gt;&lt;/h5&gt;&lt;p&gt;In HDFS, reads normally go thro
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>how to migrate Gitlab to a new server</title>
    <link href="https://t1ger.github.io/2017/12/13/how-to-migrate-Gitlab-to-a-new-server/"/>
    <id>https://t1ger.github.io/2017/12/13/how-to-migrate-Gitlab-to-a-new-server/</id>
    <published>2017-12-13T07:05:49.000Z</published>
    <updated>2017-12-13T08:35:53.640Z</updated>
    
    <content type="html"><![CDATA[<p>gitlab安装有三种方法: docker、yum 、源码,本文环境是yum安装方式<br>1.确认旧gitlab版本信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sudo gitlab-rake gitlab:env:info</div></pre></td></tr></table></figure></p>
<p>注意: 新服务版本要求保持一致,否则无法导入,如果版本比较旧,需要升级旧版本服务器或新服务版本降级后在升级<br>旧服务器升级也比较简单<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">#stop some service</div><div class="line">sudo gitlab-ctl stop unicorn</div><div class="line">sudo gitlab-ctl stop sidekiq</div><div class="line">sudo gitlab-ctl stop nginx</div><div class="line">#update</div><div class="line">sudo yum update gitlab-ce</div><div class="line">sudo gitlab-ctl reconfigure</div><div class="line">sudo gitlab-ctl restart</div></pre></td></tr></table></figure></p>
<p>2.备份配置文件和数据<br>将 /etc/gitlab/gitlab.rb 和 gitlab-secrets.json 拷贝到新服务对应目录<br>注意,我旧环境是用了自带的nginx,新环境用了机器上已经存在的nginx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">#disable nginx service</div><div class="line">vi /etc/gitlab/gitlab.rb...#设置nginx为false,关闭自带Nginxnginx[‘enable‘] = false...</div><div class="line"></div><div class="line">#check nginx config,migrate to new nginx</div><div class="line">/var/opt/gitlab/nginx/conf/nginx.conf  </div><div class="line">/var/opt/gitlab/nginx/conf/gitlab-http.conf</div><div class="line">/var/opt/gitlab/nginx/conf/nginx-status.conf</div><div class="line"></div><div class="line">#restart service</div><div class="line">sudo gitlab-ctl reconfigure</div><div class="line">sudo service nginx restart</div></pre></td></tr></table></figure>
<p>备份旧机器git数据,同时拷贝到新服务上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">#backup gitlab to  /var/opt/gitlab/backups</div><div class="line">gitlab-rake gitlab:backup:create</div></pre></td></tr></table></figure></p>
<p>在新机器上恢复数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">gitlab-rake gitlab:backup:restore RAILS_ENV=production   BACKUP=1513135372_2017_12_13</div></pre></td></tr></table></figure></p>
<p>如果新机器数据不全,可以把／var/opt/gitlab/git-data拷贝过去</p>
<p>3.迁移遇到的问题</p>
<ul>
<li><p>在新机器执行gitlab-ctl reconfigure,查看进程ps -ef|grep nginx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">root 11485 0.0 0.0 1836 608 ? Ss Mar18 0:02 runsvdir -P /opt/gitlab/service log: </div><div class="line">…..runsv nginx: warning: unable to open supervise/stat.new: </div><div class="line">file does not exist runsv nginx: warning: unable to open supervise/stat.new:</div><div class="line">file does not exist runsv nginx: warning: unable to open supervise/pid.new: </div><div class="line">file does not exist runsv nginx: warning: unable to open log/supervise/pid.new:</div><div class="line">file does not exist runsv nginx: warning: unable to open log/supervise/pid.new:</div><div class="line">file does not exist</div></pre></td></tr></table></figure>
<p>  解决方法: 重启系统解决</p>
</li>
<li><p>查看nginx日志报错</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">2017/12/13 13:19:00 [crit] 2436#0: *2 connect() to unix:/var/opt/gitlab/gitlab-workhorse/socket failed (13: Permission denied) while connecting to upstream, client: 119.6.3.75, server: gitlab.weishao.com.cn, request: &quot;GET /index.html HTTP/1.1&quot;, upstream: &quot;http://unix:/var/opt/gitlab/gitlab-workhorse/socket:/index.html&quot;, host: &quot;59.110.114.10&quot;</div></pre></td></tr></table></figure>
<p>  解决方法: 由于旧服务nginx使用git启动nginx,新服务器用nobody用户运行nginx,我们通过修改 /etc/gitlab/gitlab.rb文件解决</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">##! When bundled nginx is disabled we need to add the external webserver user to</div><div class="line">##! the GitLab webserver group.</div><div class="line">web_server[&apos;external_users&apos;] = [&apos;nobody&apos;]</div><div class="line">web_server[&apos;username&apos;] = &apos;nobody&apos;</div><div class="line">web_server[&apos;group&apos;] = &apos;nobody&apos;</div><div class="line">web_server[&apos;uid&apos;] = 99</div><div class="line">web_server[&apos;gid&apos;] = 99</div><div class="line">web_server[&apos;shell&apos;] = &apos;/bin/false&apos;</div><div class="line">web_server[&apos;home&apos;] = &apos;/var/opt/gitlab/nginx&apos;</div><div class="line"></div><div class="line">sudo gitlab-ctl reconfigure</div></pre></td></tr></table></figure>
<p>  也可以将nginx运行账号添加到gitlab-www组中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo usermod -a -G gitlab-www nobody</div><div class="line">sudo service nginx restart</div></pre></td></tr></table></figure>
<p>  但是执行sudo gitlab-ctl reconfigure后需要重新执行</p>
</li>
</ul>
<p>ref<br><a href="http://blog.pzxbc.com/2016/03/22/gitlab-install-configure/" target="_blank" rel="external">Gitlab安装配置及使用</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;gitlab安装有三种方法: docker、yum 、源码,本文环境是yum安装方式&lt;br&gt;1.确认旧gitlab版本信息&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div 
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Deploy Elasticsearch</title>
    <link href="https://t1ger.github.io/2017/11/20/Deploy-Elasticsearch/"/>
    <id>https://t1ger.github.io/2017/11/20/Deploy-Elasticsearch/</id>
    <published>2017-11-20T08:31:50.000Z</published>
    <updated>2017-11-21T09:33:58.393Z</updated>
    
    <content type="html"><![CDATA[<h5 id="ElasticSearch-deploy-doc"><a href="#ElasticSearch-deploy-doc" class="headerlink" title="ElasticSearch deploy doc"></a><b>ElasticSearch deploy doc</b></h5><ul>
<li><p>env</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# cat /etc/issue</div><div class="line">CentOS release 6.8 (Final)</div><div class="line">Kernel \r on an \m</div><div class="line"></div><div class="line">[root@localhost ~]# java -version</div><div class="line">java version &quot;1.8.0_112&quot;</div><div class="line">Java(TM) SE Runtime Environment (build 1.8.0_112-b15)</div><div class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.112-b15, mixed mode)</div></pre></td></tr></table></figure>
</li>
<li><p>download es, create es user </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">curl -L -O  https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.0.0.tar.gz</div><div class="line"></div><div class="line">tar -xzf elasticsearch-6.0.0.tar.gz</div><div class="line">sudo useradd es</div><div class="line">mv elasticsearch-6.0.0 /usr/local/elasticsearch</div><div class="line">chown es.es /usr/local/elasticsearch -R</div><div class="line"></div><div class="line">#add es.conf to  /etc/security/limits.d/es.conf</div><div class="line">[root@localhost ~]# cat  /etc/security/limits.d/es.conf</div><div class="line">es soft memlock unlimited</div><div class="line">es hard memlock unlimited</div><div class="line">es soft nofile 204800</div><div class="line">es hard nofile 204800</div><div class="line">es soft nproc  4096</div><div class="line"></div><div class="line">#add option to /etc/sysctl.conf</div><div class="line">vm.max_map_count=655360</div><div class="line">sysctl -p</div></pre></td></tr></table></figure>
</li>
<li><p>conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# cat /usr/local/elasticsearch/config/elasticsearch.yml |grep -v ^#</div><div class="line">cluster.name: es-ws-v6</div><div class="line">node.name: node-1</div><div class="line">node.master: true</div><div class="line">node.data: true</div><div class="line">path.data: /usr/local/elasticsearch/data</div><div class="line">path.logs: /usr/local/elasticsearch/logs</div><div class="line">bootstrap.memory_lock: true</div><div class="line">bootstrap.system_call_filter: false</div><div class="line">network.host: 172.16.56.193</div><div class="line">network.publish_host: 172.16.56.193</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;172.16.56.194&quot;,&quot;172.16.56.195&quot;]</div><div class="line">discovery.zen.minimum_master_nodes: 2</div><div class="line"></div><div class="line"></div><div class="line">[root@localhost ~]# cat /usr/local/elasticsearch/config/elasticsearch.yml |grep -v ^#</div><div class="line">cluster.name: es-ws-v6</div><div class="line">node.name: node-2</div><div class="line">node.master: true</div><div class="line">node.data: true</div><div class="line">path.data: /usr/local/elasticsearch/data</div><div class="line">path.logs: /usr/local/elasticsearch/logs</div><div class="line">bootstrap.memory_lock: true</div><div class="line">bootstrap.system_call_filter: false</div><div class="line">network.host: 172.16.56.194</div><div class="line">network.publish_host: 172.16.56.194</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;172.16.56.193&quot;,&quot;172.16.56.195&quot;]</div><div class="line">discovery.zen.minimum_master_nodes: 2</div><div class="line"></div><div class="line"></div><div class="line">[root@localhost ~]# cat /usr/local/elasticsearch/config/elasticsearch.yml |grep -v ^#</div><div class="line">cluster.name: es-ws-v6</div><div class="line">node.name: node-3</div><div class="line">node.master: true</div><div class="line">node.data: true</div><div class="line"></div><div class="line">path.data: /usr/local/elasticsearch/data</div><div class="line">path.logs: /usr/local/elasticsearch/logs</div><div class="line">bootstrap.memory_lock: true</div><div class="line">bootstrap.system_call_filter: false</div><div class="line">network.host: 172.16.56.195</div><div class="line">network.publish_host: 172.16.56.195</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;172.16.56.193&quot;, &quot;172.16.56.194&quot;]</div><div class="line">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>
<p>  if you need to extend,only to keep cluster.name  with es-ws-v6 ,now we add new node  with config/elasticsearch</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# cat /usr/local/elasticsearch/config/elasticsearch.yml |grep -v ^#</div><div class="line">cluster.name: es-ws-v6</div><div class="line">node.name: node-4</div><div class="line">node.master: true</div><div class="line">node.data: true</div><div class="line"></div><div class="line">path.data: /usr/local/elasticsearch/data</div><div class="line">path.logs: /usr/local/elasticsearch/logs</div><div class="line">bootstrap.memory_lock: true</div><div class="line">bootstrap.system_call_filter: false</div><div class="line">network.host: 172.16.56.196</div><div class="line">network.publish_host: 172.16.56.196</div><div class="line">discovery.zen.ping.unicast.hosts: [&quot;172.16.56.195&quot;]</div><div class="line">discovery.zen.minimum_master_nodes: 2</div></pre></td></tr></table></figure>
</li>
<li><p>start es  and check cluster health,service script look <a href="https://stackoverflow.com/questions/37914831/how-to-start-elasticsearch-run-as-service-in-centos-7" target="_blank" rel="external">here</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">#start es</div><div class="line">su es</div><div class="line">cd /usr/local/elasticsearch</div><div class="line">bin/elasticsearch -d -p es.pid</div><div class="line"># check health</div><div class="line">curl http://172.16.56.193:9200/_cluster/health</div></pre></td></tr></table></figure>
</li>
<li><p>restart es cluster service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line">#Disable shard allocation.</div><div class="line">curl -XPUT &apos;172.16.56.193:9200/_cluster/settings?pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</div><div class="line">&#123;</div><div class="line">  &quot;persistent&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;none&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">&apos;</div><div class="line"></div><div class="line">#Stop indexing and perform a synced flush.</div><div class="line">curl -XPOST &apos;172.16.56.193:9200/_flush/synced?pretty&apos;</div><div class="line"></div><div class="line">#kill all node</div><div class="line">sudo -i service elasticsearch stop</div><div class="line">#If you are running Elasticsearch as a daemon:</div><div class="line">ps aux |grep elasticsearch |awk &apos;&#123;print $2&#125;&apos; |xargs kill</div><div class="line"></div><div class="line">#Start each upgraded node.</div><div class="line">#you can use _cat/health and _cat/nodes to monitor nodes joining the cluster:</div><div class="line">#If you have dedicated master nodes, start them first and wait for them to form a cluster </div><div class="line">#and elect a master before proceeding with your data nodes. You can check progress by looking at the logs.</div><div class="line"></div><div class="line">curl -XGET &apos;172.16.56.193:9200/_cat/nodes?pretty&apos;</div><div class="line">curl -XGET &apos;172.16.56.193:9200/_cat/health?pretty&apos;</div><div class="line"></div><div class="line"></div><div class="line">#Wait for all nodes to join the cluster and report a status of yellow.</div><div class="line"></div><div class="line">#Reenable allocation</div><div class="line">curl -XPUT &apos;172.16.56.193:9200/_cluster/settings?pretty&apos; -H &apos;Content-Type: application/json&apos; -d&apos;</div><div class="line">&#123;</div><div class="line">  &quot;transient&quot;: &#123;</div><div class="line">    &quot;cluster.routing.allocation.enable&quot;: &quot;all&quot;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">&apos;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>ref<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/restart-upgrade.html" target="_blank" rel="external">Elasticsearch Reference</a><br><a href="http://wdxtub.com/2016/09/28/elasticsearch-cluster-guide/" target="_blank" rel="external">Elasticsearch 集群指南</a><br><a href="http://www.wklken.me/posts/2016/06/29/deploy-es.html" target="_blank" rel="external">ELASTICSEARCH集群部署文档</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h5 id=&quot;ElasticSearch-deploy-doc&quot;&gt;&lt;a href=&quot;#ElasticSearch-deploy-doc&quot; class=&quot;headerlink&quot; title=&quot;ElasticSearch deploy doc&quot;&gt;&lt;/a&gt;&lt;b&gt;ElasticSear
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>glibc升级引起locale警告</title>
    <link href="https://t1ger.github.io/2017/11/06/glibc%E5%8D%87%E7%BA%A7%E5%BC%95%E8%B5%B7locale%E8%AD%A6%E5%91%8A/"/>
    <id>https://t1ger.github.io/2017/11/06/glibc升级引起locale警告/</id>
    <published>2017-11-06T04:04:24.000Z</published>
    <updated>2017-11-06T04:59:27.611Z</updated>
    
    <content type="html"><![CDATA[<p>在升级glibc后,发现每次登录都提示如下警告：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">-bash: warning: setlocale: LC_CTYPE: cannot change locale (en_US.UTF-8): No such file or directory</div><div class="line">-bash: warning: setlocale: LC_COLLATE: cannot change locale (en_US.UTF-8): No such file or directory</div><div class="line">-bash: warning: setlocale: LC_MESSAGES: cannot change locale (en_US.UTF-8): No such file or directory</div><div class="line">-bash: warning: setlocale: LC_NUMERIC: cannot change locale (en_US.UTF-8): No such file or directory</div><div class="line">-bash: warning: setlocale: LC_TIME: cannot change locale (en_US.UTF-8): No such file or directory</div></pre></td></tr></table></figure></p>
<p>让我们先回顾下升级glibc步骤<br>1、使用 strings /lib64/libc.so.6 |grep GLIBC查看目前系统的glibc版本<br>2、wget <a href="http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz" target="_blank" rel="external">http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.gz</a><br>3、glibc安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# tar xvf glibc-2.14.tar.gz</div><div class="line">[root@localhost ~]# cd glibc-2.14</div><div class="line">[root@localhost glibc-2.14]# mkdir build</div><div class="line">[root@localhost glibc-2.14]# cd ./build</div><div class="line">[root@localhost build]# ../configure --prefix=/usr/local/glibc-2.14</div><div class="line">[root@localhost build]# make</div><div class="line">[root@localhost build]# make install</div></pre></td></tr></table></figure></p>
<p>4、创建glibc2.14的软链<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -sf /usr/local/glibc-2.14/lib/libc-2.14.so /lib64/libc.so.6 ###特别说明，千万不要先删除之前的软链，直接加-f参数覆盖就行了，否则无法开机</div></pre></td></tr></table></figure></p>
<p>5、设置语言相关的locale-archive文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@localhost ~]# find / -name locale-archive   ###找出glibc2.12的语言相关的 locale-archive 文件</div><div class="line">/usr/lib/locale/locale-archive</div><div class="line">[root@localhost locale]# cp /usr/lib/locale/locale-archive /usr/local/glibc-2.14/lib/locale/   ###复制到编译好的glibc 2.14的lib/locale中，记得先创建locale目录</div><div class="line">[root@localhost locale]# /usr/local/glibc-2.14/bin/localedef -i en_US -f UTF-8 en_US.UTF-8  ##运行生成相应的locale配置文件</div></pre></td></tr></table></figure></p>
<p>在升级之后出现报警的原因是漏掉了步骤5</p>
<p>ref<br><a href="http://blog.csdn.net/qq_34605594/article/details/73610126" target="_blank" rel="external">升级glibc到glibc-2.14解决version `GLIBC_2.14’ not found 问题</a><br><a href="http://www.cnblogs.com/xiaohuo2011/p/7509034.html" target="_blank" rel="external">GLIBC2.12升级GLIBC2.14源码</a></p>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在升级glibc后,发现每次登录都提示如下警告：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>go标准库04 网络(net包)</title>
    <link href="https://t1ger.github.io/2017/09/28/go%E6%A0%87%E5%87%86%E5%BA%9304-%E7%BD%91%E7%BB%9C-net%E5%8C%85/"/>
    <id>https://t1ger.github.io/2017/09/28/go标准库04-网络-net包/</id>
    <published>2017-09-28T09:17:16.000Z</published>
    <updated>2017-09-28T08:26:05.123Z</updated>
    
    <content type="html"><![CDATA[<p>net包提供了可移植的网络I/O接口，包括TCP/IP、UDP、域名解析和Unix域socket。</p>
<p>我们大部分使用者只需要Dial、Listen和Accept函数提供的基本接口；以及相关的Conn和Listener接口。crypto/tls包提供了相同的接口和类似的Dial和Listen函数。</p>
<p>Dial函数和服务端建立连接：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">conn, err := net.Dial(&quot;tcp&quot;, &quot;google.com:80&quot;)</div><div class="line">if err != nil &#123;</div><div class="line">	// handle error</div><div class="line">&#125;</div><div class="line">fmt.Fprintf(conn, &quot;GET / HTTP/1.0\r\n\r\n&quot;)</div><div class="line">status, err := bufio.NewReader(conn).ReadString(&apos;\n&apos;)</div><div class="line">// ...</div></pre></td></tr></table></figure></p>
<p>Listen函数创建的服务端：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">ln, err := net.Listen(&quot;tcp&quot;, &quot;:8080&quot;)</div><div class="line">if err != nil &#123;</div><div class="line">	// handle error</div><div class="line">&#125;</div><div class="line">for &#123;</div><div class="line">	conn, err := ln.Accept()</div><div class="line">	if err != nil &#123;</div><div class="line">		// handle error</div><div class="line">		continue</div><div class="line">	&#125;</div><div class="line">	go handleConnection(conn)</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如果我们要实现一个http web服务,一般通过两种方法实现,一种是我们使用net包的net.Listen来对端口进行监听,另一个是使用net/http包,这里我们看下用net/http如何实现</p>
<ul>
<li><p>http客户端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">import (</div><div class="line">    &quot;fmt&quot;</div><div class="line">    &quot;net/http&quot;</div><div class="line">    &quot;io/ioutil&quot;</div><div class="line">)</div><div class="line"> </div><div class="line">func main() &#123;</div><div class="line">    response,_ := http.Get(&quot;http://www.baidu.com&quot;)</div><div class="line">    defer response.Body.Close()</div><div class="line">    body,_ := ioutil.ReadAll(response.Body)</div><div class="line">    fmt.Println(string(body))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>http服务端</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"> </div><div class="line">import (</div><div class="line">    &quot;net/http&quot;</div><div class="line">)</div><div class="line"> </div><div class="line">func SayHello(w http.ResponseWriter, req *http.Request) &#123;</div><div class="line">    w.Write([]byte(&quot;Hello&quot;))</div><div class="line">&#125;</div><div class="line"> </div><div class="line">func main() &#123;</div><div class="line">    http.HandleFunc(&quot;/hello&quot;, SayHello)</div><div class="line">    http.ListenAndServe(&quot;:8001&quot;, nil)</div><div class="line"> </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  进行端口的监听：http.ListenAndServe(“:8001”, nil)<br>注册路径处理函数：http.HandleFunc(“/hello”, SayHello)<br>处理函数：func SayHello(w http.ResponseWriter, req *http.Request)</p>
</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;net包提供了可移植的网络I/O接口，包括TCP/IP、UDP、域名解析和Unix域socket。&lt;/p&gt;
&lt;p&gt;我们大部分使用者只需要Dial、Listen和Accept函数提供的基本接口；以及相关的Conn和Listener接口。crypto/tls包提供了相同的接口和
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>go标准库03 路径与文件</title>
    <link href="https://t1ger.github.io/2017/09/28/go%E6%A0%87%E5%87%86%E5%BA%9303-%E8%B7%AF%E5%BE%84%E4%B8%8E%E6%96%87%E4%BB%B6/"/>
    <id>https://t1ger.github.io/2017/09/28/go标准库03-路径与文件/</id>
    <published>2017-09-28T04:22:53.000Z</published>
    <updated>2017-09-28T07:45:49.825Z</updated>
    
    <content type="html"><![CDATA[<ul>
<li><p>os包<br>提供系统相关函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">import (</div><div class="line"> &quot;fmt&quot;</div><div class="line"> &quot;os&quot;</div><div class="line">)</div><div class="line">func main() &#123;</div><div class="line"> dir, _ := os.Getwd()</div><div class="line"> fmt.Println(&quot;current dir:&quot;, dir)</div><div class="line"> fmt.Println(os.Geteuid())</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  此外,还有os.Getenv(),os.Chdir(),)os.Stat(),os.Chmod(),os.Chtime(),os.Environ(),os.Exit(),os.Expand(),os.ExpandEnv(),os.Hostname()等,详细介绍请查看<a href="https://golang.org/pkg/os/" target="_blank" rel="external">这里</a></p>
</li>
<li><p>io包<br>io包提供了大量的输入输出相关的函数,用来处理io.Reader和io.Writer.(*os.File类型的值能同时满足这两个接口的定义).另外,这个包还能用来创建内存中的同步管道.<br>io/ioutil包提供一些高级的辅助函数.<br>在io包中最重要的是两个接口：Reader和Writer接口</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">type Reader interface &#123;</div><div class="line">    Read(p []byte) (n int, err error)</div><div class="line">&#125;</div><div class="line"></div><div class="line">type Writer interface &#123;</div><div class="line">    Write(p []byte) (n int, err error)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  Read 将 len(p) 个字节读取到 p 中，当遇到任何错误（包括EOF）会立即返回已读取的字节数，函数结束会返回成功读取的字节数和任何错误。<br>Write 将 len(p) 字节数据从 p 写入底层的数据流，然后返回成功写入的字节数和任何错误。<br>从接口名称很容易猜到，一般地，Go中接口的命名约定：接口名以er结尾。<br>注意，这里并非强行要求，你完全可以不以 er 结尾。标准库中有些接口也不是以 er 结尾的</p>
</li>
<li><p>path包<br>path包用来操作unix风格的路径<br>path/filepath包提供了和path相同的函数,其目标是提供平台无关的路径处理,提供了filepath.Walk()函数来遍历读出一个给定路径下的所有文件和目录信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">        &quot;fmt&quot;</div><div class="line">        &quot;path/filepath&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line"></div><div class="line">        absName, err := filepath.Abs(&quot;/a/b/c.txt&quot;)</div><div class="line">        if err != nil &#123;</div><div class="line">                fmt.Println(err)</div><div class="line">        &#125;</div><div class="line">        fmt.Println(absName)</div><div class="line"></div><div class="line">        baseName := filepath.Base(&quot;/a/b/c/e.txt&quot;)</div><div class="line">        fmt.Println(baseName)</div><div class="line"></div><div class="line">        p := &quot;../..//././//a/b/c.txt&quot;</div><div class="line">        pc := filepath.Clean(p)</div><div class="line">        fmt.Println(pc)</div><div class="line"></div><div class="line">        d := filepath.Dir(&quot;/a/b/c/d.txt&quot;)</div><div class="line">        fmt.Println(d)</div><div class="line"></div><div class="line">        e, _ := filepath.EvalSymlinks(&quot;/home/tiger/abc&quot;)</div><div class="line">        fmt.Println(e)</div><div class="line"></div><div class="line">        f := filepath.Ext(&quot;/tmp/1.txt&quot;)</div><div class="line">        fmt.Println(f)</div><div class="line"></div><div class="line">        m, _ := filepath.Glob(&quot;/usr/*&quot;)</div><div class="line">        fmt.Println(m)</div><div class="line"></div><div class="line">        fmt.Println(&quot;On Unix:&quot;)</div><div class="line">        fmt.Println(filepath.Join(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;))</div><div class="line">        fmt.Println(filepath.Join(&quot;a&quot;, &quot;b/c&quot;))</div><div class="line">        fmt.Println(filepath.Join(&quot;a/b&quot;, &quot;c&quot;))</div><div class="line">        fmt.Println(filepath.Join(&quot;a/b&quot;, &quot;/c&quot;))</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  此外,还有 Split(), Walk()等</p>
</li>
</ul>
<ul>
<li>runtime包<br>runtime包含一些函数和类型,用来访问go语言的运行时系统<br>这里介绍几个跟平台有关的方法：NumCPU ,GOROOT ,GOOS ,GOMAXPROCS ,Gosched<br>func NumCPU() int<br>func GOROOT() string<br>func GOMAXPROCS(n int) int<br>func Gosched()<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;fmt&quot;</div><div class="line">    &quot;runtime&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    fmt.Println(&quot;cpus:&quot;, runtime.NumCPU())</div><div class="line">    fmt.Println(&quot;goroot:&quot;, runtime.GOROOT())</div><div class="line">    fmt.Println(&quot;os/platform:&quot;, runtime.GOOS)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;&lt;p&gt;os包&lt;br&gt;提供系统相关函数&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>go标准库02 时间与日期</title>
    <link href="https://t1ger.github.io/2017/09/28/go%E6%A0%87%E5%87%86%E5%BA%9302-%E6%97%B6%E9%97%B4%E4%B8%8E%E6%97%A5%E6%9C%9F/"/>
    <id>https://t1ger.github.io/2017/09/28/go标准库02-时间与日期/</id>
    <published>2017-09-28T02:56:14.000Z</published>
    <updated>2017-09-28T03:19:12.363Z</updated>
    
    <content type="html"><![CDATA[<p>Go具有良好的时间和日期管理功能。实际上，计算机只会维护一个挂钟时间(wall clock time)，这个时间是从某个固定时间起点到现在的时间间隔。时间起点的选择与计算机相关，但一台计算机的话，这一时间起点是固定的。其它的日期信息都是从这一时间计算得到的。</p>
<h5 id="time包"><a href="#time包" class="headerlink" title="time包"></a><b>time包</b></h5><ul>
<li><p>时间</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;fmt&quot;</div><div class="line">    &quot;time&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    //时间戳</div><div class="line">    t := time.Now().Unix()</div><div class="line">    fmt.Print(t)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>time.sleep()<br>可以将程序置于休眠状态，直到某时间间隔之后再唤醒程序，让程序继续运行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;fmt&quot;</div><div class="line">    &quot;time&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">        fmt.Println(&quot;start&quot;)</div><div class="line">        time.Sleep(time.Second * 10)  // sleep for 10 seconds</div><div class="line">        fmt.Println(&quot;wake up&quot;)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>  当我们需要定时地查看程序运行状态时，就可以利用该方法。</p>
</li>
<li><p>time.After(time.Duration)<br>和Sleep差不多，在取出管道内容前不阻塞</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;fmt&quot;</div><div class="line">    &quot;time&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    fmt.Println(&quot;this is one&quot;)</div><div class="line">    tc:=time.After(time.Second)</div><div class="line">    fmt.Println(&quot;this is two&quot;)</div><div class="line">    fmt.Println(&quot;this is three&quot;)</div><div class="line">    &lt;-tc //阻塞中，直到取出tc管道里的数据 </div><div class="line">    fmt.Println(&quot;this is four&quot;)</div><div class="line">&#125;</div><div class="line">//打印this is one后，获得了一个空管道，这个管道1秒后会有数据进来</div><div class="line">//打印this is two</div><div class="line">//打印this is three</div><div class="line">//等待，直到可以取出管道的数据（取出数据的时间与获得tc管道的时间正好差1秒钟）</div><div class="line">//打印this is four</div></pre></td></tr></table></figure>
</li>
<li><p>time.AfterFunc(time.Duration,func())<br>和After差不多，意思是多少时间之后在goroutine line执行函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;time&quot;</div><div class="line">    &quot;fmt&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    f := func() &#123;</div><div class="line">        fmt.Println(&quot;Time out&quot;)</div><div class="line">    &#125;</div><div class="line">    time.AfterFunc(1*time.Second,f)</div><div class="line">    time.Sleep(2 * time.Second) //要保证主线比子线“死的晚”，否则主线死了，子线也等于死了</div><div class="line">&#125;</div><div class="line">//将一个间隔和一个函数给AfterFunc后</div><div class="line">//间隔时间过后，执行传入的函数</div></pre></td></tr></table></figure>
</li>
<li><p>Before &amp; After方法<br>判断一个时间点是否在另一个时间点的前面（后面），返回true或false</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;time&quot;</div><div class="line">    &quot;fmt&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    t1 := time.Now()</div><div class="line">    time.Sleep(time.Second)</div><div class="line">    t2 := time.Now()</div><div class="line">    a := t2.After(t1)</div><div class="line">    fmt.Println(a) //true</div><div class="line">    b := t2.Before(t1)</div><div class="line">    fmt.Println(b) //false</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>sub方法<br>两个时间点相减，获得时间差(Duration)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;time&quot;</div><div class="line">    &quot;fmt&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    t1 := time.Now()</div><div class="line">    time.Sleep(time.Second)</div><div class="line">    t2 :=time.Now()</div><div class="line">    d := t2.Sub(t1) //时间2减去时间1</div><div class="line">    fmt.Println(d)  //打印结果差不多为1.000123几秒，因为Sleep无法做到精确的睡1秒</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
<li><p>Add方法<br>拿一个时间点，add一个时长，获得另一个时间点</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">package main</div><div class="line"></div><div class="line">import (</div><div class="line">    &quot;time&quot;</div><div class="line">    &quot;fmt&quot;</div><div class="line">)</div><div class="line"></div><div class="line">func main() &#123;</div><div class="line">    t1 := time.Now()</div><div class="line">    t2 := t1.Add(time.Hour)</div><div class="line">    fmt.Println(t2)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<hr>
<p>您的鼓励是我写作最大的动力</p>
<p>俗话说，投资效率是最好的投资。 如果您感觉我的文章质量不错，读后收获很大，预计能为您提高 10% 的工作效率，不妨小额捐助我一下，让我有动力继续写出更多好文章。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Go具有良好的时间和日期管理功能。实际上，计算机只会维护一个挂钟时间(wall clock time)，这个时间是从某个固定时间起点到现在的时间间隔。时间起点的选择与计算机相关，但一台计算机的话，这一时间起点是固定的。其它的日期信息都是从这一时间计算得到的。&lt;/p&gt;
&lt;h5
    
    </summary>
    
    
  </entry>
  
</feed>
